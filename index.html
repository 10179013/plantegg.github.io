<!doctype html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />





  <link rel="alternate" href="/atom.xml" title="plantegg" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="java mysql tcp performance network docker Linux">
<meta property="og:type" content="website">
<meta property="og:title" content="plantegg">
<meta property="og:url" content="https://plantegg.github.io/index.html">
<meta property="og:site_name" content="plantegg">
<meta property="og:description" content="java mysql tcp performance network docker Linux">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="plantegg">
<meta name="twitter:description" content="java mysql tcp performance network docker Linux">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://plantegg.github.io/"/>





  <title>plantegg - java tcp mysql performance network docker Linux</title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  















  
  
    
  

  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta custom-logo">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">plantegg</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description">java tcp mysql performance network docker Linux</h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-categories"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-sitemap">
          <a href="/sitemap.xml" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-sitemap"></i> <br />
            
            站点地图
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2117/06/07/关于本博/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2117/06/07/关于本博/" itemprop="url">关于本博</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2117-06-07T18:30:03+08:00">
                2117-06-07
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/others/" itemprop="url" rel="index">
                    <span itemprop="name">others</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="关于本博"><a href="#关于本博" class="headerlink" title="关于本博"></a>关于本博</h2><p>关注基础知识，一次把问题搞清楚，从案例出发深挖相关知识。</p>
<p>以前觉得自己一看就懂，实际是一问就打鼓，一用就糊涂。所以现在开始记录并总结再联系案例，一般是先把零散知识记录下来（看到过），慢慢地相关知识积累更多，直到碰到实践案例或是有点领悟到于是发现这块知识可以整理成一篇系统些的文章（基本快懂了）。</p>
<p>“技术变化太快，容易过时”，我的看法是网络知识、操作系统、计算机原理等核心概念知识的寿命会比你的职业生涯还长。这些都是40岁之后还会还会很有用，你看我40多了还在学习这些 :)</p>
<p><a href="https://plantegg.github.io/2018/05/23/%E5%A6%82%E4%BD%95%E5%9C%A8%E5%B7%A5%E4%BD%9C%E4%B8%AD%E5%AD%A6%E4%B9%A0/">如何在工作中学习</a> 所有方法我都记录在这篇文章中了，希望对你能有所帮助。</p>
<p>所有新文章从<a href="https://plantegg.github.io/archives">这里可以看到</a>，即使再简单的一篇总结我可以持续总结三五年，有新的发现、感悟都是直接在原文上增减，不会发表新的文章。</p>
<p><img src="/images/951413iMgBlog/image-20220421102225491.png" alt="image-20220421102225491"></p>
<p>为什么写博客而不是公众号，我见过20年前的互联网，深度依赖搜索引擎，所以还是喜欢博客。另外技术类文章更适合电脑阅读（随时摘录、实验）</p>
<h2 id="精华文章推荐"><a href="#精华文章推荐" class="headerlink" title="精华文章推荐"></a>精华文章推荐</h2><h4 id="国产CPU和Intel、AMD性能PK-从Intel、AMD、海光、鲲鹏920、飞腾2500-等CPU在TPCC、sysbench下的性能对比来分析他们的性能差距，同时分析内存延迟对性能的影响"><a href="#国产CPU和Intel、AMD性能PK-从Intel、AMD、海光、鲲鹏920、飞腾2500-等CPU在TPCC、sysbench下的性能对比来分析他们的性能差距，同时分析内存延迟对性能的影响" class="headerlink" title="国产CPU和Intel、AMD性能PK 从Intel、AMD、海光、鲲鹏920、飞腾2500 等CPU在TPCC、sysbench下的性能对比来分析他们的性能差距，同时分析内存延迟对性能的影响"></a><a href="https://plantegg.github.io/2022/01/13/%E4%B8%8D%E5%90%8CCPU%E6%80%A7%E8%83%BD%E5%A4%A7PK/">国产CPU和Intel、AMD性能PK</a> 从Intel、AMD、海光、鲲鹏920、飞腾2500 等CPU在TPCC、sysbench下的性能对比来分析他们的性能差距，同时分析内存延迟对性能的影响</h4><p><img src="/images/951413iMgBlog/image-20220319115644219.png" alt="image-20220319115644219"></p>
<h4 id="CPU的制造和概念-从最底层的沙子开始用8篇文章来回答关于CPU的各种疑问以及大量的实验对比案例和测试数据来展示了CPU的各种原理，比如多核、超线程、NUMA、睿频、功耗、GPU、大小核再到分支预测、cache-line失效、加锁代价、IPC等各种指标（都有对应的代码和测试数据）。"><a href="#CPU的制造和概念-从最底层的沙子开始用8篇文章来回答关于CPU的各种疑问以及大量的实验对比案例和测试数据来展示了CPU的各种原理，比如多核、超线程、NUMA、睿频、功耗、GPU、大小核再到分支预测、cache-line失效、加锁代价、IPC等各种指标（都有对应的代码和测试数据）。" class="headerlink" title="CPU的制造和概念 从最底层的沙子开始用8篇文章来回答关于CPU的各种疑问以及大量的实验对比案例和测试数据来展示了CPU的各种原理，比如多核、超线程、NUMA、睿频、功耗、GPU、大小核再到分支预测、cache_line失效、加锁代价、IPC等各种指标（都有对应的代码和测试数据）。"></a><a href="https://plantegg.github.io/2021/06/01/CPU的制造和概念/">CPU的制造和概念</a> 从最底层的沙子开始用8篇文章来回答关于CPU的各种疑问以及大量的实验对比案例和测试数据来展示了CPU的各种原理，比如多核、超线程、NUMA、睿频、功耗、GPU、大小核再到分支预测、cache_line失效、加锁代价、IPC等各种指标（都有对应的代码和测试数据）。</h4><p><img src="/images/951413iMgBlog/image-20210802161410524-1011377.png" alt="image-20210802161410524"> </p>
<h4 id="在2010年前后MySQL、PG、Oracle数据库在使用NUMA的时候碰到了性能问题，流传最广的这篇-MySQL-–-The-MySQL-“swap-insanity”-problem-and-the-effects-of-the-NUMA-architecture-http-blog-jcole-us-2010-09-28-mysql-swap-insanity-and-the-numa-architecture-文章描述了性能问题的原因-文章中把原因找错了-以及解决方案：关闭NUMA。-实际这个原因是kernel实现的一个低级bug，这个Bug在2014年修复了https-github-com-torvalds-linux-commit-4f9b16a64753d0bb607454347036dc997fd03b82，但是修复这么多年后仍然以讹传讹，这篇文章希望正本清源、扭转错误的认识。"><a href="#在2010年前后MySQL、PG、Oracle数据库在使用NUMA的时候碰到了性能问题，流传最广的这篇-MySQL-–-The-MySQL-“swap-insanity”-problem-and-the-effects-of-the-NUMA-architecture-http-blog-jcole-us-2010-09-28-mysql-swap-insanity-and-the-numa-architecture-文章描述了性能问题的原因-文章中把原因找错了-以及解决方案：关闭NUMA。-实际这个原因是kernel实现的一个低级bug，这个Bug在2014年修复了https-github-com-torvalds-linux-commit-4f9b16a64753d0bb607454347036dc997fd03b82，但是修复这么多年后仍然以讹传讹，这篇文章希望正本清源、扭转错误的认识。" class="headerlink" title="在2010年前后MySQL、PG、Oracle数据库在使用NUMA的时候碰到了性能问题，流传最广的这篇  MySQL – The MySQL “swap insanity” problem and the effects of the NUMA architecture http://blog.jcole.us/2010/09/28/mysql-swap-insanity-and-the-numa-architecture/ 文章描述了性能问题的原因(文章中把原因找错了)以及解决方案：关闭NUMA。 实际这个原因是kernel实现的一个低级bug，这个Bug在2014年修复了https://github.com/torvalds/linux/commit/4f9b16a64753d0bb607454347036dc997fd03b82，但是修复这么多年后仍然以讹传讹，这篇文章希望正本清源、扭转错误的认识。"></a><a href="https://plantegg.github.io/2021/05/14/%E5%8D%81%E5%B9%B4%E5%90%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%98%E6%98%AF%E4%B8%8D%E6%95%A2%E6%8B%A5%E6%8A%B1NUMA/">在2010年前后MySQL、PG、Oracle数据库在使用NUMA的时候碰到了性能问题，流传最广的这篇  MySQL – The MySQL “swap insanity” problem and the effects of the NUMA architecture http://blog.jcole.us/2010/09/28/mysql-swap-insanity-and-the-numa-architecture/ 文章描述了性能问题的原因(文章中把原因找错了)以及解决方案：关闭NUMA。 实际这个原因是kernel实现的一个低级bug，这个Bug在2014年修复了https://github.com/torvalds/linux/commit/4f9b16a64753d0bb607454347036dc997fd03b82，但是修复这么多年后仍然以讹传讹，这篇文章希望正本清源、扭转错误的认识。</a></h4><p><img src="/images/951413iMgBlog/image-20210517082233798.png" alt="image-20210517082233798"></p>
<h4 id="《Intel-PAUSE指令变化是如何影响自旋锁以及MySQL的性能的》-从一个参数引起的rt抖动定位到OS锁等待再到CPU-Pause指令，以及不同CPU型号对Pause使用cycles不同的影响，最终反馈到应用层面的rt全过程。在MySQL内核开发的时候考虑了Pause，但是没有考虑不同的CPU型号，所以换了CPU型号后性能差异比较大"><a href="#《Intel-PAUSE指令变化是如何影响自旋锁以及MySQL的性能的》-从一个参数引起的rt抖动定位到OS锁等待再到CPU-Pause指令，以及不同CPU型号对Pause使用cycles不同的影响，最终反馈到应用层面的rt全过程。在MySQL内核开发的时候考虑了Pause，但是没有考虑不同的CPU型号，所以换了CPU型号后性能差异比较大" class="headerlink" title="《Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的》 从一个参数引起的rt抖动定位到OS锁等待再到CPU Pause指令，以及不同CPU型号对Pause使用cycles不同的影响，最终反馈到应用层面的rt全过程。在MySQL内核开发的时候考虑了Pause，但是没有考虑不同的CPU型号，所以换了CPU型号后性能差异比较大"></a><a href="https://plantegg.github.io/2019/12/16/Intel%20PAUSE%E6%8C%87%E4%BB%A4%E5%8F%98%E5%8C%96%E6%98%AF%E5%A6%82%E4%BD%95%E5%BD%B1%E5%93%8D%E8%87%AA%E6%97%8B%E9%94%81%E4%BB%A5%E5%8F%8AMySQL%E7%9A%84%E6%80%A7%E8%83%BD%E7%9A%84/">《Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的》 从一个参数引起的rt抖动定位到OS锁等待再到CPU Pause指令，以及不同CPU型号对Pause使用cycles不同的影响，最终反馈到应用层面的rt全过程。在MySQL内核开发的时候考虑了Pause，但是没有考虑不同的CPU型号，所以换了CPU型号后性能差异比较大</a></h4><p><img src="/images/oss/d567449fe52725a9d0b9d4ec9baa372c.png" alt="image.png"></p>
<h4 id="10倍性能提升全过程-在双11的紧张流程下，将系统tps从500优化到5500，从网络到snat、再到Spring和StackTrace，一次全栈性能优化过程的详细记录和分析。"><a href="#10倍性能提升全过程-在双11的紧张流程下，将系统tps从500优化到5500，从网络到snat、再到Spring和StackTrace，一次全栈性能优化过程的详细记录和分析。" class="headerlink" title="10倍性能提升全过程 在双11的紧张流程下，将系统tps从500优化到5500，从网络到snat、再到Spring和StackTrace，一次全栈性能优化过程的详细记录和分析。"></a><a href="https://plantegg.github.io/2018/01/23/10+%E5%80%8D%E6%80%A7%E8%83%BD%E6%8F%90%E5%8D%87%E5%85%A8%E8%BF%87%E7%A8%8B/">10倍性能提升全过程</a> 在双11的紧张流程下，将系统tps从500优化到5500，从网络到snat、再到Spring和StackTrace，一次全栈性能优化过程的详细记录和分析。</h4><p><img src="/images/oss/05703c168e63e96821ea9f921d83712b.png" alt="image.png"></p>
<h4 id="就是要你懂TCP–半连接队列和全连接队列：偶发性的连接reset异常、重启服务后短时间的连接异常，通过一篇文章阐明TCP连接的半连接队列和全连接队大小是怎么影响连接创建的，以及用什么工具来观察队列有没有溢出、连接为什么会RESET"><a href="#就是要你懂TCP–半连接队列和全连接队列：偶发性的连接reset异常、重启服务后短时间的连接异常，通过一篇文章阐明TCP连接的半连接队列和全连接队大小是怎么影响连接创建的，以及用什么工具来观察队列有没有溢出、连接为什么会RESET" class="headerlink" title="就是要你懂TCP–半连接队列和全连接队列：偶发性的连接reset异常、重启服务后短时间的连接异常，通过一篇文章阐明TCP连接的半连接队列和全连接队大小是怎么影响连接创建的，以及用什么工具来观察队列有没有溢出、连接为什么会RESET"></a><a href="https://plantegg.github.io/2017/06/07/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E5%8D%8A%E8%BF%9E%E6%8E%A5%E9%98%9F%E5%88%97%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5%E9%98%9F%E5%88%97/">就是要你懂TCP–半连接队列和全连接队列：偶发性的连接reset异常、重启服务后短时间的连接异常，通过一篇文章阐明TCP连接的半连接队列和全连接队大小是怎么影响连接创建的，以及用什么工具来观察队列有没有溢出、连接为什么会RESET</a></h4><p><img src="/images/oss/1579241362064-807d8378-6c54-4a2c-a888-ff2337df817c.png" alt="image.png" style="zoom:80%;"></p>
<h4 id="就是要你懂TCP–性能和发送接收Buffer的关系：发送窗口大小-Buffer-、接收窗口大小-Buffer-对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响。BDP、RT、带宽对传输速度又是怎么影响的"><a href="#就是要你懂TCP–性能和发送接收Buffer的关系：发送窗口大小-Buffer-、接收窗口大小-Buffer-对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响。BDP、RT、带宽对传输速度又是怎么影响的" class="headerlink" title="就是要你懂TCP–性能和发送接收Buffer的关系：发送窗口大小(Buffer)、接收窗口大小(Buffer)对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响。BDP、RT、带宽对传输速度又是怎么影响的"></a><a href="https://plantegg.github.io/2019/09/28/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E6%80%A7%E8%83%BD%E5%92%8C%E5%8F%91%E9%80%81%E6%8E%A5%E6%94%B6Buffer%E7%9A%84%E5%85%B3%E7%B3%BB/">就是要你懂TCP–性能和发送接收Buffer的关系：发送窗口大小(Buffer)、接收窗口大小(Buffer)对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响。BDP、RT、带宽对传输速度又是怎么影响的</a></h4><p><img src="/images/oss/e177d59ecb886daef5905ed80a84dfd2.png" alt=""></p>
<h4 id="就是要你懂网络–一个网络包的旅程：教科书式地阐述书本中的路由、网关、子网、Mac地址、IP地址是如何一起协作让网络包最终传输到目标机器上。-同时可以跟讲这块的RFC1180比较一下，RFC1180-写的确实很好，清晰简洁，图文并茂，结构逻辑合理，但是对于90-的程序员没有什么卵用，看完几周后就忘得差不多，因为他不是从实践的角度来阐述问题，中间没有很多为什么，所以一般资质的程序员看完当时感觉很好，实际还是不会灵活运用"><a href="#就是要你懂网络–一个网络包的旅程：教科书式地阐述书本中的路由、网关、子网、Mac地址、IP地址是如何一起协作让网络包最终传输到目标机器上。-同时可以跟讲这块的RFC1180比较一下，RFC1180-写的确实很好，清晰简洁，图文并茂，结构逻辑合理，但是对于90-的程序员没有什么卵用，看完几周后就忘得差不多，因为他不是从实践的角度来阐述问题，中间没有很多为什么，所以一般资质的程序员看完当时感觉很好，实际还是不会灵活运用" class="headerlink" title="就是要你懂网络–一个网络包的旅程：教科书式地阐述书本中的路由、网关、子网、Mac地址、IP地址是如何一起协作让网络包最终传输到目标机器上。  同时可以跟讲这块的RFC1180比较一下，RFC1180 写的确实很好，清晰简洁，图文并茂，结构逻辑合理，但是对于90%的程序员没有什么卵用，看完几周后就忘得差不多，因为他不是从实践的角度来阐述问题，中间没有很多为什么，所以一般资质的程序员看完当时感觉很好，实际还是不会灵活运用"></a><a href="https://plantegg.github.io/2019/05/15/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E7%BD%91%E7%BB%9C--%E4%B8%80%E4%B8%AA%E7%BD%91%E7%BB%9C%E5%8C%85%E7%9A%84%E6%97%85%E7%A8%8B/">就是要你懂网络–一个网络包的旅程：教科书式地阐述书本中的路由、网关、子网、Mac地址、IP地址是如何一起协作让网络包最终传输到目标机器上。</a>  同时可以跟讲这块的<a href="https://tools.ietf.org/html/rfc1180" target="_blank" rel="external">RFC1180</a>比较一下，RFC1180 写的确实很好，清晰简洁，图文并茂，结构逻辑合理，但是对于90%的程序员没有什么卵用，看完几周后就忘得差不多，因为他不是从实践的角度来阐述问题，中间没有很多为什么，所以一般资质的程序员看完当时感觉很好，实际还是不会灵活运用</h4><p><img src="/images/oss/8f5d8518c1d92ed68d23218028e3cd11.png" alt=""></p>
<h4 id="从网络路由连通性的原理上来看负载均衡lvs的DR、NAT、FullNAT到底搞了些什么鬼，以及为什么要这么搞，和带来的优缺点：《就是要你懂负载均衡–lvs和转发模式》"><a href="#从网络路由连通性的原理上来看负载均衡lvs的DR、NAT、FullNAT到底搞了些什么鬼，以及为什么要这么搞，和带来的优缺点：《就是要你懂负载均衡–lvs和转发模式》" class="headerlink" title="从网络路由连通性的原理上来看负载均衡lvs的DR、NAT、FullNAT到底搞了些什么鬼，以及为什么要这么搞，和带来的优缺点：《就是要你懂负载均衡–lvs和转发模式》"></a><a href="/2019/06/20/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1--lvs%E5%92%8C%E8%BD%AC%E5%8F%91%E6%A8%A1%E5%BC%8F/">从网络路由连通性的原理上来看负载均衡lvs的DR、NAT、FullNAT到底搞了些什么鬼，以及为什么要这么搞，和带来的优缺点：《就是要你懂负载均衡–lvs和转发模式》</a></h4><p><img src="/images/oss/94d55b926b5bb1573c4cab8353428712.png" alt=""></p>
<h4 id="LVS-20倍的负载不均衡，原来是内核的这个Bug，这个内核bug现在还在，可以稳定重现，有兴趣的话去重现一下，然后对照源代码以及抓包分析一下就清楚了。"><a href="#LVS-20倍的负载不均衡，原来是内核的这个Bug，这个内核bug现在还在，可以稳定重现，有兴趣的话去重现一下，然后对照源代码以及抓包分析一下就清楚了。" class="headerlink" title="LVS 20倍的负载不均衡，原来是内核的这个Bug，这个内核bug现在还在，可以稳定重现，有兴趣的话去重现一下，然后对照源代码以及抓包分析一下就清楚了。"></a><a href="/2019/07/19/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1--%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E5%92%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E5%9D%87%E8%A1%A1/">LVS 20倍的负载不均衡，原来是内核的这个Bug</a>，这个内核bug现在还在，可以稳定重现，有兴趣的话去重现一下，然后对照源代码以及抓包分析一下就清楚了。</h4><h4 id="就是要你懂TCP–握手和挥手，不是你想象中三次握手、四次挥手就理解了TCP，本文从握手的本质–握手都做了什么事情、连接的本质是什么等来阐述握手、挥手的原理"><a href="#就是要你懂TCP–握手和挥手，不是你想象中三次握手、四次挥手就理解了TCP，本文从握手的本质–握手都做了什么事情、连接的本质是什么等来阐述握手、挥手的原理" class="headerlink" title="就是要你懂TCP–握手和挥手，不是你想象中三次握手、四次挥手就理解了TCP，本文从握手的本质–握手都做了什么事情、连接的本质是什么等来阐述握手、挥手的原理"></a><a href="/2017/06/02/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E8%BF%9E%E6%8E%A5%E5%92%8C%E6%8F%A1%E6%89%8B/">就是要你懂TCP–握手和挥手，不是你想象中三次握手、四次挥手就理解了TCP，本文从握手的本质–握手都做了什么事情、连接的本质是什么等来阐述握手、挥手的原理</a></h4><p><img src="/images/oss/6d66dadecb72e11e3e5ab765c6c3ea2e.png" alt=""></p>
<h4 id="nslookup-OK-but-ping-fail–看看老司机是如何解决问题的，解决问题的方法肯定比知识点重要多了，同时透过一个问题怎么样通篇来理解一大块知识，让这块原理真正在你的只是提示中扎根下来"><a href="#nslookup-OK-but-ping-fail–看看老司机是如何解决问题的，解决问题的方法肯定比知识点重要多了，同时透过一个问题怎么样通篇来理解一大块知识，让这块原理真正在你的只是提示中扎根下来" class="headerlink" title="nslookup OK but ping fail–看看老司机是如何解决问题的，解决问题的方法肯定比知识点重要多了，同时透过一个问题怎么样通篇来理解一大块知识，让这块原理真正在你的只是提示中扎根下来"></a><a href="/2019/01/09/nslookup-OK-but-ping-fail/">nslookup OK but ping fail–看看老司机是如何解决问题的，解决问题的方法肯定比知识点重要多了，同时透过一个问题怎么样通篇来理解一大块知识，让这块原理真正在你的只是提示中扎根下来</a></h4><p><img src="/images/oss/ca466bb6430f1149958ceb41b9ffe591.png" alt=""></p>
<h4 id="如何在工作中学习-一篇很土但是很务实可以复制的方法论文章。不要讲举一反三、触类旁通，谁都知道要举一反三、触类旁通，但是为什么我总是不能够举一反三、触类旁通？"><a href="#如何在工作中学习-一篇很土但是很务实可以复制的方法论文章。不要讲举一反三、触类旁通，谁都知道要举一反三、触类旁通，但是为什么我总是不能够举一反三、触类旁通？" class="headerlink" title="如何在工作中学习 一篇很土但是很务实可以复制的方法论文章。不要讲举一反三、触类旁通，谁都知道要举一反三、触类旁通，但是为什么我总是不能够举一反三、触类旁通？"></a><a href="/2018/05/23/%E5%A6%82%E4%BD%95%E5%9C%A8%E5%B7%A5%E4%BD%9C%E4%B8%AD%E5%AD%A6%E4%B9%A0/">如何在工作中学习</a> 一篇很土但是很务实可以复制的方法论文章。不要讲举一反三、触类旁通，谁都知道要举一反三、触类旁通，但是为什么我总是不能够举一反三、触类旁通？</h4><h4 id="举三反一–从理论知识到实际问题的推导-坚决不让思路跑偏，如何从一个理论知识点推断可能的问题"><a href="#举三反一–从理论知识到实际问题的推导-坚决不让思路跑偏，如何从一个理论知识点推断可能的问题" class="headerlink" title="举三反一–从理论知识到实际问题的推导 坚决不让思路跑偏，如何从一个理论知识点推断可能的问题"></a><a href="/2020/11/02/举三反一--从理论知识到实际问题的推导/">举三反一–从理论知识到实际问题的推导</a> 坚决不让思路跑偏，如何从一个理论知识点推断可能的问题</h4><h2 id="性能相关（2015-2018年）"><a href="#性能相关（2015-2018年）" class="headerlink" title="性能相关（2015-2018年）"></a>性能相关（2015-2018年）</h2><h4 id="就是要你懂TCP–半连接队列和全连接队列-偶发性的连接reset异常、重启服务后短时间的连接异常"><a href="#就是要你懂TCP–半连接队列和全连接队列-偶发性的连接reset异常、重启服务后短时间的连接异常" class="headerlink" title="就是要你懂TCP–半连接队列和全连接队列  偶发性的连接reset异常、重启服务后短时间的连接异常"></a><a href="/2017/06/07/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E5%8D%8A%E8%BF%9E%E6%8E%A5%E9%98%9F%E5%88%97%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5%E9%98%9F%E5%88%97/">就是要你懂TCP–半连接队列和全连接队列</a>  偶发性的连接reset异常、重启服务后短时间的连接异常</h4><h4 id="就是要你懂TCP–性能和发送接收Buffer的关系：发送窗口大小-Buffer-、接收窗口大小-Buffer-对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响。BDP、RT、带宽对传输速度又是怎么影响的-发送窗口大小-Buffer-、接收窗口大小-Buffer-对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响"><a href="#就是要你懂TCP–性能和发送接收Buffer的关系：发送窗口大小-Buffer-、接收窗口大小-Buffer-对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响。BDP、RT、带宽对传输速度又是怎么影响的-发送窗口大小-Buffer-、接收窗口大小-Buffer-对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响" class="headerlink" title="就是要你懂TCP–性能和发送接收Buffer的关系：发送窗口大小(Buffer)、接收窗口大小(Buffer)对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响。BDP、RT、带宽对传输速度又是怎么影响的  发送窗口大小(Buffer)、接收窗口大小(Buffer)对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响"></a><a href="/2019/09/28/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E6%80%A7%E8%83%BD%E5%92%8C%E5%8F%91%E9%80%81%E6%8E%A5%E6%94%B6Buffer%E7%9A%84%E5%85%B3%E7%B3%BB/">就是要你懂TCP–性能和发送接收Buffer的关系：发送窗口大小(Buffer)、接收窗口大小(Buffer)对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响。BDP、RT、带宽对传输速度又是怎么影响的</a>  发送窗口大小(Buffer)、接收窗口大小(Buffer)对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响</h4><h4 id="就是要你懂TCP–性能优化大全"><a href="#就是要你懂TCP–性能优化大全" class="headerlink" title="就是要你懂TCP–性能优化大全"></a><a href="/2019/06/21/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%A4%A7%E5%85%A8/">就是要你懂TCP–性能优化大全</a></h4><h4 id="就是要你懂TCP–TCP性能问题-Nagle算法和delay-ack"><a href="#就是要你懂TCP–TCP性能问题-Nagle算法和delay-ack" class="headerlink" title="就是要你懂TCP–TCP性能问题 Nagle算法和delay ack"></a><a href="/2018/06/14/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E6%9C%80%E7%BB%8F%E5%85%B8%E7%9A%84TCP%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98/">就是要你懂TCP–TCP性能问题</a> Nagle算法和delay ack</h4><h4 id="10倍性能提升全过程-在双11的紧张流程下，将系统tps从500优化到5500，从网络到snat、再到Spring和StackTrace，看看一个性能全栈工程师如何在各种工具加持下发现各种问题的。"><a href="#10倍性能提升全过程-在双11的紧张流程下，将系统tps从500优化到5500，从网络到snat、再到Spring和StackTrace，看看一个性能全栈工程师如何在各种工具加持下发现各种问题的。" class="headerlink" title="10倍性能提升全过程 在双11的紧张流程下，将系统tps从500优化到5500，从网络到snat、再到Spring和StackTrace，看看一个性能全栈工程师如何在各种工具加持下发现各种问题的。"></a><a href="/2018/01/23/10+%E5%80%8D%E6%80%A7%E8%83%BD%E6%8F%90%E5%8D%87%E5%85%A8%E8%BF%87%E7%A8%8B/">10倍性能提升全过程</a> 在双11的紧张流程下，将系统tps从500优化到5500，从网络到snat、再到Spring和StackTrace，看看一个性能全栈工程师如何在各种工具加持下发现各种问题的。</h4><h2 id="CPU系列文章（2021年完成）"><a href="#CPU系列文章（2021年完成）" class="headerlink" title="CPU系列文章（2021年完成）"></a>CPU系列文章（2021年完成）</h2><h4 id="CPU的制造和概念"><a href="#CPU的制造和概念" class="headerlink" title="CPU的制造和概念"></a><a href="/2021/06/01/CPU的制造和概念/">CPU的制造和概念</a></h4><h4 id="十年后数据库还是不敢拥抱NUMA？"><a href="#十年后数据库还是不敢拥抱NUMA？" class="headerlink" title="十年后数据库还是不敢拥抱NUMA？"></a><a href="/2021/05/14/十年后数据库还是不敢拥抱NUMA/">十年后数据库还是不敢拥抱NUMA？</a></h4><h4 id="Intel-PAUSE指令变化是如何影响自旋锁以及MySQL的性能的"><a href="#Intel-PAUSE指令变化是如何影响自旋锁以及MySQL的性能的" class="headerlink" title="Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的"></a><a href="/2019/12/16/Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的/">Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的</a></h4><h4 id="Perf-IPC以及CPU性能"><a href="#Perf-IPC以及CPU性能" class="headerlink" title="Perf IPC以及CPU性能"></a><a href="/2021/05/16/Perf IPC以及CPU利用率/">Perf IPC以及CPU性能</a></h4><h4 id="CPU性能和CACHE"><a href="#CPU性能和CACHE" class="headerlink" title="CPU性能和CACHE"></a><a href="https://plantegg.github.io/2021/07/19/CPU性能和CACHE/">CPU性能和CACHE</a></h4><h4 id="CPU-性能和Cache-Line"><a href="#CPU-性能和Cache-Line" class="headerlink" title="CPU 性能和Cache Line"></a><a href="/2021/05/16/CPU Cache Line 和性能/">CPU 性能和Cache Line</a></h4><h4 id="AMD-Zen-CPU-架构-以及-AMD、海光、Intel、鲲鹏的性能对比"><a href="#AMD-Zen-CPU-架构-以及-AMD、海光、Intel、鲲鹏的性能对比" class="headerlink" title="AMD Zen CPU 架构 以及 AMD、海光、Intel、鲲鹏的性能对比"></a><a href="/2021/08/13/AMD_Zen_CPU架构/">AMD Zen CPU 架构 以及 AMD、海光、Intel、鲲鹏的性能对比</a></h4><h4 id="Intel、海光、鲲鹏920、飞腾2500-CPU性能对比"><a href="#Intel、海光、鲲鹏920、飞腾2500-CPU性能对比" class="headerlink" title="Intel、海光、鲲鹏920、飞腾2500 CPU性能对比"></a><a href="/2021/06/18/几款CPU性能对比/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></h4><h2 id="网络相关基础知识（2017年完成）"><a href="#网络相关基础知识（2017年完成）" class="headerlink" title="网络相关基础知识（2017年完成）"></a>网络相关基础知识（2017年完成）</h2><h4 id="就是要你懂网络–一个网络包的旅程"><a href="#就是要你懂网络–一个网络包的旅程" class="headerlink" title="就是要你懂网络–一个网络包的旅程"></a><a href="/2019/05/15/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E7%BD%91%E7%BB%9C--%E4%B8%80%E4%B8%AA%E7%BD%91%E7%BB%9C%E5%8C%85%E7%9A%84%E6%97%85%E7%A8%8B/">就是要你懂网络–一个网络包的旅程</a></h4><h4 id="通过案例来理解MSS、MTU等相关TCP概念"><a href="#通过案例来理解MSS、MTU等相关TCP概念" class="headerlink" title="通过案例来理解MSS、MTU等相关TCP概念"></a><a href="/2018/05/07/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E9%80%9A%E8%BF%87%E6%A1%88%E4%BE%8B%E6%9D%A5%E5%AD%A6%E4%B9%A0MSS%E3%80%81MTU/">通过案例来理解MSS、MTU等相关TCP概念</a></h4><h4 id="就是要你懂TCP–握手和挥手"><a href="#就是要你懂TCP–握手和挥手" class="headerlink" title="就是要你懂TCP–握手和挥手"></a><a href="/2017/06/02/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E8%BF%9E%E6%8E%A5%E5%92%8C%E6%8F%A1%E6%89%8B/">就是要你懂TCP–握手和挥手</a></h4><h4 id="wireshark-dup-ack-issue-and-keepalive"><a href="#wireshark-dup-ack-issue-and-keepalive" class="headerlink" title="wireshark-dup-ack-issue and keepalive"></a><a href="/2017/06/02/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--wireshark-dup-ack-issue/">wireshark-dup-ack-issue and keepalive</a></h4><h4 id="一个没有遵守tcp规则导致的问题"><a href="#一个没有遵守tcp规则导致的问题" class="headerlink" title="一个没有遵守tcp规则导致的问题"></a><a href="/2018/11/26/%E4%B8%80%E4%B8%AA%E6%B2%A1%E6%9C%89%E9%81%B5%E5%AE%88tcp%E8%A7%84%E5%88%99%E5%AF%BC%E8%87%B4%E7%9A%84%E9%97%AE%E9%A2%98/">一个没有遵守tcp规则导致的问题</a></h4><h4 id="kubernetes-service-和-kube-proxy详解"><a href="#kubernetes-service-和-kube-proxy详解" class="headerlink" title="kubernetes service 和 kube-proxy详解"></a><a href="/2020/09/22/kubernetes service 和 kube-proxy详解/">kubernetes service 和 kube-proxy详解</a></h4><h2 id="DNS相关"><a href="#DNS相关" class="headerlink" title="DNS相关"></a>DNS相关</h2><h4 id="就是要你懂DNS–一文搞懂域名解析相关问题"><a href="#就是要你懂DNS–一文搞懂域名解析相关问题" class="headerlink" title="就是要你懂DNS–一文搞懂域名解析相关问题"></a><a href="/2019/06/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/">就是要你懂DNS–一文搞懂域名解析相关问题</a></h4><h4 id="nslookup-OK-but-ping-fail"><a href="#nslookup-OK-but-ping-fail" class="headerlink" title="nslookup OK but ping fail"></a><a href="/2019/01/09/nslookup-OK-but-ping-fail/">nslookup OK but ping fail</a></h4><h4 id="Docker中的DNS解析过程"><a href="#Docker中的DNS解析过程" class="headerlink" title="Docker中的DNS解析过程"></a><a href="/2019/01/12/Docker%E4%B8%AD%E7%9A%84DNS%E8%A7%A3%E6%9E%90%E8%BF%87%E7%A8%8B/">Docker中的DNS解析过程</a></h4><h4 id="windows7的wifi总是报DNS域名异常无法上网"><a href="#windows7的wifi总是报DNS域名异常无法上网" class="headerlink" title="windows7的wifi总是报DNS域名异常无法上网"></a><a href="/2019/01/10/windows7%E7%9A%84wifi%E6%80%BB%E6%98%AF%E6%8A%A5DNS%E5%9F%9F%E5%90%8D%E5%BC%82%E5%B8%B8%E6%97%A0%E6%B3%95%E4%B8%8A%E7%BD%91/">windows7的wifi总是报DNS域名异常无法上网</a></h4><h2 id="LVS-负载均衡"><a href="#LVS-负载均衡" class="headerlink" title="LVS 负载均衡"></a>LVS 负载均衡</h2><h4 id="就是要你懂负载均衡–lvs和转发模式"><a href="#就是要你懂负载均衡–lvs和转发模式" class="headerlink" title="就是要你懂负载均衡–lvs和转发模式"></a><a href="/2019/06/20/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1--lvs%E5%92%8C%E8%BD%AC%E5%8F%91%E6%A8%A1%E5%BC%8F/">就是要你懂负载均衡–lvs和转发模式</a></h4><h4 id="就是要你懂负载均衡–负载均衡调度算法和为什么不均衡"><a href="#就是要你懂负载均衡–负载均衡调度算法和为什么不均衡" class="headerlink" title="就是要你懂负载均衡–负载均衡调度算法和为什么不均衡"></a><a href="/2019/07/19/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1--%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E5%92%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E5%9D%87%E8%A1%A1/">就是要你懂负载均衡–负载均衡调度算法和为什么不均衡</a></h4><h2 id="网络工具"><a href="#网络工具" class="headerlink" title="网络工具"></a>网络工具</h2><h4 id="就是要你懂Unix-Socket-进行抓包解析"><a href="#就是要你懂Unix-Socket-进行抓包解析" class="headerlink" title="就是要你懂Unix Socket 进行抓包解析"></a><a href="/2018/01/01/%E9%80%9A%E8%BF%87tcpdump%E5%AF%B9Unix%20Socket%20%E8%BF%9B%E8%A1%8C%E6%8A%93%E5%8C%85%E8%A7%A3%E6%9E%90/">就是要你懂Unix Socket 进行抓包解析</a></h4><h4 id="就是要你懂网络监控–ss用法大全"><a href="#就是要你懂网络监控–ss用法大全" class="headerlink" title="就是要你懂网络监控–ss用法大全"></a><a href="/2016/10/12/ss%E7%94%A8%E6%B3%95%E5%A4%A7%E5%85%A8/">就是要你懂网络监控–ss用法大全</a></h4><h4 id="就是要你懂抓包–WireShark之命令行版tshark"><a href="#就是要你懂抓包–WireShark之命令行版tshark" class="headerlink" title="就是要你懂抓包–WireShark之命令行版tshark"></a><a href="/2019/06/21/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E6%8A%93%E5%8C%85--WireShark%E4%B9%8B%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%89%88tshark/">就是要你懂抓包–WireShark之命令行版tshark</a></h4><h4 id="netstat-timer-keepalive-explain"><a href="#netstat-timer-keepalive-explain" class="headerlink" title="netstat timer keepalive explain"></a><a href="/2017/08/28/netstat%20%E7%AD%89%E7%BD%91%E7%BB%9C%E5%B7%A5%E5%85%B7/">netstat timer keepalive explain</a></h4><h4 id="Git-HTTP-Proxy-and-SSH-Proxy"><a href="#Git-HTTP-Proxy-and-SSH-Proxy" class="headerlink" title="Git HTTP Proxy and SSH Proxy"></a><a href="/2018/03/14/%E5%A6%82%E4%BD%95%E8%AE%BE%E7%BD%AEgit%20Proxy/">Git HTTP Proxy and SSH Proxy</a></h4>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2022/11/04/nginx性能和软中断/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/11/04/nginx性能和软中断/" itemprop="url">nginx性能和软中断</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-11-04T12:30:03+08:00">
                2022-11-04
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/performance/" itemprop="url" rel="index">
                    <span itemprop="name">performance</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="nginx性能和软中断"><a href="#nginx性能和软中断" class="headerlink" title="nginx性能和软中断"></a>nginx性能和软中断</h1><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><ul>
<li>如何调整软中断才能达到最优性能？</li>
<li>通过 top 观察软中断 和 si%、sy% 的关系</li>
</ul>
<h2 id="测试机型"><a href="#测试机型" class="headerlink" title="测试机型"></a>测试机型</h2><p>双路 Intel(R) Xeon(R) CPU E5-2682 v4</p>
<p>两块万兆网卡：Intel Corporation 82599ES 10-Gigabit SFI/SFP+ Network Connection (rev 01)</p>
<p>内核：3.10.0-327</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">NUMA node0 CPU(s):     0-15,32-47</div><div class="line">NUMA node1 CPU(s):     16-31,48-63</div></pre></td></tr></table></figure>
<h2 id="软中断和-si"><a href="#软中断和-si" class="headerlink" title="软中断和 si%"></a>软中断和 si%</h2><p>压nginx 碰到一个奇怪的问题，将软中断绑到48-63核，如果nginx绑到这个socket下的其它核比如 16-23，我就基本上看不到 si% 的使用率；如果所有条件都不变我将nginx 绑0-7core（另外一个socket），那么我能看到0-7 core上的软中断 si%使用率达到600%以上（8core累加）。 si%使用率应该只和 PPS、流量相关，这个测试中不同绑核nginx的QPS 差了20%以内。</p>
<p><img src="/images/951413iMgBlog/image-20221031152031791.png" alt="image-20221031152031791"><img src="/images/951413iMgBlog/image-20221031152044825.png" alt="image-20221031152044825"></p>
<p>CPU是intel E5，网卡插在node0上</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Model name:            Intel(R) Xeon(R) CPU E5-2682 v4 @ 2.50GHz</div><div class="line">NUMA node0 CPU(s):     0-15,32-47</div><div class="line">NUMA node1 CPU(s):     16-31,48-63</div><div class="line"></div><div class="line">软中断绑定：IRQBALANCE_BANNED_CPUS=0000ffff,ffffffff</div></pre></td></tr></table></figure>
<p>默认业务进程调用内核软中断do_softirq等来处理收发包，不需要跨core，如果将软中断绑定到具体的core后，会触发ksoftirqd 来调用do_softirq来处理收发包，整体上肯定效率不如同一个core处理业务和软中断的效率高。进一步如果软中断跨socket绑定导致处理时长进一步升高、总效率更差</p>
<p><a href="https://askubuntu.com/questions/7858/why-is-ksoftirqd-0-process-using-all-of-my-cpu" target="_blank" rel="external">https://askubuntu.com/questions/7858/why-is-ksoftirqd-0-process-using-all-of-my-cpu</a></p>
<p><img src="/images/951413iMgBlog/image-20221101113948809.png" alt="image-20221101113948809"></p>
<p>下图场景下，收包没有占用 si，而是占用的 sy</p>
<p><img src="/images/951413iMgBlog/image-20221101114217738.png" alt="image-20221101114217738"></p>
<p>将软中断和业务进程拆开绑核，均将软中断、业务基本压满的情况下，如果软中断在本node，QPS 增加20%+</p>
<p>软中断打满单核后的IPC：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line">#perf stat --cpu 29  //软中断所在core，si%=100%，和业务以及网卡跨node</div><div class="line">^C</div><div class="line"> Performance counter stats for &apos;CPU(s) 29&apos;:</div><div class="line"></div><div class="line">       4470.584807      task-clock (msec)         #    1.001 CPUs utilized            (100.00%)</div><div class="line">               252      context-switches          #    0.056 K/sec                    (100.00%)</div><div class="line">                 8      cpu-migrations            #    0.002 K/sec                    (100.00%)</div><div class="line">                 3      page-faults               #    0.001 K/sec</div><div class="line">    11,158,106,237      cycles                    #    2.496 GHz                      (100.00%)</div><div class="line">   &lt;not supported&gt;      stalled-cycles-frontend</div><div class="line">   &lt;not supported&gt;      stalled-cycles-backend</div><div class="line">     7,976,745,525      instructions              #    0.71  insns per cycle          (100.00%)</div><div class="line">     1,444,740,326      branches                  #  323.166 M/sec                    (100.00%)</div><div class="line">         7,073,805      branch-misses             #    0.49% of all branches</div><div class="line"></div><div class="line">       4.465613433 seconds time elapsed</div><div class="line"></div><div class="line">#perf stat --cpu 1  //软中断所在core，si%=100%，和业务以及网卡跨node</div><div class="line">^C</div><div class="line">^C</div><div class="line"> Performance counter stats for &apos;CPU(s) 1&apos;:</div><div class="line"></div><div class="line">       5132.639092      task-clock (msec)         #    1.002 CPUs utilized            (100.00%)</div><div class="line">             1,119      context-switches          #    0.218 K/sec                    (100.00%)</div><div class="line">                 6      cpu-migrations            #    0.001 K/sec                    (100.00%)</div><div class="line">                 0      page-faults               #    0.000 K/sec</div><div class="line">    12,773,996,227      cycles                    #    2.489 GHz                      (100.00%)</div><div class="line">   &lt;not supported&gt;      stalled-cycles-frontend</div><div class="line">   &lt;not supported&gt;      stalled-cycles-backend</div><div class="line">    12,457,832,798      instructions              #    0.98  insns per cycle          (100.00%)</div><div class="line">     2,243,820,953      branches                  #  437.167 M/sec                    (100.00%)</div><div class="line">        12,769,358      branch-misses             #    0.57% of all branches</div><div class="line"></div><div class="line">       5.124937947 seconds time elapsed</div></pre></td></tr></table></figure>
<p>Nginx业务进程的IPC</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line">#perf stat -p 30434   //软中断跨node</div><div class="line"></div><div class="line"> Performance counter stats for process id &apos;30434&apos;:</div><div class="line"></div><div class="line">       6838.088642      task-clock (msec)         #    0.953 CPUs utilized            (100.00%)</div><div class="line">            19,664      context-switches          #    0.003 M/sec                    (100.00%)</div><div class="line">                 0      cpu-migrations            #    0.000 K/sec                    (100.00%)</div><div class="line">                 4      page-faults               #    0.001 K/sec</div><div class="line">    17,027,659,259      cycles                    #    2.490 GHz                      (100.00%)</div><div class="line">   &lt;not supported&gt;      stalled-cycles-frontend</div><div class="line">   &lt;not supported&gt;      stalled-cycles-backend</div><div class="line">    14,315,679,297      instructions              #    0.84  insns per cycle          (100.00%)</div><div class="line">     2,919,774,303      branches                  #  426.987 M/sec                    (100.00%)</div><div class="line">        34,643,571      branch-misses             #    1.19% of all branches</div><div class="line"></div><div class="line">       7.176493377 seconds time elapsed      </div><div class="line">       </div><div class="line">#perf stat -p 30434    //软中断和nginx、网卡在同一node</div><div class="line">^C</div><div class="line"> Performance counter stats for process id &apos;30434&apos;:</div><div class="line"></div><div class="line">       5720.308631      task-clock (msec)         #    0.979 CPUs utilized            (100.00%)</div><div class="line">            11,513      context-switches          #    0.002 M/sec                    (100.00%)</div><div class="line">                 1      cpu-migrations            #    0.000 K/sec                    (100.00%)</div><div class="line">                 0      page-faults               #    0.000 K/sec</div><div class="line">    14,234,226,577      cycles                    #    2.488 GHz                      (100.00%)</div><div class="line">   &lt;not supported&gt;      stalled-cycles-frontend</div><div class="line">   &lt;not supported&gt;      stalled-cycles-backend</div><div class="line">    14,741,777,543      instructions              #    1.04  insns per cycle          (100.00%)</div><div class="line">     3,009,021,477      branches                  #  526.024 M/sec                    (100.00%)</div><div class="line">        35,690,882      branch-misses             #    1.19% of all branches</div><div class="line"></div><div class="line">       5.845534744 seconds time elapsed</div></pre></td></tr></table></figure>
<p>如果将nginx绑到node1（和网卡分开），同样再将软中断绑到node0、node1上，这个时候同样是软中断和业务在同一node性能要好，也就是软中断要和业务在一个node和网卡在哪里没关系。</p>
<p>网络包收发涉及两块内存分配：描述符(指针)和data buffer（存放网络包数据）；</p>
<p><a href="https://ata.alibaba-inc.com/articles/230545" target="_blank" rel="external">网卡的描述符、data buffer申请的内存都在设备所在的numa上</a>， 如果将队列的中断绑定到其他cpu上， 那么队列申请的data buffer的节点也会跟着中断迁移，但是描述符是和网卡所在的node绑定不会迁移的。</p>
<p>Top 看到的 ksoftirqd 占用cpu不高，但是去看对应的 CPU core si消耗比较高，这是因为 ksoftirqd 只是触发软中断后的入口，进而会调用do_softirq/net_rx_action 等内核函数，在 si% 的消耗中包含了这些被调用的消耗</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li><p>软中断绑定优先让irqbalance自己决定，默认系统倾向于自动在业务中调用软中断，代价最低</p>
</li>
<li><p>尽量不要让包溢出net.core.netdev_budget，溢出后触发ksoftirqd 来处理效率更低</p>
</li>
<li><p>尽量控制不要让 ksoftirqd 打满，所以可以绑定更多core来</p>
</li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2022/10/10/Linux BUG内核导致的 TCP连接卡死/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/10/10/Linux BUG内核导致的 TCP连接卡死/" itemprop="url">一个Linux 内核 bug 导致的 TCP连接卡死</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-10-10T17:30:03+08:00">
                2022-10-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Linux/" itemprop="url" rel="index">
                    <span itemprop="name">Linux</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Linux-BUG内核导致的-TCP连接卡死"><a href="#Linux-BUG内核导致的-TCP连接卡死" class="headerlink" title="Linux BUG内核导致的 TCP连接卡死"></a>Linux BUG内核导致的 TCP连接卡死</h1><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>客户端从 server 拖数据，偶尔会出现 TCP 连接卡死，卡死的现象就是 server 不遵循 TCP 重传逻辑，客户端不停地发 dup ack，但是服务端不响应这些dup ack仍然发新的包(从server抓包可以看到)，直至服务端不再发任何新包，最终连接闲置过久被reset，客户端抛连接异常.</p>
<h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>服务端抓包可以看到：这个 TCP 流， 17:40:40 后 3306 端口不做任何响应，进入卡死状态，在卡死前有一些重传</p>
<p><img src="/images/951413iMgBlog/1662602586968-b20b6006-884e-4c33-9938-0277c012579e.png" alt="image.png"></p>
<p>同时通过观察这些连接的实时状态：</p>
<p><img src="/images/951413iMgBlog/image-20220922092105581.png" alt="image-20220922092105581"></p>
<p>rto一直在增加，但是这个时候 server 上抓不到任何包，说明内核在做 rto 重传，但是重传包没有到达本机网卡，应该还是被内核其它环节吃掉了。</p>
<p>再观察 netstat -s 状态，重传的时候，TCPWqueueTooBig 值会增加，也就是重传-&gt;TCPWqueueTooBig-&gt;重传包未发出-&gt;循环-&gt;相当于 TCP 连接卡死、静默状态</p>
<p><img src="/images/951413iMgBlog/image-20220922092321039.png" alt="image-20220922092321039"></p>
<p>顺着 TCPWqueueTooBig 查看<a href="https://github.com/torvalds/linux/commit/f070ef2ac66716357066b683fb0baf55f8191a2e" target="_blank" rel="external">内核代码提交记录</a>， 红色部分是修 CVE-2019-11478 添加的代码，引入了这个 卡死 的bug，绿色部分增加了更严格的条件又修复了卡死的 bug</p>
<p><img src="/images/951413iMgBlog/1662698955965-276e9936-6ca4-4269-9fbd-ae05176bf1a6.png" alt="image.png"></p>
<h2 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h2><p>2019-05 为了解决 <a href="https://www.secrss.com/articles/11570" target="_blank" rel="external">CVE-2019-11478</a> 增加了这个commit：<a href="https://github.com/torvalds/linux/commit/f070ef2ac66716357066b683fb0baf55f8191a2e" target="_blank" rel="external">f070ef2ac66716357066b683fb0baf55f8191a2e</a>，这部分代码在发送 buffer 满的时候忽略要发的包，进入静默</p>
<p>为了解决这个问题 2019-07-20 fix 版本：<a href="https://github.com/torvalds/linux/commit/b617158dc096709d8600c53b6052144d12b89fab" target="_blank" rel="external">https://github.com/torvalds/linux/commit/b617158dc096709d8600c53b6052144d12b89fab</a></p>
<p>4.19.57 是 2019-07-03 发布，完美引入了这个 bug</p>
<p>快速确认：netstat -s | grep TCPWqueueTooBig  如果不为0 就出现过 TCP 卡死，同时还可以看到 tb(待发送队列) 大于 rb（发送队列 buffer）</p>
<h2 id="重现条件"><a href="#重现条件" class="headerlink" title="重现条件"></a>重现条件</h2><p>必要条件：合并了 commit：<a href="https://github.com/torvalds/linux/commit/f070ef2ac66716357066b683fb0baf55f8191a2e" target="_blank" rel="external">f070ef2ac66716357066b683fb0baf55f8191a2e</a> 的内核版本</p>
<p>提高重现概率的其它非必要条件：</p>
<ol>
<li>数据量大—拖数据任务、大查询；</li>
<li>有丢包—链路偏长连接，丢包概率大；</li>
<li>多个任务 —一个失败整个任务失败，客户体感强烈</li>
<li>Server 设置了小buffer，出现概率更高</li>
</ol>
<p>在这四种情况下出现概率更高。用户单个小查询SQL 睬中这个bug后一般可能就是个连接异常，重试就过去了，所以可能没有抱怨。 得这四个条件一起用户的抱怨就会凸显出来。</p>
<h2 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h2><p>升级内核到带有2019-07-20 fix 版本：<a href="https://github.com/torvalds/linux/commit/b617158dc096709d8600c53b6052144d12b89fab" target="_blank" rel="external">https://github.com/torvalds/linux/commit/b617158dc096709d8600c53b6052144d12b89fab</a></p>
<h2 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h2><p><a href="https://www.secrss.com/articles/11570" target="_blank" rel="external">https://www.secrss.com/articles/11570</a></p>
<p><a href="https://access.redhat.com/solutions/4302501" target="_blank" rel="external">https://access.redhat.com/solutions/4302501</a></p>
<p><a href="https://access.redhat.com/solutions/5162381" target="_blank" rel="external">https://access.redhat.com/solutions/5162381</a></p>
<p>databricks 的相同案例： <a href="https://www.databricks.com/blog/2019/09/16/adventures-in-the-tcp-stack-performance-regressions-vulnerability-fixes.html" target="_blank" rel="external">https://www.databricks.com/blog/2019/09/16/adventures-in-the-tcp-stack-performance-regressions-vulnerability-fixes.html</a></p>
<p>6月第一个人报了这个bug：<a href="https://lore.kernel.org/netdev/CALMXkpYVRxgeqarp4gnmX7GqYh1sWOAt6UaRFqYBOaaNFfZ5sw@mail.gmail.com/" target="_blank" rel="external">https://lore.kernel.org/netdev/CALMXkpYVRxgeqarp4gnmX7GqYh1sWOAt6UaRFqYBOaaNFfZ5sw@mail.gmail.com/</a></p>
<blockquote>
<p>Hi Eric, I now have a packetdrill test that started failing (see below). Admittedly, a bit weird test with the SO_SNDBUF forced so low. Nevertheless, previously this test would pass, now it stalls after the write() because tcp_fragment() returns -ENOMEM. Your commit-message mentions that this could trigger when one sets SO_SNDBUF low. But, here we have a complete stall of the connection and we never recover.<br>I don’t know if we care about this, but there it is :-)</p>
</blockquote>
<p><a href="https://patches.linaro.org/project/stable/patch/20210125183204.684104321@linuxfoundation.org/" target="_blank" rel="external">一个 zero windows 下卡死的内核bug</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2022/10/10/Nginx性能测试/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/10/10/Nginx性能测试/" itemprop="url">Nginx 性能测试</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-10-10T12:30:03+08:00">
                2022-10-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/performance/" itemprop="url" rel="index">
                    <span itemprop="name">performance</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Nginx-性能测试"><a href="#Nginx-性能测试" class="headerlink" title="Nginx 性能测试"></a>Nginx 性能测试</h1><p>压测工具选择 wrk ，apache ab压nginx单核没问题，多核的话 ab 自己先到瓶颈。另外默认关闭 access.log 避免 osq(osq 优化的自旋锁)。</p>
<h2 id="Nginx-官方测试数据"><a href="#Nginx-官方测试数据" class="headerlink" title="Nginx 官方测试数据"></a><a href="https://www.nginx.com/blog/testing-the-performance-of-nginx-and-nginx-plus-web-servers/" target="_blank" rel="external">Nginx 官方测试数据</a></h2><p>普通测试数据参考官方数据，不再多做测试</p>
<h3 id="RPS-for-HTTP-Requests"><a href="#RPS-for-HTTP-Requests" class="headerlink" title="RPS for HTTP Requests"></a>RPS for HTTP Requests</h3><p>The table and graph below show the number of HTTP requests for varying numbers of CPUs and varying request sizes, in kilobytes (KB).</p>
<table>
<thead>
<tr>
<th style="text-align:center">CPUs</th>
<th style="text-align:center">0 KB</th>
<th style="text-align:center">1 KB</th>
<th style="text-align:center">10 KB</th>
<th style="text-align:center">100 KB</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">145,551</td>
<td style="text-align:center">74,091</td>
<td style="text-align:center">54,684</td>
<td style="text-align:center">33,125</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">249,293</td>
<td style="text-align:center">131,466</td>
<td style="text-align:center">102,069</td>
<td style="text-align:center">62,554</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">543,061</td>
<td style="text-align:center">261,269</td>
<td style="text-align:center">207,848</td>
<td style="text-align:center">88,691</td>
</tr>
<tr>
<td style="text-align:center">8</td>
<td style="text-align:center">1,048,421</td>
<td style="text-align:center">524,745</td>
<td style="text-align:center">392,151</td>
<td style="text-align:center">91,640</td>
</tr>
<tr>
<td style="text-align:center">16</td>
<td style="text-align:center">2,001,846</td>
<td style="text-align:center">972,382</td>
<td style="text-align:center">663,921</td>
<td style="text-align:center">91,623</td>
</tr>
<tr>
<td style="text-align:center">32</td>
<td style="text-align:center">3,019,182</td>
<td style="text-align:center">1,316,362</td>
<td style="text-align:center">774,567</td>
<td style="text-align:center">91,640</td>
</tr>
<tr>
<td style="text-align:center">36</td>
<td style="text-align:center">3,298,511</td>
<td style="text-align:center">1,309,358</td>
<td style="text-align:center">764,744</td>
<td style="text-align:center">91,655</td>
</tr>
</tbody>
</table>
<p><a href="https://www.nginx.com/wp-content/uploads/2017/08/NGINX-HTTP-RPS.png" target="_blank" rel="external"><img src="/images/951413iMgBlog/NGINX-HTTP-RPS.png" alt="img"></a></p>
<h3 id="RPS-for-HTTPS-Requests"><a href="#RPS-for-HTTPS-Requests" class="headerlink" title="RPS for HTTPS Requests"></a>RPS for HTTPS Requests</h3><p>HTTPS RPS is lower than HTTP RPS for the same provisioned bare‑metal hardware because the data encryption and decryption necessary to secure data transmitted between machines is computationally expensive.</p>
<p>Nonetheless, continued advances in Intel architecture – resulting in servers with faster processors and better memory management – mean that the performance of software for CPU‑bound encryption tasks continually improves compared to dedicated hardware encryption devices.</p>
<p>Though RPS for HTTPS are roughly one‑quarter less than for HTTP at the 16‑CPU mark, “throwing hardware at the problem” – in the form of additional CPUs – is more effective than for HTTP, for the more commonly used file sizes and all the way up to 36 CPUs.</p>
<table>
<thead>
<tr>
<th style="text-align:center">CPUs</th>
<th style="text-align:center">0 KB</th>
<th style="text-align:center">1 KB</th>
<th style="text-align:center">10 KB</th>
<th style="text-align:center">100 KB</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">71,561</td>
<td style="text-align:center">40,207</td>
<td style="text-align:center">23,308</td>
<td style="text-align:center">4,830</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">151,325</td>
<td style="text-align:center">85,139</td>
<td style="text-align:center">48,654</td>
<td style="text-align:center">9,871</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">324,654</td>
<td style="text-align:center">178,395</td>
<td style="text-align:center">96,808</td>
<td style="text-align:center">19,355</td>
</tr>
<tr>
<td style="text-align:center">8</td>
<td style="text-align:center">647,213</td>
<td style="text-align:center">359,576</td>
<td style="text-align:center">198,818</td>
<td style="text-align:center">38,900</td>
</tr>
<tr>
<td style="text-align:center">16</td>
<td style="text-align:center">1,262,999</td>
<td style="text-align:center">690,329</td>
<td style="text-align:center">383,860</td>
<td style="text-align:center">77,427</td>
</tr>
<tr>
<td style="text-align:center">32</td>
<td style="text-align:center">2,197,336</td>
<td style="text-align:center">1,207,959</td>
<td style="text-align:center">692,804</td>
<td style="text-align:center">90,430</td>
</tr>
<tr>
<td style="text-align:center">36</td>
<td style="text-align:center">2,175,945</td>
<td style="text-align:center">1,239,624</td>
<td style="text-align:center">733,745</td>
<td style="text-align:center">89,842</td>
</tr>
</tbody>
</table>
<h2 id="参考配置参数"><a href="#参考配置参数" class="headerlink" title="参考配置参数"></a>参考配置参数</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div></pre></td><td class="code"><pre><div class="line">user nginx;</div><div class="line">worker_processes 4;</div><div class="line">worker_cpu_affinity 00000000000000000000000000001111;</div><div class="line"></div><div class="line"># Load dynamic modules. See /usr/share/doc/nginx/README.dynamic.</div><div class="line">include /usr/share/nginx/modules/*.conf;</div><div class="line"></div><div class="line">events &#123;</div><div class="line">    use epoll;</div><div class="line">    accept_mutex off;</div><div class="line">    worker_connections 102400;</div><div class="line">&#125;</div><div class="line">http &#123;</div><div class="line">    access_log off;</div><div class="line"></div><div class="line">    sendfile            on;</div><div class="line">    sendfile_max_chunk 512k;</div><div class="line">    tcp_nopush          on;</div><div class="line">    keepalive_timeout   60;</div><div class="line">    keepalive_requests 100000000000;</div><div class="line"></div><div class="line">		#在 nginx.conf 中增加以下开销能提升短连接 RPS</div><div class="line">    open_file_cache max=10240000 inactive=60s;</div><div class="line">    open_file_cache_valid 80s;</div><div class="line">    open_file_cache_min_uses 1;</div><div class="line"></div><div class="line">    include             /etc/nginx/mime.types;</div><div class="line">    default_type        application/octet-stream;</div><div class="line"></div><div class="line">    # Load modular configuration files from the /etc/nginx/conf.d directory.</div><div class="line">    # See http://nginx.org/en/docs/ngx_core_module.html#include</div><div class="line">    # for more information.</div><div class="line">    include /etc/nginx/conf.d/*.conf;</div><div class="line"></div><div class="line">    server &#123;</div><div class="line">        listen       80 default_server;</div><div class="line">        listen       [::]:80 default_server;</div><div class="line">        server_name  _;</div><div class="line">        root         /usr/share/nginx/html;</div><div class="line"></div><div class="line">        # Load configuration files for the default server block.</div><div class="line">        include /etc/nginx/default.d/*.conf;</div><div class="line"></div><div class="line">        location / &#123;</div><div class="line">        		#return 200 &apos;a&apos;;</div><div class="line">        		#root   /usr/share/nginx/html;</div><div class="line">        		#index  index.html index.htm;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        error_page 404 /404.html;</div><div class="line">            location = /40x.html &#123;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        error_page 500 502 503 504 /50x.html;</div><div class="line">            location = /50x.html &#123;</div><div class="line">        &#125;</div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<h3 id="https-配置"><a href="#https-配置" class="headerlink" title="https 配置"></a>https 配置</h3><p>解开https默认配置注释 // sed -i “57,81s/#(.*)/\1/“ /etc/nginx/nginx.conf</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"># Settings for a TLS enabled server.</div><div class="line">#</div><div class="line">#    server &#123;</div><div class="line">#        listen       443 ssl http2 default_server;</div><div class="line">#        listen       [::]:443 ssl http2 default_server;</div><div class="line">#        server_name  _;</div><div class="line">#        root         /usr/share/nginx/html;</div><div class="line">#</div><div class="line">#        ssl_certificate &quot;/etc/pki/nginx/server.crt&quot;;</div><div class="line">#        ssl_certificate_key &quot;/etc/pki/nginx/private/server.key&quot;;</div><div class="line">#        ssl_session_cache shared:SSL:1m;</div><div class="line">#        ssl_session_timeout  10m;</div><div class="line">#        ssl_ciphers HIGH:!aNULL:!MD5;</div><div class="line">#        ssl_prefer_server_ciphers on;</div><div class="line">#</div><div class="line">#        # Load configuration files for the default server block.</div><div class="line">#        include /etc/nginx/default.d/*.conf;</div><div class="line">#</div><div class="line">#        location / &#123;</div><div class="line">#        &#125;</div><div class="line">#</div><div class="line">#        error_page 404 /404.html;</div><div class="line">#            location = /40x.html &#123;</div><div class="line">#        &#125;</div><div class="line">#</div><div class="line">#        error_page 500 502 503 504 /50x.html;</div><div class="line">#            location = /50x.html &#123;</div><div class="line">#        &#125;</div><div class="line">#    &#125;</div></pre></td></tr></table></figure>
<p>生成秘钥文件和配置https</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">mkdir /etc/pki/nginx/  /etc/pki/nginx/private -p</div><div class="line">openssl genrsa -des3 -out server.key 2048  #会有两次要求输入密码,输入同一个即可</div><div class="line">openssl rsa -in server.key -out server.key</div><div class="line">openssl req -new -key server.key -out server.csr</div><div class="line">openssl req -new -x509 -key server.key -out server.crt -days 3650</div><div class="line">openssl req -new -x509 -key server.key -out ca.crt -days 3650</div><div class="line">openssl x509 -req -days 3650 -in server.csr -CA ca.crt -CAkey server.key -CAcreateserial -out server.crt</div><div class="line"></div><div class="line">cp server.crt /etc/pki/nginx/</div><div class="line">cp server.key /etc/pki/nginx/private</div><div class="line"></div><div class="line">启动nginx</div><div class="line">systemctl start nginx</div></pre></td></tr></table></figure>
<h3 id="创建ecdsa-P256-秘钥和证书"><a href="#创建ecdsa-P256-秘钥和证书" class="headerlink" title="创建ecdsa P256 秘钥和证书"></a>创建ecdsa P256 秘钥和证书</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">openssl req -x509 -sha256 -nodes -days 365 -newkey ec:&lt;(openssl ecparam -name prime256v1) -keyout ecdsa.key -out ecdsa.crt -subj &quot;/C=CN/ST=Beijing/L=Beijing/O=Example Inc./OU=Web Security/CN=example1.com&quot;</div></pre></td></tr></table></figure>
<h3 id="https-长连接"><a href="#https-长连接" class="headerlink" title="https 长连接"></a>https 长连接</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">wrk -t 32 -c 1000 -d 30 --latency https://$serverIP:443</div></pre></td></tr></table></figure>
<h3 id="https-短连接"><a href="#https-短连接" class="headerlink" title="https 短连接"></a>https 短连接</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">wrk -t 32 -c 1000 -d 30  -H &apos;Connection: close&apos;  --latency https://$serverIP:443</div></pre></td></tr></table></figure>
<h2 id="不同-CPU-型号下-Nginx-静态页面的处理能力"><a href="#不同-CPU-型号下-Nginx-静态页面的处理能力" class="headerlink" title="不同 CPU 型号下 Nginx 静态页面的处理能力"></a>不同 CPU 型号下 Nginx 静态页面的处理能力</h2><p>对比不同 CPU 型号下 Nginx 静态页面的处理能力。静态文件下容易出现 同一文件上的 自旋锁（OSQ），null 测试场景表示直接返回，不读取文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">wrk -t12 -c400 -d30s http://100.81.131.221:18082/index.html //参数可以调整，目标就是将 CPU 压满</div></pre></td></tr></table></figure>
<p>软中断在 node0 上，intel E5和 M的对比，在M上访问单个文件锁竞争太激励，改成请求直接 return 后多核能保持较好的线性能力（下表中 null标识）</p>
<table>
<thead>
<tr>
<th style="text-align:center">CPUs(括号中为core序号)</th>
<th style="text-align:center">E5-2682</th>
<th>E5-2682 null</th>
<th>M</th>
<th style="text-align:center">M  null</th>
<th>AMD 7t83 null</th>
<th>AMD 7t83</th>
<th>ft s2500  on null</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1(0)</td>
<td style="text-align:center">69282/61500.77</td>
<td>118694/106825</td>
<td>74091</td>
<td style="text-align:center">135539/192691</td>
<td>190568</td>
<td>87190</td>
<td>35064</td>
</tr>
<tr>
<td style="text-align:center">2(1,2)</td>
<td style="text-align:center">130648 us 31%</td>
<td>233947</td>
<td>131466</td>
<td style="text-align:center"></td>
<td>365315</td>
<td></td>
<td></td>
</tr>
<tr>
<td style="text-align:center">2(1对HT)</td>
<td style="text-align:center">94158 34%</td>
<td>160114</td>
<td></td>
<td style="text-align:center"></td>
<td>217783</td>
<td></td>
<td></td>
</tr>
<tr>
<td style="text-align:center">4(0-3)</td>
<td style="text-align:center">234884/211897</td>
<td>463033/481010</td>
<td></td>
<td style="text-align:center">499507/748880</td>
<td>730189</td>
<td>323591</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">8(0-7)</td>
<td style="text-align:center">467658/431308</td>
<td>923348/825002</td>
<td></td>
<td style="text-align:center">1015744/1529721</td>
<td>1442115</td>
<td>650780</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">8(0-15)</td>
<td style="text-align:center"></td>
<td>1689722/1363031</td>
<td></td>
<td style="text-align:center">1982448/3047778</td>
<td>2569314</td>
<td>915399</td>
</tr>
</tbody>
</table>
<p>测试说明：</p>
<ul>
<li>压测要将多个核打满，有时候因为软中断的挤占会导致部分核打不满</li>
<li>要考虑软中断对CPU使用的挤占/以及软中断跨node的影响</li>
<li>测试结果两组数字的话，前者为nginx、软中断分别在不同的node</li>
<li>E5/M 软中断绑 node1，测试结果的两组数据表示软中断和nginx跨node和同node（同 node时软中断和nginx尽量错开）</li>
<li>null 指的是 nginx 直接返回 200，不从文件读取html，保证没有文件锁</li>
<li>AMD 软中断总是能跟着绑核的nginx进程跑</li>
<li>压测要将多个核打满，有时候因为软中断的挤占会导致部分核打不满</li>
</ul>
<p>M是裸金属ECS，moc卡插在Die1上，所以软中断默认绑在 Die1 上，测试强行将软中断绑定到 Die0 实际测试结果和绑定在 Die1 性能一样，猜测改了驱动将网络包的描述符没有按硬件绑死而是跟软中断就近分配。</p>
<h2 id="sendfile-和-tcp-nopush"><a href="#sendfile-和-tcp-nopush" class="headerlink" title="sendfile 和 tcp_nopush"></a>sendfile 和 tcp_nopush</h2><h3 id="tcp-nopush-对性能的影响"><a href="#tcp-nopush-对性能的影响" class="headerlink" title="tcp_nopush 对性能的影响"></a>tcp_nopush 对性能的影响</h3><p>M上，返回很小的 html页面，如果 tcp_nopush=on 性能能有20%的提升，并且开启后 si% 使用率从10%降到了0. Tcp_nodelay=on 就基本对性能没啥影响</p>
<blockquote>
<p>TCP_NOPUSH 是 FreeBSD 的一个 socket 选项，对应 Linux 的 TCP_CORK，Nginx 里统一用 <code>tcp_nopush</code> 来控制它。启用它之后，数据包会累计到一定大小之后才会发送，减小了额外开销，提高网络效率。</p>
<p>To keep everything logical, Nginx tcp_nopush activates the TCP_CORK option in the Linux TCP stack since the TCP_NOPUSH one exists on FreeBSD only.</p>
</blockquote>
<p>nginx on M 8核，http 长连接，访问极小的静态页面（AMD 上测试也是 sendfile off 性能要好30%左右）</p>
<table>
<thead>
<tr>
<th></th>
<th>tcp_nopush on</th>
<th>tcp_nopush off</th>
</tr>
</thead>
<tbody>
<tr>
<td>sendfile on</td>
<td>46万(PPS 44万)</td>
<td>37万（PPS 73万）</td>
</tr>
<tr>
<td>sendfile off</td>
<td>49万(PPS 48万)</td>
<td>49万（PPS 48万)</td>
</tr>
</tbody>
</table>
<p>问题：为什么 sendfile off 性能反而好？（PPS 明显低了）</p>
<p>答：一次请求Nginx要回复header+body, header在用户态内存，body走sendfile在内核态内存，nginx没有机会合并header+body, sendfile on后导致每次请求要回复两个tcp包。而 sendfile off的时候虽然有用户态内核态切换、copy，但是有机会把 header/body 合并成一个tcp包</p>
<p>从抓包来看，sendfile on的时候每次 http get都是回复两个包：1) http 包头（len：288）2）http body(len: 58) </p>
<p><img src="/images/951413iMgBlog/image-20221008100922349.png" alt="image-20221008100922349"></p>
<p>sendfile off的时候每次 http get都是回复一个包： http 包头+body（len：292=288+4）</p>
<p><img src="/images/951413iMgBlog/image-20221008100808480.png" alt="image-20221008100808480"></p>
<p>在这个小包场景，如果sendfile=off 后，回包在http层面就已经合并从1个了，导致内核没机会再次 cork（合并包）；如果sendfile=on 则是每次请求回复两个tcp包，如果设置了  nopush 会在内核层面合并一次。</p>
<p>如果不是访问磁盘上的静态页面，而是直接 return某个内存的内容的话，sendfile on/off 对性能没有影响，原理也如上，不需要访问磁盘，也就没有机会分两个包发送包头和body了。</p>
<h3 id="分析参考数据"><a href="#分析参考数据" class="headerlink" title="分析参考数据"></a>分析参考数据</h3><p>一下数据都是变换不同的 sendfile、tcp_nopush等组合来观察QPS、setsockopt、PPS来分析这些参数起了什么作用</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div></pre></td><td class="code"><pre><div class="line">//tcp_nopush off; QPS 37万  很明显 pps 比46万高了将近1倍，这是因为 tcp_cork 合并了小包</div><div class="line">//nginx 创建连接设置的 sock opt</div><div class="line">#cat strace.log.88206</div><div class="line">08:31:19.632581 setsockopt(3, SOL_TCP, TCP_NODELAY, [1], 4) = 0 &lt;0.000013&gt;</div><div class="line"></div><div class="line">#tsar --traffic --live -i1</div><div class="line">Time              ---------------------traffic--------------------</div><div class="line">Time               bytin  bytout   pktin  pktout  pkterr  pktdrp</div><div class="line">30/09/22-07:00:22  52.9M  122.8M  748.2K  726.8K    0.00    0.00</div><div class="line">30/09/22-07:00:23  52.9M  122.7M  748.1K  726.2K    0.00    0.00</div><div class="line">30/09/22-07:00:24  53.0M  122.9M  749.2K  727.2K    0.00    0.00</div><div class="line">30/09/22-07:00:25  53.0M  122.8M  749.3K  726.6K    0.00    0.00</div><div class="line">30/09/22-07:00:26  52.9M  122.8M  748.2K  727.1K    0.00    0.00</div><div class="line">30/09/22-07:00:27  53.1M  123.0M  750.5K  728.0K    0.00    0.00</div><div class="line"></div><div class="line">//tcp_nopush      on; QPS 46万</div><div class="line">#tsar --traffic --live -i1</div><div class="line">Time              ---------------------traffic--------------------</div><div class="line">Time               bytin  bytout   pktin  pktout  pkterr  pktdrp</div><div class="line">30/09/22-07:00:54  40.2M  127.6M  447.6K  447.6K    0.00    0.00</div><div class="line">30/09/22-07:00:55  40.2M  127.5M  447.1K  447.1K    0.00    0.00</div><div class="line">30/09/22-07:00:56  40.1M  127.4M  446.8K  446.8K    0.00    0.00</div><div class="line"></div><div class="line">//sendfile on ,tcp_nopush on, quickack on; QPS 46万</div><div class="line">#ip route change 172.16.0.0/24 dev eth0 quickack 1</div><div class="line"></div><div class="line">#ip route</div><div class="line">default via 172.16.0.253 dev eth0</div><div class="line">169.254.0.0/16 dev eth0 scope link metric 1002</div><div class="line">172.16.0.0/24 dev eth0 scope link quickack 1</div><div class="line">192.168.5.0/24 dev docker0 proto kernel scope link src 192.168.5.1</div><div class="line"></div><div class="line">//nginx 创建连接设置的 sock opt </div><div class="line">#cat strace.log.85937</div><div class="line">08:27:44.702111 setsockopt(3, SOL_TCP, TCP_CORK, [1], 4) = 0 &lt;0.000011&gt;</div><div class="line">08:27:44.702353 setsockopt(3, SOL_TCP, TCP_CORK, [0], 4) = 0 &lt;0.000013&gt;</div><div class="line"></div><div class="line">#tsar --traffic -i1 --live</div><div class="line">Time              ---------------------traffic--------------------</div><div class="line">Time               bytin  bytout   pktin  pktout  pkterr  pktdrp</div><div class="line">08/10/22-03:27:23  40.7M  152.9M  452.6K  905.2K    0.00    0.00</div><div class="line">08/10/22-03:27:24  40.7M  152.9M  452.6K  905.2K    0.00    0.00</div><div class="line">08/10/22-03:27:25  40.6M  152.8M  452.3K  904.5K    0.00    0.00</div><div class="line">08/10/22-03:27:26  40.6M  152.7M  452.1K  904.1K    0.00    0.00</div><div class="line">08/10/22-03:27:27  40.6M  152.7M  452.0K  904.0K    0.00    0.00</div><div class="line">08/10/22-03:27:28  40.7M  153.1M  453.2K  906.5K    0.00    0.00</div><div class="line"></div><div class="line">//sendfile on , quickack on; QPS 42万</div><div class="line">#tsar --traffic -i1 --live</div><div class="line">Time              ---------------------traffic--------------------</div><div class="line">Time               bytin  bytout   pktin  pktout  pkterr  pktdrp</div><div class="line">08/10/22-04:02:53  57.9M  158.7M  812.3K    1.2M    0.00    0.00</div><div class="line">08/10/22-04:02:54  58.3M  159.6M  817.3K    1.2M    0.00    0.00</div><div class="line">08/10/22-04:02:55  58.2M  159.4M  816.0K    1.2M    0.00    0.00</div></pre></td></tr></table></figure>
<p><a href="https://thoughts.t37.net/nginx-optimization-understanding-sendfile-tcp-nodelay-and-tcp-nopush-c55cdd276765" target="_blank" rel="external">This behavior is confirmed in a comment from the TCP stack source about TCP_CORK</a>:</p>
<blockquote>
<p>When set indicates to always queue non-full frames. Later the user clears this option and we transmit any pending partial frames in the queue. This is meant to be used alongside sendfile() to get properly filled frames when the user (for example) must write out headers with a write() call first and then use sendfile to send out the data parts. TCP_CORK can be set together with TCP_NODELAY and it is stronger than TCP_NODELAY.</p>
</blockquote>
<h3 id="perf-top-数据"><a href="#perf-top-数据" class="headerlink" title="perf top 数据"></a>perf top 数据</h3><p>以下都是 sendfile on的时候变换 tcp_nopush 参数得到的不同 perf 数据</p>
<p>tcp_nopush=off：(QPS 37万)</p>
<p><img src="/images/951413iMgBlog/image-20220930143920567.png" alt="image-20220930143920567"></p>
<p>tcp_nopush=on：(QPS 46万)</p>
<p><img src="/images/951413iMgBlog/image-20220930143419304.png" alt="image-20220930143419304"></p>
<p>对比一下，在sendfile on的时候，用不同而push 参数对应的 tcp 栈</p>
<p><img src="/images/951413iMgBlog/image-20221009093842151.png" alt="image-20221009093842151"></p>
<h2 id="Nginx-在16核后再增加核数性能提升很少的分析"><a href="#Nginx-在16核后再增加核数性能提升很少的分析" class="headerlink" title="Nginx 在16核后再增加核数性能提升很少的分析"></a>Nginx 在16核后再增加核数性能提升很少的分析</h2><p>16核 perf top</p>
<p><img src="/images/951413iMgBlog/image-20220916174106821.png" alt="image-20220916174106821"></p>
<p>32核 perf top</p>
<p><img src="/images/951413iMgBlog/image-20220916174234039.png" alt="image-20220916174234039"></p>
<p>从以上两个perf top 对比可以看到内核锁消耗增加非常明显</p>
<p>这是因为<a href="https://www.cnblogs.com/LoyenWang/p/12826811.html" target="_blank" rel="external">读写文件锁 osq_lock</a> ，比如nginx需要写日志访问 access.log，需要加锁</p>
<p><code>osq(optimistci spinning queue)</code>是基于MCS算法的一个具体实现，osq_lock 是Linux 中对MCS的实现</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">location / &#123;</div><div class="line">        return 200 &apos;&lt;!DOCTYPE html&gt;&lt;h2&gt;null!&lt;/h2&gt;\n&apos;; #直接内存返回，不读磁盘文件，避免文件锁</div><div class="line">        # because default content-type is application/octet-stream,</div><div class="line">    		# browser will offer to &quot;save the file&quot;...</div><div class="line">    		# if you want to see reply in browser, uncomment next line </div><div class="line">    		# add_header Content-Type text/plain;</div><div class="line">        root   /usr/share/nginx/html;</div><div class="line">        index  index.html index.htm;</div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<h3 id="ARM下这个瓶颈更明显"><a href="#ARM下这个瓶颈更明显" class="headerlink" title="ARM下这个瓶颈更明显"></a>ARM下这个瓶颈更明显</h3><p>M上用40-64 core 并发的时候 perf top都是如下图，40 core以上网络瓶颈，pps 达到620万（离ECS规格承诺的1200万还很远），CPU压不起来了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">#tsar --traffic -i1 --live</div><div class="line">Time              ---------------------traffic--------------------</div><div class="line">Time               bytin  bytout   pktin  pktout  pkterr  pktdrp</div><div class="line">16/09/22-12:41:07 289.4M  682.8M    3.2M    3.2M    0.00    0.00</div><div class="line">16/09/22-12:41:08 285.5M  674.4M    3.1M    3.1M    0.00    0.00</div><div class="line">16/09/22-12:41:09 285.0M  672.6M    3.1M    3.1M    0.00    0.00</div><div class="line">16/09/22-12:41:10 287.5M  678.3M    3.1M    3.1M    0.00    0.00</div><div class="line">16/09/22-12:41:11 289.2M  682.0M    3.2M    3.2M    0.00    0.00</div><div class="line">16/09/22-12:41:12 290.1M  685.1M    3.2M    3.2M    0.00    0.00</div><div class="line">16/09/22-12:41:13 288.3M  680.4M    3.1M    3.1M    0.00    0.00</div><div class="line"></div><div class="line">#ethtool -l eth0</div><div class="line">Channel parameters for eth0:</div><div class="line">Pre-set maximums:</div><div class="line">RX:		0</div><div class="line">TX:		0</div><div class="line">Other:		0</div><div class="line">Combined:	32  //所以用不满64 core，依据上面的测试数据推算64队列的话那么基本可以跑到1200万pps</div><div class="line">Current hardware settings:</div><div class="line">RX:		0</div><div class="line">TX:		0</div><div class="line">Other:		0</div><div class="line">Combined:	32</div></pre></td></tr></table></figure>
<p><img src="/images/951413iMgBlog/image-20220916202347245.png" alt="image-20220916202347245"></p>
<h3 id="文件锁的竞争"><a href="#文件锁的竞争" class="headerlink" title="文件锁的竞争"></a>文件锁的竞争</h3><p>Nginx 在M 上使用 16 core的时候完全压不起来，都是内核态锁竞争，16core QPS 不到23万，线性能力很差（单核68000）</p>
<p>从下图可以看到 sys 偏高，真正用于 us 的 CPU 太少，而内核态 CPU 消耗过高的是 osq_lock(写日志文件锁相关)</p>
<p><img src="/images/951413iMgBlog/image-20220916151006533.png" alt="image-20220916151006533"></p>
<p><img src="/images/951413iMgBlog/image-20220916151310488.png" alt="image-20220916151310488"></p>
<p><img src="/images/951413iMgBlog/1663329200304-4f4b615b-8507-47c8-87ff-7e92939f12bc.png" alt="img"></p>
<p><img src="/images/951413iMgBlog/image-20220916151613388.png" alt="image-20220916151613388"></p>
<p>16核对应的perf状态</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">Performance counter stats for process id &apos;49643&apos;:</div><div class="line"></div><div class="line">      2479.448740      task-clock (msec)         #    0.994 CPUs utilized</div><div class="line">              233      context-switches          #    0.094 K/sec</div><div class="line">                0      cpu-migrations            #    0.000 K/sec</div><div class="line">                0      page-faults               #    0.000 K/sec</div><div class="line">    3,389,330,461      cycles                    #    1.367 GHz</div><div class="line">    1,045,248,301      stalled-cycles-frontend   #   30.84% frontend cycles idle</div><div class="line">    1,378,321,174      stalled-cycles-backend    #   40.67% backend  cycles idle</div><div class="line">    3,877,095,782      instructions              #    1.14  insns per cycle</div><div class="line">                                                 #    0.36  stalled cycles per insn</div><div class="line">  &lt;not supported&gt;      branches</div><div class="line">        2,128,918      branch-misses             #    0.00% of all branches</div><div class="line"></div><div class="line">      2.493168013 seconds time elapsed</div></pre></td></tr></table></figure>
<h2 id="软中断和-nginx-所在-node-关系"><a href="#软中断和-nginx-所在-node-关系" class="headerlink" title="软中断和 nginx 所在 node 关系"></a>软中断和 nginx 所在 node 关系</h2><p>以下两种情况的软中断都绑在 32-47 core上</p>
<p>软中断和 nginx 在同一个node，这时基本看不到多少 si% </p>
<p><img src="/images/951413iMgBlog/image-20220919180725510.png" alt="image-20220919180725510"></p>
<p><img src="/images/951413iMgBlog/image-20220919180758887.png" alt="image-20220919180758887"></p>
<p>软中断和 nginx 跨node（性能相当于同node的70-80%）, 软中断几乎快打满 8 个核了，同时性能还差</p>
<p><img src="/images/951413iMgBlog/image-20220919180916190.png" alt="image-20220919180916190"></p>
<h3 id="网络描述符、数据缓冲区，设备的关系"><a href="#网络描述符、数据缓冲区，设备的关系" class="headerlink" title="网络描述符、数据缓冲区，设备的关系"></a>网络描述符、数据缓冲区，设备的关系</h3><p>网络描述符的内存分配跟着设备走（设备插在哪个node 就就近在本 node 分配描述符的内存）， 数据缓冲区内存跟着队列(中断)走， 如果队列绑定到DIE0， 而设备在DIE1上，这样在做DMA通信时， 会产生跨 DIE 的交织访问.</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>要考虑软中断、以及网卡软中断队列数量对性能的影响</p>
<p>sendfile不一定导致性能变好了</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>完善的Nginx在AWS Graviton上的测试报告<a href="https://armkeil.blob.core.windows.net/developer/Files/pdf/white-paper/guidelines-for-deploying-nginx-plus-on-aws.pdf" target="_blank" rel="external">https://armkeil.blob.core.windows.net/developer/Files/pdf/white-paper/guidelines-for-deploying-nginx-plus-on-aws.pdf</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2022/06/05/上下文切换开销/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/06/05/上下文切换开销/" itemprop="url">上下文切换的代价</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-06-05T17:30:00+08:00">
                2022-06-05
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/performance/" itemprop="url" rel="index">
                    <span itemprop="name">performance</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="上下文切换的代价"><a href="#上下文切换的代价" class="headerlink" title="上下文切换的代价"></a>上下文切换的代价</h1><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>进程切换、软中断、内核态用户态切换、CPU超线程切换</p>
<p>内核态用户态切换：还是在一个线程中，只是由用户态进入内核态为了安全等因素需要更多的指令，系统调用具体多做了啥请看：<a href="https://github.com/torvalds/linux/blob/v5.2/arch/x86/entry/entry_64.S#L145" target="_blank" rel="external">https://github.com/torvalds/linux/blob/v5.2/arch/x86/entry/entry_64.S#L145</a></p>
<p>软中断：比如网络包到达，触发ksoftirqd(每个核一个)进程来处理，是进程切换的一种</p>
<p>进程切换是里面最重的，少不了上下文切换，代价还有进程阻塞唤醒调度。另外进程切换有主动让出CPU的切换、也有时间片用完后被切换</p>
<p>CPU超线程切换：最轻，发生在CPU内部，OS、应用都无法感知</p>
<p>多线程调度下的热点火焰图：</p>
<p><img src="/images/951413iMgBlog/7ece6c553c78927c7886f70c09d7e15b.png" alt="image.png"></p>
<p>上下文切换后还会因为调度的原因导致线程卡顿更久</p>
<p>Linux 内核进程调度时间片一般是HZ的倒数，HZ在编译的时候一般设置为1000，倒数也就是1ms，也就是每个进程的时间片是1ms（早年是10ms–HZ 为100的时候），如果进程1阻塞让出CPU进入调度队列，这个时候调度队列前还有两个进程2/3在排队，也就是最差会在2ms后才轮到1被调度执行。负载决定了排队等待调度队列的长短，如果轮到调度的进程已经ready那么性能没有浪费，反之如果轮到被调度但是没有ready（比如网络回包没到达）相当浪费了一次调度</p>
<blockquote>
<p><code>sched_min_granularity_ns</code> is the most prominent setting. In the original <a href="https://elixir.bootlin.com/linux/v2.6.25/source/Documentation/scheduler/sched-design-CFS.txt#L82" target="_blank" rel="external">sched-design-CFS.txt</a> this was described as the only “tunable” setting, “to tune the scheduler from ‘desktop’ (low latencies) to ‘server’ (good batching) workloads.”</p>
<p>In other words, we can change this setting to reduce overheads from context-switching, and therefore improve throughput at the cost of responsiveness (“latency”).</p>
<p>The CFS setting as mimicking the previous build-time setting, <a href="https://elixir.bootlin.com/linux/v2.6.25/source/kernel/Kconfig.hz" target="_blank" rel="external">CONFIG_HZ</a>. In the first version of the CFS code, the default value was 1 ms, equivalent to 1000 Hz for “desktop” usage. Other supported values of CONFIG_HZ were 250 Hz (the default), and 100 Hz for the “server” end. 100 Hz was also useful when running Linux on very slow CPUs, this was one of the reasons given <a href="https://lwn.net/Articles/56378/" target="_blank" rel="external">when CONFIG_HZ was first added as an build setting on X86</a>.</p>
</blockquote>
<p>或者参数调整：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">#sysctl -a |grep -i sched_ |grep -v cpu</div><div class="line">kernel.sched_autogroup_enabled = 0</div><div class="line">kernel.sched_cfs_bandwidth_slice_us = 5000</div><div class="line">kernel.sched_cfs_bw_burst_enabled = 1</div><div class="line">kernel.sched_cfs_bw_burst_onset_percent = 0</div><div class="line">kernel.sched_child_runs_first = 0</div><div class="line">kernel.sched_latency_ns = 24000000</div><div class="line">kernel.sched_migration_cost_ns = 500000</div><div class="line">kernel.sched_min_granularity_ns = 3000000</div><div class="line">kernel.sched_nr_migrate = 32</div><div class="line">kernel.sched_rr_timeslice_ms = 100</div><div class="line">kernel.sched_rt_period_us = 1000000</div><div class="line">kernel.sched_rt_runtime_us = 950000</div><div class="line">kernel.sched_schedstats = 1</div><div class="line">kernel.sched_tunable_scaling = 1</div><div class="line">kernel.sched_wakeup_granularity_ns = 4000000</div></pre></td></tr></table></figure>
<h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><h3 id="How-long-does-it-take-to-make-a-context-switch"><a href="#How-long-does-it-take-to-make-a-context-switch" class="headerlink" title="How long does it take to make a context switch?"></a><a href="https://blog.tsunanet.net/2010/11/how-long-does-it-take-to-make-context.html" target="_blank" rel="external">How long does it take to make a context switch?</a></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div></pre></td><td class="code"><pre><div class="line">model name : Intel(R) Xeon(R) Platinum 8269CY CPU @ 2.50GHz</div><div class="line">2 physical CPUs, 26 cores/CPU, 2 hardware threads/core = 104 hw threads total</div><div class="line">-- No CPU affinity --</div><div class="line">10000000 system calls in 1144720626ns (114.5ns/syscall)</div><div class="line">2000000 process context switches in 6280519812ns (3140.3ns/ctxsw)</div><div class="line">2000000  thread context switches in 6417846724ns (3208.9ns/ctxsw)</div><div class="line">2000000  thread context switches in 147035970ns (73.5ns/ctxsw)</div><div class="line">-- With CPU affinity --</div><div class="line">10000000 system calls in 1109675081ns (111.0ns/syscall)</div><div class="line">2000000 process context switches in 4204573541ns (2102.3ns/ctxsw)</div><div class="line">2000000  thread context switches in 2740739815ns (1370.4ns/ctxsw)</div><div class="line">2000000  thread context switches in 474815006ns (237.4ns/ctxsw)</div><div class="line">-- With CPU affinity to CPU 0 --</div><div class="line">10000000 system calls in 1039827099ns (104.0ns/syscall)</div><div class="line">2000000 process context switches in 5622932975ns (2811.5ns/ctxsw)</div><div class="line">2000000  thread context switches in 5697704164ns (2848.9ns/ctxsw)</div><div class="line">2000000  thread context switches in 143474146ns (71.7ns/ctxsw)</div><div class="line">----------</div><div class="line">model name : Intel(R) Xeon(R) CPU E5-2682 v4 @ 2.50GHz</div><div class="line">2 physical CPUs, 16 cores/CPU, 2 hardware threads/core = 64 hw threads total</div><div class="line">-- No CPU affinity --</div><div class="line">10000000 system calls in 772827735ns (77.3ns/syscall)</div><div class="line">2000000 process context switches in 4009838007ns (2004.9ns/ctxsw)</div><div class="line">2000000  thread context switches in 5234823470ns (2617.4ns/ctxsw)</div><div class="line">2000000  thread context switches in 193276269ns (96.6ns/ctxsw)</div><div class="line">-- With CPU affinity --</div><div class="line">10000000 system calls in 746578449ns (74.7ns/syscall)</div><div class="line">2000000 process context switches in 3598569493ns (1799.3ns/ctxsw)</div><div class="line">2000000  thread context switches in 2475733882ns (1237.9ns/ctxsw)</div><div class="line">2000000  thread context switches in 381484302ns (190.7ns/ctxsw)</div><div class="line">-- With CPU affinity to CPU 0 --</div><div class="line">10000000 system calls in 746674401ns (74.7ns/syscall)</div><div class="line">2000000 process context switches in 4129856807ns (2064.9ns/ctxsw)</div><div class="line">2000000  thread context switches in 4226458450ns (2113.2ns/ctxsw)</div><div class="line">2000000  thread context switches in 193047255ns (96.5ns/ctxsw)</div><div class="line">---------</div><div class="line">model name : Intel(R) Xeon(R) Platinum 8163 CPU @ 2.50GHz</div><div class="line">2 physical CPUs, 24 cores/CPU, 2 hardware threads/core = 96 hw threads total</div><div class="line">-- No CPU affinity --</div><div class="line">10000000 system calls in 765013680ns (76.5ns/syscall)</div><div class="line">2000000 process context switches in 5906908170ns (2953.5ns/ctxsw)</div><div class="line">2000000  thread context switches in 6741875538ns (3370.9ns/ctxsw)</div><div class="line">2000000  thread context switches in 173271254ns (86.6ns/ctxsw)</div><div class="line">-- With CPU affinity --</div><div class="line">10000000 system calls in 764139687ns (76.4ns/syscall)</div><div class="line">2000000 process context switches in 4040915457ns (2020.5ns/ctxsw)</div><div class="line">2000000  thread context switches in 2327904634ns (1164.0ns/ctxsw)</div><div class="line">2000000  thread context switches in 378847082ns (189.4ns/ctxsw)</div><div class="line">-- With CPU affinity to CPU 0 --</div><div class="line">10000000 system calls in 762375921ns (76.2ns/syscall)</div><div class="line">2000000 process context switches in 5827318932ns (2913.7ns/ctxsw)</div><div class="line">2000000  thread context switches in 6360562477ns (3180.3ns/ctxsw)</div><div class="line">2000000  thread context switches in 173019064ns (86.5ns/ctxsw)</div><div class="line">--------ECS</div><div class="line">model name : Intel(R) Xeon(R) Platinum 8269CY CPU @ 2.50GHz</div><div class="line">1 physical CPUs, 2 cores/CPU, 2 hardware threads/core = 4 hw threads total</div><div class="line">-- No CPU affinity --</div><div class="line">10000000 system calls in 561242906ns (56.1ns/syscall)</div><div class="line">2000000 process context switches in 3025706345ns (1512.9ns/ctxsw)</div><div class="line">2000000  thread context switches in 3333843503ns (1666.9ns/ctxsw)</div><div class="line">2000000  thread context switches in 145410372ns (72.7ns/ctxsw)</div><div class="line">-- With CPU affinity --</div><div class="line">10000000 system calls in 586742944ns (58.7ns/syscall)</div><div class="line">2000000 process context switches in 2369203084ns (1184.6ns/ctxsw)</div><div class="line">2000000  thread context switches in 1929627973ns (964.8ns/ctxsw)</div><div class="line">2000000  thread context switches in 335827569ns (167.9ns/ctxsw)</div><div class="line">-- With CPU affinity to CPU 0 --</div><div class="line">10000000 system calls in 630259940ns (63.0ns/syscall)</div><div class="line">2000000 process context switches in 3027444795ns (1513.7ns/ctxsw)</div><div class="line">2000000  thread context switches in 3172677638ns (1586.3ns/ctxsw)</div><div class="line">2000000  thread context switches in 144168251ns (72.1ns/ctxsw)</div><div class="line">---------kupeng 920</div><div class="line">2 physical CPUs, 96 cores/CPU, 1 hardware threads/core = 192 hw threads total</div><div class="line">-- No CPU affinity --</div><div class="line">10000000 system calls in 1216730780ns (121.7ns/syscall)</div><div class="line">2000000 process context switches in 4653366132ns (2326.7ns/ctxsw)</div><div class="line">2000000  thread context switches in 4689966324ns (2345.0ns/ctxsw)</div><div class="line">2000000  thread context switches in 167871167ns (83.9ns/ctxsw)</div><div class="line">-- With CPU affinity --</div><div class="line">10000000 system calls in 1220106854ns (122.0ns/syscall)</div><div class="line">2000000 process context switches in 3420506934ns (1710.3ns/ctxsw)</div><div class="line">2000000  thread context switches in 2962106029ns (1481.1ns/ctxsw)</div><div class="line">2000000  thread context switches in 543325133ns (271.7ns/ctxsw)</div><div class="line">-- With CPU affinity to CPU 0 --</div><div class="line">10000000 system calls in 1216466158ns (121.6ns/syscall)</div><div class="line">2000000 process context switches in 2797948549ns (1399.0ns/ctxsw)</div><div class="line">2000000  thread context switches in 3119316050ns (1559.7ns/ctxsw)</div><div class="line">2000000  thread context switches in 167728516ns (83.9ns/ctxsw)</div></pre></td></tr></table></figure>
<p>测试代码仓库：<a href="https://github.com/tsuna/contextswitch" target="_blank" rel="external">https://github.com/tsuna/contextswitch</a></p>
<p>Source code: <a href="https://github.com/tsuna/contextswitch/blob/master/timectxsw.c" target="_blank" rel="external">timectxsw.c</a> Results:</p>
<ul>
<li>Intel 5150: ~4300ns/context switch</li>
<li>Intel E5440: ~3600ns/context switch</li>
<li>Intel E5520: ~4500ns/context switch</li>
<li>Intel X5550: ~3000ns/context switch</li>
<li>Intel L5630: ~3000ns/context switch</li>
<li>Intel E5-2620: ~3000ns/context switch</li>
</ul>
<p>如果绑核后上下文切换能提速在66-45%之间</p>
<p>系统调用代价</p>
<p>Source code: <a href="https://github.com/tsuna/contextswitch/blob/master/timesyscall.c" target="_blank" rel="external">timesyscall.c</a> Results:</p>
<ul>
<li>Intel 5150: 105ns/syscall</li>
<li>Intel E5440: 87ns/syscall</li>
<li>Intel E5520: 58ns/syscall</li>
<li>Intel X5550: 52ns/syscall</li>
<li>Intel L5630: 58ns/syscall</li>
<li>Intel E5-2620: 67ns/syscall</li>
</ul>
<p><a href="https://mp.weixin.qq.com/s/uq5s5vwk5vtPOZ30sfNsOg" target="_blank" rel="external">https://mp.weixin.qq.com/s/uq5s5vwk5vtPOZ30sfNsOg</a> 进程/线程切换究竟需要多少开销？</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/*</span></div><div class="line">创建两个进程并在它们之间传送一个令牌。其中一个进程在读取令牌时就会引起阻塞。另一个进程发送令牌后等待其返回时也处于阻塞状态。如此往返传送一定的次数，然后统计他们的平均单次切换时间开销</div><div class="line">代码来自：https://www.jianshu.com/p/be3250786a91</div><div class="line">*/</div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;  </span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;  </span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/time.h&gt;  </span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;time.h&gt;  </span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sched.h&gt;  </span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/types.h&gt;  </span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;      //pipe()  </span></span></div><div class="line">  </div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span>  </span></div><div class="line">&#123;  </div><div class="line">    <span class="keyword">int</span> x, i, fd[<span class="number">2</span>], p[<span class="number">2</span>];  </div><div class="line">    <span class="keyword">char</span> send    = <span class="string">'s'</span>;  </div><div class="line">    <span class="keyword">char</span> receive;  </div><div class="line">    pipe(fd);  </div><div class="line">    pipe(p);  </div><div class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">timeval</span> <span class="title">tv</span>;</span>  </div><div class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">sched_param</span> <span class="title">param</span>;</span>  </div><div class="line">    param.sched_priority = <span class="number">0</span>;  </div><div class="line">  </div><div class="line">    <span class="keyword">while</span> ((x = fork()) == <span class="number">-1</span>); </div><div class="line">    <span class="keyword">if</span> (x==<span class="number">0</span>) &#123;  </div><div class="line">        sched_setscheduler(getpid(), SCHED_FIFO, &amp;param);  </div><div class="line">        gettimeofday(&amp;tv, <span class="literal">NULL</span>);  </div><div class="line">        <span class="built_in">printf</span>(<span class="string">"Before Context Switch Time%u s, %u us\n"</span>, tv.tv_sec, tv.tv_usec);  </div><div class="line">        <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; <span class="number">10000</span>; i++) &#123;  </div><div class="line">            read(fd[<span class="number">0</span>], &amp;receive, <span class="number">1</span>);  </div><div class="line">            write(p[<span class="number">1</span>], &amp;send, <span class="number">1</span>);  </div><div class="line">        &#125;  </div><div class="line">        <span class="built_in">exit</span>(<span class="number">0</span>);  </div><div class="line">    &#125;  </div><div class="line">    <span class="keyword">else</span> &#123;  </div><div class="line">        sched_setscheduler(getpid(), SCHED_FIFO, &amp;param);  </div><div class="line">        <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; <span class="number">10000</span>; i++) &#123;  </div><div class="line">            write(fd[<span class="number">1</span>], &amp;send, <span class="number">1</span>);  </div><div class="line">            read(p[<span class="number">0</span>], &amp;receive, <span class="number">1</span>);  </div><div class="line">        &#125;  </div><div class="line">        gettimeofday(&amp;tv, <span class="literal">NULL</span>);  </div><div class="line">        <span class="built_in">printf</span>(<span class="string">"After Context SWitch Time%u s, %u us\n"</span>, tv.tv_sec, tv.tv_usec);  </div><div class="line">    &#125;  </div><div class="line">    <span class="keyword">return</span> <span class="number">0</span>;  </div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>平均每次上下文切换耗时3.5us左右</p>
<h2 id="软中断开销计算"><a href="#软中断开销计算" class="headerlink" title="软中断开销计算"></a>软中断开销计算</h2><p>下面的计算方法比较糙，仅供参考。压力越大，一次软中断需要处理的网络包数量就越多，消耗的时间越长。如果包数量太少那么测试干扰就太严重了，数据也不准确。</p>
<p>测试机将收发队列设置为1，让所有软中断交给一个core来处理。</p>
<p>无压力时 interrupt大概4000，然后故意跑压力，CPU跑到80%，通过vmstat和top查看：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">$vmstat 1 </div><div class="line">procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----</div><div class="line"> r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st</div><div class="line">19  0      0 174980 151840 3882800    0    0     0    11    1    1  1  0 99  0  0</div><div class="line">11  0      0 174820 151844 3883668    0    0     0     0 30640 113918 59 22 20  0  0</div><div class="line"> 9  0      0 175952 151852 3884576    0    0     0   224 29611 108549 57 22 21  0  0</div><div class="line">11  0      0 171752 151852 3885636    0    0     0  3452 30682 113874 57 22 21  0  0</div></pre></td></tr></table></figure>
<p>top看到 si% 大概为20%，也就是一个核25000个interrupt需要消耗 20% 的CPU, 说明这些软中断消耗了200毫秒</p>
<p>200*1000微秒/25000=200/25=8微秒，8000纳秒 – 偏高</p>
<p>降低压力CPU 跑到55% si消耗12%</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----</div><div class="line"> r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st</div><div class="line"> 6  0      0 174180 152076 3884360    0    0     0     0 25314 119681 40 17 43  0  0</div><div class="line"> 1  0      0 172600 152080 3884308    0    0     0   252 24971 116407 40 17 43  0  0</div><div class="line"> 4  0      0 174664 152080 3884540    0    0     0  3536 25164 118175 39 18 42  0  0</div></pre></td></tr></table></figure>
<p>120*1000微秒/(21000)=5.7微秒， 5700纳秒 – 偏高</p>
<p>降低压力（4核CPU只压到15%）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----</div><div class="line"> r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st</div><div class="line"> 0  0      0 183228 151788 3876288    0    0     0     0 15603 42460  6  3 91  0  0</div><div class="line"> 0  0      0 181312 151788 3876032    0    0     0     0 15943 43129  7  2 91  0  0</div><div class="line"> 1  0      0 181728 151788 3876544    0    0     0  3232 15790 42409  7  3 90  0  0</div><div class="line"> 0  0      0 181584 151788 3875956    0    0     0     0 15728 42641  7  3 90  0  0</div><div class="line"> 1  0      0 179276 151792 3876848    0    0     0   192 15862 42875  6  3 91  0  0</div><div class="line"> 0  0      0 179508 151796 3876424    0    0     0     0 15404 41899  7  2 91  0  0</div></pre></td></tr></table></figure>
<p>单核11000 interrupt，对应 si CPU 2.2%</p>
<p>22*1000/11000= 2微秒 2000纳秒 略微靠谱</p>
<h2 id="超线程切换开销"><a href="#超线程切换开销" class="headerlink" title="超线程切换开销"></a>超线程切换开销</h2><p>最小，基本可以忽略，1ns以内</p>
<h2 id="lmbench测试工具"><a href="#lmbench测试工具" class="headerlink" title="lmbench测试工具"></a>lmbench测试工具</h2><p>lmbench的lat_ctx等，单位是微秒，压力小的时候一次进程的上下文是1540纳秒</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">[root@plantegg 13:19 /root/lmbench3]</div><div class="line"><span class="meta">#</span><span class="bash">taskset -c 4 ./bin/lat_ctx -P 2 -W warmup -s 64 2  //CPU 打满</span></div><div class="line">"size=64k ovr=3.47</div><div class="line">2 7.88</div><div class="line"><span class="meta"></span></div><div class="line">#<span class="bash">taskset -c 4 ./bin/lat_ctx -P 1 -W warmup -s 64 2</span></div><div class="line">"size=64k ovr=3.46</div><div class="line">2 1.54</div><div class="line"><span class="meta"></span></div><div class="line">#<span class="bash">taskset -c 4-5 ./bin/lat_ctx  -W warmup -s 64 2</span></div><div class="line">"size=64k ovr=3.44</div><div class="line">2 3.11</div><div class="line"><span class="meta"></span></div><div class="line">#<span class="bash">taskset -c 4-7 ./bin/lat_ctx -P 2 -W warmup -s 64 2  //CPU 打到50%</span></div><div class="line">"size=64k ovr=3.48</div><div class="line">2 3.14</div><div class="line"><span class="meta"></span></div><div class="line">#<span class="bash">taskset -c 4-15 ./bin/lat_ctx -P 3 -W warmup -s 64 2</span></div><div class="line">"size=64k ovr=3.46</div><div class="line">2 3.18</div></pre></td></tr></table></figure>
<h2 id="协程对性能的影响"><a href="#协程对性能的影响" class="headerlink" title="协程对性能的影响"></a>协程对性能的影响</h2><p>将WEB服务改用协程调度后，TPS提升50%（30000提升到45000），而contextswitch数量从11万降低到8000（无压力的cs也有4500）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----</div><div class="line"> r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st</div><div class="line"> 5  0      0 3831480 153136 3819244    0    0     0     0 23599 6065 79 19  2  0  0</div><div class="line"> 4  0      0 3829208 153136 3818824    0    0     0   160 23324 7349 80 18  2  0  0</div><div class="line"> 4  0      0 3833320 153140 3818672    0    0     0     0 24567 8213 80 19  2  0  0</div><div class="line"> 4  0      0 3831880 153140 3818532    0    0     0     0 24339 8350 78 20  2  0  0</div><div class="line"> </div><div class="line">[  99s] threads: 60, tps: 0.00, reads/s: 44609.77, writes/s: 0.00, response time: 2.05ms (95%)</div><div class="line">[ 100s] threads: 60, tps: 0.00, reads/s: 46538.27, writes/s: 0.00, response time: 1.99ms (95%)</div><div class="line">[ 101s] threads: 60, tps: 0.00, reads/s: 46061.84, writes/s: 0.00, response time: 2.01ms (95%)</div><div class="line">[ 102s] threads: 60, tps: 0.00, reads/s: 46961.05, writes/s: 0.00, response time: 1.94ms (95%)</div><div class="line">[ 103s] threads: 60, tps: 0.00, reads/s: 46224.15, writes/s: 0.00, response time: 2.00ms (95%)</div><div class="line">[ 104s] threads: 60, tps: 0.00, reads/s: 46556.93, writes/s: 0.00, response time: 1.98ms (95%)</div><div class="line">[ 105s] threads: 60, tps: 0.00, reads/s: 45965.12, writes/s: 0.00, response time: 1.97ms (95%)</div><div class="line">[ 106s] threads: 60, tps: 0.00, reads/s: 46369.96, writes/s: 0.00, response time: 2.01ms (95%)</div><div class="line"></div><div class="line">//4core 机器下</div><div class="line"> PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND</div><div class="line"> 11588 admin     20   0   12.9g   6.9g  22976 R 95.7 45.6   0:33.07 Root-Worke //四个协程把CPU基本跑满</div><div class="line"> 11586 admin     20   0   12.9g   6.9g  22976 R 93.7 45.6   0:34.29 Root-Worke</div><div class="line"> 11587 admin     20   0   12.9g   6.9g  22976 R 93.7 45.6   0:32.58 Root-Worke</div><div class="line"> 11585 admin     20   0   12.9g   6.9g  22976 R 92.0 45.6   0:33.25 Root-Worke</div></pre></td></tr></table></figure>
<p>没开协程CPU有20%闲置打不上去，开了协程后CPU 跑到95%</p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><ul>
<li>进程上下文切换需要几千纳秒（不同CPU型号会有差异）</li>
<li>如果做taskset 那么上下文切换会减少50%的时间（避免了L1、L2 Miss等）</li>
<li>线程比进程上下文切换略快10%左右</li>
<li>测试数据和实际运行场景相关很大，比较难以把控，CPU竞争太激烈容易把等待调度时间计入；如果CPU比较闲体现不出cache miss等导致的时延加剧</li>
<li>系统调用相对进程上下文切换就很轻了，大概100ns以内</li>
<li>函数调用更轻，大概几个ns，压栈跳转</li>
<li>CPU的超线程调度和函数调用差不多，都是几个ns可以搞定</li>
</ul>
<p>看完这些数据再想想协程是在做什么、为什么效率高就很自然的了</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2022/05/05/Netty和Disruptor的cache_line对齐实践/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/05/05/Netty和Disruptor的cache_line对齐实践/" itemprop="url">Netty和Disruptor的cache_line对齐实践</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-05-05T18:20:03+08:00">
                2022-05-05
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CPU/" itemprop="url" rel="index">
                    <span itemprop="name">CPU</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Netty和Disruptor的cache-line对齐实践"><a href="#Netty和Disruptor的cache-line对齐实践" class="headerlink" title="Netty和Disruptor的cache_line对齐实践"></a>Netty和Disruptor的cache_line对齐实践</h1><p>原理先看这篇：<a href="https://plantegg.github.io/2021/05/16/CPU_Cache_Line%E5%92%8C%E6%80%A7%E8%83%BD/">CPU 性能和Cache Line</a></p>
<p>写这篇文章的起因是这个 <a href="https://mp.weixin.qq.com/s/vkCskOVSpzxt3Umzc_GYrQ" target="_blank" rel="external">记一次 Netty PR 的提交</a>，然后我去看了下这次提交，发现Netty的这部分代码有问题、这次提交也有问题</p>
<h2 id="什么是-cache-line"><a href="#什么是-cache-line" class="headerlink" title="什么是 cache_line"></a>什么是 cache_line</h2><p>CPU从内存中读取数据的时候是一次读一个cache_line到 cache中以提升效率，一般情况下cache_line的大小是64 byte，也就是每次读取64byte到CPU cache中，按照热点逻辑这个cache line中的数据大概率会被访问到。</p>
<h3 id="cache-失效"><a href="#cache-失效" class="headerlink" title="cache 失效"></a>cache 失效</h3><p>假设CPU的两个核 A 和 B, 都在各自本地 Cache Line 里有同一个变量1的拷贝时，此时该 Cache Line 处于 Shared 状态。当 核A 在本地修改了变量2，除去把本地变量所属的 Cache Line 置为 Modified 状态以外，还必须在另一个 核B 读另一个变量2前，对该变量所在的 B 处理器本地 Cache Line 发起 Invaidate 操作，标记 B 处理器的那条 Cache Line 为 Invalidate 状态。随后，若处理器 B 在对变量做读写操作时，如果遇到这个标记为 Invalidate 的状态的 Cache Line，即会引发 Cache Miss，从而将内存中最新的数据拷贝到 Cache Line 里，然后处理器 B 再对此 Cache Line 对变量做读写操作。</p>
<p>上面这个过程也叫false-share, 即伪共享，因为变量1、2不是真的关联共享，本来变量1失效不应该导致变量2失效，但是因为cache line机制的存在导致 变量2也失效了，所以这里变量1、2叫false-share</p>
<h2 id="Disruptor中对cache-line的使用"><a href="#Disruptor中对cache-line的使用" class="headerlink" title="Disruptor中对cache_line的使用"></a>Disruptor中对cache_line的使用</h2><p>Disruptor中为了保护下面的那几个final 成员变量，前后都加了 p1-p7就是为了避免这4个final成员不要和别的变量放到同一个cache line中。</p>
<p>重点留意下面代码中的p1-p7这几个没有用的long变量，实际使用来占位，占住实际变量前后的位置，这样避免这些变量被其他变量的修改而失效。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">abstract class RingBufferPad</div><div class="line">&#123;</div><div class="line">    protected long p1, p2, p3, p4, p5, p6, p7;</div><div class="line">&#125;</div><div class="line">  </div><div class="line">abstract class RingBufferFields&lt;E&gt; extends RingBufferPad</div><div class="line">&#123;</div><div class="line">    ......    </div><div class="line">    private final long indexMask;</div><div class="line">    private final Object[] entries;</div><div class="line">    protected final int bufferSize;</div><div class="line">    protected final Sequencer sequencer;</div><div class="line">    ......    </div><div class="line">&#125;</div><div class="line"></div><div class="line">public final class RingBuffer&lt;E&gt; extends RingBufferFields&lt;E&gt; implements Cursored, EventSequencer&lt;E&gt;, EventSink&lt;E&gt;</div><div class="line">&#123;</div><div class="line">    ......    </div><div class="line">    protected long p1, p2, p3, p4, p5, p6, p7;</div><div class="line">    ......</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>结果如下图所示绿色部分很好地被保护起来一定是独占一个cache line，本来绿色部分都是final，也就是你理解成只读的，不会更改了，这样不会因为共享cache line的变量被修改导致他们所在的cache失效（完全没必要）</p>
<p><img src="/images/951413iMgBlog/1620984677390-81694fd0-0323-4052-98d1-32be39a02248-4505908.png" alt="image.png"></p>
<p>队列大部分时候都是空的（head挨着tail），也就导致head 和 tail在一个cache line中，读和写会造成没必要的cache ping-pong，一般可以通过将head 和 tail 中间填充其它内容来实现错开到不同的cache line中</p>
<p><img src="/images/951413iMgBlog/1577093636588-6b58c36c-1617-4f2c-aba9-156c52972689-1744256.png" alt="image"></p>
<p>数组(RingBuffer)基本能保证元素在内存中是连续的，但是Queue（链表）就不一定了，连续的话更利于CPU cache</p>
<h2 id="Netty中cache-line的对齐"><a href="#Netty中cache-line的对齐" class="headerlink" title="Netty中cache line的对齐"></a>Netty中cache line的对齐</h2><p><a href="https://github.com/arthur-zhang/netty/blob/e8250372cafe4cf5435a1dbc4c8e400072fb9791/common/src/main/java/io/netty/util/internal/InternalThreadLocalMap.java" target="_blank" rel="external">注意下图12行</a>的代码，重点也请注意下11行的注释</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">// String-related thread-locals</div><div class="line">private StringBuilder stringBuilder;</div><div class="line">private Map&lt;Charset, CharsetEncoder&gt; charsetEncoderCache;</div><div class="line">private Map&lt;Charset, CharsetDecoder&gt; charsetDecoderCache;</div><div class="line"></div><div class="line">// ArrayList-related thread-locals</div><div class="line">private ArrayList&lt;Object&gt; arrayList;</div><div class="line"></div><div class="line">private BitSet cleanerFlags;</div><div class="line"></div><div class="line">/** @deprecated These padding fields will be removed in the future. */</div><div class="line">public long rp1, rp2, rp3, rp4, rp5, rp6, rp7, rp8;</div><div class="line"></div><div class="line">static &#123;</div><div class="line">    STRING_BUILDER_INITIAL_SIZE =</div><div class="line">            SystemPropertyUtil.getInt(&quot;io.netty.threadLocalMap.stringBuilder.initialSize&quot;, 1024);</div><div class="line">    logger.debug(&quot;-Dio.netty.threadLocalMap.stringBuilder.initialSize: &#123;&#125;&quot;, STRING_BUILDER_INITIAL_SIZE);</div><div class="line"></div><div class="line">    STRING_BUILDER_MAX_SIZE = SystemPropertyUtil.getInt(&quot;io.netty.threadLocalMap.stringBuilder.maxSize&quot;, 1024 * 4);</div><div class="line">    logger.debug(&quot;-Dio.netty.threadLocalMap.stringBuilder.maxSize: &#123;&#125;&quot;, STRING_BUILDER_MAX_SIZE);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>一看这里也和Disruptor一样想保护某个变量尽量少失效，可是这个实现我看不出来想要保护哪个变量，因为这种保护办法只对齐了一边，还有一边是和别的变量共享cache line。</p>
<p>另外这个代码之前是9个long rp来对齐，这个<a href="https://github.com/netty/netty/pull/12309" target="_blank" rel="external">PR</a>改成了8个，9个就实在是迷惑了（9个long占72bytes了）对齐也是64bytes就好了</p>
<p>还是按照11行注释所说去掉这个对齐的rp吧，要不明确要保护哪些变量，前后夹击真正保护起来，并且做好对比测试</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Netty的这段代码纸上谈兵更多一点，Donald E. Knuth 告诉我们不要提前优化</p>
<h2 id="系列文章"><a href="#系列文章" class="headerlink" title="系列文章"></a>系列文章</h2><p><a href="/2021/06/01/CPU的制造和概念/">CPU的制造和概念</a></p>
<p><a href="/2021/05/16/Perf IPC以及CPU利用率/">Perf IPC以及CPU性能</a></p>
<p><a href="/2021/05/16/CPU Cache Line 和性能/">CPU 性能和Cache Line</a></p>
<p><a href="/2021/05/14/十年后数据库还是不敢拥抱NUMA/">十年后数据库还是不敢拥抱NUMA？</a></p>
<p><a href="/2019/12/16/Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的/">Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的</a></p>
<p><a href="/2021/06/18/几款CPU性能对比/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></p>
<p><a href="/2021/03/07/一次海光物理机资源竞争压测的记录/">一次海光物理机资源竞争压测的记录</a></p>
<p><a href="/2021/05/15/飞腾ARM芯片-FT2500的性能测试/">飞腾ARM芯片(FT2500)的性能测试</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2022/03/15/记一次听风扇声音来定位性能/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/03/15/记一次听风扇声音来定位性能/" itemprop="url">听风扇声音来定位性能瓶颈</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-03-15T17:30:03+08:00">
                2022-03-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CPU/" itemprop="url" rel="index">
                    <span itemprop="name">CPU</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="记一次听风扇声音来定位性能瓶颈"><a href="#记一次听风扇声音来定位性能瓶颈" class="headerlink" title="记一次听风扇声音来定位性能瓶颈"></a>记一次听风扇声音来定位性能瓶颈</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在一次POC测试过程中，测试机构提供了两台Intel压力机来压我们的集群</p>
<ul>
<li>压力机1：两路共72core intel 5XXX系列 CPU，主频2.2GHz， 128G内存</li>
<li>压力机2：四路共196core intel 8XXX系列 CPU，主频2.5GHz， 256G内存 （8系列比5系列 CPU的性能要好、要贵）</li>
</ul>
<p>从CPU硬件指标来看压力机2都是碾压压力机1，但是实际测试是压力机2只能跑到接近压力机1的能力，两台机器CPU基本都跑满，并且都是压测进程消耗了90%以上的CPU，内核态消耗不到5%CPU</p>
<p>所以接下来需要在调试我们集群性能前先把测试机优化好，才能把压力打上来。</p>
<h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>测试机构提供的机器上没有任何工具来评估CPU性能，也无法安装，只能<strong>仔细听196core机器的CPU风扇声音更小，说明196core的CPU出工不出力，大概是流水线在频繁地Stall</strong>（不管你信不信反正我是信的）</p>
<p>进一步分析，首先看到 业务消耗了90%以上的CPU，内核态消耗不到5%CPU，两台机器都是这样，这说明 196core 只跑出了 72core的水平，一定是CPU效率出了问题，top看到的CPU占用率不完全是全力在运算，其实cpu 流水线stall也是占用CPU的。</p>
<p>这个分析理论请参考我的文章<a href="https://plantegg.github.io/2021/05/16/Perf%20IPC%E4%BB%A5%E5%8F%8ACPU%E5%88%A9%E7%94%A8%E7%8E%87/">《Perf IPC以及CPU性能》</a></p>
<h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>通过stream测试读写内存的带宽和时延，得到如下数据：</p>
<p>72core机器，  本路时延1.1，跨路时延1.4，因为是2路所以有50%的概率跨路，性能下降30%</p>
<p>196core机器，本路时延1.2，跨路时延1.85，因为是4路所以有75%的概率跨路，性能下降50%</p>
<p>从以上测试数据可以明显看到虽然196core机器拥有更强的单核能力以及更多的核数，但是因为访问内存太慢严重拖累了CPU运算能力，导致大部分时间CPU都在等待内存，这里CPU和内存的速度差了2个数量级，所以内存延时才是整体的瓶颈。</p>
<p>测试数据和方法请参考我的文章<a href="https://plantegg.github.io/2021/06/18/%E5%87%A0%E6%AC%BECPU%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94/">《AMD Zen CPU 架构以及不同CPU性能大PK》</a></p>
<p>有了这个数据心里非常有底问题在哪里了，但是还要想清楚怎么解释给测试机构他们才会信服，因为第一次解释他们直接说不可能，怎么会196core打不过72core呢，再说从来没有集群是测试机构196core压力机打不满的，这台压力机用了几年从来没有人说过这个问题 :(</p>
<h2 id="内存信息"><a href="#内存信息" class="headerlink" title="内存信息"></a>内存信息</h2><p>接下来需要拿到更详细的硬件信息来说服测试机构了。</p>
<p>通过dmidecode 获取两台机器内存的速度，分别是2100（196core） VS 2900（72core），同时系统也吐出了内存延时分别是 0.5ns VS 0.3 ns，这两个时间对比很直观，普通人也能看懂。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div></pre></td><td class="code"><pre><div class="line">//以下硬件信息是从家里机器上获取，并非测试机构提供的机器，测试机构提供的机器不让拍照和采集</div><div class="line">#dmidecode -t memory</div><div class="line"># dmidecode 3.2</div><div class="line">Getting SMBIOS data from sysfs.</div><div class="line">SMBIOS 3.2.1 present.</div><div class="line"># SMBIOS implementations newer than version 3.2.0 are not</div><div class="line"># fully supported by this version of dmidecode.</div><div class="line"></div><div class="line">Handle 0x0033, DMI type 16, 23 bytes </div><div class="line">Physical Memory Array</div><div class="line">	Location: System Board Or Motherboard</div><div class="line">	Use: System Memory</div><div class="line">	Error Correction Type: Multi-bit ECC</div><div class="line">	Maximum Capacity: 2 TB  //最大支持2T</div><div class="line">	Error Information Handle: 0x0032</div><div class="line">	Number Of Devices: 32   //32个插槽</div><div class="line">	</div><div class="line">	Handle 0x0041, DMI type 17, 84 bytes</div><div class="line">Memory Device</div><div class="line">	Array Handle: 0x0033</div><div class="line">	Error Information Handle: 0x0040</div><div class="line">	Total Width: 72 bits</div><div class="line">	Data Width: 64 bits</div><div class="line">	Size: 32 GB</div><div class="line">	Form Factor: DIMM</div><div class="line">	Set: None</div><div class="line">	Locator: CPU0_DIMMA0</div><div class="line">	Bank Locator: P0 CHANNEL A</div><div class="line">	Type: DDR4</div><div class="line">	Type Detail: Synchronous Registered (Buffered)</div><div class="line">	Speed: 2933 MT/s                    //dmmi 内存插槽支持最大速度 ?</div><div class="line">	Manufacturer: SK Hynix</div><div class="line">	Serial Number: 220F9EC0</div><div class="line">	Asset Tag: Not Specified</div><div class="line">	Part Number: HMAA4GR7AJR8N-WM</div><div class="line">	Rank: 2</div><div class="line">	Configured Memory Speed: 2100 MT/s  //内存实际运行速度</div><div class="line">	Minimum Voltage: 1.2 V</div><div class="line">	Maximum Voltage: 1.2 V</div><div class="line">	Configured Voltage: 1.2 V</div><div class="line">	Memory Technology: DRAM</div><div class="line">	Memory Operating Mode Capability: Volatile memory</div><div class="line">	Module Manufacturer ID: Bank 1, Hex 0xAD</div><div class="line">	Non-Volatile Size: None</div><div class="line">	Volatile Size: 32 GB</div><div class="line">	</div><div class="line">	#lshw</div><div class="line">	*-bank:19  //主板插槽槽位</div><div class="line">             description: DIMM DDR4 Synchronous Registered (Buffered) 2933 MHz (0.3 ns) </div><div class="line">             product: HMAA4GR7AJR8N-WM</div><div class="line">             vendor: SK Hynix</div><div class="line">             physical id: 13</div><div class="line">             serial: 220F9F63</div><div class="line">             slot: CPU1_DIMMB0</div><div class="line">             size: 32GiB  //实际所插内存大小</div><div class="line">             width: 64 bits</div><div class="line">             clock: 2933MHz (0.3ns)</div></pre></td></tr></table></figure>
<blockquote>
<p>In <code>dmidecode</code>’s output for memory, “Speed” is the highest speed supported by the DIMM, as determined by <a href="https://en.wikipedia.org/wiki/JEDEC" target="_blank" rel="external">JEDEC</a> SPD information. “Configured Clock Speed” is the speed at which it is currently running (as set up during boot).</p>
</blockquote>
<p>Dimm（双列直插式存储模块（dual In-line memory module））： DIMM是内存条印刷电路板正反面均有金手指与主板上的内存条槽接触，这种结构被称为DIMM。于是内存条也有人叫DIMM条，主板上的内存槽也有人称为DIMM槽。</p>
<p>DIMM 代表物理上的一根内存条，下图中三根内存条共享一个channel连到 CPU</p>
<p><img src="/images/951413iMgBlog/05-05_DPC_Bandwidth_Impact.svg" alt="05-05_DPC_Bandwidth_Impact"></p>
<p><img src="/images/951413iMgBlog/image-20220705104403314.png" alt="image-20220705104403314"></p>
<p><img src="/images/951413iMgBlog/8f04a1f57fe07692327b9269ba484ce4.jpg" alt="img"></p>
<h2 id="最终的运行方案"><a href="#最终的运行方案" class="headerlink" title="最终的运行方案"></a>最终的运行方案</h2><p>给196core的机器换上新的2933 MHz (0.3 ns)的内存条，速度一下子就上去了。</p>
<p>然后在196core的机器上起4个压力进程，每个进程分担25%的压力，避免跨路访问内存导致时延从1.2掉到1.8，实际测试也是只用196core中的48core性能和用全部196core是一样的，所以这里一定要起多个进程做内存亲和性绑定，充分使用全部196core。</p>
<p><strong>最终整机196core机器的打压能力达到了原来的3.6倍左右。</strong></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>程序员要保护好听力，关键时刻可能会用上 :)</p>
<p>你说196core机器用了这么强的CPU但是为什么搭配那么差的内存以及主板，我也不知道，大概是有人拿回扣吧。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://frankdenneman.nl/2016/07/13/numa-deep-dive-4-local-memory-optimization/" target="_blank" rel="external">NUMA DEEP DIVE PART 4: LOCAL MEMORY OPTIMIZATION</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2022/01/25/ssd_san和sas磁盘性能比较/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/01/25/ssd_san和sas磁盘性能比较/" itemprop="url">ssd/san/sas/磁盘/光纤性能比较</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-01-25T17:30:03+08:00">
                2022-01-25
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/performance/" itemprop="url" rel="index">
                    <span itemprop="name">performance</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="ssd-san-sas-磁盘-光纤-RAID性能比较"><a href="#ssd-san-sas-磁盘-光纤-RAID性能比较" class="headerlink" title="ssd/san/sas/磁盘/光纤/RAID性能比较"></a>ssd/san/sas/磁盘/光纤/RAID性能比较</h1><p>本文汇总HDD、SSD、SAN、LVM、软RAID等一些性能数据</p>
<h2 id="性能比较"><a href="#性能比较" class="headerlink" title="性能比较"></a>性能比较</h2><p>正好有机会用到一个san存储设备，跑了一把性能数据，记录一下</p>
<p><img src="/images/oss/d57a004c846e193126ca01398e394319.png" alt="image.png"></p>
<p>所使用的测试命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">fio -ioengine=libaio -bs=4k -direct=1 -thread -rw=randwrite -size=1000G -filename=/data/fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div></pre></td></tr></table></figure>
<p>ssd（Solid State Drive）和san的比较是在同一台物理机上，所以排除了其他因素的干扰。</p>
<p>简要的结论： </p>
<ul>
<li><p>本地ssd性能最好、sas机械盘(RAID10)性能最差</p>
</li>
<li><p>san存储走特定的光纤网络，不是走tcp的san（至少从网卡看不到san的流量），性能居中</p>
</li>
<li><p>从rt来看 ssd:san:sas 大概是 1:3:15</p>
</li>
<li><p>san比本地sas机械盘性能要好，这也许取决于san的网络传输性能和san存储中的设备（比如用的ssd而不是机械盘）</p>
</li>
</ul>
<h2 id="NVMe-SSD-和-HDD的性能比较"><a href="#NVMe-SSD-和-HDD的性能比较" class="headerlink" title="NVMe SSD 和 HDD的性能比较"></a>NVMe SSD 和 HDD的性能比较</h2><p><img src="/images/oss/d64a0f78ebf471ac69d447ecb46d90f1.png" alt="image.png"></p>
<p>表中性能差异比上面测试还要大，SSD 的随机 IO 延迟比传统硬盘快百倍以上，一般在微妙级别；IO 带宽也高很多倍，可以达到每秒几个 GB；随机 IOPS 更是快了上千倍，可以达到几十万。</p>
<p><strong>HDD只有一个磁头，并发没有意义，但是SSD支持高并发写入读取。SSD没有磁头、不需要旋转，所以随机读取和顺序读取基本没有差别。</strong></p>
<p><img src="/images/951413iMgBlog/1ab661ee2d3a71f54bae3ecf62982e7e.png" alt="img"></p>
<p>从上图可以看出如果是随机读写HDD性能极差，但是如果是顺序读写HDD和SDD、内存差异就不那么大了。</p>
<h2 id="磁盘类型查看"><a href="#磁盘类型查看" class="headerlink" title="磁盘类型查看"></a>磁盘类型查看</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">$cat /sys/block/vda/queue/rotational</div><div class="line">1  //1表示旋转，非ssd，0表示ssd</div><div class="line"></div><div class="line">或者</div><div class="line">lsblk -d -o name,rota,size,label,uuid</div></pre></td></tr></table></figure>
<h2 id="fio测试"><a href="#fio测试" class="headerlink" title="fio测试"></a>fio测试</h2><p>以下是两块测试的SSD磁盘测试前的基本情况</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line">/dev/sda	240.06G  SSD_SATA  //sata</div><div class="line">/dev/sfd0n1	3200G	 SSD_PCIE  //PCIE</div><div class="line"></div><div class="line">Filesystem      Size  Used Avail Use% Mounted on</div><div class="line">/dev/sda3        49G   29G   18G  63% / </div><div class="line">/dev/sfdv0n1p1  2.0T  803G  1.3T  40% /data</div><div class="line"></div><div class="line"># cat /sys/block/sda/queue/rotational </div><div class="line">0</div><div class="line"># cat /sys/block/sfdv0n1/queue/rotational </div><div class="line">0</div><div class="line"></div><div class="line">#测试前的iostat状态</div><div class="line"># iostat -d sfdv0n1 sda3 1 -x</div><div class="line">Linux 3.10.0-957.el7.x86_64 (nu4d01142.sqa.nu8) 	2021年02月23日 	_x86_64_	(104 CPU)</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">sda3              0.00    10.67    1.24   18.78     7.82   220.69    22.83     0.03    1.64    1.39    1.66   0.08   0.17</div><div class="line">sfdv0n1           0.00     0.21    9.91  841.42   128.15  8237.10    19.65     0.93    0.04    0.25    0.04   1.05  89.52</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">sda3              0.00    15.00    0.00   17.00     0.00   136.00    16.00     0.03    2.00    0.00    2.00   1.29   2.20</div><div class="line">sfdv0n1           0.00     0.00    0.00 11158.00     0.00 54448.00     9.76     1.03    0.02    0.00    0.02   0.09 100.00</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">sda3              0.00     5.00    0.00   18.00     0.00   104.00    11.56     0.01    0.61    0.00    0.61   0.61   1.10</div><div class="line">sfdv0n1           0.00     0.00    0.00 10970.00     0.00 53216.00     9.70     1.02    0.03    0.00    0.03   0.09 100.10</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">sda3              0.00     0.00    0.00   24.00     0.00   100.00     8.33     0.01    0.58    0.00    0.58   0.08   0.20</div><div class="line">sfdv0n1           0.00     0.00    0.00 11206.00     0.00 54476.00     9.72     1.03    0.03    0.00    0.03   0.09  99.90</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">sda3              0.00    14.00    0.00   21.00     0.00   148.00    14.10     0.01    0.48    0.00    0.48   0.33   0.70</div><div class="line">sfdv0n1           0.00     0.00    0.00 10071.00     0.00 49028.00     9.74     1.02    0.03    0.00    0.03   0.10  99.80</div></pre></td></tr></table></figure>
<h3 id="NVMe-SSD测试数据"><a href="#NVMe-SSD测试数据" class="headerlink" title="NVMe SSD测试数据"></a>NVMe SSD测试数据</h3><p>对一块ssd进行如下测试(挂载在/data 目录)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line">fio -ioengine=libaio -bs=4k -direct=1 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div><div class="line">EBS 4K randwrite test: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</div><div class="line">fio-3.7</div><div class="line">Starting 1 thread</div><div class="line">EBS 4K randwrite test: Laying out IO file (1 file / 16384MiB)</div><div class="line">Jobs: 1 (f=1): [w(1)][100.0%][r=0KiB/s,w=63.8MiB/s][r=0,w=16.3k IOPS][eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=258871: Tue Feb 23 14:12:23 2021</div><div class="line">  write: IOPS=18.9k, BW=74.0MiB/s (77.6MB/s)(4441MiB/60001msec)</div><div class="line">    slat (usec): min=4, max=6154, avg=48.82, stdev=56.38</div><div class="line">    clat (nsec): min=1049, max=12360k, avg=3326362.62, stdev=920683.43</div><div class="line">     lat (usec): min=68, max=12414, avg=3375.52, stdev=928.97</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[ 1483],  5.00th=[ 1811], 10.00th=[ 2114], 20.00th=[ 2376],</div><div class="line">     | 30.00th=[ 2704], 40.00th=[ 3130], 50.00th=[ 3523], 60.00th=[ 3785],</div><div class="line">     | 70.00th=[ 3949], 80.00th=[ 4080], 90.00th=[ 4293], 95.00th=[ 4490],</div><div class="line">     | 99.00th=[ 5604], 99.50th=[ 5997], 99.90th=[ 7111], 99.95th=[ 7832],</div><div class="line">     | 99.99th=[ 9634]</div><div class="line">   bw (  KiB/s): min=61024, max=118256, per=99.98%, avg=75779.58, stdev=12747.95, samples=120</div><div class="line">   iops        : min=15256, max=29564, avg=18944.88, stdev=3186.97, samples=120</div><div class="line">  lat (usec)   : 2=0.01%, 100=0.01%, 250=0.01%, 500=0.01%, 750=0.02%</div><div class="line">  lat (usec)   : 1000=0.06%</div><div class="line">  lat (msec)   : 2=7.40%, 4=66.19%, 10=26.32%, 20=0.01%</div><div class="line">  cpu          : usr=5.23%, sys=46.71%, ctx=846953, majf=0, minf=6</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued rwts: total=0,1136905,0,0 short=0,0,0,0 dropped=0,0,0,0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">  WRITE: bw=74.0MiB/s (77.6MB/s), 74.0MiB/s-74.0MiB/s (77.6MB/s-77.6MB/s), io=4441MiB (4657MB), run=60001-60001msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">  sfdv0n1: ios=0/1821771, merge=0/7335, ticks=0/39708, in_queue=78295, util=100.00%</div></pre></td></tr></table></figure>
<p>如上测试iops为：18944，测试期间的iostat，测试中一直有mysql在导入数据，所以测试开始前util就已经100%了，并且w/s到了13K左右</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"># iostat -d sfdv0n1 3 -x</div><div class="line">Linux 3.10.0-957.el7.x86_64 (nu4d01142.sqa.nu8) 	2021年02月23日 	_x86_64_	(104 CPU)</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">sfdv0n1           0.00     0.18    3.45  769.17   102.83  7885.16    20.68     0.93    0.04    0.26    0.04   1.16  89.46</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">sfdv0n1           0.00     0.00    0.00 13168.67     0.00 66244.00    10.06     1.05    0.03    0.00    0.03   0.08 100.10</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">sfdv0n1           0.00     0.00    0.00 12822.67     0.00 65542.67    10.22     1.04    0.02    0.00    0.02   0.08 100.07</div><div class="line"></div><div class="line">//增加压力</div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">sfdv0n1           0.00     0.00    0.00 27348.33     0.00 214928.00    15.72     1.27    0.02    0.00    0.02   0.04 100.17</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">sfdv0n1           0.00     1.00    0.00 32661.67     0.00 271660.00    16.63     1.32    0.02    0.00    0.02   0.03 100.37</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">sfdv0n1           0.00     0.00    0.00 31645.00     0.00 265988.00    16.81     1.33    0.02    0.00    0.02   0.03 100.37</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">sfdv0n1           0.00   574.00    0.00 31961.67     0.00 271094.67    16.96     1.36    0.02    0.00    0.02   0.03 100.13</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">sfdv0n1           0.00     0.00    0.00 27656.33     0.00 224586.67    16.24     1.28    0.02    0.00    0.02   0.04 100.37</div></pre></td></tr></table></figure>
<p>从iostat看出，测试开始前util已经100%（因为ssd，util失去参考意义），w/s 13K左右，压力跑起来后w/s能到30K，svctm、await均保持稳定</p>
<p>如下测试中direct=1和direct=0的write avg iops分别为42K、16K</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div></pre></td><td class="code"><pre><div class="line"># fio -ioengine=libaio -bs=4k -direct=1 -buffered=0 -thread -rw=randrw -rwmixread=70 -size=16G -filename=/data/fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60 </div><div class="line">EBS 4K randwrite test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</div><div class="line">fio-3.7</div><div class="line">Starting 1 thread</div><div class="line">Jobs: 1 (f=1): [m(1)][100.0%][r=507MiB/s,w=216MiB/s][r=130k,w=55.2k IOPS][eta 00m:00s] </div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=415921: Tue Feb 23 14:34:33 2021</div><div class="line">   read: IOPS=99.8k, BW=390MiB/s (409MB/s)(11.2GiB/29432msec)</div><div class="line">    slat (nsec): min=1043, max=917837, avg=4273.86, stdev=3792.17</div><div class="line">    clat (usec): min=2, max=4313, avg=459.80, stdev=239.61</div><div class="line">     lat (usec): min=4, max=4328, avg=464.16, stdev=241.81</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[  251],  5.00th=[  277], 10.00th=[  289], 20.00th=[  310],</div><div class="line">     | 30.00th=[  326], 40.00th=[  343], 50.00th=[  363], 60.00th=[  400],</div><div class="line">     | 70.00th=[  502], 80.00th=[  603], 90.00th=[  750], 95.00th=[  881],</div><div class="line">     | 99.00th=[ 1172], 99.50th=[ 1401], 99.90th=[ 3032], 99.95th=[ 3359],</div><div class="line">     | 99.99th=[ 3785]</div><div class="line">   bw (  KiB/s): min=182520, max=574856, per=99.24%, avg=395975.64, stdev=119541.78, samples=58</div><div class="line">   iops        : min=45630, max=143714, avg=98993.90, stdev=29885.42, samples=58</div><div class="line">  write: IOPS=42.8k, BW=167MiB/s (175MB/s)(4915MiB/29432msec)</div><div class="line">    slat (usec): min=3, max=263, avg= 9.34, stdev= 4.35</div><div class="line">    clat (usec): min=14, max=2057, avg=402.26, stdev=140.67</div><div class="line">     lat (usec): min=19, max=2070, avg=411.72, stdev=142.67</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[  237],  5.00th=[  281], 10.00th=[  293], 20.00th=[  314],</div><div class="line">     | 30.00th=[  330], 40.00th=[  343], 50.00th=[  359], 60.00th=[  379],</div><div class="line">     | 70.00th=[  404], 80.00th=[  457], 90.00th=[  586], 95.00th=[  717],</div><div class="line">     | 99.00th=[  930], 99.50th=[ 1004], 99.90th=[ 1254], 99.95th=[ 1385],</div><div class="line">     | 99.99th=[ 1532]</div><div class="line">   bw (  KiB/s): min=78104, max=244408, per=99.22%, avg=169671.52, stdev=51142.10, samples=58</div><div class="line">   iops        : min=19526, max=61102, avg=42417.86, stdev=12785.51, samples=58</div><div class="line">  lat (usec)   : 4=0.01%, 10=0.01%, 20=0.01%, 50=0.02%, 100=0.04%</div><div class="line">  lat (usec)   : 250=1.02%, 500=73.32%, 750=17.28%, 1000=6.30%</div><div class="line">  lat (msec)   : 2=1.83%, 4=0.19%, 10=0.01%</div><div class="line">  cpu          : usr=15.84%, sys=83.31%, ctx=13765, majf=0, minf=7</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued rwts: total=2936000,1258304,0,0 short=0,0,0,0 dropped=0,0,0,0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">   READ: bw=390MiB/s (409MB/s), 390MiB/s-390MiB/s (409MB/s-409MB/s), io=11.2GiB (12.0GB), run=29432-29432msec</div><div class="line">  WRITE: bw=167MiB/s (175MB/s), 167MiB/s-167MiB/s (175MB/s-175MB/s), io=4915MiB (5154MB), run=29432-29432msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">  sfdv0n1: ios=795793/1618341, merge=0/11, ticks=218710/27721, in_queue=264935, util=100.00%</div><div class="line">[root@nu4d01142 data]# </div><div class="line">[root@nu4d01142 data]# fio -ioengine=libaio -bs=4k -direct=0 -buffered=0 -thread -rw=randrw -rwmixread=70 -size=6G -filename=/data/fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60 </div><div class="line">EBS 4K randwrite test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</div><div class="line">fio-3.7</div><div class="line">Starting 1 thread</div><div class="line">Jobs: 1 (f=1): [m(1)][100.0%][r=124MiB/s,w=53.5MiB/s][r=31.7k,w=13.7k IOPS][eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=437523: Tue Feb 23 14:37:54 2021</div><div class="line">   read: IOPS=38.6k, BW=151MiB/s (158MB/s)(4300MiB/28550msec)</div><div class="line">    slat (nsec): min=1205, max=1826.7k, avg=13253.36, stdev=17173.87</div><div class="line">    clat (nsec): min=236, max=5816.8k, avg=1135969.25, stdev=337142.34</div><div class="line">     lat (nsec): min=1977, max=5831.2k, avg=1149404.84, stdev=341232.87</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[  461],  5.00th=[  627], 10.00th=[  717], 20.00th=[  840],</div><div class="line">     | 30.00th=[  938], 40.00th=[ 1029], 50.00th=[ 1123], 60.00th=[ 1221],</div><div class="line">     | 70.00th=[ 1319], 80.00th=[ 1434], 90.00th=[ 1565], 95.00th=[ 1680],</div><div class="line">     | 99.00th=[ 1893], 99.50th=[ 1975], 99.90th=[ 2671], 99.95th=[ 3261],</div><div class="line">     | 99.99th=[ 3851]</div><div class="line">   bw (  KiB/s): min=119304, max=216648, per=100.00%, avg=154273.07, stdev=29925.10, samples=57</div><div class="line">   iops        : min=29826, max=54162, avg=38568.25, stdev=7481.30, samples=57</div><div class="line">  write: IOPS=16.5k, BW=64.6MiB/s (67.7MB/s)(1844MiB/28550msec)</div><div class="line">    slat (usec): min=3, max=3565, avg=21.07, stdev=22.23</div><div class="line">    clat (usec): min=14, max=9983, avg=1164.21, stdev=459.66</div><div class="line">     lat (usec): min=21, max=10011, avg=1185.57, stdev=463.28</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[  498],  5.00th=[  619], 10.00th=[  709], 20.00th=[  832],</div><div class="line">     | 30.00th=[  930], 40.00th=[ 1020], 50.00th=[ 1123], 60.00th=[ 1237],</div><div class="line">     | 70.00th=[ 1336], 80.00th=[ 1450], 90.00th=[ 1598], 95.00th=[ 1713],</div><div class="line">     | 99.00th=[ 2311], 99.50th=[ 3851], 99.90th=[ 5932], 99.95th=[ 6456],</div><div class="line">     | 99.99th=[ 7701]</div><div class="line">   bw (  KiB/s): min=50800, max=92328, per=100.00%, avg=66128.47, stdev=12890.64, samples=57</div><div class="line">   iops        : min=12700, max=23082, avg=16532.07, stdev=3222.66, samples=57</div><div class="line">  lat (nsec)   : 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.01%</div><div class="line">  lat (usec)   : 2=0.01%, 4=0.01%, 10=0.01%, 20=0.02%, 50=0.03%</div><div class="line">  lat (usec)   : 100=0.04%, 250=0.18%, 500=1.01%, 750=11.05%, 1000=25.02%</div><div class="line">  lat (msec)   : 2=61.87%, 4=0.62%, 10=0.14%</div><div class="line">  cpu          : usr=10.87%, sys=61.98%, ctx=218415, majf=0, minf=7</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued rwts: total=1100924,471940,0,0 short=0,0,0,0 dropped=0,0,0,0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">   READ: bw=151MiB/s (158MB/s), 151MiB/s-151MiB/s (158MB/s-158MB/s), io=4300MiB (4509MB), run=28550-28550msec</div><div class="line">  WRITE: bw=64.6MiB/s (67.7MB/s), 64.6MiB/s-64.6MiB/s (67.7MB/s-67.7MB/s), io=1844MiB (1933MB), run=28550-28550msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">  sfdv0n1: ios=536103/822037, merge=0/1442, ticks=66507/17141, in_queue=99429, util=100.00%</div></pre></td></tr></table></figure>
<h3 id="SATA-SSD测试数据"><a href="#SATA-SSD测试数据" class="headerlink" title="SATA SSD测试数据"></a>SATA SSD测试数据</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"># cat /sys/block/sda/queue/rotational </div><div class="line">0</div><div class="line"># lsblk -d -o name,rota</div><div class="line">NAME     ROTA</div><div class="line">sda         0</div><div class="line">sfdv0n1     0</div></pre></td></tr></table></figure>
<p>-direct=0 -buffered=0读写iops分别为15.8K、6.8K 比ssd差了不少（都是direct=0），如果direct、buffered都是1的话，ESSD性能很差，读写iops分别为4312、1852</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div></pre></td><td class="code"><pre><div class="line"># fio -ioengine=libaio -bs=4k -direct=0 -buffered=0 -thread -rw=randrw -rwmixread=70 -size=2G -filename=/var/lib/docker/fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60 </div><div class="line">EBS 4K randwrite test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</div><div class="line">fio-3.7</div><div class="line">Starting 1 thread</div><div class="line">EBS 4K randwrite test: Laying out IO file (1 file / 2048MiB)</div><div class="line">Jobs: 1 (f=1): [m(1)][100.0%][r=68.7MiB/s,w=29.7MiB/s][r=17.6k,w=7594 IOPS][eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=13261: Tue Feb 23 14:42:41 2021</div><div class="line">   read: IOPS=15.8k, BW=61.8MiB/s (64.8MB/s)(1432MiB/23172msec)</div><div class="line">    slat (nsec): min=1266, max=7261.0k, avg=7101.88, stdev=20655.54</div><div class="line">    clat (usec): min=167, max=27670, avg=2832.68, stdev=1786.18</div><div class="line">     lat (usec): min=175, max=27674, avg=2839.93, stdev=1784.42</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[  437],  5.00th=[  668], 10.00th=[  873], 20.00th=[  988],</div><div class="line">     | 30.00th=[ 1401], 40.00th=[ 2442], 50.00th=[ 2835], 60.00th=[ 3195],</div><div class="line">     | 70.00th=[ 3523], 80.00th=[ 4047], 90.00th=[ 5014], 95.00th=[ 5866],</div><div class="line">     | 99.00th=[ 8160], 99.50th=[ 9372], 99.90th=[13829], 99.95th=[15008],</div><div class="line">     | 99.99th=[23725]</div><div class="line">   bw (  KiB/s): min=44183, max=149440, per=99.28%, avg=62836.17, stdev=26590.84, samples=46</div><div class="line">   iops        : min=11045, max=37360, avg=15709.02, stdev=6647.72, samples=46</div><div class="line">  write: IOPS=6803, BW=26.6MiB/s (27.9MB/s)(616MiB/23172msec)</div><div class="line">    slat (nsec): min=1566, max=11474k, avg=8460.17, stdev=38221.51</div><div class="line">    clat (usec): min=77, max=24047, avg=2789.68, stdev=2042.55</div><div class="line">     lat (usec): min=80, max=24054, avg=2798.29, stdev=2040.85</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[  265],  5.00th=[  433], 10.00th=[  635], 20.00th=[  840],</div><div class="line">     | 30.00th=[  979], 40.00th=[ 2212], 50.00th=[ 2671], 60.00th=[ 3130],</div><div class="line">     | 70.00th=[ 3523], 80.00th=[ 4228], 90.00th=[ 5342], 95.00th=[ 6456],</div><div class="line">     | 99.00th=[ 9241], 99.50th=[10421], 99.90th=[13960], 99.95th=[15533],</div><div class="line">     | 99.99th=[23725]</div><div class="line">   bw (  KiB/s): min=18435, max=63112, per=99.26%, avg=27012.57, stdev=11299.42, samples=46</div><div class="line">   iops        : min= 4608, max=15778, avg=6753.11, stdev=2824.87, samples=46</div><div class="line">  lat (usec)   : 100=0.01%, 250=0.23%, 500=3.14%, 750=5.46%, 1000=15.27%</div><div class="line">  lat (msec)   : 2=11.47%, 4=43.09%, 10=20.88%, 20=0.44%, 50=0.01%</div><div class="line">  cpu          : usr=3.53%, sys=18.08%, ctx=47448, majf=0, minf=6</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued rwts: total=366638,157650,0,0 short=0,0,0,0 dropped=0,0,0,0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">   READ: bw=61.8MiB/s (64.8MB/s), 61.8MiB/s-61.8MiB/s (64.8MB/s-64.8MB/s), io=1432MiB (1502MB), run=23172-23172msec</div><div class="line">  WRITE: bw=26.6MiB/s (27.9MB/s), 26.6MiB/s-26.6MiB/s (27.9MB/s-27.9MB/s), io=616MiB (646MB), run=23172-23172msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">  sda: ios=359202/155123, merge=299/377, ticks=946305/407820, in_queue=1354596, util=99.61%</div><div class="line">  </div><div class="line"># fio -ioengine=libaio -bs=4k -direct=1 -buffered=0 -thread -rw=randrw -rwmixread=70 -size=2G -filename=/var/lib/docker/fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60 </div><div class="line">EBS 4K randwrite test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</div><div class="line">fio-3.7</div><div class="line">Starting 1 thread</div><div class="line">Jobs: 1 (f=1): [m(1)][95.5%][r=57.8MiB/s,w=25.7MiB/s][r=14.8k,w=6568 IOPS][eta 00m:01s] </div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=26167: Tue Feb 23 14:44:40 2021</div><div class="line">   read: IOPS=16.9k, BW=65.9MiB/s (69.1MB/s)(1432MiB/21730msec)</div><div class="line">    slat (nsec): min=1312, max=4454.2k, avg=8489.99, stdev=15763.97</div><div class="line">    clat (usec): min=201, max=18856, avg=2679.38, stdev=1720.02</div><div class="line">     lat (usec): min=206, max=18860, avg=2688.03, stdev=1717.19</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[  635],  5.00th=[  832], 10.00th=[  914], 20.00th=[  971],</div><div class="line">     | 30.00th=[ 1090], 40.00th=[ 2114], 50.00th=[ 2704], 60.00th=[ 3064],</div><div class="line">     | 70.00th=[ 3392], 80.00th=[ 3851], 90.00th=[ 4817], 95.00th=[ 5735],</div><div class="line">     | 99.00th=[ 7767], 99.50th=[ 8979], 99.90th=[13698], 99.95th=[15139],</div><div class="line">     | 99.99th=[16581]</div><div class="line">   bw (  KiB/s): min=45168, max=127528, per=100.00%, avg=67625.19, stdev=26620.82, samples=43</div><div class="line">   iops        : min=11292, max=31882, avg=16906.28, stdev=6655.20, samples=43</div><div class="line">  write: IOPS=7254, BW=28.3MiB/s (29.7MB/s)(616MiB/21730msec)</div><div class="line">    slat (nsec): min=1749, max=3412.2k, avg=9816.22, stdev=14501.05</div><div class="line">    clat (usec): min=97, max=23473, avg=2556.02, stdev=1980.53</div><div class="line">     lat (usec): min=107, max=23477, avg=2566.01, stdev=1977.65</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[  277],  5.00th=[  486], 10.00th=[  693], 20.00th=[  824],</div><div class="line">     | 30.00th=[  881], 40.00th=[ 1205], 50.00th=[ 2442], 60.00th=[ 2868],</div><div class="line">     | 70.00th=[ 3326], 80.00th=[ 3949], 90.00th=[ 5080], 95.00th=[ 6128],</div><div class="line">     | 99.00th=[ 8717], 99.50th=[10159], 99.90th=[14484], 99.95th=[15926],</div><div class="line">     | 99.99th=[18744]</div><div class="line">   bw (  KiB/s): min=19360, max=55040, per=100.00%, avg=29064.05, stdev=11373.59, samples=43</div><div class="line">   iops        : min= 4840, max=13760, avg=7266.00, stdev=2843.41, samples=43</div><div class="line">  lat (usec)   : 100=0.01%, 250=0.17%, 500=1.66%, 750=3.74%, 1000=22.57%</div><div class="line">  lat (msec)   : 2=12.66%, 4=40.62%, 10=18.20%, 20=0.38%, 50=0.01%</div><div class="line">  cpu          : usr=4.17%, sys=22.27%, ctx=14314, majf=0, minf=7</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued rwts: total=366638,157650,0,0 short=0,0,0,0 dropped=0,0,0,0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">   READ: bw=65.9MiB/s (69.1MB/s), 65.9MiB/s-65.9MiB/s (69.1MB/s-69.1MB/s), io=1432MiB (1502MB), run=21730-21730msec</div><div class="line">  WRITE: bw=28.3MiB/s (29.7MB/s), 28.3MiB/s-28.3MiB/s (29.7MB/s-29.7MB/s), io=616MiB (646MB), run=21730-21730msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">  sda: ios=364744/157621, merge=779/473, ticks=851759/352008, in_queue=1204024, util=99.61%</div><div class="line"></div><div class="line"># fio -ioengine=libaio -bs=4k -direct=1 -buffered=1 -thread -rw=randrw -rwmixread=70 -size=2G -filename=/var/lib/docker/fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60 </div><div class="line">EBS 4K randwrite test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</div><div class="line">fio-3.7</div><div class="line">Starting 1 thread</div><div class="line">Jobs: 1 (f=1): [m(1)][100.0%][r=15.9MiB/s,w=7308KiB/s][r=4081,w=1827 IOPS][eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=31560: Tue Feb 23 14:46:10 2021</div><div class="line">   read: IOPS=4312, BW=16.8MiB/s (17.7MB/s)(1011MiB/60001msec)</div><div class="line">    slat (usec): min=63, max=14320, avg=216.76, stdev=430.61</div><div class="line">    clat (usec): min=5, max=778861, avg=10254.92, stdev=22345.40</div><div class="line">     lat (usec): min=1900, max=782277, avg=10472.16, stdev=22657.06</div><div class="line">    clat percentiles (msec):</div><div class="line">     |  1.00th=[    6],  5.00th=[    6], 10.00th=[    6], 20.00th=[    7],</div><div class="line">     | 30.00th=[    7], 40.00th=[    7], 50.00th=[    7], 60.00th=[    7],</div><div class="line">     | 70.00th=[    8], 80.00th=[    8], 90.00th=[    8], 95.00th=[   11],</div><div class="line">     | 99.00th=[  107], 99.50th=[  113], 99.90th=[  132], 99.95th=[  197],</div><div class="line">     | 99.99th=[  760]</div><div class="line">   bw (  KiB/s): min=  168, max=29784, per=100.00%, avg=17390.92, stdev=10932.90, samples=119</div><div class="line">   iops        : min=   42, max= 7446, avg=4347.71, stdev=2733.21, samples=119</div><div class="line">  write: IOPS=1852, BW=7410KiB/s (7588kB/s)(434MiB/60001msec)</div><div class="line">    slat (usec): min=3, max=666432, avg=23.59, stdev=2745.39</div><div class="line">    clat (msec): min=3, max=781, avg=10.14, stdev=20.50</div><div class="line">     lat (msec): min=3, max=781, avg=10.16, stdev=20.72</div><div class="line">    clat percentiles (msec):</div><div class="line">     |  1.00th=[    6],  5.00th=[    6], 10.00th=[    6], 20.00th=[    7],</div><div class="line">     | 30.00th=[    7], 40.00th=[    7], 50.00th=[    7], 60.00th=[    7],</div><div class="line">     | 70.00th=[    7], 80.00th=[    8], 90.00th=[    8], 95.00th=[   11],</div><div class="line">     | 99.00th=[  107], 99.50th=[  113], 99.90th=[  131], 99.95th=[  157],</div><div class="line">     | 99.99th=[  760]</div><div class="line">   bw (  KiB/s): min=   80, max=12328, per=100.00%, avg=7469.53, stdev=4696.69, samples=119</div><div class="line">   iops        : min=   20, max= 3082, avg=1867.34, stdev=1174.19, samples=119</div><div class="line">  lat (usec)   : 10=0.01%</div><div class="line">  lat (msec)   : 2=0.01%, 4=0.01%, 10=94.64%, 20=1.78%, 50=0.11%</div><div class="line">  lat (msec)   : 100=1.80%, 250=1.63%, 500=0.01%, 750=0.02%, 1000=0.01%</div><div class="line">  cpu          : usr=2.51%, sys=10.98%, ctx=260210, majf=0, minf=7</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued rwts: total=258768,111147,0,0 short=0,0,0,0 dropped=0,0,0,0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">   READ: bw=16.8MiB/s (17.7MB/s), 16.8MiB/s-16.8MiB/s (17.7MB/s-17.7MB/s), io=1011MiB (1060MB), run=60001-60001msec</div><div class="line">  WRITE: bw=7410KiB/s (7588kB/s), 7410KiB/s-7410KiB/s (7588kB/s-7588kB/s), io=434MiB (455MB), run=60001-60001msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">  sda: ios=258717/89376, merge=0/735, ticks=52540/564186, in_queue=616999, util=90.07%</div></pre></td></tr></table></figure>
<h3 id="ESSD磁盘测试数据"><a href="#ESSD磁盘测试数据" class="headerlink" title="ESSD磁盘测试数据"></a>ESSD磁盘测试数据</h3><p>这是一块虚拟的阿里云网络盘，不能算完整意义的SSD（承诺IOPS 4200），数据仅供参考，磁盘概况：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">$df -lh</div><div class="line">Filesystem      Size  Used Avail Use% Mounted on</div><div class="line">/dev/vda1        99G   30G   65G  32% /</div><div class="line"></div><div class="line">$cat /sys/block/vda/queue/rotational</div><div class="line">1</div></pre></td></tr></table></figure>
<p>测试数据：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div></pre></td><td class="code"><pre><div class="line">$fio -ioengine=libaio -bs=4k -direct=1 -buffered=1  -thread -rw=randrw  -size=4G -filename=/home/admin/fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div><div class="line">EBS 4K randwrite test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</div><div class="line">fio-3.1</div><div class="line">Starting 1 thread</div><div class="line">Jobs: 1 (f=1): [m(1)][100.0%][r=10.8MiB/s,w=11.2MiB/s][r=2757,w=2876 IOPS][eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=25641: Tue Feb 23 16:35:19 2021</div><div class="line">   read: IOPS=2136, BW=8545KiB/s (8750kB/s)(501MiB/60001msec)</div><div class="line">    slat (usec): min=190, max=830992, avg=457.20, stdev=3088.80</div><div class="line">    clat (nsec): min=1792, max=1721.3M, avg=14657528.60, stdev=63188988.75</div><div class="line">     lat (usec): min=344, max=1751.1k, avg=15115.20, stdev=65165.80</div><div class="line">    clat percentiles (msec):</div><div class="line">     |  1.00th=[    8],  5.00th=[    9], 10.00th=[    9], 20.00th=[   10],</div><div class="line">     | 30.00th=[   10], 40.00th=[   11], 50.00th=[   11], 60.00th=[   11],</div><div class="line">     | 70.00th=[   12], 80.00th=[   12], 90.00th=[   13], 95.00th=[   14],</div><div class="line">     | 99.00th=[   17], 99.50th=[   53], 99.90th=[ 1028], 99.95th=[ 1167],</div><div class="line">     | 99.99th=[ 1653]</div><div class="line">   bw (  KiB/s): min=   56, max=12648, per=100.00%, avg=8598.92, stdev=5289.40, samples=118</div><div class="line">   iops        : min=   14, max= 3162, avg=2149.73, stdev=1322.35, samples=118</div><div class="line">  write: IOPS=2137, BW=8548KiB/s (8753kB/s)(501MiB/60001msec)</div><div class="line">    slat (usec): min=2, max=181, avg= 6.67, stdev= 7.22</div><div class="line">    clat (usec): min=628, max=1721.1k, avg=14825.32, stdev=65017.66</div><div class="line">     lat (usec): min=636, max=1721.1k, avg=14832.10, stdev=65018.10</div><div class="line">    clat percentiles (msec):</div><div class="line">     |  1.00th=[    8],  5.00th=[    9], 10.00th=[    9], 20.00th=[   10],</div><div class="line">     | 30.00th=[   10], 40.00th=[   11], 50.00th=[   11], 60.00th=[   11],</div><div class="line">     | 70.00th=[   12], 80.00th=[   12], 90.00th=[   13], 95.00th=[   14],</div><div class="line">     | 99.00th=[   17], 99.50th=[   53], 99.90th=[ 1045], 99.95th=[ 1200],</div><div class="line">     | 99.99th=[ 1687]</div><div class="line">   bw (  KiB/s): min=   72, max=13304, per=100.00%, avg=8602.99, stdev=5296.31, samples=118</div><div class="line">   iops        : min=   18, max= 3326, avg=2150.75, stdev=1324.08, samples=118</div><div class="line">  lat (usec)   : 2=0.01%, 500=0.01%, 750=0.01%</div><div class="line">  lat (msec)   : 2=0.01%, 4=0.01%, 10=37.85%, 20=61.53%, 50=0.10%</div><div class="line">  lat (msec)   : 100=0.06%, 250=0.03%, 500=0.01%, 750=0.03%, 1000=0.25%</div><div class="line">  lat (msec)   : 2000=0.14%</div><div class="line">  cpu          : usr=0.70%, sys=4.01%, ctx=135029, majf=0, minf=4</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued rwt: total=128180,128223,0, short=0,0,0, dropped=0,0,0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">   READ: bw=8545KiB/s (8750kB/s), 8545KiB/s-8545KiB/s (8750kB/s-8750kB/s), io=501MiB (525MB), run=60001-60001msec</div><div class="line">  WRITE: bw=8548KiB/s (8753kB/s), 8548KiB/s-8548KiB/s (8753kB/s-8753kB/s), io=501MiB (525MB), run=60001-60001msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">  vda: ios=127922/87337, merge=0/237, ticks=55122/4269885, in_queue=2209125, util=94.29%</div><div class="line"></div><div class="line">$fio -ioengine=libaio -bs=4k -direct=1 -buffered=0  -thread -rw=randrw  -size=4G -filename=/home/admin/fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div><div class="line">EBS 4K randwrite test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</div><div class="line">fio-3.1</div><div class="line">Starting 1 thread</div><div class="line">Jobs: 1 (f=1): [m(1)][100.0%][r=9680KiB/s,w=9712KiB/s][r=2420,w=2428 IOPS][eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=25375: Tue Feb 23 16:33:03 2021</div><div class="line">   read: IOPS=2462, BW=9849KiB/s (10.1MB/s)(577MiB/60011msec)</div><div class="line">    slat (nsec): min=1558, max=10663k, avg=5900.28, stdev=46286.64</div><div class="line">    clat (usec): min=290, max=93493, avg=13054.57, stdev=4301.89</div><div class="line">     lat (usec): min=332, max=93497, avg=13060.60, stdev=4301.68</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[ 1844],  5.00th=[10159], 10.00th=[10290], 20.00th=[10421],</div><div class="line">     | 30.00th=[10552], 40.00th=[10552], 50.00th=[10683], 60.00th=[10814],</div><div class="line">     | 70.00th=[18482], 80.00th=[19006], 90.00th=[19006], 95.00th=[19268],</div><div class="line">     | 99.00th=[19530], 99.50th=[19792], 99.90th=[29492], 99.95th=[30278],</div><div class="line">     | 99.99th=[43779]</div><div class="line">   bw (  KiB/s): min= 9128, max=30392, per=100.00%, avg=9850.12, stdev=1902.00, samples=120</div><div class="line">   iops        : min= 2282, max= 7598, avg=2462.52, stdev=475.50, samples=120</div><div class="line">  write: IOPS=2465, BW=9864KiB/s (10.1MB/s)(578MiB/60011msec)</div><div class="line">    slat (usec): min=2, max=10586, avg= 6.92, stdev=67.34</div><div class="line">    clat (usec): min=240, max=69922, avg=12902.33, stdev=4307.92</div><div class="line">     lat (usec): min=244, max=69927, avg=12909.37, stdev=4307.03</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[ 1729],  5.00th=[10159], 10.00th=[10290], 20.00th=[10290],</div><div class="line">     | 30.00th=[10421], 40.00th=[10421], 50.00th=[10552], 60.00th=[10683],</div><div class="line">     | 70.00th=[18220], 80.00th=[18744], 90.00th=[19006], 95.00th=[19006],</div><div class="line">     | 99.00th=[19268], 99.50th=[19530], 99.90th=[21103], 99.95th=[35390],</div><div class="line">     | 99.99th=[50594]</div><div class="line">   bw (  KiB/s): min= 8496, max=31352, per=100.00%, avg=9862.92, stdev=1991.48, samples=120</div><div class="line">   iops        : min= 2124, max= 7838, avg=2465.72, stdev=497.87, samples=120</div><div class="line">  lat (usec)   : 250=0.01%, 500=0.03%, 750=0.02%, 1000=0.02%</div><div class="line">  lat (msec)   : 2=1.70%, 4=0.41%, 10=1.25%, 20=96.22%, 50=0.34%</div><div class="line">  lat (msec)   : 100=0.01%</div><div class="line">  cpu          : usr=0.89%, sys=4.09%, ctx=206337, majf=0, minf=4</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued rwt: total=147768,147981,0, short=0,0,0, dropped=0,0,0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">   READ: bw=9849KiB/s (10.1MB/s), 9849KiB/s-9849KiB/s (10.1MB/s-10.1MB/s), io=577MiB (605MB), run=60011-60011msec</div><div class="line">  WRITE: bw=9864KiB/s (10.1MB/s), 9864KiB/s-9864KiB/s (10.1MB/s-10.1MB/s), io=578MiB (606MB), run=60011-60011msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">  vda: ios=147515/148154, merge=0/231, ticks=1922378/1915751, in_queue=3780605, util=98.46%</div><div class="line">  </div><div class="line">$fio -ioengine=libaio -bs=4k -direct=0 -buffered=1  -thread -rw=randrw  -size=4G -filename=/home/admin/fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div><div class="line">EBS 4K randwrite test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</div><div class="line">fio-3.1</div><div class="line">Starting 1 thread</div><div class="line">Jobs: 1 (f=1): [m(1)][100.0%][r=132KiB/s,w=148KiB/s][r=33,w=37 IOPS][eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=25892: Tue Feb 23 16:37:41 2021</div><div class="line">   read: IOPS=1987, BW=7949KiB/s (8140kB/s)(467MiB/60150msec)</div><div class="line">    slat (usec): min=192, max=599873, avg=479.26, stdev=2917.52</div><div class="line">    clat (usec): min=15, max=1975.6k, avg=16004.22, stdev=76024.60</div><div class="line">     lat (msec): min=5, max=2005, avg=16.48, stdev=78.00</div><div class="line">    clat percentiles (msec):</div><div class="line">     |  1.00th=[    8],  5.00th=[    9], 10.00th=[    9], 20.00th=[   10],</div><div class="line">     | 30.00th=[   10], 40.00th=[   11], 50.00th=[   11], 60.00th=[   11],</div><div class="line">     | 70.00th=[   12], 80.00th=[   12], 90.00th=[   13], 95.00th=[   14],</div><div class="line">     | 99.00th=[   19], 99.50th=[  317], 99.90th=[ 1133], 99.95th=[ 1435],</div><div class="line">     | 99.99th=[ 1871]</div><div class="line">   bw (  KiB/s): min=   32, max=12672, per=100.00%, avg=8034.08, stdev=5399.63, samples=119</div><div class="line">   iops        : min=    8, max= 3168, avg=2008.52, stdev=1349.91, samples=119</div><div class="line">  write: IOPS=1984, BW=7937KiB/s (8127kB/s)(466MiB/60150msec)</div><div class="line">    slat (usec): min=2, max=839634, avg=18.39, stdev=2747.10</div><div class="line">    clat (msec): min=5, max=1975, avg=15.64, stdev=73.06</div><div class="line">     lat (msec): min=5, max=1975, avg=15.66, stdev=73.28</div><div class="line">    clat percentiles (msec):</div><div class="line">     |  1.00th=[    8],  5.00th=[    9], 10.00th=[    9], 20.00th=[   10],</div><div class="line">     | 30.00th=[   10], 40.00th=[   11], 50.00th=[   11], 60.00th=[   11],</div><div class="line">     | 70.00th=[   12], 80.00th=[   12], 90.00th=[   13], 95.00th=[   14],</div><div class="line">     | 99.00th=[   18], 99.50th=[  153], 99.90th=[ 1116], 99.95th=[ 1435],</div><div class="line">     | 99.99th=[ 1921]</div><div class="line">   bw (  KiB/s): min=   24, max=13160, per=100.00%, avg=8021.18, stdev=5405.12, samples=119</div><div class="line">   iops        : min=    6, max= 3290, avg=2005.29, stdev=1351.28, samples=119</div><div class="line">  lat (usec)   : 20=0.01%</div><div class="line">  lat (msec)   : 10=36.51%, 20=62.63%, 50=0.21%, 100=0.12%, 250=0.05%</div><div class="line">  lat (msec)   : 500=0.02%, 750=0.02%, 1000=0.19%, 2000=0.26%</div><div class="line">  cpu          : usr=0.62%, sys=4.04%, ctx=125974, majf=0, minf=3</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued rwt: total=119533,119347,0, short=0,0,0, dropped=0,0,0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">   READ: bw=7949KiB/s (8140kB/s), 7949KiB/s-7949KiB/s (8140kB/s-8140kB/s), io=467MiB (490MB), run=60150-60150msec</div><div class="line">  WRITE: bw=7937KiB/s (8127kB/s), 7937KiB/s-7937KiB/s (8127kB/s-8127kB/s), io=466MiB (489MB), run=60150-60150msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">  vda: ios=119533/108186, merge=0/214, ticks=54093/4937255, in_queue=2525052, util=93.99%</div><div class="line">  </div><div class="line">$fio -ioengine=libaio -bs=4k -direct=0 -buffered=0  -thread -rw=randrw  -size=4G -filename=/home/admin/fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div><div class="line">EBS 4K randwrite test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</div><div class="line">fio-3.1</div><div class="line">Starting 1 thread</div><div class="line">Jobs: 1 (f=1): [m(1)][100.0%][r=9644KiB/s,w=9792KiB/s][r=2411,w=2448 IOPS][eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=26139: Tue Feb 23 16:39:43 2021</div><div class="line">   read: IOPS=2455, BW=9823KiB/s (10.1MB/s)(576MiB/60015msec)</div><div class="line">    slat (nsec): min=1619, max=18282k, avg=5882.81, stdev=71214.52</div><div class="line">    clat (usec): min=281, max=64630, avg=13055.68, stdev=4233.17</div><div class="line">     lat (usec): min=323, max=64636, avg=13061.69, stdev=4232.79</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[ 2040],  5.00th=[10290], 10.00th=[10421], 20.00th=[10421],</div><div class="line">     | 30.00th=[10552], 40.00th=[10552], 50.00th=[10683], 60.00th=[10814],</div><div class="line">     | 70.00th=[18220], 80.00th=[19006], 90.00th=[19006], 95.00th=[19268],</div><div class="line">     | 99.00th=[19530], 99.50th=[20055], 99.90th=[28967], 99.95th=[29754],</div><div class="line">     | 99.99th=[30540]</div><div class="line">   bw (  KiB/s): min= 8776, max=27648, per=100.00%, avg=9824.29, stdev=1655.78, samples=120</div><div class="line">   iops        : min= 2194, max= 6912, avg=2456.05, stdev=413.95, samples=120</div><div class="line">  write: IOPS=2458, BW=9835KiB/s (10.1MB/s)(576MiB/60015msec)</div><div class="line">    slat (usec): min=2, max=10681, avg= 6.79, stdev=71.30</div><div class="line">    clat (usec): min=221, max=70411, avg=12909.50, stdev=4312.40</div><div class="line">     lat (usec): min=225, max=70414, avg=12916.40, stdev=4312.05</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[ 1909],  5.00th=[10159], 10.00th=[10290], 20.00th=[10290],</div><div class="line">     | 30.00th=[10421], 40.00th=[10421], 50.00th=[10552], 60.00th=[10683],</div><div class="line">     | 70.00th=[18220], 80.00th=[18744], 90.00th=[19006], 95.00th=[19006],</div><div class="line">     | 99.00th=[19268], 99.50th=[19530], 99.90th=[28705], 99.95th=[40109],</div><div class="line">     | 99.99th=[60031]</div><div class="line">   bw (  KiB/s): min= 8568, max=28544, per=100.00%, avg=9836.03, stdev=1737.29, samples=120</div><div class="line">   iops        : min= 2142, max= 7136, avg=2458.98, stdev=434.32, samples=120</div><div class="line">  lat (usec)   : 250=0.01%, 500=0.03%, 750=0.02%, 1000=0.02%</div><div class="line">  lat (msec)   : 2=1.03%, 4=1.10%, 10=0.98%, 20=96.43%, 50=0.38%</div><div class="line">  lat (msec)   : 100=0.01%</div><div class="line">  cpu          : usr=0.82%, sys=4.32%, ctx=212008, majf=0, minf=4</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued rwt: total=147386,147564,0, short=0,0,0, dropped=0,0,0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">   READ: bw=9823KiB/s (10.1MB/s), 9823KiB/s-9823KiB/s (10.1MB/s-10.1MB/s), io=576MiB (604MB), run=60015-60015msec</div><div class="line">  WRITE: bw=9835KiB/s (10.1MB/s), 9835KiB/s-9835KiB/s (10.1MB/s-10.1MB/s), io=576MiB (604MB), run=60015-60015msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">  vda: ios=147097/147865, merge=0/241, ticks=1916703/1915836, in_queue=3791443, util=98.68%</div></pre></td></tr></table></figure>
<p>各类型云盘的性能比较如下表所示。</p>
<table>
<thead>
<tr>
<th style="text-align:left">性能类别</th>
<th style="text-align:left">ESSD AutoPL云盘（邀测）</th>
<th style="text-align:left">ESSD PL-X云盘（邀测）</th>
<th style="text-align:left">ESSD云盘 PL3</th>
<th style="text-align:left">ESSD云盘 PL0</th>
<th style="text-align:left">ESSD云盘 PL1</th>
<th style="text-align:left">ESSD云盘 PL0</th>
<th>SSD云盘</th>
<th>高效云盘</th>
<th>普通云盘</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">单盘容量范围（GiB）</td>
<td style="text-align:left">40~32,768</td>
<td style="text-align:left">40~32,768</td>
<td style="text-align:left">1261~32,768</td>
<td style="text-align:left">461~32,768</td>
<td style="text-align:left">20~32,768</td>
<td style="text-align:left">40~32,768</td>
<td>20~32,768</td>
<td>20~32,768</td>
<td>5~2,000</td>
</tr>
<tr>
<td style="text-align:left">最大IOPS</td>
<td style="text-align:left">100,000</td>
<td style="text-align:left">3,000,000</td>
<td style="text-align:left">1,000,000</td>
<td style="text-align:left">100,000</td>
<td style="text-align:left">50,000</td>
<td style="text-align:left">10,000</td>
<td>25,000</td>
<td>5,000</td>
<td>数百</td>
</tr>
<tr>
<td style="text-align:left">最大吞吐量（MB/s）</td>
<td style="text-align:left">1,131</td>
<td style="text-align:left">12,288</td>
<td style="text-align:left">4,000</td>
<td style="text-align:left">750</td>
<td style="text-align:left">350</td>
<td style="text-align:left">180</td>
<td>300</td>
<td>140</td>
<td>30~40</td>
</tr>
<tr>
<td style="text-align:left">单盘IOPS性能计算公式</td>
<td style="text-align:left">min{1,800+50*容量, 50,000}</td>
<td style="text-align:left">预配置IOPS</td>
<td style="text-align:left">min{1,800+50*容量, 1,000,000}</td>
<td style="text-align:left">min{1,800+50*容量, 100,000}</td>
<td style="text-align:left">min{1,800+50*容量, 50,000}</td>
<td style="text-align:left">min{ 1,800+12*容量, 10,000 }</td>
<td>min{1,800+30*容量, 25,000}</td>
<td>min{1,800+8*容量, 5,000}</td>
<td>无</td>
</tr>
<tr>
<td style="text-align:left">单盘吞吐量性能计算公式（MB/s）</td>
<td style="text-align:left">min{120+0.5*容量, 350}</td>
<td style="text-align:left">4 KB*预配置IOPS/1024</td>
<td style="text-align:left">min{120+0.5*容量, 4,000}</td>
<td style="text-align:left">min{120+0.5*容量, 750}</td>
<td style="text-align:left">min{120+0.5*容量, 350}</td>
<td style="text-align:left">min{100+0.25*容量, 180}</td>
<td>min{120+0.5*容量, 300}</td>
<td>min{100+0.15*容量, 140}</td>
<td>无</td>
</tr>
<tr>
<td style="text-align:left">单路随机写平均时延（ms），Block Size=4K</td>
<td style="text-align:left">0.2</td>
<td style="text-align:left">0.03</td>
<td style="text-align:left">0.2</td>
<td style="text-align:left">0.2</td>
<td style="text-align:left">0.2</td>
<td style="text-align:left">0.3~0.5</td>
<td>0.5~2</td>
<td>1~3</td>
<td>5~10</td>
</tr>
<tr>
<td style="text-align:left">API参数取值</td>
<td style="text-align:left">cloud_auto</td>
<td style="text-align:left">cloud_plx</td>
<td style="text-align:left">cloud_essd</td>
<td style="text-align:left">cloud_essd</td>
<td style="text-align:left">cloud_essd</td>
<td style="text-align:left">cloud_essd</td>
<td>cloud_ssd</td>
<td>cloud_efficiency</td>
<td>cloud</td>
</tr>
</tbody>
</table>
<h4 id="ESSD-PL3测试"><a href="#ESSD-PL3测试" class="headerlink" title="ESSD PL3测试"></a>ESSD PL3测试</h4><p>测试命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">fio -ioengine=libaio -bs=4k -buffered=1 -thread -rw=randwrite -rwmixread=70 -size=160G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div></pre></td></tr></table></figure>
<p>ESSD 是aliyun 购买的 ESSD PL3，LVM是海光物理机下两块本地NVMe SSD做的LVM，测试基于ext4文件系统，阿里云官方提供ESSD的 IOPS 性能数据是裸盘（不含文件系统的）</p>
<table>
<thead>
<tr>
<th></th>
<th>本地LVM</th>
<th>ESSD</th>
</tr>
</thead>
<tbody>
<tr>
<td>fio -ioengine=libaio -bs=4k -buffered=1 read</td>
<td>bw=36636KB/s, iops=9159<br>nvme0n1:util=42.31%<br>nvme1n1: util=41.63%</td>
<td>IOPS=3647, BW=14.2MiB/s<br>util=88.08%</td>
</tr>
<tr>
<td>fio -ioengine=libaio -bs=4k -buffered=1 write</td>
<td>bw=383626KB/s, iops=95906<br>nvme0n1:util=37.16%<br>nvme1n1: util=33.58%</td>
<td>IOPS=104k, BW=406MiB/s<br>util=39.06%</td>
</tr>
<tr>
<td>fio -ioengine=libaio -bs=4k -buffered=1 randrw rwmixread=70</td>
<td>write: bw=12765KB/s, iops=3191<br>read : bw=29766KB/s, iops=7441<br>nvme0n1:util=35.18%<br>nvme1n1: util=35.04%</td>
<td>write:IOPS=1701, BW=6808KiB/s<br>read: IOPS=3962, BW=15.5MiB/s<br> nvme7n1: util=99.35%</td>
</tr>
<tr>
<td>fio -ioengine=libaio -bs=4k -direct=1 -buffered=0 read</td>
<td>bw=67938KB/s, iops=16984<br>nvme0n1:util=43.17%<br>nvme1n1: util=39.18%</td>
<td>IOPS=4687, BW=18.3MiB/s<br>util=99.75%</td>
</tr>
<tr>
<td>fio -ioengine=libaio -bs=4k -direct=1 -buffered=0 write</td>
<td>bw=160775KB/s, iops=40193<br>nvme0n1:util=28.66%<br>nvme1n1: util=21.67%</td>
<td>IOPS=7153, BW=27.9MiB/s<br>util=99.85%</td>
</tr>
<tr>
<td>fio -ioengine=libaio -bs=4k -direct=1 -buffered=0 randrw rwmixread=70</td>
<td>write: bw=23087KB/s, iops=5771<br>read : bw=53849KB/s, iops=13462</td>
<td>write:IOPS=1511, BW=6045KiB/s<br>read: IOPS=3534, BW=13.8MiB/s</td>
</tr>
</tbody>
</table>
<p>结论：</p>
<ul>
<li>ESSD只要有随机读性能就很差,纯读是本地盘（LVM）的40%，纯写和本地盘差不多</li>
<li>direct 读是本地盘的四分之一</li>
<li>direct 写是本地盘的六分之一，写16K Page差距缩小到五分之一（5749/25817）</li>
<li>intel direct 写本地intel SSDPE2KX040T8 iops=55826（比海光好40%，海光是memblaze）</li>
<li>ESSD 带 buffer 读写抖动很大</li>
<li>ESSD 出现过多次卡死，表现就是磁盘不响应任何操作，大概N分钟后恢复，原因未知</li>
</ul>
<p>PL3单盘IOPS性能计算公式  min{1800+50*容量, 1000000}</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div></pre></td><td class="code"><pre><div class="line">[essd_pl3]# fio -ioengine=libaio -bs=4k -direct=1 -buffered=1 -thread -rw=randwrite -rwmixread=70 -size=160G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div><div class="line">EBS 4K randwrite test: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</div><div class="line">fio-3.7</div><div class="line">Starting 1 thread</div><div class="line">Jobs: 1 (f=1): [w(1)][100.0%][r=0KiB/s,w=566MiB/s][r=0,w=145k IOPS][eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=2416234: Thu Apr  7 17:03:07 2022</div><div class="line">  write: IOPS=96.2k, BW=376MiB/s (394MB/s)(22.0GiB/60000msec)</div><div class="line">    slat (usec): min=2, max=530984, avg= 8.27, stdev=1104.96</div><div class="line">    clat (usec): min=2, max=944103, avg=599.25, stdev=9230.93</div><div class="line">     lat (usec): min=7, max=944111, avg=607.60, stdev=9308.81</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[   392],  5.00th=[   400], 10.00th=[   404], 20.00th=[   408],</div><div class="line">     | 30.00th=[   412], 40.00th=[   416], 50.00th=[   420], 60.00th=[   424],</div><div class="line">     | 70.00th=[   433], 80.00th=[   441], 90.00th=[   457], 95.00th=[   482],</div><div class="line">     | 99.00th=[   627], 99.50th=[   766], 99.90th=[  1795], 99.95th=[  4228],</div><div class="line">     | 99.99th=[488637]</div><div class="line">   bw (  KiB/s): min=  168, max=609232, per=100.00%, avg=422254.17, stdev=257181.75, samples=108</div><div class="line">   iops        : min=   42, max=152308, avg=105563.63, stdev=64295.48, samples=108</div><div class="line">  lat (usec)   : 4=0.01%, 10=0.01%, 50=0.01%, 100=0.01%, 250=0.01%</div><div class="line">  lat (usec)   : 500=96.35%, 750=3.11%, 1000=0.26%</div><div class="line">  lat (msec)   : 2=0.19%, 4=0.03%, 10=0.02%, 250=0.01%, 500=0.03%</div><div class="line">  lat (msec)   : 750=0.01%, 1000=0.01%</div><div class="line">  cpu          : usr=13.56%, sys=60.78%, ctx=1455, majf=0, minf=9743</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued rwts: total=0,5771972,0,0 short=0,0,0,0 dropped=0,0,0,0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">  WRITE: bw=376MiB/s (394MB/s), 376MiB/s-376MiB/s (394MB/s-394MB/s), io=22.0GiB (23.6GB), run=60000-60000msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">  vdb: ios=0/1463799, merge=0/7373, ticks=0/2011879, in_queue=2011879, util=27.85%</div><div class="line">  </div><div class="line">[essd_pl3]# fio -ioengine=libaio -bs=4k -direct=1 -buffered=1 -thread -rw=randread -rwmixread=70 -size=160G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div><div class="line">EBS 4K randwrite test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</div><div class="line">fio-3.7</div><div class="line">Starting 1 thread</div><div class="line">Jobs: 1 (f=1): [r(1)][100.0%][r=15.9MiB/s,w=0KiB/s][r=4058,w=0 IOPS][eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=2441598: Thu Apr  7 17:05:10 2022</div><div class="line">   read: IOPS=3647, BW=14.2MiB/s (14.9MB/s)(855MiB/60001msec)</div><div class="line">    slat (usec): min=183, max=10119, avg=239.01, stdev=110.20</div><div class="line">    clat (usec): min=2, max=54577, avg=15170.17, stdev=1324.10</div><div class="line">     lat (usec): min=237, max=55110, avg=15409.34, stdev=1338.09</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[13960],  5.00th=[14091], 10.00th=[14222], 20.00th=[14484],</div><div class="line">     | 30.00th=[14615], 40.00th=[14746], 50.00th=[14877], 60.00th=[15139],</div><div class="line">     | 70.00th=[15270], 80.00th=[15533], 90.00th=[16057], 95.00th=[16712],</div><div class="line">     | 99.00th=[20317], 99.50th=[22152], 99.90th=[26346], 99.95th=[30802],</div><div class="line">     | 99.99th=[52691]</div><div class="line">   bw (  KiB/s): min= 6000, max=17272, per=100.00%, avg=16511.28, stdev=1140.64, samples=105</div><div class="line">   iops        : min= 1500, max= 4318, avg=4127.81, stdev=285.16, samples=105</div><div class="line">  lat (usec)   : 4=0.01%, 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.01%</div><div class="line">  lat (msec)   : 2=0.01%, 4=0.01%, 10=0.01%, 20=98.91%, 50=1.05%</div><div class="line">  lat (msec)   : 100=0.02%</div><div class="line">  cpu          : usr=0.18%, sys=17.18%, ctx=219041, majf=0, minf=4215</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued rwts: total=218835,0,0,0 short=0,0,0,0 dropped=0,0,0,0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">   READ: bw=14.2MiB/s (14.9MB/s), 14.2MiB/s-14.2MiB/s (14.9MB/s-14.9MB/s), io=855MiB (896MB), run=60001-60001msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">  vdb: ios=218343/7992, merge=0/8876, ticks=50566/3749, in_queue=54315, util=88.08%  </div><div class="line"> </div><div class="line">[essd_pl3]# fio -ioengine=libaio -bs=4k -direct=1 -buffered=1 -thread -rw=randrw -rwmixread=70 -size=160G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div><div class="line">EBS 4K randwrite test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</div><div class="line">fio-3.7</div><div class="line">Starting 1 thread</div><div class="line">Jobs: 1 (f=1): [m(1)][100.0%][r=15.7MiB/s,w=7031KiB/s][r=4007,w=1757 IOPS][eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=2641414: Thu Apr  7 17:21:10 2022</div><div class="line">   read: IOPS=3962, BW=15.5MiB/s (16.2MB/s)(929MiB/60001msec)</div><div class="line">    slat (usec): min=182, max=7194, avg=243.23, stdev=116.87</div><div class="line">    clat (usec): min=2, max=235715, avg=11020.01, stdev=3366.61</div><div class="line">     lat (usec): min=253, max=235991, avg=11263.40, stdev=3375.49</div><div class="line">    clat percentiles (msec):</div><div class="line">     |  1.00th=[    9],  5.00th=[   10], 10.00th=[   10], 20.00th=[   11],</div><div class="line">     | 30.00th=[   11], 40.00th=[   11], 50.00th=[   11], 60.00th=[   12],</div><div class="line">     | 70.00th=[   12], 80.00th=[   12], 90.00th=[   13], 95.00th=[   14],</div><div class="line">     | 99.00th=[   16], 99.50th=[   18], 99.90th=[   31], 99.95th=[   36],</div><div class="line">     | 99.99th=[  234]</div><div class="line">   bw (  KiB/s): min=10808, max=17016, per=100.00%, avg=15977.89, stdev=895.35, samples=118</div><div class="line">   iops        : min= 2702, max= 4254, avg=3994.47, stdev=223.85, samples=118</div><div class="line">  write: IOPS=1701, BW=6808KiB/s (6971kB/s)(399MiB/60001msec)</div><div class="line">    slat (usec): min=3, max=221631, avg=10.16, stdev=693.59</div><div class="line">    clat (usec): min=486, max=235772, avg=11029.42, stdev=3590.93</div><div class="line">     lat (usec): min=493, max=235780, avg=11039.67, stdev=3659.04</div><div class="line">    clat percentiles (msec):</div><div class="line">     |  1.00th=[    9],  5.00th=[   10], 10.00th=[   10], 20.00th=[   11],</div><div class="line">     | 30.00th=[   11], 40.00th=[   11], 50.00th=[   11], 60.00th=[   12],</div><div class="line">     | 70.00th=[   12], 80.00th=[   12], 90.00th=[   13], 95.00th=[   14],</div><div class="line">     | 99.00th=[   16], 99.50th=[   18], 99.90th=[   31], 99.95th=[   37],</div><div class="line">     | 99.99th=[  234]</div><div class="line">   bw (  KiB/s): min= 4480, max= 7728, per=100.00%, avg=6862.60, stdev=475.79, samples=118</div><div class="line">   iops        : min= 1120, max= 1932, avg=1715.64, stdev=118.97, samples=118</div><div class="line">  lat (usec)   : 4=0.01%, 500=0.01%, 750=0.01%</div><div class="line">  lat (msec)   : 2=0.01%, 4=0.01%, 10=20.77%, 20=78.89%, 50=0.31%</div><div class="line">  lat (msec)   : 100=0.01%, 250=0.02%</div><div class="line">  cpu          : usr=0.65%, sys=7.20%, ctx=239089, majf=0, minf=8292</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued rwts: total=237743,102115,0,0 short=0,0,0,0 dropped=0,0,0,0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">   READ: bw=15.5MiB/s (16.2MB/s), 15.5MiB/s-15.5MiB/s (16.2MB/s-16.2MB/s), io=929MiB (974MB), run=60001-60001msec</div><div class="line">  WRITE: bw=6808KiB/s (6971kB/s), 6808KiB/s-6808KiB/s (6971kB/s-6971kB/s), io=399MiB (418MB), run=60001-60001msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">  vdb: ios=237216/118960, merge=0/8118, ticks=55191/148225, in_queue=203416, util=99.35%</div><div class="line">  </div><div class="line">[essd_pl3]# fio  -bs=4k -direct=1 -buffered=0 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=30</div><div class="line">EBS 4K randwrite test: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=psync, iodepth=64</div><div class="line">fio-3.7</div><div class="line">Starting 1 thread</div><div class="line">Jobs: 1 (f=1): [w(1)][100.0%][r=0KiB/s,w=28.3MiB/s][r=0,w=7249 IOPS][eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=2470117: Fri Apr  8 15:35:20 2022</div><div class="line">  write: IOPS=7222, BW=28.2MiB/s (29.6MB/s)(846MiB/30001msec)</div><div class="line">    clat (usec): min=115, max=7155, avg=137.29, stdev=68.48</div><div class="line">     lat (usec): min=115, max=7156, avg=137.36, stdev=68.49</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[  121],  5.00th=[  123], 10.00th=[  125], 20.00th=[  126],</div><div class="line">     | 30.00th=[  127], 40.00th=[  129], 50.00th=[  130], 60.00th=[  133],</div><div class="line">     | 70.00th=[  135], 80.00th=[  139], 90.00th=[  149], 95.00th=[  163],</div><div class="line">     | 99.00th=[  255], 99.50th=[  347], 99.90th=[  668], 99.95th=[  947],</div><div class="line">     | 99.99th=[ 3589]</div><div class="line">   bw (  KiB/s): min=23592, max=30104, per=99.95%, avg=28873.29, stdev=1084.49, samples=59</div><div class="line">   iops        : min= 5898, max= 7526, avg=7218.32, stdev=271.12, samples=59</div><div class="line">  lat (usec)   : 250=98.95%, 500=0.81%, 750=0.17%, 1000=0.03%</div><div class="line">  lat (msec)   : 2=0.02%, 4=0.02%, 10=0.01%</div><div class="line">  cpu          : usr=0.72%, sys=5.08%, ctx=216767, majf=0, minf=148</div><div class="line">  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, &gt;=64=0.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     issued rwts: total=0,216677,0,0 short=0,0,0,0 dropped=0,0,0,0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">  WRITE: bw=28.2MiB/s (29.6MB/s), 28.2MiB/s-28.2MiB/s (29.6MB/s-29.6MB/s), io=846MiB (888MB), run=30001-30001msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">  vdb: ios=0/219122, merge=0/3907, ticks=0/29812, in_queue=29812, util=99.52% </div><div class="line">  </div><div class="line">[root@hygon8 14:44 /polarx/lvm]</div><div class="line">#fio  -bs=4k -direct=1 -buffered=0 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=30</div><div class="line">EBS 4K randwrite test: (g=0): rw=randwrite, bs=4K-4K/4K-4K/4K-4K, ioengine=sync, iodepth=64</div><div class="line">fio-2.2.8</div><div class="line">Starting 1 thread</div><div class="line">Jobs: 1 (f=1): [w(1)] [100.0% done] [0KB/157.2MB/0KB /s] [0/40.3K/0 iops] [eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=3486352: Fri Apr  8 14:45:43 2022</div><div class="line">  write: io=4710.4MB, bw=160775KB/s, iops=40193, runt= 30001msec</div><div class="line">    clat (usec): min=18, max=4164, avg=22.05, stdev= 7.33</div><div class="line">     lat (usec): min=19, max=4165, avg=22.59, stdev= 7.36</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[   20],  5.00th=[   20], 10.00th=[   21], 20.00th=[   21],</div><div class="line">     | 30.00th=[   21], 40.00th=[   21], 50.00th=[   21], 60.00th=[   22],</div><div class="line">     | 70.00th=[   22], 80.00th=[   22], 90.00th=[   23], 95.00th=[   25],</div><div class="line">     | 99.00th=[   36], 99.50th=[   40], 99.90th=[   62], 99.95th=[   99],</div><div class="line">     | 99.99th=[  157]</div><div class="line">    bw (KB  /s): min=147568, max=165400, per=100.00%, avg=160803.12, stdev=2704.22</div><div class="line">    lat (usec) : 20=0.08%, 50=99.70%, 100=0.17%, 250=0.04%, 500=0.01%</div><div class="line">    lat (usec) : 750=0.01%, 1000=0.01%</div><div class="line">    lat (msec) : 2=0.01%, 10=0.01%</div><div class="line">  cpu          : usr=6.95%, sys=31.18%, ctx=1205994, majf=0, minf=1573</div><div class="line">  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, &gt;=64=0.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     issued    : total=r=0/w=1205849/d=0, short=r=0/w=0/d=0, drop=r=0/w=0/d=0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">  WRITE: io=4710.4MB, aggrb=160774KB/s, minb=160774KB/s, maxb=160774KB/s, mint=30001msec, maxt=30001msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">    dm-2: ios=0/1204503, merge=0/0, ticks=0/15340, in_queue=15340, util=50.78%, aggrios=0/603282, aggrmerge=0/463, aggrticks=0/8822, aggrin_queue=0, aggrutil=28.66%</div><div class="line">  nvme0n1: ios=0/683021, merge=0/474, ticks=0/9992, in_queue=0, util=28.66%</div><div class="line">  nvme1n1: ios=0/523543, merge=0/452, ticks=0/7652, in_queue=0, util=21.67%</div><div class="line">  </div><div class="line">[root@x86.170 /polarx/lvm]</div><div class="line">#/usr/sbin/nvme list</div><div class="line">Node             SN                   Model                                    Namespace Usage                      Format           FW Rev</div><div class="line">---------------- -------------------- ---------------------------------------- --------- -------------------------- ---------------- --------</div><div class="line">/dev/nvme0n1     BTLJ932205P44P0DGN   INTEL SSDPE2KX040T8                      1           3.84  TB /   3.84  TB    512   B +  0 B   VDV10131</div><div class="line">/dev/nvme1n1     BTLJ932207H04P0DGN   INTEL SSDPE2KX040T8                      1           3.84  TB /   3.84  TB    512   B +  0 B   VDV10131</div><div class="line">/dev/nvme2n1     BTLJ932205AS4P0DGN   INTEL SSDPE2KX040T8                      1           3.84  TB /   3.84  TB    512   B +  0 B   VDV10131</div><div class="line">[root@x86.170 /polarx/lvm]</div><div class="line">#fio  -bs=4k  -direct=1 -buffered=0 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=30</div><div class="line">EBS 4K randwrite test: (g=0): rw=randwrite, bs=4K-4K/4K-4K/4K-4K, ioengine=sync, iodepth=64</div><div class="line">fio-2.2.8</div><div class="line">Starting 1 thread</div><div class="line">Jobs: 1 (f=1): [w(1)] [100.0% done] [0KB/240.2MB/0KB /s] [0/61.5K/0 iops] [eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=11516: Fri Apr  8 15:44:36 2022</div><div class="line">  write: io=7143.3MB, bw=243813KB/s, iops=60953, runt= 30001msec</div><div class="line">    clat (usec): min=10, max=818, avg=14.96, stdev= 4.14</div><div class="line">     lat (usec): min=10, max=818, avg=15.14, stdev= 4.15</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[   11],  5.00th=[   12], 10.00th=[   12], 20.00th=[   14],</div><div class="line">     | 30.00th=[   15], 40.00th=[   15], 50.00th=[   15], 60.00th=[   15],</div><div class="line">     | 70.00th=[   15], 80.00th=[   16], 90.00th=[   16], 95.00th=[   16],</div><div class="line">     | 99.00th=[   20], 99.50th=[   32], 99.90th=[   78], 99.95th=[   84],</div><div class="line">     | 99.99th=[  105]</div><div class="line">    bw (KB  /s): min=236768, max=246424, per=99.99%, avg=243794.17, stdev=1736.82</div><div class="line">    lat (usec) : 20=98.96%, 50=0.73%, 100=0.29%, 250=0.01%, 500=0.01%</div><div class="line">    lat (usec) : 750=0.01%, 1000=0.01%</div><div class="line">  cpu          : usr=10.65%, sys=42.66%, ctx=1828699, majf=0, minf=7</div><div class="line">  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, &gt;=64=0.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     issued    : total=r=0/w=1828662/d=0, short=r=0/w=0/d=0, drop=r=0/w=0/d=0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">  WRITE: io=7143.3MB, aggrb=243813KB/s, minb=243813KB/s, maxb=243813KB/s, mint=30001msec, maxt=30001msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">    dm-0: ios=0/1823575, merge=0/0, ticks=0/13666, in_queue=13667, util=45.56%, aggrios=0/609558, aggrmerge=0/2, aggrticks=0/4280, aggrin_queue=4198, aggrutil=14.47%</div><div class="line">  nvme0n1: ios=0/609144, merge=0/6, ticks=0/4438, in_queue=4353, util=14.47%</div><div class="line">  nvme1n1: ios=0/609470, merge=0/0, ticks=0/4186, in_queue=4109, util=13.65%</div><div class="line">  nvme2n1: ios=0/610060, merge=0/0, ticks=0/4216, in_queue=4134, util=13.74%</div></pre></td></tr></table></figure>
<h3 id="HDD性能测试数据"><a href="#HDD性能测试数据" class="headerlink" title="HDD性能测试数据"></a>HDD性能测试数据</h3><p><img src="/images/951413iMgBlog/0868d560-067f-4302-bc60-bffc3d4460ed.png" alt="img"></p>
<p>从上图可以看到这个磁盘的IOPS 读 935 写 400，读rt 10731nsec 大约10us, 写 17us。如果IOPS是1000的话，rt应该是1ms，实际比1ms小两个数量级，<del>应该是cache、磁盘阵列在起作用。</del></p>
<p>SATA硬盘，10K转</p>
<p>万转机械硬盘组成RAID5阵列，在顺序条件最好的情况下，带宽可以达到1GB/s以上，平均延时也非常低，最低只有20多us。但是在随机IO的情况下，机械硬盘的短板就充分暴露了，零点几兆的带宽，将近5ms的延迟，IOPS只有200左右。其原因是因为</p>
<ul>
<li>随机访问直接让RAID卡缓存成了个摆设</li>
<li>磁盘不能并行工作，因为我的机器RAID宽度Strip Size为128 KB</li>
<li>机械轴也得在各个磁道之间跳来跳去。</li>
</ul>
<p>理解了磁盘顺序IO时候的几十M甚至一个GB的带宽，随机IO这个真的是太可怜了。</p>
<p>从上面的测试数据中我们看到了机械硬盘在顺序IO和随机IO下的巨大性能差异。在顺序IO情况下，磁盘是最擅长的顺序IO,再加上Raid卡缓存命中率也高。这时带宽表现有几十、几百M，最好条件下甚至能达到1GB。IOPS这时候能有2-3W左右。到了随机IO的情形下，机械轴也被逼的跳来跳去寻道，RAID卡缓存也失效了。带宽跌到了1MB以下，最低只有100K，IOPS也只有可怜巴巴的200左右。</p>
<h2 id="测试数据总结"><a href="#测试数据总结" class="headerlink" title="测试数据总结"></a>测试数据总结</h2><table>
<thead>
<tr>
<th></th>
<th>-direct=1 -buffered=1</th>
<th>-direct=0 -buffered=1</th>
<th>-direct=1 -buffered=0</th>
<th>-direct=0 -buffered=0</th>
</tr>
</thead>
<tbody>
<tr>
<td>NVMe SSD</td>
<td>R=10.6k W=4544</td>
<td>R=10.8K W=4642</td>
<td>R=99.8K W=42.8K</td>
<td>R=38.6k W=16.5k</td>
</tr>
<tr>
<td>SATA SSD</td>
<td>R=4312 W=1852</td>
<td>R=5389 W=2314</td>
<td>R=16.9k W=7254</td>
<td>R=15.8k W=6803</td>
</tr>
<tr>
<td>ESSD</td>
<td>R=2149 W=2150</td>
<td>R=1987 W=1984</td>
<td>R=2462 W=2465</td>
<td>R=2455 W=2458</td>
</tr>
</tbody>
</table>
<p>看起来，<strong>对于SSD如果buffered为1的话direct没啥用，如果buffered为0那么direct为1性能要好很多</strong></p>
<p><strong>SATA SSD的IOPS比NVMe性能差很多</strong>。</p>
<p>SATA SSD当-buffered=1参数下SATA SSD的latency在7-10us之间。 </p>
<p>NVMe SSD以及SATA SSD当buffered=0的条件下latency均为2-3us,  NVMe SSD latency参考文章第一个表格， 和本次NVMe测试结果一致.  </p>
<p>ESSD的latency基本是13-16us。</p>
<p>以上NVMe SSD测试数据是在测试过程中还有mysql在全力导入数据的情况下，用fio测试所得。所以空闲情况下测试结果会更好。</p>
<h3 id="网上测试数据参考"><a href="#网上测试数据参考" class="headerlink" title="网上测试数据参考"></a><a href="https://zhuanlan.zhihu.com/p/40497397" target="_blank" rel="external">网上测试数据参考</a></h3><p>我们来一起看一下具体的数据。首先来看NVＭe如何减小了协议栈本身的时间消耗，我们用<em>blktrace</em>工具来分析一组传输在应用程序层、操作系统层、驱动层和硬件层消耗的时间和占比，来了解AHCI和NVMe协议的性能区别：</p>
<p><img src="/images/951413iMgBlog/v2-8b37f236d5c754efabe17aa9706f99a3_720w.jpg" alt="img"></p>
<p>硬盘HDD作为一个参考基准，它的时延是非常大的，达到14ms，而AHCI SATA为125us，NVMe为111us。我们从图中可以看出，NVMe相对AHCI，协议栈及之下所占用的时间比重明显减小，应用程序层面等待的时间占比很高，这是因为SSD物理硬盘速度不够快，导致应用空转。NVMe也为将来Optane硬盘这种低延迟介质的速度提高留下了广阔的空间。</p>
<h2 id="对比LVM-、RAID0和-一块NVMe-SSD"><a href="#对比LVM-、RAID0和-一块NVMe-SSD" class="headerlink" title="对比LVM 、RAID0和 一块NVMe SSD"></a>对比LVM 、RAID0和 一块NVMe SSD</h2><p>曙光H620-G30A机型下测试</p>
<p>各拿两块nvme，分别作LVM和RAID0，另外单独拿一块nvme直接读写，条带用的是4块nvme做的，然后比较顺序、随机读写，测试结果如下：</p>
<table>
<thead>
<tr>
<th></th>
<th>RAID0（2块盘）</th>
<th>NVMe</th>
<th>LVM</th>
<th>RAID0（4块盘）</th>
<th>条带（4块 linear）</th>
</tr>
</thead>
<tbody>
<tr>
<td>dd write bs=1M count=10240 conv=fsync</td>
<td>10.9秒</td>
<td>23秒</td>
<td>24.6秒</td>
<td>10.9秒</td>
<td>11.9秒</td>
</tr>
<tr>
<td>fio -ioengine=libaio -bs=4k  -buffered=1</td>
<td>bw=346744KB/s, iops=86686 <br> nvme6n1: util=38.43%<br> nvme7n1: util=38.96%</td>
<td>bw=380816KB/s, iops=95203<br>nvme2n1: util=68.31%</td>
<td>bw=175704KB/s, iops=43925<br>nvme0n1:util=29.60%<br>nvme1n1: util=25.64%</td>
<td>bw=337495KB/s, iops=84373<br> nvme6n1: util=20.93%<br> nvme5n1: util=21.30%<br> nvme4n1: util=21.12%<br> nvme7n1: util=20.95%</td>
<td>bw=329721KB/s, iops=82430<br> nvme0n1: util=67.22%<br> nvme3n1: util=0%<br>条带每次只写一块盘</td>
</tr>
<tr>
<td>fio -ioengine=libaio -bs=4k -direct=1 -buffered=0</td>
<td>bw=121556KB/s, iops=30389 <br> nvme6n1: util=18.70%<br> nvme7n1: util=18.91%</td>
<td>bw=126215KB/s, iops=31553<br>nvme2n1: util=37.27%</td>
<td>bw=117192KB/s, iops=29297<br>nvme0n1:util=21.16%<br>nvme1n1: util=13.35%</td>
<td>bw=119145KB/s, iops=29786<br> nvme6n1: util=9.19%<br> nvme5n1: util=9.45%<br> nvme4n1: util=9.45%<br> nvme7n1: util=9.30%</td>
<td>bw=116688KB/s, iops=29171<br> nvme0n1: util=37.87%<br> nvme3n1: util=0%<br>条带每次只写一块盘</td>
</tr>
<tr>
<td>fio -bs=4k -direct=1 -buffered=0</td>
<td>bw=104107KB/s, iops=26026 <br> nvme6n1: util=15.55%<br> nvme7n1: util=15.00%</td>
<td>bw=105115KB/s, iops=26278<br>nvme2n1: util=31.25%</td>
<td>bw=101936KB/s, iops=25484<br>nvme0n1:util=17.76%<br>nvme1n1: util=12.07%</td>
<td>bw=102517KB/s, iops=25629<br> nvme6n1: util=8.13%<br> nvme5n1: util=7.65%<br> nvme4n1: util=7.57%<br> nvme7n1: util=7.75%</td>
<td>bw=87280KB/s, iops=21820<br> nvme0n1: util=31.27%<br> nvme3n1: util=0%<br>条带每次只写一块盘</td>
</tr>
</tbody>
</table>
<ul>
<li>整体看 nvme 最好(顺序写除外)，raid0性能接近nvme，LVM最差</li>
<li>顺序写raid0是nvme、LVM的两倍</li>
<li>随机读写带buffered的话 nvme最好，raid0略差（猜测是软件消耗），LVM只有前两者的一半</li>
<li>关掉buffered 三者性能下降都很大，最终差异变小</li>
<li>raid0下两块盘非常均衡，LVM下两块盘负载差异比较大</li>
<li>性能不在单块盘到了瓶颈，当阵列中盘数变多后，软件实现的LVM、RAID性能都有下降</li>
<li>开buffer对性能提升非常大</li>
<li>每次测试前都会echo 3 &gt; /proc/sys/vm/drop_caches ; rm -f ./fio.test ;测试跑多次，取稳定值</li>
</ul>
<h3 id="顺序读写"><a href="#顺序读写" class="headerlink" title="顺序读写"></a>顺序读写</h3><p>然后同时做dd写入测试</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">time taskset -c 0 dd if=/dev/zero of=./tempfile2 bs=1M count=40240 &amp;</div></pre></td></tr></table></figure>
<p>下图上面两块nvme做的LVM，下面两块nvme做成RAID0，同时开始测试，可以看到RAID0的两块盘写入速度更快</p>
<p><img src="/images/951413iMgBlog/image-20211231205730735.png" alt="image-20211231205730735"></p>
<p>测试结果</p>
<p><img src="/images/951413iMgBlog/image-20211231205842753.png" alt="image-20211231205842753"></p>
<p>实际单独写一块nvme也比写两块nvme做的LVM要快一倍，对dd这样的顺序读写，软RAID0还是能提升一倍速度的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line">[root@hygon33 14:02 /nvme]</div><div class="line">#echo 3 &gt; /proc/sys/vm/drop_caches ; rm -f ./tempfile2 ; time taskset -c 16 dd if=/dev/zero of=./tempfile2 bs=1M count=10240 conv=fsync</div><div class="line">记录了10240+0 的读入</div><div class="line">记录了10240+0 的写出</div><div class="line">10737418240字节（11 GB，10 GiB）已复制，23.0399 s，466 MB/s</div><div class="line"></div><div class="line">real	0m23.046s</div><div class="line">user	0m0.004s</div><div class="line">sys	0m8.033s</div><div class="line"></div><div class="line">[root@hygon33 14:08 /nvme]</div><div class="line">#cd ../md0/</div><div class="line"></div><div class="line">[root@hygon33 14:08 /md0]</div><div class="line">#echo 3 &gt; /proc/sys/vm/drop_caches ; rm -f ./tempfile2 ; time taskset -c 16 dd if=/dev/zero of=./tempfile2 bs=1M count=10240 conv=fsync</div><div class="line">记录了10240+0 的读入</div><div class="line">记录了10240+0 的写出</div><div class="line">10737418240字节（11 GB，10 GiB）已复制，10.9632 s，979 MB/s</div><div class="line"></div><div class="line">real	0m10.967s</div><div class="line">user	0m0.004s</div><div class="line">sys	0m10.899s</div><div class="line"></div><div class="line">[root@hygon33 14:08 /md0]</div><div class="line">#cd /polarx/</div><div class="line"></div><div class="line">[root@hygon33 14:08 /polarx]</div><div class="line">#echo 3 &gt; /proc/sys/vm/drop_caches ; rm -f ./tempfile2 ; time taskset -c 16 dd if=/dev/zero of=./tempfile2 bs=1M count=10240 conv=fsync</div><div class="line">记录了10240+0 的读入</div><div class="line">记录了10240+0 的写出</div><div class="line">10737418240字节（11 GB，10 GiB）已复制，24.6481 s，436 MB/s</div><div class="line"></div><div class="line">real	0m24.653s</div><div class="line">user	0m0.008s</div><div class="line">sys	0m24.557s</div></pre></td></tr></table></figure>
<h3 id="随机读写"><a href="#随机读写" class="headerlink" title="随机读写"></a>随机读写</h3><p>SSD单独的随机读IOPS大概是随机写IOPS的10%, 应该是因为write有cache</p>
<p>RAID0是使用mdadm做的软raid，系统层面还是有消耗，没法和RAID卡硬件比较</p>
<p>左边是一块nvme，中间是两块nvme做了LVM，右边是两块nvme做RAID0，看起来速度差不多，一块nvme似乎要好一点点</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">fio -ioengine=libaio -bs=4k -buffered=1 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div></pre></td></tr></table></figure>
<p><img src="/images/951413iMgBlog/image-20220101104145331.png" alt="image-20220101104145331"></p>
<p>从观察来看，RAID0的两块盘读写、iops都非常均衡，LVM的两块盘</p>
<p>三个测试分开跑，独立nvme性能最好，LVM最差并且不均衡</p>
<p><img src="/images/951413iMgBlog/image-20220101110016074.png" alt="image-20220101110016074"></p>
<p>三个测试分开跑，去掉 aio，性能都只有原来的一半</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">fio  -bs=4k -direct=1 -buffered=0 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div></pre></td></tr></table></figure>
<p><img src="/images/951413iMgBlog/image-20220101110708888.png" alt="image-20220101110708888"></p>
<p>修改fio参数，用最快的 direct=0 buffered=1 aio 结论是raid0最快，直接写nvme略慢，LVM只有raid0的一半</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div></pre></td><td class="code"><pre><div class="line">[root@hygon33 13:43 /md0]</div><div class="line">#echo 3 &gt; /proc/sys/vm/drop_caches ; rm -f ./fio.test; fio -ioengine=libaio -bs=4k -direct=0 -buffered=1 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div><div class="line">EBS 4K randwrite test: (g=0): rw=randwrite, bs=4K-4K/4K-4K/4K-4K, ioengine=libaio, iodepth=64</div><div class="line">fio-2.2.8</div><div class="line">Starting 1 thread</div><div class="line">EBS 4K randwrite test: Laying out IO file(s) (1 file(s) / 16384MB)</div><div class="line">Jobs: 1 (f=1): [w(1)] [98.1% done] [0KB/394.3MB/0KB /s] [0/101K/0 iops] [eta 00m:01s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=21016: Sat Jan  1 13:45:25 2022</div><div class="line">  write: io=16384MB, bw=329974KB/s, iops=82493, runt= 50844msec</div><div class="line">    slat (usec): min=3, max=1496, avg= 9.00, stdev= 2.76</div><div class="line">    clat (usec): min=5, max=2272, avg=764.73, stdev=101.63</div><div class="line">     lat (usec): min=10, max=2282, avg=774.19, stdev=103.15</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[  510],  5.00th=[  612], 10.00th=[  644], 20.00th=[  684],</div><div class="line">     | 30.00th=[  700], 40.00th=[  716], 50.00th=[  772], 60.00th=[  820],</div><div class="line">     | 70.00th=[  844], 80.00th=[  860], 90.00th=[  884], 95.00th=[  908],</div><div class="line">     | 99.00th=[  932], 99.50th=[  940], 99.90th=[  988], 99.95th=[ 1064],</div><div class="line">     | 99.99th=[ 1336]</div><div class="line">    bw (KB  /s): min=277928, max=490720, per=99.84%, avg=329447.45, stdev=40386.54</div><div class="line">    lat (usec) : 10=0.01%, 20=0.01%, 50=0.01%, 100=0.01%, 250=0.01%</div><div class="line">    lat (usec) : 500=0.17%, 750=48.67%, 1000=51.08%</div><div class="line">    lat (msec) : 2=0.08%, 4=0.01%</div><div class="line">  cpu          : usr=17.79%, sys=81.97%, ctx=113, majf=0, minf=5526</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued    : total=r=0/w=4194304/d=0, short=r=0/w=0/d=0, drop=r=0/w=0/d=0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">  WRITE: io=16384MB, aggrb=329974KB/s, minb=329974KB/s, maxb=329974KB/s, mint=50844msec, maxt=50844msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">    md0: ios=0/2883541, merge=0/0, ticks=0/0, in_queue=0, util=0.00%, aggrios=0/1232592, aggrmerge=0/219971, aggrticks=0/44029, aggrin_queue=0, aggrutil=38.91%</div><div class="line">  nvme6n1: ios=0/1228849, merge=0/219880, ticks=0/43940, in_queue=0, util=37.19%</div><div class="line">  nvme7n1: ios=0/1236335, merge=0/220062, ticks=0/44119, in_queue=0, util=38.91%</div><div class="line">  </div><div class="line">[root@hygon33 13:46 /nvme]</div><div class="line">#echo 3 &gt; /proc/sys/vm/drop_caches ; rm -f ./fio.test; fio -ioengine=libaio -bs=4k -direct=0 -buffered=1 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div><div class="line">EBS 4K randwrite test: (g=0): rw=randwrite, bs=4K-4K/4K-4K/4K-4K, ioengine=libaio, iodepth=64</div><div class="line">fio-2.2.8</div><div class="line">Starting 1 thread</div><div class="line">EBS 4K randwrite test: Laying out IO file(s) (1 file(s) / 16384MB)</div><div class="line">Jobs: 1 (f=1): [w(1)] [100.0% done] [0KB/314.3MB/0KB /s] [0/80.5K/0 iops] [eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=21072: Sat Jan  1 13:47:32 2022</div><div class="line">  write: io=16384MB, bw=309554KB/s, iops=77388, runt= 54198msec</div><div class="line">    slat (usec): min=3, max=88800, avg= 9.83, stdev=44.88</div><div class="line">    clat (usec): min=5, max=89662, avg=815.09, stdev=381.75</div><div class="line">     lat (usec): min=27, max=89748, avg=825.38, stdev=385.05</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[  470],  5.00th=[  612], 10.00th=[  652], 20.00th=[  684],</div><div class="line">     | 30.00th=[  716], 40.00th=[  756], 50.00th=[  796], 60.00th=[  836],</div><div class="line">     | 70.00th=[  876], 80.00th=[  932], 90.00th=[ 1012], 95.00th=[ 1096],</div><div class="line">     | 99.00th=[ 1272], 99.50th=[ 1368], 99.90th=[ 1688], 99.95th=[ 1912],</div><div class="line">     | 99.99th=[ 3920]</div><div class="line">    bw (KB  /s): min=247208, max=523840, per=99.99%, avg=309507.85, stdev=34709.01</div><div class="line">    lat (usec) : 10=0.01%, 50=0.01%, 100=0.01%, 250=0.01%, 500=1.73%</div><div class="line">    lat (usec) : 750=37.71%, 1000=49.60%</div><div class="line">    lat (msec) : 2=10.91%, 4=0.03%, 10=0.01%, 100=0.01%</div><div class="line">  cpu          : usr=16.00%, sys=79.36%, ctx=138668, majf=0, minf=5522</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued    : total=r=0/w=4194304/d=0, short=r=0/w=0/d=0, drop=r=0/w=0/d=0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">  WRITE: io=16384MB, aggrb=309554KB/s, minb=309554KB/s, maxb=309554KB/s, mint=54198msec, maxt=54198msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">    dm-0: ios=77/1587455, merge=0/0, ticks=184/244940, in_queue=245124, util=98.23%, aggrios=77/1584444, aggrmerge=0/5777, aggrticks=183/193531, aggrin_queue=76, aggrutil=81.60%</div><div class="line">  sda: ios=77/1584444, merge=0/5777, ticks=183/193531, in_queue=76, util=81.60%</div><div class="line">  </div><div class="line">[root@hygon33 13:50 /polarx]</div><div class="line">#echo 3 &gt; /proc/sys/vm/drop_caches ; rm -f ./fio.test; fio -ioengine=libaio -bs=4k -direct=0 -buffered=1 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div><div class="line">EBS 4K randwrite test: (g=0): rw=randwrite, bs=4K-4K/4K-4K/4K-4K, ioengine=libaio, iodepth=64</div><div class="line">fio-2.2.8</div><div class="line">Starting 1 thread</div><div class="line">EBS 4K randwrite test: Laying out IO file(s) (1 file(s) / 16384MB)</div><div class="line">Jobs: 1 (f=1): [w(1)] [100.0% done] [0KB/293.2MB/0KB /s] [0/75.1K/0 iops] [eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=22787: Sat Jan  1 13:51:16 2022</div><div class="line">  write: io=10270MB, bw=175269KB/s, iops=43817, runt= 60001msec</div><div class="line">    slat (usec): min=4, max=2609, avg=19.43, stdev=19.84</div><div class="line">    clat (usec): min=4, max=6420, avg=1438.87, stdev=483.15</div><div class="line">     lat (usec): min=17, max=6718, avg=1458.80, stdev=490.29</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[  700],  5.00th=[  788], 10.00th=[  852], 20.00th=[  964],</div><div class="line">     | 30.00th=[ 1080], 40.00th=[ 1208], 50.00th=[ 1368], 60.00th=[ 1560],</div><div class="line">     | 70.00th=[ 1752], 80.00th=[ 1944], 90.00th=[ 2128], 95.00th=[ 2224],</div><div class="line">     | 99.00th=[ 2416], 99.50th=[ 2480], 99.90th=[ 2672], 99.95th=[ 3248],</div><div class="line">     | 99.99th=[ 5088]</div><div class="line">    bw (KB  /s): min=109992, max=308016, per=99.40%, avg=174219.83, stdev=56844.59</div><div class="line">    lat (usec) : 10=0.01%, 20=0.01%, 50=0.01%, 100=0.01%, 250=0.01%</div><div class="line">    lat (usec) : 500=0.01%, 750=2.87%, 1000=20.63%</div><div class="line">    lat (msec) : 2=59.43%, 4=17.03%, 10=0.03%</div><div class="line">  cpu          : usr=9.11%, sys=57.07%, ctx=762410, majf=0, minf=1769</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued    : total=r=0/w=2629079/d=0, short=r=0/w=0/d=0, drop=r=0/w=0/d=0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">  WRITE: io=10270MB, aggrb=175269KB/s, minb=175269KB/s, maxb=175269KB/s, mint=60001msec, maxt=60001msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">    dm-2: ios=1/3185487, merge=0/0, ticks=0/86364, in_queue=86364, util=46.24%, aggrios=0/1576688, aggrmerge=0/16344, aggrticks=0/40217, aggrin_queue=0, aggrutil=29.99%</div><div class="line">  nvme0n1: ios=0/1786835, merge=0/16931, ticks=0/44447, in_queue=0, util=29.99%</div><div class="line">  nvme1n1: ios=1/1366541, merge=0/15758, ticks=0/35987, in_queue=0, util=25.44%</div></pre></td></tr></table></figure>
<p>将RAID0从两块nvme改成四块后，整体性能略微下降</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line">#fio  -bs=4k -direct=1 -buffered=0 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div><div class="line">EBS 4K randwrite test: (g=0): rw=randwrite, bs=4K-4K/4K-4K/4K-4K, ioengine=sync, iodepth=64</div><div class="line">fio-2.2.8</div><div class="line">Starting 1 thread</div><div class="line">EBS 4K randwrite test: Laying out IO file(s) (1 file(s) / 16384MB)</div><div class="line">Jobs: 1 (f=1): [w(1)] [100.0% done] [0KB/99756KB/0KB /s] [0/24.1K/0 iops] [eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=30608: Sat Jan  1 12:09:29 2022</div><div class="line">  write: io=5733.9MB, bw=97857KB/s, iops=24464, runt= 60001msec</div><div class="line">    clat (usec): min=29, max=2885, avg=37.95, stdev=12.19</div><div class="line">     lat (usec): min=30, max=2886, avg=38.49, stdev=12.20</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[   32],  5.00th=[   33], 10.00th=[   34], 20.00th=[   35],</div><div class="line">     | 30.00th=[   36], 40.00th=[   36], 50.00th=[   37], 60.00th=[   37],</div><div class="line">     | 70.00th=[   38], 80.00th=[   39], 90.00th=[   40], 95.00th=[   49],</div><div class="line">     | 99.00th=[   65], 99.50th=[   76], 99.90th=[  109], 99.95th=[  125],</div><div class="line">     | 99.99th=[  203]</div><div class="line">    bw (KB  /s): min=92968, max=108344, per=99.99%, avg=97846.18, stdev=2085.73</div><div class="line">    lat (usec) : 50=95.20%, 100=4.61%, 250=0.18%, 500=0.01%, 750=0.01%</div><div class="line">    lat (usec) : 1000=0.01%</div><div class="line">    lat (msec) : 2=0.01%, 4=0.01%</div><div class="line">  cpu          : usr=4.67%, sys=56.35%, ctx=1467919, majf=0, minf=1144</div><div class="line">  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, &gt;=64=0.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     issued    : total=r=0/w=1467872/d=0, short=r=0/w=0/d=0, drop=r=0/w=0/d=0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">  WRITE: io=5733.9MB, aggrb=97856KB/s, minb=97856KB/s, maxb=97856KB/s, mint=60001msec, maxt=60001msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">    md0: ios=0/1553786, merge=0/0, ticks=0/0, in_queue=0, util=0.00%, aggrios=0/370860, aggrmerge=0/17733, aggrticks=0/6539, aggrin_queue=0, aggrutil=8.41%</div><div class="line">  nvme6n1: ios=0/369576, merge=0/17648, ticks=0/6439, in_queue=0, util=7.62%</div><div class="line">  nvme5n1: ios=0/370422, merge=0/17611, ticks=0/6600, in_queue=0, util=7.72%</div><div class="line">  nvme4n1: ios=0/371559, merge=0/18092, ticks=0/6511, in_queue=0, util=8.41%</div><div class="line">  nvme7n1: ios=0/371886, merge=0/17584, ticks=0/6606, in_queue=0, util=8.17%</div></pre></td></tr></table></figure>
<h3 id="raid6测试"><a href="#raid6测试" class="headerlink" title="raid6测试"></a>raid6测试</h3><p>raid6开buffer性能比raid0还要好10-20%，实际是将刷盘延迟异步在做，如果用-buffer=0 raid6的性能只有raid0的一半</p>
<p><img src="/images/951413iMgBlog/image-20220105173206915.png" alt="image-20220105173206915"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div></pre></td><td class="code"><pre><div class="line">[root@hygon33 17:19 /md6]</div><div class="line">#echo 3 &gt; /proc/sys/vm/drop_caches ; rm -f ./fio.test; fio -ioengine=libaio -bs=4k -direct=1 -buffered=1 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div><div class="line">EBS 4K randwrite test: (g=0): rw=randwrite, bs=4K-4K/4K-4K/4K-4K, ioengine=libaio, iodepth=64</div><div class="line">fio-2.2.8</div><div class="line">Starting 1 thread</div><div class="line">EBS 4K randwrite test: Laying out IO file(s) (1 file(s) / 16384MB)</div><div class="line">Jobs: 1 (f=1): [w(1)] [100.0% done] [0KB/424.9MB/0KB /s] [0/109K/0 iops] [eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=117679: Wed Jan  5 17:21:13 2022</div><div class="line">  write: io=16384MB, bw=432135KB/s, iops=108033, runt= 38824msec</div><div class="line">    slat (usec): min=4, max=7289, avg= 6.06, stdev= 5.28</div><div class="line">    clat (usec): min=3, max=7973, avg=584.23, stdev=45.35</div><div class="line">     lat (usec): min=10, max=7986, avg=590.77, stdev=45.75</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[  548],  5.00th=[  556], 10.00th=[  564], 20.00th=[  572],</div><div class="line">     | 30.00th=[  580], 40.00th=[  580], 50.00th=[  580], 60.00th=[  588],</div><div class="line">     | 70.00th=[  588], 80.00th=[  596], 90.00th=[  604], 95.00th=[  612],</div><div class="line">     | 99.00th=[  636], 99.50th=[  660], 99.90th=[  796], 99.95th=[  820],</div><div class="line">     | 99.99th=[  916]</div><div class="line">    bw (KB  /s): min=423896, max=455400, per=99.97%, avg=432015.17, stdev=6404.92</div><div class="line">    lat (usec) : 4=0.01%, 20=0.01%, 50=0.01%, 100=0.01%, 250=0.01%</div><div class="line">    lat (usec) : 500=0.01%, 750=99.78%, 1000=0.21%</div><div class="line">    lat (msec) : 2=0.01%, 4=0.01%, 10=0.01%</div><div class="line">  cpu          : usr=21.20%, sys=78.56%, ctx=57, majf=0, minf=1769</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued    : total=r=0/w=4194304/d=0, short=r=0/w=0/d=0, drop=r=0/w=0/d=0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">  WRITE: io=16384MB, aggrb=432135KB/s, minb=432135KB/s, maxb=432135KB/s, mint=38824msec, maxt=38824msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">    md6: ios=0/162790, merge=0/0, ticks=0/0, in_queue=0, util=0.00%, aggrios=83058/153522, aggrmerge=1516568/962072, aggrticks=29792/16802, aggrin_queue=2425, aggrutil=44.71%</div><div class="line">  nvme0n1: ios=83410/144109, merge=1517412/995022, ticks=31218/16718, in_queue=2416, util=43.62%</div><div class="line">  nvme3n1: ios=83301/162626, merge=1517086/927594, ticks=24190/17067, in_queue=2364, util=34.14%</div><div class="line">  nvme2n1: ios=81594/144341, merge=1514750/992273, ticks=32204/16646, in_queue=2504, util=44.71%</div><div class="line">  nvme1n1: ios=83929/163013, merge=1517025/933399, ticks=31559/16780, in_queue=2416, util=42.83%</div><div class="line"></div><div class="line">[root@hygon33 17:21 /md6]</div><div class="line">#echo 3 &gt; /proc/sys/vm/drop_caches ; rm -f ./fio.test; fio -ioengine=libaio -bs=4k -direct=1 -buffered=0 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div><div class="line">EBS 4K randwrite test: (g=0): rw=randwrite, bs=4K-4K/4K-4K/4K-4K, ioengine=libaio, iodepth=64</div><div class="line">fio-2.2.8</div><div class="line">Starting 1 thread</div><div class="line">EBS 4K randwrite test: Laying out IO file(s) (1 file(s) / 16384MB)</div><div class="line">Jobs: 1 (f=0): [w(1)] [22.9% done] [0KB/51034KB/0KB /s] [0/12.8K/0 iops] [eta 03m:25s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=164871: Wed Jan  5 17:25:17 2022</div><div class="line">  write: io=3743.6MB, bw=63887KB/s, iops=15971, runt= 60003msec</div><div class="line">    slat (usec): min=11, max=123152, avg=29.39, stdev=283.93</div><div class="line">    clat (usec): min=261, max=196197, avg=3975.22, stdev=3526.29</div><div class="line">     lat (usec): min=300, max=196223, avg=4005.13, stdev=3554.65</div><div class="line">    clat percentiles (msec):</div><div class="line">     |  1.00th=[    3],  5.00th=[    3], 10.00th=[    4], 20.00th=[    4],</div><div class="line">     | 30.00th=[    4], 40.00th=[    4], 50.00th=[    4], 60.00th=[    4],</div><div class="line">     | 70.00th=[    5], 80.00th=[    5], 90.00th=[    5], 95.00th=[    6],</div><div class="line">     | 99.00th=[    7], 99.50th=[    7], 99.90th=[   39], 99.95th=[   88],</div><div class="line">     | 99.99th=[  167]</div><div class="line">    bw (KB  /s): min=41520, max=78176, per=100.00%, avg=64093.14, stdev=6896.65</div><div class="line">    lat (usec) : 500=0.02%, 750=0.03%, 1000=0.02%</div><div class="line">    lat (msec) : 2=0.73%, 4=64.28%, 10=34.72%, 20=0.06%, 50=0.08%</div><div class="line">    lat (msec) : 100=0.02%, 250=0.05%</div><div class="line">  cpu          : usr=4.11%, sys=48.69%, ctx=357564, majf=0, minf=2653</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued    : total=r=0/w=958349/d=0, short=r=0/w=0/d=0, drop=r=0/w=0/d=0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">  WRITE: io=3743.6MB, aggrb=63886KB/s, minb=63886KB/s, maxb=63886KB/s, mint=60003msec, maxt=60003msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">    md6: ios=0/1022450, merge=0/0, ticks=0/0, in_queue=0, util=0.00%, aggrios=262364/764703, aggrmerge=430291/192464, aggrticks=38687/55432, aggrin_queue=317, aggrutil=42.63%</div><div class="line">  nvme0n1: ios=262282/759874, merge=430112/209613, ticks=43304/55197, in_queue=324, util=42.63%</div><div class="line">  nvme3n1: ios=260535/771153, merge=430415/176326, ticks=25263/55664, in_queue=280, util=26.11%</div><div class="line">  nvme2n1: ios=263663/758974, merge=430349/208189, ticks=42754/55761, in_queue=280, util=42.14%</div><div class="line">  nvme1n1: ios=262976/768813, merge=430289/175731, ticks=43430/55109, in_queue=384, util=42.00%</div></pre></td></tr></table></figure>
<p>测试完成很久后ssd还维持高水位的读写</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</div><div class="line">           0.28    0.00    1.15    0.05    0.00   98.51</div><div class="line"></div><div class="line">Device            r/s     rkB/s   rrqm/s  %rrqm r_await rareq-sz     w/s     wkB/s   wrqm/s  %wrqm w_await wareq-sz     d/s     dkB/s   drqm/s  %drqm d_await dareq-sz  aqu-sz  %util</div><div class="line">dm-0             5.00     56.00     0.00   0.00    0.53    11.20   39.00    292.33     0.00   0.00    0.00     7.50    0.00      0.00     0.00   0.00    0.00     0.00    0.00   0.27</div><div class="line">md6              0.00      0.00     0.00   0.00    0.00     0.00   14.00   1794.67     0.00   0.00    0.00   128.19    0.00      0.00     0.00   0.00    0.00     0.00    0.00   0.00</div><div class="line">nvme0n1       1164.67 144488.00 34935.33  96.77    0.74   124.06 3203.67  53877.83 10267.00  76.22    0.16    16.82    0.00      0.00     0.00   0.00    0.00     0.00    0.32  32.13</div><div class="line">nvme1n1       1172.33 144402.67 34925.00  96.75    0.74   123.18 3888.67  46635.17  7771.33  66.65    0.13    11.99    0.00      0.00     0.00   0.00    0.00     0.00    0.33  29.60</div><div class="line">nvme2n1       1166.67 144372.00 34914.00  96.77    0.74   123.75 3263.00  53699.17 10162.67  75.70    0.14    16.46    0.00      0.00     0.00   0.00    0.00     0.00    0.33  27.87</div><div class="line">nvme3n1       1157.67 144414.67 34934.33  96.79    0.64   124.75 3894.33  47073.83  7875.00  66.91    0.13    12.09    0.00      0.00     0.00   0.00    0.00     0.00    0.31  20.80</div><div class="line">sda              5.00     56.00     0.00   0.00    0.13    11.20   39.00    204.17     0.00   0.00    0.12     5.24    0.00      0.00     0.00   0.00    0.00     0.00    0.00   0.27</div></pre></td></tr></table></figure>
<h2 id="fio-结果解读"><a href="#fio-结果解读" class="headerlink" title="fio 结果解读"></a>fio 结果解读</h2><p>slat，异步场景下才有</p>
<blockquote>
<p>其中slat指的是发起IO的时间，在异步IO模式下，发起IO以后，IO会异步完成。例如调用一个异步的write，虽然write返回成功了，但是IO还未完成，slat约等于发起write的耗时；</p>
<p>slat (usec): min=4, max=6154, avg=48.82, stdev=56.38： The first latency metric you’ll see is the ‘slat’ or submission latency. It is pretty much what it sounds like, meaning “how long did it take to submit this IO to the kernel for processing?”</p>
</blockquote>
<p>clat</p>
<blockquote>
<p>clat指的是完成时间，从发起IO后到完成IO的时间，在同步IO模式下，clat是指整个写动作完成时间</p>
</blockquote>
<p>lat</p>
<blockquote>
<p>lat是总延迟时间，指的是IO单元创建到完成的总时间，通常这项数据关注较多。同步场景几乎等于clat，异步场景等于clat+slat<br>这项数据需要关注的是max，看看有没有极端的高延迟IO；另外还需要关注stdev，这项数据越大说明，IO响应时间波动越大，反之越小，波动越小</p>
</blockquote>
<p>clat percentiles (usec)：处于某个百分位的io操作时延</p>
<p>cpu          : usr=9.11%, sys=57.07%, ctx=762410, majf=0, minf=1769  //用户和系统的CPU占用时间百分比，线程切换次数，major以及minor页面错误的数量。</p>
<p>direct和buffered参数是冲突的，用一个就行，应该是direct=0性能更好，实际不是这样，这里还需要找资料求证下</p>
<blockquote>
<ul>
<li><p><code>direct``=bool</code></p>
<p>If value is true, use non-buffered I/O. This is usually O_DIRECT. Note that OpenBSD and ZFS on Solaris don’t support direct I/O. On Windows the synchronous ioengines don’t support direct I/O. Default: false.</p>
</li>
<li><p><code>buffered``=bool</code></p>
<p>If value is true, use buffered I/O. This is the opposite of the <a href="https://fio.readthedocs.io/en/latest/fio_man.html#cmdoption-arg-direct" target="_blank" rel="external"><code>direct</code></a> option. Defaults to true.</p>
</li>
</ul>
</blockquote>
<h2 id="iostat-结果解读"><a href="#iostat-结果解读" class="headerlink" title="iostat 结果解读"></a><a href="linuxtools-rst.readthedocs.io/zh_CN/latest/tool/iostat.html">iostat 结果解读</a></h2><p>Dm-0就是lvm</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</div><div class="line">           0.32    0.00    3.34    0.13    0.00   96.21</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">sda               0.00    11.40   66.00    7.20  1227.20    74.40    35.56     0.03    0.43    0.47    0.08   0.12   0.88</div><div class="line">nvme0n1           0.00  8612.00    0.00 51749.60     0.00 241463.20     9.33     4.51    0.09    0.00    0.09   0.02  78.56</div><div class="line">dm-0              0.00     0.00    0.00 60361.80     0.00 241463.20     8.00   152.52    2.53    0.00    2.53   0.01  78.26</div><div class="line"></div><div class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</div><div class="line">           0.36    0.00    3.46    0.17    0.00   96.00</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">sda               0.00     8.80    9.20    5.20  1047.20    67.20   154.78     0.01    0.36    0.46    0.19   0.33   0.48</div><div class="line">nvme0n1           0.00 11354.20    0.00 50876.80     0.00 248944.00     9.79     5.25    0.10    0.00    0.10   0.02  80.06</div><div class="line">dm-0              0.00     0.00    0.00 62231.00     0.00 248944.80     8.00   199.49    3.21    0.00    3.21   0.01  78.86</div></pre></td></tr></table></figure>
<p>avgqu_sz，是iostat的一项比较重要的数据。如果队列过长，则表示有大量IO在处理或等待，但是这还不足以说明后端的存储系统达到了处理极限。例如后端存储的并发能力是4096，客户端并发发送了256个IO下去，那么队列长度就是256。即使长时间队列长度是256，也不能说明什么，仅仅表明队列长度是256，有256个IO在处理或者排队。</p>
<p>那么怎么判断IO是在调度队列排队等待，还是在设备上处理呢？iostat有两项数据可以给出一个大致的判断。svctime，这项数据的指的是IO在设备处理中耗费的时间。另外一项数据await，指的是IO从排队到完成的时间，包括了svctime和排队等待的时间。那么通过对比这两项数据，如果两项数据差不多，则说明IO基本没有排队等待，耗费的时间都是设备处理。如果await远大于svctime，则说明有大量的IO在排队，并没有发送给设备处理。</p>
<h2 id="不同厂家SSD性能对比"><a href="#不同厂家SSD性能对比" class="headerlink" title="不同厂家SSD性能对比"></a>不同厂家SSD性能对比</h2><p>国产SSD指的是AliFlash</p>
<p><img src="/images/951413iMgBlog/1638359029693-73b42c13-2649-4f20-9112-a7c4c5dd5432.png" alt="img"></p>
<p><img src="/images/951413iMgBlog/1638358969626-507f34aa-201b-4fd3-91de-66c88c6ce04a.png" alt="img"></p>
<h2 id="rq-affinity"><a href="#rq-affinity" class="headerlink" title="rq_affinity"></a>rq_affinity</h2><p>参考<a href="https://help.aliyun.com/knowledge_detail/65077.html#title-x10-2c0-yll" target="_blank" rel="external">aliyun测试文档</a> , rq_affinity增加2的commit： git show 5757a6d76c</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line">function RunFio</div><div class="line">&#123;</div><div class="line"> numjobs=$1   # 实例中的测试线程数，例如示例中的10</div><div class="line"> iodepth=$2   # 同时发出I/O数的上限，例如示例中的64</div><div class="line"> bs=$3        # 单次I/O的块文件大小，例如示例中的4k</div><div class="line"> rw=$4        # 测试时的读写策略，例如示例中的randwrite</div><div class="line"> filename=$5  # 指定测试文件的名称，例如示例中的/dev/your_device</div><div class="line"> nr_cpus=`cat /proc/cpuinfo |grep &quot;processor&quot; |wc -l`</div><div class="line"> if [ $nr_cpus -lt $numjobs ];then</div><div class="line">     echo “Numjobs is more than cpu cores, exit!”</div><div class="line">     exit -1</div><div class="line"> fi</div><div class="line"> let nu=$numjobs+1</div><div class="line"> cpulist=&quot;&quot;</div><div class="line"> for ((i=1;i&lt;10;i++))</div><div class="line"> do</div><div class="line">     list=`cat /sys/block/your_device/mq/*/cpu_list | awk &apos;&#123;if(i&lt;=NF) print $i;&#125;&apos; i=&quot;$i&quot; | tr -d &apos;,&apos; | tr &apos;\n&apos; &apos;,&apos;`</div><div class="line">     if [ -z $list ];then</div><div class="line">         break</div><div class="line">     fi</div><div class="line">     cpulist=$&#123;cpulist&#125;$&#123;list&#125;</div><div class="line"> done</div><div class="line"> spincpu=`echo $cpulist | cut -d &apos;,&apos; -f 2-$&#123;nu&#125;`</div><div class="line"> echo $spincpu</div><div class="line"> fio --ioengine=libaio --runtime=30s --numjobs=$&#123;numjobs&#125; --iodepth=$&#123;iodepth&#125; --bs=$&#123;bs&#125; --rw=$&#123;rw&#125; --filename=$&#123;filename&#125; --time_based=1 --direct=1 --name=test --group_reporting --cpus_allowed=$spincpu --cpus_allowed_policy=split</div><div class="line">&#125;</div><div class="line">echo 2 &gt; /sys/block/your_device/queue/rq_affinity</div><div class="line">sleep 5</div><div class="line">RunFio 10 64 4k randwrite filename</div></pre></td></tr></table></figure>
<p>对NVME SSD进行测试，左边rq_affinity是2，右边rq_affinity为1，在这个测试参数下rq_affinity为1的性能要好(后许多次测试两者性能差不多)</p>
<p><img src="/images/951413iMgBlog/image-20210607113709945.png" alt="image-20210607113709945"></p>
<h2 id="磁盘挂载参数"><a href="#磁盘挂载参数" class="headerlink" title="磁盘挂载参数"></a>磁盘挂载参数</h2><p>内核一般配置的脏页回写超时时间是30s，理论上page cache能buffer住所有的脏页，但是ext4文件系统的默认挂载参数开始支持日志（journal），文件的inode被修改后，需要刷到journal里，这样系统crash了文件系统能恢复过来，内核配置默认5s刷一次journal。</p>
<p>ext4还有一个配置项叫挂载方式，有<code>ordered</code>和<code>writeback</code>两个选项，区别是ordered在把inode刷到journal里之前，会把inode的所有脏页先回写到磁盘里，如果不希望inode这么快写回到磁盘则可以用writeback参数。当SSD开始写盘的时候会严重影响SSD读能力</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># 编辑/etc/fstab，挂载参数设置为defaults,noatime,nodiratime,delalloc,nobarrier,data=writeback</div><div class="line">/dev/lvm1 /data    ext4    defaults,noatime,nodiratime,delalloc,nobarrier,data=writeback 0 0</div></pre></td></tr></table></figure>
<p><code>noatime</code> 读取文件时，将禁用对元数据的更新。它还启用了 nodiratime 行为，该行为会在读取目录时禁用对元数据的更新</p>
<p><code>nodelalloc</code> 参数是关闭了ext4的delayed  allocation 特性。所谓delayed allocation 是指，把磁盘block的分配推后到真正要写数据的时候，比如写入文件的时候，先写内存，当数据需要落盘的时候，再由文件系统分配磁盘块，这有利于文件系统做出更佳的磁盘块分配决策，比如可以分配大片连续的磁盘块。显然 nodelalloc 性能要差些</p>
<blockquote>
<p>delalloc吞吐高，但是偶发性延迟抖动，平均延迟略高<br>nodelalloc延迟稳定，但是吞吐会下降，偶发性会延迟剧烈抖动.</p>
</blockquote>
<p><code>nobarrier</code> 参数是不保证先写入文件系统日志然后才写入数据，也就是不保证系统崩溃后文件系统恢复的正确性,但是对写入性能有提升</p>
<h3 id="优化case"><a href="#优化case" class="headerlink" title="优化case"></a>优化case</h3><p>10个GB的原始文件里面都是随机数，如何快速建索引支持分页查询top(k,n)场景，机器配置是24核，JVM堆内存限制2.5G，磁盘读写为490-500MB/s左右。</p>
<p>最后成绩在22.9s，去掉评测方法引入的1.1s，5次查询含建索引总时间21.8s，因为读10GB文件就需要21.5s时间。当向SSD开始写索引文件后SSD读取性能下降厉害，实际期望的是写出索引到SSD的时候会被PageCache，没触发刷脏。但是这里的刷盘就是ext4挂载参数 ordered 导致了刷盘。</p>
<p>整个方案是：原始文件切割成小分片，喂给24个worker；每个worker读数据，处理数据，定期批量写索引出去；最后查询会去读每个worker生成的所有索引文件，通过跳表快速seek。</p>
<p><img src="/images/951413iMgBlog/586fef765e3f08f6183907f311a76259.png" alt="img"></p>
<h2 id="LVM性能对比"><a href="#LVM性能对比" class="headerlink" title="LVM性能对比"></a>LVM性能对比</h2><p>磁盘信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">#lsblk</div><div class="line">NAME         MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT</div><div class="line">sda            8:0    0 223.6G  0 disk</div><div class="line">├─sda1         8:1    0     3M  0 part</div><div class="line">├─sda2         8:2    0     1G  0 part /boot</div><div class="line">├─sda3         8:3    0    96G  0 part /</div><div class="line">├─sda4         8:4    0    10G  0 part /tmp</div><div class="line">└─sda5         8:5    0 116.6G  0 part /home</div><div class="line">nvme0n1      259:4    0   2.7T  0 disk</div><div class="line">└─nvme0n1p1  259:5    0   2.7T  0 part</div><div class="line">  └─vg1-drds 252:0    0   5.4T  0 lvm  /drds</div><div class="line">nvme1n1      259:0    0   2.7T  0 disk</div><div class="line">└─nvme1n1p1  259:2    0   2.7T  0 part /u02</div><div class="line">nvme2n1      259:1    0   2.7T  0 disk</div><div class="line">└─nvme2n1p1  259:3    0   2.7T  0 part</div><div class="line">  └─vg1-drds 252:0    0   5.4T  0 lvm  /drds</div></pre></td></tr></table></figure>
<p>单块nvme SSD盘跑mysql server，运行sysbench导入测试数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div></pre></td><td class="code"><pre><div class="line">#iostat -x nvme1n1 1</div><div class="line">Linux 3.10.0-327.ali2017.alios7.x86_64 (k28a11352.eu95sqa) 	05/13/2021 	_x86_64_	(64 CPU)</div><div class="line"></div><div class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</div><div class="line">           0.32    0.00    0.17    0.07    0.00   99.44</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">nvme1n1           0.00    47.19    0.19  445.15     2.03 43110.89   193.62     0.31    0.70    0.03    0.70   0.06   2.85</div><div class="line"></div><div class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</div><div class="line">           1.16    0.00    0.36    0.17    0.00   98.31</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">nvme1n1           0.00   122.00    0.00 3290.00     0.00 271052.00   164.77     1.65    0.50    0.00    0.50   0.05  17.00</div><div class="line"></div><div class="line">#iostat 1</div><div class="line">Linux 3.10.0-327.ali2017.alios7.x86_64 (k28a11352.eu95sqa) 	05/13/2021 	_x86_64_	(64 CPU)</div><div class="line"></div><div class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</div><div class="line">           0.14    0.00    0.13    0.05    0.00   99.67</div><div class="line"></div><div class="line">Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn</div><div class="line">sda              49.21       554.51      2315.83    1416900    5917488</div><div class="line">nvme1n1           5.65         2.34       844.73       5989    2158468</div><div class="line">nvme2n1           0.06         1.13         0.00       2896          0</div><div class="line">nvme0n1           0.06         1.13         0.00       2900          0</div><div class="line">dm-0              0.02         0.41         0.00       1036          0</div><div class="line"></div><div class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</div><div class="line">           1.39    0.00    0.23    0.08    0.00   98.30</div><div class="line"></div><div class="line">Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn</div><div class="line">sda               8.00         0.00        60.00          0         60</div><div class="line">nvme1n1         868.00         0.00    132100.00          0     132100</div><div class="line">nvme2n1           0.00         0.00         0.00          0          0</div><div class="line">nvme0n1           0.00         0.00         0.00          0          0</div><div class="line">dm-0              0.00         0.00         0.00          0          0</div><div class="line"></div><div class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</div><div class="line">           1.44    0.00    0.14    0.09    0.00   98.33</div><div class="line"></div><div class="line">Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn</div><div class="line">sda               0.00         0.00         0.00          0          0</div><div class="line">nvme1n1         766.00         0.00    132780.00          0     132780</div><div class="line">nvme2n1           0.00         0.00         0.00          0          0</div><div class="line">nvme0n1           0.00         0.00         0.00          0          0</div><div class="line">dm-0              0.00         0.00         0.00          0          0</div><div class="line"></div><div class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</div><div class="line">           1.41    0.00    0.16    0.09    0.00   98.34</div><div class="line"></div><div class="line">Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn</div><div class="line">sda             105.00         0.00       532.00          0        532</div><div class="line">nvme1n1         760.00         0.00    122236.00          0     122236</div><div class="line">nvme2n1           0.00         0.00         0.00          0          0</div><div class="line">nvme0n1           0.00         0.00         0.00          0          0</div><div class="line">dm-0              0.00         0.00         0.00          0          0</div></pre></td></tr></table></figure>
<p>如果同样写lvm，由两块nvme组成</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div></pre></td><td class="code"><pre><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">nvme2n1           0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00</div><div class="line">nvme0n1           0.00   137.00    0.00 5730.00     0.00 421112.00   146.98     2.95    0.52    0.00    0.52   0.05  27.30</div><div class="line"></div><div class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</div><div class="line">           1.17    0.00    0.34    0.19    0.00   98.30</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">nvme2n1           0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00</div><div class="line">nvme0n1           0.00   109.00    0.00 2533.00     0.00 271236.00   214.16     1.08    0.43    0.00    0.43   0.06  15.90</div><div class="line"></div><div class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</div><div class="line">           1.38    0.00    0.42    0.20    0.00   98.00</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">nvme2n1           0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00</div><div class="line">nvme0n1           0.00   118.00    0.00 3336.00     0.00 320708.00   192.27     1.50    0.45    0.00    0.45   0.06  20.00</div><div class="line"></div><div class="line">[root@k28a11352.eu95sqa /var/lib]</div><div class="line">#iostat  1</div><div class="line">Linux 3.10.0-327.ali2017.alios7.x86_64 (k28a11352.eu95sqa) 	05/13/2021 	_x86_64_	(64 CPU)</div><div class="line"></div><div class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</div><div class="line">           0.40    0.00    0.20    0.07    0.00   99.33</div><div class="line"></div><div class="line">Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn</div><div class="line">sda              38.96       334.64      1449.68    1419236    6148304</div><div class="line">nvme1n1         324.95         1.43     31201.30       6069  132329072</div><div class="line">nvme2n1           0.07         0.90         0.00       3808          0</div><div class="line">nvme0n1         256.24         1.60     22918.46       6801   97200388</div><div class="line">dm-0            266.98         1.38     22918.46       5849   97200388</div><div class="line"></div><div class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</div><div class="line">           1.20    0.00    0.42    0.25    0.00   98.12</div><div class="line"></div><div class="line">Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn</div><div class="line">sda               0.00         0.00         0.00          0          0</div><div class="line">nvme1n1           0.00         0.00         0.00          0          0</div><div class="line">nvme2n1           0.00         0.00         0.00          0          0</div><div class="line">nvme0n1        4460.00         0.00    332288.00          0     332288</div><div class="line">dm-0           4608.00         0.00    332288.00          0     332288</div><div class="line"></div><div class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</div><div class="line">           1.35    0.00    0.38    0.22    0.00   98.06</div><div class="line"></div><div class="line">Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn</div><div class="line">sda              48.00         0.00       200.00          0        200</div><div class="line">nvme1n1           0.00         0.00         0.00          0          0</div><div class="line">nvme2n1           0.00         0.00         0.00          0          0</div><div class="line">nvme0n1        4187.00         0.00    332368.00          0     332368</div><div class="line">dm-0           4348.00         0.00    332368.00          0     332368</div></pre></td></tr></table></figure>
<h2 id="数据总结"><a href="#数据总结" class="headerlink" title="数据总结"></a>数据总结</h2><ul>
<li>性能排序 NVMe SSD &gt; SATA SSD &gt; SAN &gt; ESSD &gt; HDD</li>
<li>本地ssd性能最好、sas机械盘(RAID10)性能最差</li>
<li>san存储走特定的光纤网络，不是走tcp的san（至少从网卡看不到san的流量），性能居中</li>
<li>从rt来看 ssd:san:sas 大概是 1:3:15</li>
<li>san比本地sas机械盘性能要好，这也许取决于san的网络传输性能和san存储中的设备（比如用的ssd而不是机械盘）</li>
<li>NVMe SSD比SATA SSD快很多，latency更稳定</li>
<li>阿里云的云盘ESSD比本地SAS RAID10阵列性能还好</li>
<li>软RAID、LVM等阵列都会导致性能损耗，即使多盘一起读写也不如单盘性能</li>
<li>不同测试场景(4K/8K/ 读写、随机与否)会导致不同品牌性能数据差异较大</li>
</ul>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="http://cizixs.com/2017/01/03/how-slow-is-disk-and-network" target="_blank" rel="external">http://cizixs.com/2017/01/03/how-slow-is-disk-and-network</a></p>
<p><a href="https://tobert.github.io/post/2014-04-17-fio-output-explained.html" target="_blank" rel="external">https://tobert.github.io/post/2014-04-17-fio-output-explained.html</a> </p>
<p><a href="https://zhuanlan.zhihu.com/p/40497397" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/40497397</a></p>
<p><a href="https://linux.die.net/man/1/fio" target="_blank" rel="external">https://linux.die.net/man/1/fio</a></p>
<p><a href="https://www.atatech.org/articles/167736?spm=ata.home.0.0.11fd75362qwsg7&amp;flag_data_from=home_algorithm_article" target="_blank" rel="external">块存储NVMe云盘原型实践</a></p>
<p><a href="https://mp.weixin.qq.com/s?__biz=MjM5Njg5NDgwNA==&amp;mid=2247483999&amp;idx=1&amp;sn=238d3d1a8cf24443db0da4aa00c9fb7e&amp;chksm=a6e3036491948a72704e0b114790483f227b7ce82f5eece5dd870ef88a8391a03eca27e8ff61&amp;scene=178&amp;cur_album_id=1371808335259090944#rd" target="_blank" rel="external">机械硬盘随机IO慢的超乎你的想象</a></p>
<p><a href="https://mp.weixin.qq.com/s?__biz=MjM5Njg5NDgwNA==&amp;mid=2247484023&amp;idx=1&amp;sn=1946b4c286ed72da023b402cc30908b6&amp;chksm=a6e3034c91948a5aa3b0e6beb31c1d3804de9a11c668400d598c2a6b12462e179cf9f1dc33e2&amp;scene=178&amp;cur_album_id=1371808335259090944#rd" target="_blank" rel="external">搭载固态硬盘的服务器究竟比搭机械硬盘快多少？</a></p>
<p><a href="http://www.360doc.com/content/15/0318/15/16824943_456186965.shtml" target="_blank" rel="external">SSD基本工作原理</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/347599423" target="_blank" rel="external">SSD原理解读</a></p>
<p><a href="https://mp.weixin.qq.com/s?__biz=MzAxNDI5NzEzNg==&amp;mid=2651171913&amp;idx=1&amp;sn=68f658c539edc2b5063d6d15d0bfa0cf" target="_blank" rel="external">Linux 后台开发必知的 I/O 优化知识总结</a></p>
<p><a href="https://www.sohu.com/a/390625596_505795" target="_blank" rel="external">SSD性能怎么测？看这一篇就够了</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2022/01/19/kubernetes calico网络/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/01/19/kubernetes calico网络/" itemprop="url">kubernetes calico网络</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-01-19T11:30:03+08:00">
                2022-01-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/docker/" itemprop="url" rel="index">
                    <span itemprop="name">docker</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="kubernetes-calico网络"><a href="#kubernetes-calico网络" class="headerlink" title="kubernetes calico网络"></a>kubernetes calico网络</h1><h2 id="cni-网络"><a href="#cni-网络" class="headerlink" title="cni 网络"></a>cni 网络</h2><blockquote>
<p> <strong>cni0</strong> is a Linux network bridge device, all <strong>veth</strong> devices will connect to this bridge, so all Pods on the same node can communicate with each other, as explained in <strong>Kubernetes Network Model</strong> and the hotel analogy above.</p>
</blockquote>
<h3 id="cni（Container-Network-Interface）"><a href="#cni（Container-Network-Interface）" class="headerlink" title="cni（Container Network Interface）"></a>cni（Container Network Interface）</h3><p>CNI 全称为 Container Network Interface，是用来定义容器网络的一个 <a href="https://github.com/containernetworking/cni/blob/master/SPEC.md" target="_blank" rel="external">规范</a>。<a href="https://github.com/containernetworking/cni" target="_blank" rel="external">containernetworking/cni</a> 是一个 CNCF 的 CNI 实现项目，包括基本额 bridge,macvlan等基本网络插件。</p>
<p>一般将cni各种网络插件的可执行文件二进制放到 <code>/opt/cni/bin</code> ，在 <code>/etc/cni/net.d/</code> 下创建配置文件，剩下的就交给 K8s 或者 containerd 了，我们不关心也不了解其实现。</p>
<p>比如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">#ls -lh /opt/cni/bin/</div><div class="line">总用量 90M</div><div class="line">-rwxr-x--- 1 root root 4.0M 12月 23 09:39 bandwidth</div><div class="line">-rwxr-x--- 1 root root  35M 12月 23 09:39 calico</div><div class="line">-rwxr-x--- 1 root root  35M 12月 23 09:39 calico-ipam</div><div class="line">-rwxr-x--- 1 root root 3.0M 12月 23 09:39 flannel</div><div class="line">-rwxr-x--- 1 root root 3.5M 12月 23 09:39 host-local</div><div class="line">-rwxr-x--- 1 root root 3.1M 12月 23 09:39 loopback</div><div class="line">-rwxr-x--- 1 root root 3.8M 12月 23 09:39 portmap</div><div class="line">-rwxr-x--- 1 root root 3.3M 12月 23 09:39 tuning</div><div class="line"></div><div class="line">[root@hygon3 15:55 /root]</div><div class="line">#ls -lh /etc/cni/net.d/</div><div class="line">总用量 12K</div><div class="line">-rw-r--r-- 1 root root  607 12月 23 09:39 10-calico.conflist</div><div class="line">-rw-r----- 1 root root  292 12月 23 09:47 10-flannel.conflist</div><div class="line">-rw------- 1 root root 2.6K 12月 23 09:39 calico-kubeconfig</div></pre></td></tr></table></figure>
<p>CNI 插件都是直接通过 exec 的方式调用，而不是通过 socket 这样 C/S 方式，所有参数都是通过环境变量、标准输入输出来实现的。</p>
<p>Step-by-step communication from <strong>Pod 1</strong> to <strong>Pod 6</strong>:</p>
<ol>
<li><em>Package leaves</em> <strong><em>Pod 1 netns\</em></strong> <em>through the</em> <strong><em>eth1\</em></strong> <em>interface and reaches the</em> <strong><em>root netns\</em></strong> <em>through the virtual interface</em> <strong><em>veth1*</em></strong>;*</li>
<li><em>Package leaves</em> <strong><em>veth1\</em></strong> <em>and reaches</em> <strong><em>cni0*</em></strong>, looking for<em> **</em>Pod 6*<em>**’s</em> <em>address;</em></li>
<li><em>Package leaves</em> <strong><em>cni0\</em></strong> <em>and is redirected to</em> <strong><em>eth0*</em></strong>;*</li>
<li><em>Package leaves</em> <strong><em>eth0\</em></strong> <em>from</em> <strong><em>Master 1\</em></strong> <em>and reaches the</em> <strong><em>gateway*</em></strong>;*</li>
<li><em>Package leaves the</em> <strong><em>gateway\</em></strong> <em>and reaches the</em> <strong><em>root netns\</em></strong> <em>through the</em> <strong><em>eth0\</em></strong> <em>interface on</em> <strong><em>Worker 1*</em></strong>;*</li>
<li><em>Package leaves</em> <strong><em>eth0\</em></strong> <em>and reaches</em> <strong><em>cni0*</em></strong>, looking for<em> **</em>Pod 6*<em>**’s</em> <em>address;</em></li>
<li><em>Package leaves</em> <strong><em>cni0\</em></strong> <em>and is redirected to the</em> <strong><em>veth6\</em></strong> <em>virtual interface;</em></li>
<li><em>Package leaves the</em> <strong><em>root netns\</em></strong> <em>through</em> <strong><em>veth6\</em></strong> <em>and reaches the</em> <strong><em>Pod 6 netns\</em></strong> <em>though the</em> <strong><em>eth6\</em></strong> <em>interface;</em></li>
</ol>
<p><img src="/images/951413iMgBlog/image-20220115124747936.png" alt="image-20220115124747936"></p>
<h2 id="kubernetes-calico-网络"><a href="#kubernetes-calico-网络" class="headerlink" title="kubernetes calico 网络"></a>kubernetes calico 网络</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml</div><div class="line"></div><div class="line">#或者老版本的calico</div><div class="line">curl https://docs.projectcalico.org/v3.15/manifests/calico.yaml -o calico.yaml</div></pre></td></tr></table></figure>
<p>默认calico用的是ipip封包（这个性能跟原生网络差多少有待验证，本质也是overlay网络，比flannel那种要好很多吗？）</p>
<p>跨宿主机的两个容器之间的流量链路是：</p>
<blockquote>
<p>cali-容器eth0-&gt;宿主机cali27dce37c0e8-&gt;tunl0-&gt;内核ipip模块封包-&gt;物理网卡（ipip封包后）—远程–&gt; 物理网卡-&gt;内核ipip模块解包-&gt;tunl0-&gt;cali-容器</p>
</blockquote>
<p><img src="/images/oss/a1767a5f2cbc2c48c1a35da9f3232a2c.png" alt="image.png"></p>
<p>Calico IPIP模式对物理网络无侵入，符合云原生容器网络要求；使用IPIP封包，性能略低于Calico BGP模式；无法使用传统防火墙管理、也无法和存量网络直接打通。Pod在Node做SNAT访问外部，Pod流量不易被监控。</p>
<h2 id="calico-ipip网络不通"><a href="#calico-ipip网络不通" class="headerlink" title="calico ipip网络不通"></a>calico ipip网络不通</h2><p>集群有五台机器192.168.0.110-114, 同时每个node都有另外一个ip：192.168.3.110-114，部分节点之间不通。每台机器部署好calico网络后，会分配一个 /26 CIRD 子网（64个ip）。</p>
<h3 id="案例1"><a href="#案例1" class="headerlink" title="案例1"></a>案例1</h3><p>目标机是10.122.127.128（宿主机ip 192.168.3.112），如果从10.122.17.64（宿主机ip 192.168.3.110） ping 10.122.127.128不通，查看10.122.127.128路由表：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[root@az3-k8s-13 ~]# ip route |grep tunl0</div><div class="line">10.122.17.64/26 via 10.122.127.128 dev tunl0  //这条路由不通</div><div class="line">[root@az3-k8s-13 ~]# ip route del 10.122.17.64/26 via 10.122.127.128 dev tunl0 ; ip route add 10.122.17.64/26 via 192.168.3.110 dev tunl0 proto bird onlink</div><div class="line"></div><div class="line">[root@az3-k8s-13 ~]# ip route |grep tunl0</div><div class="line">10.122.17.64/26 via 192.168.3.110 dev tunl0 proto bird onlink //这样就通了</div></pre></td></tr></table></figure>
<p>在10.122.127.128抓包如下，明显可以看到icmp request到了 tunl0网卡，tunl0网卡也回复了，但是回复包没有经过kernel ipip模块封装后发到eth1上：</p>
<p><img src="/images/oss/d3111417ce646ca1475def5bea01e6b9.png" alt="image.png"></p>
<p>正常机器应该是这样，上图不正常的时候缺少红框中的reply：</p>
<p><img src="/images/oss/9ea9041af1211b2a5b8de4e216044465.png" alt="image.png"></p>
<p>解决：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">ip route del 10.122.17.64/26 via 10.122.127.128 dev tunl0 ; </div><div class="line">ip route add 10.122.17.64/26 via 192.168.3.110 dev tunl0 proto bird onlink</div></pre></td></tr></table></figure>
<p>删除错误路由增加新的路由就可以了，新增路由的意思是从tunl0发给10.122.17.64/26的包下一跳是 192.168.3.110。</p>
<p> via 192.168.3.110 表示下一跳的ip</p>
<p>onlink参数的作用：<br>使用这个参数将会告诉内核，不必检查网关是否可达。因为在linux内核中，网关与本地的网段不同是被认为不可达的，从而拒绝执行添加路由的操作。</p>
<p>因为tunl0网卡ip的 CIDR 是32，也就是不属于任何子网，那么这个网卡上的路由没有网关，配置路由的话必须是onlink, 内核存也没法根据子网来选择到这块网卡，所以还会加上 dev 指定网卡。</p>
<h3 id="案例2"><a href="#案例2" class="headerlink" title="案例2"></a>案例2</h3><p>集群有五台机器192.168.0.110-114, 同时每个node都有另外一个ip：192.168.3.110-114，只有node2没有192.168.3.111这个ip，结果node2跟其他节点都不通：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">#calicoctl node status</div><div class="line">Calico process is running.</div><div class="line"></div><div class="line">IPv4 BGP status</div><div class="line">+---------------+-------------------+-------+------------+-------------+</div><div class="line">| PEER ADDRESS  |     PEER TYPE     | STATE |   SINCE    |    INFO     |</div><div class="line">+---------------+-------------------+-------+------------+-------------+</div><div class="line">| 192.168.0.111 | node-to-node mesh | up    | 2020-08-29 | Established |</div><div class="line">| 192.168.3.112 | node-to-node mesh | up    | 2020-08-29 | Established |</div><div class="line">| 192.168.3.113 | node-to-node mesh | up    | 2020-08-29 | Established |</div><div class="line">| 192.168.3.114 | node-to-node mesh | up    | 2020-08-29 | Established |</div><div class="line">+---------------+-------------------+-------+------------+-------------+</div></pre></td></tr></table></figure>
<p>从node4 ping node2，然后在node2上抓包，可以看到 icmp request都发到了node2上，但是node2收到后没有发给tunl0：</p>
<p><img src="/images/oss/16fda9322e9a59c37c11629acc611bf3.png" alt="image.png"></p>
<p>所以icmp没有回复，这里的问题在于<strong>kernel收到包后为什么不给tunl0</strong></p>
<p>同样，在node2上ping node4，同时在node2上抓包，可以看到发给node4的request包和reply包：</p>
<p><img src="/images/oss/c6d1706b6f8162cfac528ddf5319c8e2.png" alt="image.png"></p>
<p>从request包可以看到src ip 是0.111， dest ip是 3.113，<strong>因为 node2 没有192.168.3.111这个ip</strong></p>
<p>非常关键的我们看到node4的回复包 src ip 不是3.113，而是0.113（根据node4的路由就应该是0.113）</p>
<p><img src="/images/oss/5c7172e2422579eb99c66e881d47bf99.png" alt="image.png"></p>
<p>这就是问题所在，从node4过来的ipip包src ip都是0.113，实际这里ipip能认识的只是3.113. </p>
<p>如果这个时候在3.113机器上把0.113网卡down掉，那么3.113上的：</p>
<p>10.122.124.128/26 via 192.168.0.111 dev tunl0 proto bird onlink 路由被自动删除，3.113将不再回复request。这是因为calico记录的node2的ip是192.168.0.111，所以会自动增加</p>
<p>解决办法，在node4上删除这条路由记录，也就是强制让回复包走3.113网卡，这样收发的ip就能对应上了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">ip route del 192.168.0.0/24 dev eth0 proto kernel scope link src 192.168.0.113</div><div class="line">//同时将默认路由改到3.113</div><div class="line">ip route del default via 192.168.0.253 dev eth0; </div><div class="line">ip route add default via 192.168.3.253 dev eth1</div></pre></td></tr></table></figure>
<p>最终OK后，node4上的ip route是这样的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">[root@az3-k8s-14 ~]# ip route</div><div class="line">default via 192.168.3.253 dev eth1 </div><div class="line">10.122.17.64/26 via 192.168.3.110 dev tunl0 proto bird onlink </div><div class="line">10.122.124.128/26 via 192.168.0.111 dev tunl0 proto bird onlink </div><div class="line">10.122.127.128/26 via 192.168.3.112 dev tunl0 proto bird onlink </div><div class="line">blackhole 10.122.157.128/26 proto bird </div><div class="line">10.122.157.129 dev cali19f6ea143e3 scope link </div><div class="line">10.122.157.130 dev cali09e016ead53 scope link </div><div class="line">10.122.157.131 dev cali0ad3225816d scope link </div><div class="line">10.122.157.132 dev cali55a5ff1a4aa scope link </div><div class="line">10.122.157.133 dev cali01cf8687c65 scope link </div><div class="line">10.122.157.134 dev cali65232d7ada6 scope link </div><div class="line">10.122.173.128/26 via 192.168.3.114 dev tunl0 proto bird onlink </div><div class="line">172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 </div><div class="line">192.168.3.0/24 dev eth1 proto kernel scope link src 192.168.3.113</div></pre></td></tr></table></figure>
<p>正常后的抓包, 注意这里drequest的est ip 和reply的 src ip终于一致了：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">//request</div><div class="line">00:16:3e:02:06:1e &gt; ee:ff:ff:ff:ff:ff, ethertype IPv4 (0x0800), length 118: (tos 0x0, ttl 64, id 57971, offset 0, flags [DF], proto IPIP (4), length 104)</div><div class="line">    192.168.0.111 &gt; 192.168.3.110: (tos 0x0, ttl 64, id 18953, offset 0, flags [DF], proto ICMP (1), length 84)</div><div class="line">    10.122.124.128 &gt; 10.122.17.64: ICMP echo request, id 22001, seq 4, length 64</div><div class="line">    </div><div class="line">//reply    </div><div class="line">ee:ff:ff:ff:ff:ff &gt; 00:16:3e:02:06:1e, ethertype IPv4 (0x0800), length 118: (tos 0x0, ttl 64, id 2565, offset 0, flags [none], proto IPIP (4), length 104)</div><div class="line">    192.168.3.110 &gt; 192.168.0.111: (tos 0x0, ttl 64, id 26374, offset 0, flags [none], proto ICMP (1), length 84)</div><div class="line">    10.122.17.64 &gt; 10.122.124.128: ICMP echo reply, id 22001, seq 4, length 64</div></pre></td></tr></table></figure>
<p>总结下来这两个案例都还是对路由不够了解，特别是案例2，因为有了多个网卡后导致路由更复杂。calico ipip的基本原理就是利用内核进行ipip封包，然后修改路由来保证网络的畅通。</p>
<h2 id="netns-操作"><a href="#netns-操作" class="headerlink" title="netns 操作"></a><a href="https://mp.weixin.qq.com/s/lscMpc5BWAEzjgYw6H0wBw" target="_blank" rel="external">netns 操作</a></h2><p>以下case创建一个名为 ren 的netns，然后在里面增加一对虚拟网卡veth1 veth1_p,  veth1放置在ren里面，veth1_p 放在物理机上，给他们配置上ip并up就能通了。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div></pre></td><td class="code"><pre><div class="line"> 1004  [2021-10-27 10:49:08] ip netns add ren</div><div class="line"> 1005  [2021-10-27 10:49:12] ip netns show</div><div class="line"> 1006  [2021-10-27 10:49:22] ip netns exec ren route   //为空</div><div class="line"> 1007  [2021-10-27 10:49:29] ip netns exec ren iptables -L</div><div class="line"> 1008  [2021-10-27 10:49:55] ip link add veth1 type veth peer name veth1_p //此时宿主机上能看到这两块网卡</div><div class="line"> 1009  [2021-10-27 10:50:07] ip link set veth1 netns ren //将veth1从宿主机默认网络空间挪到ren中，宿主机中看不到veth1了</div><div class="line"> 1010  [2021-10-27 10:50:18] ip netns exec ren route  </div><div class="line"> 1011  [2021-10-27 10:50:25] ip netns exec ren iptables -L</div><div class="line"> 1012  [2021-10-27 10:50:39] ifconfig</div><div class="line"> 1013  [2021-10-27 10:50:51] ip link list</div><div class="line"> 1014  [2021-10-27 10:51:29] ip netns exec ren ip link list</div><div class="line"> 1017  [2021-10-27 10:53:27] ip netns exec ren ip addr add 172.19.0.100/24 dev veth1 </div><div class="line"> 1018  [2021-10-27 10:53:31] ip netns exec ren ip link list</div><div class="line"> 1019  [2021-10-27 10:53:39] ip netns exec ren ifconfig</div><div class="line"> 1020  [2021-10-27 10:53:42] ip netns exec ren ifconfig -a</div><div class="line"> 1021  [2021-10-27 10:54:13] ip netns exec ren ip link set dev veth1 up</div><div class="line"> 1022  [2021-10-27 10:54:16] ip netns exec ren ifconfig</div><div class="line"> 1023  [2021-10-27 10:54:22] ping 172.19.0.100</div><div class="line"> 1024  [2021-10-27 10:54:35] ifconfig -a</div><div class="line"> 1025  [2021-10-27 10:55:03] ip netns exec ren ip addr add 172.19.0.101/24 dev veth1_p</div><div class="line"> 1026  [2021-10-27 10:55:10] ip addr add 172.19.0.101/24 dev veth1_p</div><div class="line"> 1027  [2021-10-27 10:55:16] ifconfig veth1_p</div><div class="line"> 1028  [2021-10-27 10:55:30] ip link set dev veth1_p up</div><div class="line"> 1029  [2021-10-27 10:55:32] ifconfig veth1_p</div><div class="line"> 1030  [2021-10-27 10:55:38] ping 172.19.0.101</div><div class="line"> 1031  [2021-10-27 10:55:43] ping 172.19.0.100</div><div class="line"> 1032  [2021-10-27 10:55:53] ip link set dev veth1_p down</div><div class="line"> 1033  [2021-10-27 10:55:54] ping 172.19.0.100</div><div class="line"> 1034  [2021-10-27 10:55:58] ping 172.19.0.101</div><div class="line"> 1035  [2021-10-27 10:56:08] ifconfig veth1_p</div><div class="line"> 1036  [2021-10-27 10:56:32] ping 172.19.0.101</div><div class="line"> 1037  [2021-10-27 10:57:04] ip netns exec ren route</div><div class="line"> 1038  [2021-10-27 10:57:52] ip netns exec ren ping 172.19.0.101</div><div class="line"> 1039  [2021-10-27 10:57:58] ip link set dev veth1_p up</div><div class="line"> 1040  [2021-10-27 10:57:59] ip netns exec ren ping 172.19.0.101</div><div class="line"> 1041  [2021-10-27 10:58:06] ip netns exec ren ping 172.19.0.100</div><div class="line"> 1042  [2021-10-27 10:58:14] ip netns exec ren ifconfig</div><div class="line"> 1043  [2021-10-27 10:58:19] ip netns exec ren route</div><div class="line"> 1044  [2021-10-27 10:58:26] ip netns exec ren ping 172.19.0.100 -I veth1</div><div class="line"> 1045  [2021-10-27 10:58:58] ifconfig veth1_p</div><div class="line"> 1046  [2021-10-27 10:59:10] ping 172.19.0.100</div><div class="line"> 1047  [2021-10-27 10:59:26] ip netns exec ren ping 172.19.0.101 -I veth1</div><div class="line"> </div><div class="line"> 把网卡加入到docker0的bridge下</div><div class="line"> 1160  [2021-10-27 12:17:37] brctl show</div><div class="line"> 1161  [2021-10-27 12:18:05] ip link set dev veth3_p master docker0</div><div class="line"> 1162  [2021-10-27 12:18:09] ip link set dev veth1_p master docker0</div><div class="line"> 1163  [2021-10-27 12:18:13] ip link set dev veth2 master docker0</div><div class="line"> 1164  [2021-10-27 12:18:15] brctl show</div><div class="line"> </div><div class="line">brctl showmacs br0</div><div class="line">brctl show cni0</div><div class="line">brctl addif cni0 veth1 veth2 veth3  //往cni bridge添加多个容器peer 网卡</div></pre></td></tr></table></figure>
<p>Linux 上存在一个默认的网络命名空间，Linux 中的 1 号进程初始使用该默认空间。Linux 上其它所有进程都是由 1 号进程派生出来的，在派生 clone 的时候如果没有额外特别指定，所有的进程都将共享这个默认网络空间。</p>
<p>所有的网络设备刚创建出来都是在宿主机默认网络空间下的。可以通过 <code>ip link set 设备名 netns 网络空间名</code> 将设备移动到另外一个空间里去，socket也是归属在某一个网络命名空间下的，由创建socket进程所在的netns来决定socket所在的netns</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//file: net/socket.c</span></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">sock_create</span><span class="params">(<span class="keyword">int</span> family, <span class="keyword">int</span> type, <span class="keyword">int</span> protocol, struct socket **res)</span></span></div><div class="line">&#123;</div><div class="line"> <span class="keyword">return</span> __sock_create(current-&gt;nsproxy-&gt;net_ns, family, type, protocol, res, <span class="number">0</span>);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//file: include/net/sock.h</span></div><div class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span></span></div><div class="line"><span class="keyword">void</span> <span class="title">sock_net_set</span><span class="params">(struct sock *sk, struct net *net)</span></div><div class="line">&#123;</div><div class="line"> write_pnet(&amp;sk-&gt;sk_net, net);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>内核提供了三种操作命名空间的方式，分别是 clone、setns 和 unshare。ip netns add 使用的是 unshare，原理和 clone 是类似的。</p>
<p><img src="/images/951413iMgBlog/640-5304524." alt="Image"></p>
<p>每个 net 下都包含了自己的路由表、iptable 以及内核参数配置等等</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://morven.life/notes/networking-3-ipip/" target="_blank" rel="external">https://morven.life/notes/networking-3-ipip/</a></p>
<p><a href="https://www.cnblogs.com/bakari/p/10564347.html" target="_blank" rel="external">https://www.cnblogs.com/bakari/p/10564347.html</a></p>
<p><a href="https://www.cnblogs.com/goldsunshine/p/10701242.html" target="_blank" rel="external">https://www.cnblogs.com/goldsunshine/p/10701242.html</a></p>
<p><a href="https://docker-k8s-lab.readthedocs.io/en/latest/docker/docker-flannel.html" target="_blank" rel="external">手工拉起flannel网络</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2022/01/19/kubernetes_Flannel网络剖析/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/01/19/kubernetes_Flannel网络剖析/" itemprop="url">kubernetes Flannel网络剖析</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-01-19T11:30:03+08:00">
                2022-01-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/docker/" itemprop="url" rel="index">
                    <span itemprop="name">docker</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="kubernetes-Flannel网络剖析"><a href="#kubernetes-Flannel网络剖析" class="headerlink" title="kubernetes Flannel网络剖析"></a>kubernetes Flannel网络剖析</h1><h2 id="cni（Container-Network-Interface）"><a href="#cni（Container-Network-Interface）" class="headerlink" title="cni（Container Network Interface）"></a>cni（Container Network Interface）</h2><p>CNI 全称为 Container Network Interface，是用来定义容器网络的一个 <a href="https://github.com/containernetworking/cni/blob/master/SPEC.md" target="_blank" rel="external">规范</a>。<a href="https://github.com/containernetworking/cni" target="_blank" rel="external">containernetworking/cni</a> 是一个 CNCF 的 CNI 实现项目，包括基本额 bridge,macvlan等基本网络插件。</p>
<p>一般将cni各种网络插件的可执行文件二进制放到 <code>/opt/cni/bin</code> ，在 <code>/etc/cni/net.d/</code> 下创建配置文件，剩下的就交给 K8s 或者 containerd 了，我们不关心也不了解其实现。</p>
<p>比如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">#ls -lh /opt/cni/bin/</div><div class="line">总用量 90M</div><div class="line">-rwxr-x--- 1 root root 4.0M 12月 23 09:39 bandwidth</div><div class="line">-rwxr-x--- 1 root root  35M 12月 23 09:39 calico</div><div class="line">-rwxr-x--- 1 root root  35M 12月 23 09:39 calico-ipam</div><div class="line">-rwxr-x--- 1 root root 3.0M 12月 23 09:39 flannel</div><div class="line">-rwxr-x--- 1 root root 3.5M 12月 23 09:39 host-local</div><div class="line">-rwxr-x--- 1 root root 3.1M 12月 23 09:39 loopback</div><div class="line">-rwxr-x--- 1 root root 3.8M 12月 23 09:39 portmap</div><div class="line">-rwxr-x--- 1 root root 3.3M 12月 23 09:39 tuning</div><div class="line"></div><div class="line">[root@hygon3 15:55 /root]</div><div class="line">#ls -lh /etc/cni/net.d/</div><div class="line">总用量 12K</div><div class="line">-rw-r--r-- 1 root root  607 12月 23 09:39 10-calico.conflist</div><div class="line">-rw-r----- 1 root root  292 12月 23 09:47 10-flannel.conflist</div><div class="line">-rw------- 1 root root 2.6K 12月 23 09:39 calico-kubeconfig</div></pre></td></tr></table></figure>
<p>CNI 插件都是直接通过 exec 的方式调用，而不是通过 socket 这样 C/S 方式，所有参数都是通过环境变量、标准输入输出来实现的。</p>
<h2 id="跨主机通信流程"><a href="#跨主机通信流程" class="headerlink" title="跨主机通信流程"></a>跨主机通信流程</h2><p>Step-by-step communication from <strong>Pod 1</strong> to <strong>Pod 6</strong>:</p>
<ol>
<li><em>Package leaves</em> <strong><em>Pod 1 netns\</em></strong> <em>through the</em> <strong><em>eth1\</em></strong> <em>interface and reaches the</em> <strong><em>root netns\</em></strong> <em>through the virtual interface</em> <strong><em>veth1*</em></strong>;*</li>
<li><em>Package leaves</em> <strong><em>veth1\</em></strong> <em>and reaches</em> <strong><em>cni0*</em></strong>, looking for<em> **</em>Pod 6*<em>**’s</em> <em>address;</em></li>
<li><em>Package leaves</em> <strong><em>cni0\</em></strong> <em>and is redirected to</em> <strong><em>eth0*</em></strong>;*</li>
<li><em>Package leaves</em> <strong><em>eth0\</em></strong> <em>from</em> <strong><em>Master 1\</em></strong> <em>and reaches the</em> <strong><em>gateway*</em></strong>;*</li>
<li><em>Package leaves the</em> <strong><em>gateway\</em></strong> <em>and reaches the</em> <strong><em>root netns\</em></strong> <em>through the</em> <strong><em>eth0\</em></strong> <em>interface on</em> <strong><em>Worker 1*</em></strong>;*</li>
<li><em>Package leaves</em> <strong><em>eth0\</em></strong> <em>and reaches</em> <strong><em>cni0*</em></strong>, looking for<em> **</em>Pod 6*<em>**’s</em> <em>address;</em></li>
<li><em>Package leaves</em> <strong><em>cni0\</em></strong> <em>and is redirected to the</em> <strong><em>veth6\</em></strong> <em>virtual interface;</em></li>
<li><em>Package leaves the</em> <strong><em>root netns\</em></strong> <em>through</em> <strong><em>veth6\</em></strong> <em>and reaches the</em> <strong><em>Pod 6 netns\</em></strong> <em>though the</em> <strong><em>eth6\</em></strong> <em>interface;</em></li>
</ol>
<p><img src="/images/951413iMgBlog/image-20220115124747936.png" alt="image-20220115124747936"></p>
<blockquote>
<p><strong>cni0</strong> is a Linux network bridge device, all <strong>veth</strong> devices will connect to this bridge, so all Pods on the same node can communicate with each other, as explained in <strong>Kubernetes Network Model</strong> and the hotel analogy above.</p>
</blockquote>
<p>默认cni 网络是没法跨宿主机的，跨宿主机需要走overlay（比如flannel的vxlan）或者仅限宿主机全在一个二层网络可达（比如用flannel的host-gw模式）</p>
<h2 id="flannel-vxlan网络"><a href="#flannel-vxlan网络" class="headerlink" title="flannel vxlan网络"></a><a href="https://msazure.club/flannel-networking-demystify/" target="_blank" rel="external">flannel vxlan网络</a></h2><p>什么是 flannel</p>
<blockquote>
<p><em>Flannel is a simple and easy way to configure a layer 3 network fabric designed for Kubernetes.</em></p>
</blockquote>
<p>Flannel 工作原理</p>
<blockquote>
<p><em>Flannel runs a small, single binary agent called</em> <code>flanneld</code> on each host, and is responsible for allocating a subnet lease to each host out of a larger, preconfigured address space. Flannel uses either the Kubernetes API or etcd directly to store the network configuration, the allocated subnets, and any auxiliary data (such as the host’s public IP). Packets are forwarded using one of several backend mechanisms including VXLAN and various cloud integrations.</p>
</blockquote>
<p>核心原理就是将pod网络包通过vxlan协议封装成一个udp包，udp包的ip是数据ip，内层是pod原始网络通信包。</p>
<p>假如POD1访问POD4：</p>
<ol>
<li>从POD1中出来的包先到Bridge cni0上（因为POD1对应的veth挂在了cni0上），目标mac地址是cni0的Mac</li>
<li>然后进入到宿主机网络，宿主机有路由 10.244.2.0/24 via 10.244.2.0 dev flannel.1 onlink ，也就是目标ip 10.244.2.3的包交由 flannel.1 来处理，目标mac地址是POD4所在机器的flannel.1的Mac</li>
<li>flanneld 进程将包封装成vxlan 丢到eth0从宿主机1离开（封装后的目标ip是192.168.2.91，现在都是由内核来完成flanneld这个封包过程，性能好）</li>
<li>这个封装后的vxlan udp包正确路由到宿主机2</li>
<li>然后经由 flanneld 解包成 10.244.2.3 ，命中宿主机2上的路由：10.244.2.0/24 dev cni0 proto kernel scope link src 10.244.2.1 ，交给cni0（<strong>这里会过宿主机iptables</strong>）</li>
<li>cni0将包送给POD4</li>
</ol>
<p><img src="/images/951413iMgBlog/Flannel.jpg" alt="img"></p>
<p>flannel容器启动的时候会给自己所在的node注入一些信息：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">#kubectl describe node hygon4  |grep -i flannel</div><div class="line">Annotations:        flannel.alpha.coreos.com/backend-data: &#123;&quot;VNI&quot;:1,&quot;VtepMAC&quot;:&quot;66:c6:ba:a2:8f:a1&quot;&#125;</div><div class="line">                    flannel.alpha.coreos.com/backend-type: vxlan</div><div class="line">                    flannel.alpha.coreos.com/kube-subnet-manager: true</div><div class="line">                    flannel.alpha.coreos.com/public-ip: 10.176.4.245  ---宿主机ip，vxlan封包所用</div><div class="line">                    </div><div class="line"> &quot;VtepMAC&quot;:&quot;66:c6:ba:a2:8f:a1&quot;----宿主机网卡 flannel.1的mac</div></pre></td></tr></table></figure>
<p>flannel.1 知道如何通过物理网卡打包网络包到目标地址，flanneld 会在每个host 添加 arp，以及将本机的 vxlan fdb 添加到新的 host上</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">//这个 flannel 集群有四个 host，这是其中一个host </div><div class="line">//4e:95:a9:e2:ed:28是对方 host 上 flannel.1 的 mac</div><div class="line">#ip neigh show dev flannel.1 </div><div class="line">172.19.2.0 lladdr 4e:95:a9:e2:ed:28 PERMANENT</div><div class="line">172.19.3.0 lladdr 2e:8b:65:d7:54:3e PERMANENT</div><div class="line">172.19.1.0 lladdr 6a:78:f3:db:b1:9e PERMANENT</div><div class="line"></div><div class="line">#bridge fdb show flannel.1</div><div class="line">01:00:5e:00:00:01 dev enp125s0f0 self permanent</div><div class="line">01:00:5e:00:00:01 dev enp125s0f1 self permanent</div><div class="line">01:00:5e:00:00:01 dev enp125s0f2 self permanent</div><div class="line">01:00:5e:00:00:01 dev enp125s0f3 self permanent</div><div class="line">33:33:00:00:00:01 dev enp125s0f3 self permanent</div><div class="line">33:33:ff:8e:d6:ac dev enp125s0f3 self permanent</div><div class="line">01:00:5e:00:00:01 dev enp2s0f0 self permanent</div><div class="line">01:00:5e:00:00:01 dev enp2s0f1 self permanent</div><div class="line">33:33:00:00:00:01 dev cni0 self permanent</div><div class="line">01:00:5e:00:00:01 dev cni0 self permanent</div><div class="line">f2:64:e3:49:4c:c8 dev cni0 vlan 1 master cni0 permanent</div><div class="line">f2:64:e3:49:4c:c8 dev cni0 master cni0 permanent</div><div class="line">72:d6:f3:54:7d:d6 dev vethe54b12b5 master cni0</div><div class="line"></div><div class="line"></div><div class="line"># ip neigh show dev flannel.1 //另一个host</div><div class="line">172.19.2.0 lladdr 4e:95:a9:e2:ed:28 PERMANENT</div><div class="line">172.19.3.0 lladdr 2e:8b:65:d7:54:3e PERMANENT</div><div class="line">172.19.0.0 lladdr 92:5c:b2:af:37:62 PERMANENT</div></pre></td></tr></table></figure>
<p>包流程：</p>
<p><img src="/images/951413iMgBlog/image-20220915113511706.png" alt="image-20220915113511706"></p>
<p><a href="https://blog.michaelfmcnamara.com/2008/02/what-are-the-arp-and-fdb-tables/" target="_blank" rel="external">ARP 和 FDB:</a></p>
<p>ARP (<a href="http://en.wikipedia.org/wiki/Address_Resolution_Protocol" target="_blank" rel="external">Address Resolution Protocol</a>) table is used by a <a href="http://en.wikipedia.org/wiki/Layer_3" target="_blank" rel="external">Layer 3</a> device (router, switch, server, desktop) to store the IP address to MAC address entries for a specific network device. </p>
<p>The FDB (<a href="http://en.wikipedia.org/wiki/Forwarding_table" target="_blank" rel="external">forwarding database</a>) table is used by a Layer 2 device (switch/bridge) to store the MAC addresses that have been learned and which ports that MAC address was learned on. The MAC addresses are learned through <a href="http://en.wikipedia.org/wiki/Transparent_bridge" target="_blank" rel="external">transparent bridging</a> on switches and dedicated bridges.</p>
<h3 id="抓包演示packet流转以及封包解包"><a href="#抓包演示packet流转以及封包解包" class="headerlink" title="抓包演示packet流转以及封包解包"></a>抓包演示packet流转以及封包解包</h3><p>一次完整的抓包过程演示包的流转，从hygon3上的pod 192.168.0.4（22:d8:63:6c:e8:96） 访问 hygon4上的pod 192.168.2.56（52:e6:8e:02:80:35）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div></pre></td><td class="code"><pre><div class="line">//hygon3上的pod 192.168.0.4（22:d8:63:6c:e8:96） 访问 hygon4上的pod 192.168.2.56（52:e6:8e:02:80:35），在cni0（a2:99:4f:dc:9d:5c）上抓包，跨机不走peer veth</div><div class="line">[root@hygon3 11:08 /root]</div><div class="line">#tcpdump -i cni0 host 192.168.2.56 -nnetvv</div><div class="line">dropped privs to tcpdump</div><div class="line">tcpdump: listening on cni0, link-type EN10MB (Ethernet), capture size 262144 bytes</div><div class="line">22:d8:63:6c:e8:96 &gt; a2:99:4f:dc:9d:5c, ethertype IPv4 (0x0800), length 614: (tos 0x0, ttl 64, id 53303, offset 0, flags [DF], proto TCP (6), length 600)</div><div class="line">    192.168.0.4.40712 &gt; 192.168.2.56.3100: Flags [P.], cksum 0x85d7 (incorrect -&gt; 0x801a), seq 150533649:150534197, ack 3441674662, win 507, options [nop,nop,TS val 1239838869 ecr 2297983667], length 548</div><div class="line"></div><div class="line">//hygon3上的pod 192.168.0.4 访问 hygon4上的pod 192.168.2.56，在本机flannel.1（a2:06:5e:83:44:78）上抓包</div><div class="line">[root@hygon3 10:53 /root]</div><div class="line">#tcpdump -i flannel.1 host 192.168.0.4 -nnetvv </div><div class="line">dropped privs to tcpdump</div><div class="line">tcpdump: listening on flannel.1, link-type EN10MB (Ethernet), capture size 262144 bytes</div><div class="line">a2:06:5e:83:44:78 &gt; 66:c6:ba:a2:8f:a1, ethertype IPv4 (0x0800), length 729: (tos 0x0, ttl 63, id 52997, offset 0, flags [DF], proto TCP (6), length 715)</div><div class="line">    192.168.0.4.40712 &gt; 192.168.2.56.3100: Flags [P.], cksum 0x864a (incorrect -&gt; 0x02ae), seq 150429115:150429778, ack 3441664870, win 507, options [nop,nop,TS val 1239381169 ecr 2297525566], length 663</div><div class="line">       </div><div class="line"> [root@hygon3 11:13 /root] //通过arp 可以看到对端 flannel.1 的mac地址被缓存到了本地</div><div class="line">#arp -n |grep 66:c6:ba:a2:8f:a1</div><div class="line">192.168.2.0              ether   66:c6:ba:a2:8f:a1   CM                    flannel.1</div><div class="line">#ip route</div><div class="line">default via 10.176.3.247 dev p1p1</div><div class="line">172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1</div><div class="line">192.168.0.0/24 dev cni0 proto kernel scope link src 192.168.0.1</div><div class="line">192.168.1.0/24 via 192.168.1.0 dev flannel.1 onlink</div><div class="line">192.168.2.0/24 via 192.168.2.0 dev flannel.1 onlink</div><div class="line">192.168.3.0/24 via 192.168.3.0 dev flannel.1 onlink</div><div class="line">#ip a</div><div class="line">18: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN group default</div><div class="line">    link/ether a2:06:5e:83:44:78 brd ff:ff:ff:ff:ff:ff</div><div class="line">    inet 192.168.0.0/32 brd 192.168.0.0 scope global flannel.1</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line">19: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP group default qlen 1000</div><div class="line">    link/ether a2:99:4f:dc:9d:5c brd ff:ff:ff:ff:ff:ff</div><div class="line">    inet 192.168.0.1/24 brd 192.168.0.255 scope global cni0</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line"></div><div class="line">//宿主机物理网卡抓包，被封成了udp的vxlan包    </div><div class="line">[root@hygon3 11:12 /root]</div><div class="line">#tcpdump -i p1p1 udp and port 8472 -nnetvv</div><div class="line">0c:42:a1:db:b1:a8 &gt; 88:66:39:89:9b:cc, ethertype IPv4 (0x0800), length 967: (tos 0x0, ttl 64, id 33722, offset 0, flags [none], proto UDP (17), length 953)</div><div class="line">    10.176.3.245.45173 &gt; 10.176.4.245.8472: [bad udp cksum 0x88c6 -&gt; 0xe4db!] OTV, flags [I] (0x08), overlay 0, instance 1</div><div class="line">a2:06:5e:83:44:78 &gt; 66:c6:ba:a2:8f:a1, ethertype IPv4 (0x0800), length 917: (tos 0x0, ttl 63, id 53539, offset 0, flags [DF], proto TCP (6), length 903)</div><div class="line">    192.168.0.4.40712 &gt; 192.168.2.56.3100: Flags [P.], cksum 0x8706 (incorrect -&gt; 0xe31b), seq 150613328:150614179, ack 3441682214, win 507, options [nop,nop,TS val 1240166469 ecr 2298311268], length 851</div><div class="line"></div><div class="line">---------跨机分割线--------</div><div class="line"></div><div class="line">[root@hygon4 11:15 /root] //udp ttl为61，经过了3跳(icmp ttl为63)，不过这些都和vxlan内容无关了</div><div class="line">#tcpdump -i p1p1 udp and port 8472 -nnetvv</div><div class="line">88:66:39:2b:3f:ec &gt; 0c:42:a1:e9:77:2c, ethertype IPv4 (0x0800), length 736: (tos 0x0, ttl 61, id 49748, offset 0, flags [none], proto UDP (17), length 722)</div><div class="line">    10.176.3.245.45173 &gt; 10.176.4.245.8472: [udp sum ok] OTV, flags [I] (0x08), overlay 0, instance 1</div><div class="line">a2:06:5e:83:44:78 &gt; 66:c6:ba:a2:8f:a1, ethertype IPv4 (0x0800), length 686: (tos 0x0, ttl 63, id 53631, offset 0, flags [DF], proto TCP (6), length 672)</div><div class="line">    192.168.0.4.40712 &gt; 192.168.2.56.3100: Flags [P.], cksum 0x7f0c (correct), seq 150646020:150646640, ack 3441685158, win 507, options [nop,nop,TS val 1240301769 ecr 2298444568], length 620</div><div class="line">0c:42:a1:e9:77:2c &gt; 88:66:39:2b:3f:ec, ethertype IPv4 (0x0800), length 180: (tos 0x0, ttl 64, id 57062, offset 0, flags [none], proto UDP (17), length 166)</div><div class="line">    10.176.4.245.41515 &gt; 10.176.3.245.8472: [bad udp cksum 0x9a23 -&gt; 0x8e11!] OTV, flags [I] (0x08), overlay 0, instance 1</div><div class="line">66:c6:ba:a2:8f:a1 &gt; a2:06:5e:83:44:78, ethertype IPv4 (0x0800), length 130: (tos 0x0, ttl 63, id 12391, offset 0, flags [DF], proto TCP (6), length 116)</div><div class="line">    192.168.2.56.3100 &gt; 192.168.0.4.40712: Flags [P.], cksum 0x83f3 (incorrect -&gt; 0x77e1), seq 1:65, ack 620, win 501, options [nop,nop,TS val 2298447868 ecr 1240301769], length 64</div><div class="line">    </div><div class="line">//到对端hygon4上抓包, 因为途中都是vxlan，所以ttl、mac地址都不变</div><div class="line">[root@hygon4 10:55 /root]</div><div class="line">#tcpdump -i flannel.1 host 192.168.2.56 -nnetvv</div><div class="line">dropped privs to tcpdump</div><div class="line">tcpdump: listening on flannel.1, link-type EN10MB (Ethernet), capture size 262144 bytes</div><div class="line">a2:06:5e:83:44:78 &gt; 66:c6:ba:a2:8f:a1, ethertype IPv4 (0x0800), length 933: (tos 0x0, ttl 63, id 52807, offset 0, flags [DF], proto TCP (6), length 919)</div><div class="line">    192.168.0.4.40712 &gt; 192.168.2.56.3100: Flags [P.], cksum 0x8d0d (correct), seq 150361706:150362573, ack 3441658790, win 507, options [nop,nop,TS val 1239073069 ecr 2297216169], length 867</div><div class="line">    </div><div class="line">#ip a //only for flannel.1 and cni0</div><div class="line">10: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN group default</div><div class="line">    link/ether 66:c6:ba:a2:8f:a1 brd ff:ff:ff:ff:ff:ff</div><div class="line">    inet 192.168.2.0/32 brd 192.168.2.0 scope global flannel.1</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line">11: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP group default qlen 1000</div><div class="line">    link/ether 16:97:3a:7b:53:00 brd ff:ff:ff:ff:ff:ff</div><div class="line">    inet 192.168.2.1/24 brd 192.168.2.255 scope global cni0</div><div class="line">       valid_lft forever preferred_lft forever       </div><div class="line"></div><div class="line">[root@hygon4 11:24 /root]</div><div class="line">#arp -n | grep 44:78</div><div class="line">192.168.0.0              ether   a2:06:5e:83:44:78   CM                    flannel.1   </div><div class="line"> </div><div class="line"> //mac地址替换，ttl减1</div><div class="line"> [root@hygon4 10:55 /root]</div><div class="line">#tcpdump -i cni0 host 192.168.2.56 -nnetvv</div><div class="line">dropped privs to tcpdump</div><div class="line">tcpdump: listening on cni0, link-type EN10MB (Ethernet), capture size 262144 bytes</div><div class="line">16:97:3a:7b:53:00 &gt; 52:e6:8e:02:80:35, ethertype IPv4 (0x0800), length 935: (tos 0x0, ttl 62, id 52829, offset 0, flags [DF], proto TCP (6), length 921)</div><div class="line">    192.168.0.4.40712 &gt; 192.168.2.56.3100: Flags [P.], cksum 0x7aa8 (correct), seq 150369440:150370309, ack 3441659494, win 507, options [nop,nop,TS val 1239115869 ecr 2297259166], length 869</div></pre></td></tr></table></figure>
<p>这个流转流程如下图：</p>
<p><img src="/images/951413iMgBlog/flannel-network-flow.jpg" alt="flannel-network-flow"></p>
<p>对应宿主机查询到的ip、路由信息（和上图不是对应的）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">#ip -d -4 addr show cni0</div><div class="line">475: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP group default qlen 1000</div><div class="line">    link/ether 8e:34:ba:e2:a4:c6 brd ff:ff:ff:ff:ff:ff promiscuity 0 minmtu 68 maxmtu 65535</div><div class="line">    bridge forward_delay 1500 hello_time 200 max_age 2000 ageing_time 30000 stp_state 0 priority 32768 vlan_filtering 0 vlan_protocol 802.1Q bridge_id 8000.8e:34:ba:e2:a4:c6 designated_root 8000.8e:34:ba:e2:a4:c6 root_port 0 root_path_cost 0 topology_change 0 topology_change_detected 0 hello_timer    0.00 tcn_timer    0.00 topology_change_timer    0.00 gc_timer  161.46 vlan_default_pvid 1 vlan_stats_enabled 0 group_fwd_mask 0 group_address 01:80:c2:00:00:00 mcast_snooping 1 mcast_router 1 mcast_query_use_ifaddr 0 mcast_querier 0 mcast_hash_elasticity 4 mcast_hash_max 512 mcast_last_member_count 2 mcast_startup_query_count 2 mcast_last_member_interval 100 mcast_membership_interval 26000 mcast_querier_interval 25500 mcast_query_interval 12500 mcast_query_response_interval 1000 mcast_startup_query_interval 3124 mcast_stats_enabled 0 mcast_igmp_version 2 mcast_mld_version 1 nf_call_iptables 0 nf_call_ip6tables 0 nf_call_arptables 0 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535</div><div class="line">    inet 192.168.3.1/24 brd 192.168.3.255 scope global cni0</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line"></div><div class="line">#ip -d -4 addr show flannel.1 //vxlan id 1 local 10.133.2.252 dev bond0 --指定了物理网卡</div><div class="line">474: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN group default</div><div class="line">    link/ether fe:49:64:ae:36:af brd ff:ff:ff:ff:ff:ff promiscuity 0 minmtu 68 maxmtu 65535</div><div class="line">    vxlan id 1 local 10.133.2.252 dev bond0 srcport 0 0 dstport 8472 nolearning ttl auto ageing 300 udpcsum noudp6zerocsumtx noudp6zerocsumrx numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535</div><div class="line">    inet 192.168.3.0/32 brd 192.168.3.0 scope global flannel.1</div><div class="line">       valid_lft forever preferred_lft forever</div></pre></td></tr></table></figure>
<p>包流转<a href="https://blog.laputa.io/kubernetes-flannel-networking-6a1cb1f8ec7c" target="_blank" rel="external">示意图</a></p>
<p><img src="/images/951413iMgBlog/image-20220119114929034.png" alt="image-20220119114929034"></p>
<h2 id="flannel网络不通排查案例"><a href="#flannel网络不通排查案例" class="headerlink" title="flannel网络不通排查案例"></a>flannel网络不通排查案例</h2><p>当网络不通时，可以根据以上演示的包流转路径在不同的网络设备上抓包来定位哪个环节不通</p>
<h3 id="firewalld"><a href="#firewalld" class="headerlink" title="firewalld"></a>firewalld</h3><p>在麒麟系统的物理机上通过kubeadm setup集群，发现有的环境flannel网络不通，在宿主机上ping 其它物理机flannel.0网卡的ip，通过在对端宿主机抓包发现icmp收到后被防火墙扔掉了，抓包中可以看到错误信息：icmp unreachable - admin prohibited</p>
<p>下图中正常的icmp是直接ping 物理机ip</p>
<p><img src="/images/951413iMgBlog/image-20211228203650921.png" alt="image-20211228203650921"></p>
<blockquote>
<p>The “admin prohibited filter” seen in the tcpdump output means there is a firewall blocking a connection. It does it by sending back an ICMP packet meaning precisely that: the admin of that firewall doesn’t want those packets to get through. It could be a firewall at the destination site. It could be a firewall in between. It could be iptables on the Linux system.</p>
</blockquote>
<p>发现有问题的环境中宿主机的防火墙设置报错了：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">12月 28 23:35:08 hygon253 firewalld[10493]: WARNING: COMMAND_FAILED: &apos;/usr/sbin/iptables -w10 -t filter -X DOCKER-ISOLATION-STAGE-1&apos; failed: iptables: No chain/target/match by that name.</div><div class="line">12月 28 23:35:08 hygon253 firewalld[10493]: WARNING: COMMAND_FAILED: &apos;/usr/sbin/iptables -w10 -t filter -F DOCKER-ISOLATION-STAGE-2&apos; failed: iptables: No chain/target/match by that name.</div></pre></td></tr></table></figure>
<p>应该是因为启动docker的时候 firewalld 是运行着的</p>
<blockquote>
<p>Do you have firewalld enabled, and was it (re)started after docker was started? If so, then it’s likely that firewalld wiped docker’s IPTables rules. Restarting the docker daemon should re-create those rules.</p>
</blockquote>
<p><strong>停掉 firewalld 服务可以解决这个问题</strong>，k8s集群</p>
<h3 id="flannel网络不通"><a href="#flannel网络不通" class="headerlink" title="flannel网络不通"></a><a href="https://github.com/flannel-io/flannel/issues/799" target="_blank" rel="external">flannel网络不通</a></h3><blockquote>
<p>Starting from Docker 1.13 default iptables policy for FORWARDING is DROP</p>
</blockquote>
<p>flannel能收到包，但是cni0收不到包，说明包进到了目标宿主机，但是从flannel解开udp转送到cni的时候出了问题，大概率是iptables 拦截了包</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">It seems docker version &gt;=1.13 will add iptables rule like below,and it make this issue happen:</div><div class="line">iptables -P FORWARD DROP </div><div class="line"></div><div class="line">All you need to do is add a rule below:</div><div class="line">iptables -P FORWARD ACCEPT //将FORWARD 默认规则(没有匹配到其它规则的话）改成ACCEPT</div><div class="line"></div><div class="line">//flannel 会检查 forward chain并将之改成 accept？以下是flannel 容器日志</div><div class="line">I0913 07:52:30.965060       1 main.go:698] Using interface with name enp2s0f0 and address 192.168.0.1</div><div class="line">I0913 07:52:30.965128       1 main.go:720] Defaulting external address to interface address (192.168.0.1)</div><div class="line">I0913 07:52:30.965134       1 main.go:733] Defaulting external v6 address to interface address (&lt;nil&gt;)</div><div class="line">I0913 07:52:30.965243       1 vxlan.go:137] VXLAN config: VNI=1 Port=0 GBP=false Learning=false DirectRouting=false</div><div class="line">I0913 07:52:30.966878       1 kube.go:339] Setting NodeNetworkUnavailable</div><div class="line">I0913 07:52:30.977942       1 main.go:340] Setting up masking rules</div><div class="line">I0913 07:52:31.332105       1 main.go:361] Changing default FORWARD chain policy to ACCEPT</div></pre></td></tr></table></figure>
<h2 id="宿主机多-ip-下-flannel-网络不通"><a href="#宿主机多-ip-下-flannel-网络不通" class="headerlink" title="宿主机多 ip 下 flannel 网络不通"></a>宿主机多 ip 下 flannel 网络不通</h2><p>宿主机有两个ip，flannel组网ip是192.168，但是默认路由在1.1.网络下，此时能 ping 通，但是curl不通端口</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">#tcpdump -i enp2s0f0 -nettvv host 192.168.0.3 and udp</div><div class="line">tcpdump: listening on enp2s0f0, link-type EN10MB (Ethernet), capture size 262144 bytes</div><div class="line"></div><div class="line">//握手请求syn包，udp src ip:192.168.0.1</div><div class="line">1660897108.334556 0c:42:a1:4f:d1:e2 &gt; 0c:42:a1:4f:d1:ee, ethertype IPv4 (0x0800), length 124: (tos 0x0, ttl 64, id 32118, offset 0, flags [none], proto UDP (17), length 110)</div><div class="line">    192.168.0.1.56773 &gt; 192.168.0.3.otv: [bad udp cksum 0x81c0 -&gt; 0x459f!] OTV, flags [I] (0x08), overlay 0, instance 1</div><div class="line">56:fa:69:e3:dc:6b &gt; 4e:95:a9:e2:ed:28, ethertype IPv4 (0x0800), length 74: (tos 0x0, ttl 63, id 41108, offset 0, flags [DF], proto TCP (6), length 60)</div><div class="line">    172.19.0.6.35118 &gt; 172.19.2.39.http: Flags [S], cksum 0x10c8 (correct), seq 582983385, win 64860, options [mss 1410,sackOK,TS val 2648241865 ecr 0,nop,wscale 7], length 0</div><div class="line"></div><div class="line">//对端回复syn包, 注意udp的目标ip:1.1.1.198,应该是 192.168.0.1 才对，mac是192.168.0.1 的，mac和ip不匹配，所以被内核扔掉（但是icmp不会被扔，原因未知）</div><div class="line">1660897108.334738 0c:42:a1:4f:d1:ee &gt; 0c:42:a1:4f:d1:e2, ethertype IPv4 (0x0800), length 124: (tos 0x0, ttl 64, id 41433, offset 0, flags [none], proto UDP (17), length 110)</div><div class="line">    192.168.0.3.38086 &gt; 1.1.1.198.otv: [bad udp cksum 0x5aff -&gt; 0x1769!] OTV, flags [I] (0x08), overlay 0, instance 1</div><div class="line">4e:95:a9:e2:ed:28 &gt; 56:fa:69:e3:dc:6b, ethertype IPv4 (0x0800), length 74: (tos 0x0, ttl 63, id 0, offset 0, flags [DF], proto TCP (6), length 60)</div><div class="line">    172.19.2.39.http &gt; 172.19.0.6.35118: Flags [S.], cksum 0x8027 (correct), seq 3633913151, ack 582983386, win 64308, options [mss 1410,sackOK,TS val 3514485603 ecr 2648241865,nop,wscale 7], length 0</div><div class="line"></div><div class="line">//没有回复第三次握手，继续发syn，因为收到syn+ack后被扔掉了</div><div class="line">1660897109.363382 0c:42:a1:4f:d1:e2 &gt; 0c:42:a1:4f:d1:ee, ethertype IPv4 (0x0800), length 124: (tos 0x0, ttl 64, id 32123, offset 0, flags [none], proto UDP (17), length 110)</div><div class="line">    192.168.0.1.60933 &gt; 192.168.0.3.otv: [bad udp cksum 0x81c0 -&gt; 0x355f!] OTV, flags [I] (0x08), overlay 0, instance 1</div><div class="line">56:fa:69:e3:dc:6b &gt; 4e:95:a9:e2:ed:28, ethertype IPv4 (0x0800), length 74: (tos 0x0, ttl 63, id 41109, offset 0, flags [DF], proto TCP (6), length 60)</div><div class="line">    172.19.0.6.35118 &gt; 172.19.2.39.http: Flags [S], cksum 0x0cc3 (correct), seq 582983385, win 64860, options [mss 1410,sackOK,TS val 2648242894 ecr 0,nop,wscale 7], length 0</div></pre></td></tr></table></figure>
<p>多ip宿主机的网卡及路由</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">5: enp125s0f3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</div><div class="line">    link/ether 64:2c:ac:e9:78:3d brd ff:ff:ff:ff:ff:ff</div><div class="line">    inet 1.1.1.198/25 brd 1.1.1.255 scope global dynamic noprefixroute enp125s0f3</div><div class="line">       valid_lft 12463sec preferred_lft 12463sec</div><div class="line">    inet6 fe80::859a:7861:378e:d6ac/64 scope link noprefixroute</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line">6: enp2s0f0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000</div><div class="line">    link/ether 0c:42:a1:4f:d1:e2 brd ff:ff:ff:ff:ff:ff</div><div class="line">    inet 192.168.0.1/24 brd 192.168.0.255 scope global noprefixroute enp2s0f0</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line">       </div><div class="line">#ip route</div><div class="line">default via 1.1.1.254 dev enp125s0f3 proto dhcp metric 101</div><div class="line">1.1.1.128/25 dev enp125s0f3 proto kernel scope link src 1.1.1.198 metric 101</div><div class="line">172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 linkdown</div><div class="line">172.19.0.0/24 dev cni0 proto kernel scope link src 172.19.0.1</div><div class="line">172.19.2.0/24 via 172.19.2.0 dev flannel.1 onlink</div><div class="line">172.19.3.0/24 via 172.19.3.0 dev flannel.1 onlink</div><div class="line">192.168.0.0/24 dev enp2s0f0 proto kernel scope link src 192.168.0.1 metric 100</div></pre></td></tr></table></figure>
<p>解决办法：真正生效的是 flannel.1 中的地址</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">//比如 flannel 选用了以下公网ip（默认路由上的ip）导致flannel网络不通，应该选内网ip</div><div class="line">#ip -details link show flannel.1</div><div class="line">29: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT group default</div><div class="line">    link/ether 96:ad:e2:29:29:09 brd ff:ff:ff:ff:ff:ff promiscuity 0 minmtu 68 maxmtu 65535</div><div class="line">    vxlan id 1 local 30.1.1.1 dev eno1 srcport 0 0 dstport 8472 nolearning ttl auto ageing 300 udpcsum noudp6zerocsumtx noudp6zerocsumrx addrgenmode eui64 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535</div></pre></td></tr></table></figure>
<p>解决办法得先删掉 flannel 网络，然后在 flannel.yaml 中指定内网网卡：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="attr">containers:</span></div><div class="line"><span class="attr">      - name:</span> <span class="string">kube-flannel</span></div><div class="line"><span class="attr">        image:</span> <span class="attr">registry:5000/quay.io/coreos/flannel:v0.14.0</span></div><div class="line"><span class="attr">        command:</span></div><div class="line"><span class="bullet">        -</span> <span class="string">/opt/bin/flanneld</span></div><div class="line"><span class="attr">        args:</span></div><div class="line"><span class="bullet">        -</span> <span class="bullet">--ip-masq</span></div><div class="line"><span class="bullet">        -</span> <span class="bullet">--kube-subnet-mgr</span></div><div class="line">        <span class="comment">#指定网卡, enp33s0f0 为内网网卡，不是默认路由</span></div><div class="line">        <span class="comment">#- --iface=enp33s0f0</span></div><div class="line">        <span class="comment">#— --iface-regex=[enp0s8|enp0s9]</span></div><div class="line"></div><div class="line"><span class="string">//然后会看到</span> <span class="string">flannel.1</span> <span class="string">的地址用的是</span> <span class="string">enp33s0f0（192.168.0.1）</span></div><div class="line"><span class="comment">#ip -details link show flannel.1</span></div><div class="line"><span class="number">40</span><span class="string">:</span> <span class="string">flannel.1:</span> <span class="string">&lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt;</span> <span class="string">mtu</span> <span class="number">1450</span> <span class="string">qdisc</span> <span class="string">noqueue</span> <span class="string">state</span> <span class="string">UNKNOWN</span> <span class="string">mode</span> <span class="string">DEFAULT</span> <span class="string">group</span> <span class="string">default</span></div><div class="line">    <span class="string">link/ether</span> <span class="number">92</span><span class="string">:5c:b2:af:37:62</span> <span class="string">brd</span> <span class="attr">ff:ff:ff:ff:ff:ff</span> <span class="string">promiscuity</span> <span class="number">0</span> <span class="string">minmtu</span> <span class="number">68</span> <span class="string">maxmtu</span> <span class="number">65535</span></div><div class="line">    <span class="string">vxlan</span> <span class="string">id</span> <span class="number">1</span> <span class="string">local</span> <span class="number">192.168</span><span class="number">.0</span><span class="number">.1</span> <span class="string">dev</span> <span class="string">enp2s0f0</span> <span class="string">srcport</span> <span class="number">0</span> <span class="number">0</span> <span class="string">dstport</span> <span class="number">8472</span> <span class="string">nolearning</span> <span class="string">ttl</span> <span class="string">auto</span> <span class="string">ageing</span> <span class="number">300</span> <span class="string">udpcsum</span> <span class="string">noudp6zerocsumtx</span> <span class="string">noudp6zerocsumrx</span> <span class="string">addrgenmode</span> <span class="string">eui64</span> <span class="string">numtxqueues</span> <span class="number">1</span> <span class="string">numrxqueues</span> <span class="number">1</span> <span class="string">gso_max_size</span> <span class="number">65536</span> <span class="string">gso_max_segs</span> <span class="number">65535</span></div></pre></td></tr></table></figure>
<blockquote>
<p> If you happen to have different interfaces to be matched, you can match it on a regex pattern. Let’s say the worker nodes could’ve enp0s8 or enp0s9 configured, then the flannel args would be <code>— --iface-regex=[enp0s8|enp0s9]</code></p>
</blockquote>
<p>修改node的annotation中flannel的 public-ip。如果因为 public-ip 不对导致网络不通，在annotation中修改public-ip没用，这个值是 flannel 读取underlay 网络配置后写进来的，同时也写到了 flannel.1 的 config 中</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">kubectl annotate node ky1 flannel.alpha.coreos.com/public-ip-</div><div class="line">kubectl annotate node ky1 flannel.alpha.coreos.com/public-ip=192.168.0.1</div></pre></td></tr></table></figure>
<h2 id="抓包和调试-–-nsenter"><a href="#抓包和调试-–-nsenter" class="headerlink" title="抓包和调试 – nsenter"></a>抓包和调试 – nsenter</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line">获取pid：docker inspect -f &#123;&#123;.State.Pid&#125;&#125; c8f874efea06</div><div class="line"></div><div class="line">进入namespace：nsenter --net --pid --target 17277</div><div class="line">nsenter --net --pid --target `docker inspect -f &#123;&#123;.State.Pid&#125;&#125; c8f874efea06`</div><div class="line"></div><div class="line">//只进入network namespace，这样看到的文件还是宿主机的，能直接用tcpdump，但是看到的网卡是容器的</div><div class="line">nsenter --target 17277 --net </div><div class="line"></div><div class="line">// ip netns 获取容器网络信息</div><div class="line"> 1022  [2021-04-14 15:53:06] docker inspect -f &apos;&#123;&#123;.State.Pid&#125;&#125;&apos; ab4e471edf50   //获取容器进程id</div><div class="line"> 1023  [2021-04-14 15:53:30] ls /proc/79828/ns/net</div><div class="line"> 1024  [2021-04-14 15:53:57] ln -sfT /proc/79828/ns/net /var/run/netns/ab4e471edf50 //link 以便ip netns List能访问</div><div class="line"> </div><div class="line">// 宿主机上查看容器ip</div><div class="line"> 1026  [2021-04-14 15:54:11] ip netns list</div><div class="line"> 1028  [2021-04-14 15:55:19] ip netns exec ab4e471edf50 ifconfig</div><div class="line"> </div><div class="line"> //nsenter调试网络</div><div class="line"> Get the pause container&apos;s sandboxkey: </div><div class="line">root@worker01:~# docker inspect k8s_POD_ubuntu-5846f86795-bcbqv_default_ea44489d-3dd4-11e8-bb37-02ecc586c8d5_0 | grep SandboxKey</div><div class="line">            &quot;SandboxKey&quot;: &quot;/var/run/docker/netns/82ec9e32d486&quot;,</div><div class="line">root@worker01:~#</div><div class="line">Now, using nsenter you can see the container&apos;s information.</div><div class="line">root@worker01:~# nsenter --net=/var/run/docker/netns/82ec9e32d486 ip addr show</div><div class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1</div><div class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</div><div class="line">    inet 127.0.0.1/8 scope host lo</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line">3: eth0@if7: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP group default</div><div class="line">   link/ether 0a:58:0a:f4:01:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0</div><div class="line">   inet 10.244.1.2/24 scope global eth0</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line">Identify the peer_ifindex, and finally you can see the veth pair endpoint in root namespace.</div><div class="line">root@worker01:~# nsenter --net=/var/run/docker/netns/82ec9e32d486 ethtool -S eth0</div><div class="line">NIC statistics:</div><div class="line">     peer_ifindex: 7</div><div class="line">root@worker01:~#</div><div class="line">root@worker01:~# ip -d link show | grep &apos;7: veth&apos;</div><div class="line">7: veth5e43ca47@if3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default</div><div class="line">root@worker01:~#</div></pre></td></tr></table></figure>
<p>nsenter相当于在setns的示例程序之上做了一层封装，使我们无需指定命名空间的文件描述符，而是指定进程号即可，<a href="https://medium.com/@anilkreddyr/kubernetes-with-flannel-understanding-the-networking-part-2-78b53e5364c7" target="_blank" rel="external">详细case</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">#docker inspect cb7b05d82153 | grep -i SandboxKey   //根据 pause 容器id找network namespace</div><div class="line">            &quot;SandboxKey&quot;: &quot;/var/run/docker/netns/d6b2ef3cf886&quot;,</div><div class="line"></div><div class="line">[root@hygon252 19:00 /root]</div><div class="line">#nsenter --net=/var/run/docker/netns/d6b2ef3cf886 ip addr show</div><div class="line">3: eth0@if496: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP group default  //496对应宿主机上的veth编号</div><div class="line">    link/ether 1e:95:dd:d9:88:bd brd ff:ff:ff:ff:ff:ff link-netnsid 0</div><div class="line">    inet 192.168.3.22/24 brd 192.168.3.255 scope global eth0</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line">#nsenter --net=/var/run/docker/netns/d6b2ef3cf886 ethtool -S eth0</div><div class="line">NIC statistics:</div><div class="line">     peer_ifindex: 496</div><div class="line">     </div><div class="line">#ip -d -4 addr show cni0</div><div class="line">475: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP group default qlen 1000</div><div class="line">    link/ether 8e:34:ba:e2:a4:c6 brd ff:ff:ff:ff:ff:ff promiscuity 0 minmtu 68 maxmtu 65535</div><div class="line">    bridge forward_delay 1500 hello_time 200 max_age 2000 ageing_time 30000 stp_state 0 priority 32768 vlan_filtering 0 vlan_protocol 802.1Q bridge_id 8000.8e:34:ba:e2:a4:c6 designated_root 8000.8e:34:ba:e2:a4:c6 root_port 0 root_path_cost 0 topology_change 0 topology_change_detected 0 hello_timer    0.00 tcn_timer    0.00 topology_change_timer    0.00 gc_timer   43.31 vlan_default_pvid 1 vlan_stats_enabled 0 group_fwd_mask 0 group_address 01:80:c2:00:00:00 mcast_snooping 1 mcast_router 1 mcast_query_use_ifaddr 0 mcast_querier 0 mcast_hash_elasticity 4 mcast_hash_max 512 mcast_last_member_count 2 mcast_startup_query_count 2 mcast_last_member_interval 100 mcast_membership_interval 26000 mcast_querier_interval 25500 mcast_query_interval 12500 mcast_query_response_interval 1000 mcast_startup_query_interval 3124 mcast_stats_enabled 0 mcast_igmp_version 2 mcast_mld_version 1 nf_call_iptables 0 nf_call_ip6tables 0 nf_call_arptables 0 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535</div><div class="line">    inet 192.168.3.1/24 brd 192.168.3.255 scope global cni0</div><div class="line">       valid_lft forever preferred_lft forever</div></pre></td></tr></table></figure>
<h2 id="清理"><a href="#清理" class="headerlink" title="清理"></a><a href="https://serverfault.com/questions/247767/cannot-delete-gre-tunnel" target="_blank" rel="external">清理</a></h2><p>cni信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">/etc/cni/net.d/*</div><div class="line">/var/lib/cni/ 下存放有ip分配信息</div><div class="line"></div><div class="line">#cat /run/flannel/subnet.env</div><div class="line">FLANNEL_NETWORK=192.168.0.0/16</div><div class="line">FLANNEL_SUBNET=192.168.0.1/24</div><div class="line">FLANNEL_MTU=1450</div><div class="line">FLANNEL_IPMASQ=true</div></pre></td></tr></table></figure>
<p>calico创建的tunl0网卡是个tunnel，可以通过 ip tunnel show来查看，<a href="https://askubuntu.com/questions/1190684/how-can-i-permanently-delete-tun-interfaces#:~:text=doing%20sudo%20ip%20link%20delete,which%20removes%20all%20tun%20devices" target="_blank" rel="external">清理不掉</a>（重启可以清理掉tunl0）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">ip link set dev tunl0 name tunl0_fallback</div><div class="line">或者</div><div class="line">/sbin/ip link set eth1 down</div><div class="line">/sbin/ip link set eth1 name eth123</div><div class="line">/sbin/ip link set eth123 up</div></pre></td></tr></table></figure>
<h3 id="清理和创建flannel网络"><a href="#清理和创建flannel网络" class="headerlink" title="清理和创建flannel网络"></a>清理和创建flannel网络</h3><p>查看容器网卡和宿主机上的虚拟网卡veth pair:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">ip link //宿主机上执行</div><div class="line">cat /sys/class/net/eth0/iflink //容器中执行</div></pre></td></tr></table></figure>
<p>清理</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">ip link delete cni0</div><div class="line">ip link delete flannel.1</div></pre></td></tr></table></figure>
<p>创建</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">ip link add cni0 type bridge</div><div class="line">ip addr add dev cni0 172.30.0.0/24</div><div class="line"></div><div class="line">查看A simpler solution:</div><div class="line">ip -details link show</div><div class="line">ls -l /sys/class/net/ - virtual ones will show all in virtual and lan is on the PCI bus.</div><div class="line"></div><div class="line">brctl show cni0</div><div class="line">brctl addif cni0 veth1 veth2 veth3  //往cni bridge添加多个容器peer 网卡</div></pre></td></tr></table></figure>
<p>完全可以手工创建cni0、flannel.1等网络设备，然后将 veth添加到cni0网桥上，再在宿主机配置ip route，基本一个纯手工版本打造的flannel vxlan网络就实现了，深入理解到此任何flannel网络问题都可以解决了。</p>
<h3 id="flannel-ip在多个node之间分配错乱"><a href="#flannel-ip在多个node之间分配错乱" class="headerlink" title="flannel ip在多个node之间分配错乱"></a>flannel ip在多个node之间分配错乱</h3><p>当铲掉重新部署的时候可能cni等网络有残留，导致下一次部署会报ip已存在的错误</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">(combined from similar events): Failed create pod sandbox: rpc error: code = Unknown desc = failed to set up sandbox container &quot;f7aa44bf81b27bf0ff6c02339df2d2743cf952c1519fead4c563892d2d41a979&quot; network for pod &quot;nginx-deployment-6c8c86b759-f8fb7&quot;: NetworkPlugin cni failed to set up pod &quot;nginx-deployment-6c8c86b759-f8fb7_default&quot; network: failed to set bridge addr: &quot;cni0&quot; already has an IP address different from 172.19.2.1/24</div></pre></td></tr></table></figure>
<p> 可以铲掉网卡重新分配，或者给cni重新分配错误信息提示的ip</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ifconfig cni0 172.19.2.1/24</div></pre></td></tr></table></figure>
<p>or</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">ip link set cni0 down &amp;&amp; ip link set flannel.1 down </div><div class="line">ip link delete cni0 &amp;&amp; ip link delete flannel.1</div><div class="line">systemctl restart containerd &amp;&amp; systemctl restart kubelet</div></pre></td></tr></table></figure>
<h2 id="host-gw"><a href="#host-gw" class="headerlink" title="host-gw"></a><a href="https://msazure.club/flannel-networking-demystify/" target="_blank" rel="external">host-gw</a></h2><p>实现超级简单，就是在宿主机上配置路由规则，把其它宿主机ip当成其上所有pod的下一跳，不用封包解包，所以性能奇好，但是要求所有宿主机在一个2层网络，因为ip路由规则要求是直达其它宿主机。</p>
<p>手工配置实现就是vxlan的超级精简版，略！</p>
<h2 id="netns-操作"><a href="#netns-操作" class="headerlink" title="netns 操作"></a><a href="https://mp.weixin.qq.com/s/lscMpc5BWAEzjgYw6H0wBw" target="_blank" rel="external">netns 操作</a></h2><p>以下case创建一个名为 ren 的netns，然后在里面增加一对虚拟网卡veth1 veth1_p,  veth1放置在ren里面，veth1_p 放在物理机上，给他们配置上ip并up就能通了。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div></pre></td><td class="code"><pre><div class="line"> 1004  [2021-10-27 10:49:08] ip netns add ren</div><div class="line"> 1005  [2021-10-27 10:49:12] ip netns show</div><div class="line"> 1006  [2021-10-27 10:49:22] ip netns exec ren route   //为空</div><div class="line"> 1007  [2021-10-27 10:49:29] ip netns exec ren iptables -L</div><div class="line"> 1008  [2021-10-27 10:49:55] ip link add veth1 type veth peer name veth1_p //此时宿主机上能看到这两块网卡</div><div class="line"> 1009  [2021-10-27 10:50:07] ip link set veth1 netns ren //将veth1从宿主机默认网络空间挪到ren中，宿主机中看不到veth1了</div><div class="line"> 1010  [2021-10-27 10:50:18] ip netns exec ren route  </div><div class="line"> 1011  [2021-10-27 10:50:25] ip netns exec ren iptables -L</div><div class="line"> 1012  [2021-10-27 10:50:39] ifconfig</div><div class="line"> 1013  [2021-10-27 10:50:51] ip link list</div><div class="line"> 1014  [2021-10-27 10:51:29] ip netns exec ren ip link list</div><div class="line"> 1017  [2021-10-27 10:53:27] ip netns exec ren ip addr add 172.19.0.100/24 dev veth1 </div><div class="line"> 1018  [2021-10-27 10:53:31] ip netns exec ren ip link list</div><div class="line"> 1019  [2021-10-27 10:53:39] ip netns exec ren ifconfig</div><div class="line"> 1020  [2021-10-27 10:53:42] ip netns exec ren ifconfig -a</div><div class="line"> 1021  [2021-10-27 10:54:13] ip netns exec ren ip link set dev veth1 up</div><div class="line"> 1022  [2021-10-27 10:54:16] ip netns exec ren ifconfig</div><div class="line"> 1023  [2021-10-27 10:54:22] ping 172.19.0.100</div><div class="line"> 1024  [2021-10-27 10:54:35] ifconfig -a</div><div class="line"> 1025  [2021-10-27 10:55:03] ip netns exec ren ip addr add 172.19.0.101/24 dev veth1_p</div><div class="line"> 1026  [2021-10-27 10:55:10] ip addr add 172.19.0.101/24 dev veth1_p</div><div class="line"> 1027  [2021-10-27 10:55:16] ifconfig veth1_p</div><div class="line"> 1028  [2021-10-27 10:55:30] ip link set dev veth1_p up</div><div class="line"> 1029  [2021-10-27 10:55:32] ifconfig veth1_p</div><div class="line"> 1030  [2021-10-27 10:55:38] ping 172.19.0.101</div><div class="line"> 1031  [2021-10-27 10:55:43] ping 172.19.0.100</div><div class="line"> 1032  [2021-10-27 10:55:53] ip link set dev veth1_p down</div><div class="line"> 1033  [2021-10-27 10:55:54] ping 172.19.0.100</div><div class="line"> 1034  [2021-10-27 10:55:58] ping 172.19.0.101</div><div class="line"> 1035  [2021-10-27 10:56:08] ifconfig veth1_p</div><div class="line"> 1036  [2021-10-27 10:56:32] ping 172.19.0.101</div><div class="line"> 1037  [2021-10-27 10:57:04] ip netns exec ren route</div><div class="line"> 1038  [2021-10-27 10:57:52] ip netns exec ren ping 172.19.0.101</div><div class="line"> 1039  [2021-10-27 10:57:58] ip link set dev veth1_p up</div><div class="line"> 1040  [2021-10-27 10:57:59] ip netns exec ren ping 172.19.0.101</div><div class="line"> 1041  [2021-10-27 10:58:06] ip netns exec ren ping 172.19.0.100</div><div class="line"> 1042  [2021-10-27 10:58:14] ip netns exec ren ifconfig</div><div class="line"> 1043  [2021-10-27 10:58:19] ip netns exec ren route</div><div class="line"> 1044  [2021-10-27 10:58:26] ip netns exec ren ping 172.19.0.100 -I veth1</div><div class="line"> 1045  [2021-10-27 10:58:58] ifconfig veth1_p</div><div class="line"> 1046  [2021-10-27 10:59:10] ping 172.19.0.100</div><div class="line"> 1047  [2021-10-27 10:59:26] ip netns exec ren ping 172.19.0.101 -I veth1</div><div class="line"> </div><div class="line"> 把网卡加入到docker0的bridge下</div><div class="line"> 1160  [2021-10-27 12:17:37] brctl show</div><div class="line"> 1161  [2021-10-27 12:18:05] ip link set dev veth3_p master docker0</div><div class="line"> 1162  [2021-10-27 12:18:09] ip link set dev veth1_p master docker0</div><div class="line"> 1163  [2021-10-27 12:18:13] ip link set dev veth2 master docker0</div><div class="line"> 1164  [2021-10-27 12:18:15] brctl show</div><div class="line"> </div><div class="line">brctl showmacs br0</div><div class="line">brctl show cni0</div><div class="line">brctl addif cni0 veth1 veth2 veth3  //往cni bridge添加多个容器peer 网卡</div></pre></td></tr></table></figure>
<p>Linux 上存在一个默认的网络命名空间，Linux 中的 1 号进程初始使用该默认空间。Linux 上其它所有进程都是由 1 号进程派生出来的，在派生 clone 的时候如果没有额外特别指定，所有的进程都将共享这个默认网络空间。</p>
<p>所有的网络设备刚创建出来都是在宿主机默认网络空间下的。可以通过 <code>ip link set 设备名 netns 网络空间名</code> 将设备移动到另外一个空间里去，socket也是归属在某一个网络命名空间下的，由创建socket进程所在的netns来决定socket所在的netns</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//file: net/socket.c</span></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">sock_create</span><span class="params">(<span class="keyword">int</span> family, <span class="keyword">int</span> type, <span class="keyword">int</span> protocol, struct socket **res)</span></span></div><div class="line">&#123;</div><div class="line"> <span class="keyword">return</span> __sock_create(current-&gt;nsproxy-&gt;net_ns, family, type, protocol, res, <span class="number">0</span>);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//file: include/net/sock.h</span></div><div class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span></span></div><div class="line"><span class="keyword">void</span> <span class="title">sock_net_set</span><span class="params">(struct sock *sk, struct net *net)</span></div><div class="line">&#123;</div><div class="line"> write_pnet(&amp;sk-&gt;sk_net, net);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>内核提供了三种操作命名空间的方式，分别是 clone、setns 和 unshare。ip netns add 使用的是 unshare，原理和 clone 是类似的。</p>
<p><img src="/images/951413iMgBlog/640-5304524." alt="Image"></p>
<p>每个 net 下都包含了自己的路由表、iptable 以及内核参数配置等等</p>
<h2 id="etcd-中存储的-flannel-配置"><a href="#etcd-中存储的-flannel-配置" class="headerlink" title="etcd 中存储的 flannel 配置"></a>etcd 中存储的 flannel 配置</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line">kubectl exec -it etcd-uos21 -n=kube-system -- /bin/sh</div><div class="line"></div><div class="line">然后：</div><div class="line">ETCDCTL_API=3 etcdctl --key /etc/kubernetes/pki/etcd/peer.key --cert /etc/kubernetes/pki/etcd/peer.crt --cacert /etc/kubernetes/pki/etcd/ca.crt --endpoints=https://localhost:2379 get /registry/configmaps/kube-system/kube-flannel-cfg</div><div class="line"></div><div class="line">cni-conf.json�&#123;</div><div class="line">  &quot;name&quot;: &quot;cbr0&quot;,</div><div class="line">  &quot;cniVersion&quot;: &quot;0.3.1&quot;,</div><div class="line">  &quot;plugins&quot;: [</div><div class="line">    &#123;</div><div class="line">      &quot;type&quot;: &quot;flannel&quot;,</div><div class="line">      &quot;delegate&quot;: &#123;</div><div class="line">        &quot;hairpinMode&quot;: true,</div><div class="line">        &quot;isDefaultGateway&quot;: true</div><div class="line">      &#125;</div><div class="line">    &#125;,</div><div class="line">    &#123;</div><div class="line">      &quot;type&quot;: &quot;portmap&quot;,</div><div class="line">      &quot;capabilities&quot;: &#123;</div><div class="line">        &quot;portMappings&quot;: true</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  ]</div><div class="line">&#125;</div><div class="line">Z</div><div class="line">net-conf.jsonI&#123;</div><div class="line">  &quot;Network&quot;: &quot;172.19.0.0/18&quot;,</div><div class="line">  &quot;Backend&quot;: &#123;</div><div class="line">    &quot;Type&quot;: &quot;vxlan&quot;</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line">&quot;</div></pre></td></tr></table></figure>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>通过无论是对flannel还是calico的学习，不管是使用vxlan还是host-gw发现这些所谓的overlay网络不过是披着一层udp的皮而已，只要我们对ip route/mac地址足够了解，这些新技术剖析下来仍然逃不过 <a href="https://datatracker.ietf.org/doc/html/rfc1180" target="_blank" rel="external">RFC1180</a> 描述的几个最基础的知识点（基础知识的力量）的使用而已，这一切硬核的基础知识无比简单，只要你多看看我这篇旧文<a href="https://plantegg.github.io/2019/05/15/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E7%BD%91%E7%BB%9C--%E4%B8%80%E4%B8%AA%E7%BD%91%E7%BB%9C%E5%8C%85%E7%9A%84%E6%97%85%E7%A8%8B/">《就是要你懂网络–一个网络包的旅程》</a></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://morven.life/notes/networking-3-ipip/" target="_blank" rel="external">https://morven.life/notes/networking-3-ipip/</a></p>
<p><a href="https://www.cnblogs.com/bakari/p/10564347.html" target="_blank" rel="external">https://www.cnblogs.com/bakari/p/10564347.html</a></p>
<p><a href="https://www.cnblogs.com/goldsunshine/p/10701242.html" target="_blank" rel="external">https://www.cnblogs.com/goldsunshine/p/10701242.html</a></p>
<p><a href="https://docker-k8s-lab.readthedocs.io/en/latest/docker/docker-flannel.html" target="_blank" rel="external">手工拉起flannel网络</a></p>
<p><a href="https://plantegg.github.io/2019/05/15/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E7%BD%91%E7%BB%9C--%E4%B8%80%E4%B8%AA%E7%BD%91%E7%BB%9C%E5%8C%85%E7%9A%84%E6%97%85%E7%A8%8B/">《就是要你懂网络–一个网络包的旅程》</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/15/">15</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="weibo @plantegg" />
          <p class="site-author-name" itemprop="name">weibo @plantegg</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
           
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">145</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">21</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">240</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
</script>

<div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">weibo @plantegg</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>

<span id="busuanzi_container_site_pv">
    本站总访问量<span id="busuanzi_value_site_pv_footer"></span>次
</span>
<span id="busuanzi_container_site_uv">
  本站访客数<span id="busuanzi_value_site_uv_footer"></span>人次
</span>


        
<div class="busuanzi-count">
  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      人
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>


        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
    <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  





  






  





  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  

  

  

  

</body>
</html>
