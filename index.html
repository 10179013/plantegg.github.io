<!doctype html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />





  <link rel="alternate" href="/atom.xml" title="plantegg" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="java mysql tcp performance network docker Linux">
<meta property="og:type" content="website">
<meta property="og:title" content="plantegg">
<meta property="og:url" content="https://plantegg.github.io/index.html">
<meta property="og:site_name" content="plantegg">
<meta property="og:description" content="java mysql tcp performance network docker Linux">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="plantegg">
<meta name="twitter:description" content="java mysql tcp performance network docker Linux">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://plantegg.github.io/"/>





  <title>plantegg - java tcp mysql performance network docker Linux</title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  















  
  
    
  

  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta custom-logo">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">plantegg</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description">java tcp mysql performance network docker Linux</h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-categories"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-sitemap">
          <a href="/sitemap.xml" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-sitemap"></i> <br />
            
            站点地图
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2117/06/07/关于本博/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2117/06/07/关于本博/" itemprop="url">关于本博</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2117-06-07T18:30:03+08:00">
                2117-06-07
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/others/" itemprop="url" rel="index">
                    <span itemprop="name">others</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="关于本博"><a href="#关于本博" class="headerlink" title="关于本博"></a>关于本博</h2><p>关注基础知识，一次把问题搞清楚，从案例出发深挖相关知识。</p>
<p>以前觉得自己一看就懂，实际是一问就打鼓，一用就糊涂。所以现在开始记录并总结再联系案例，一般是先把零散知识记录下来（看到过），慢慢地相关知识积累更多，直到碰到实践案例或是有点领悟到于是发现这块知识可以整理成一篇系统些的文章（基本快懂了）。</p>
<p>“技术变化太快，容易过时”，我的看法是网络知识、操作系统、计算机原理等核心概念知识的寿命会比你的职业生涯还长。这些都是40岁之后还会还会很有用，你看我40多了还在学习这些 :)</p>
<p><a href="https://plantegg.github.io/2018/05/23/%E5%A6%82%E4%BD%95%E5%9C%A8%E5%B7%A5%E4%BD%9C%E4%B8%AD%E5%AD%A6%E4%B9%A0/">如何在工作中学习</a> 所有方法我都记录在这篇文章中了，希望对你能有所帮助</p>
<p>所有新文章从<a href="https://plantegg.github.io/archives">这里可以看到</a>，即使再简单的一篇总结我可以持续总结三五年，有新的发现、感悟都是直接在原文上增减，不会发表新的文章。</p>
<p><img src="/images/951413iMgBlog/image-20220421102225491.png" alt="image-20220421102225491"></p>
<p>为什么写博客而不是公众号，我见过20年前的互联网，深度依赖搜索引擎，所以还是喜欢博客。另外技术类文章更适合电脑阅读（随时摘录、实验）</p>
<h2 id="精华文章推荐"><a href="#精华文章推荐" class="headerlink" title="精华文章推荐"></a>精华文章推荐</h2><h4 id="国产CPU和Intel、AMD性能PK-从Intel、AMD、海光、鲲鹏920、飞腾2500-等CPU在TPCC、sysbench下的性能对比来分析他们的性能差距，同时分析内存延迟对性能的影响"><a href="#国产CPU和Intel、AMD性能PK-从Intel、AMD、海光、鲲鹏920、飞腾2500-等CPU在TPCC、sysbench下的性能对比来分析他们的性能差距，同时分析内存延迟对性能的影响" class="headerlink" title="国产CPU和Intel、AMD性能PK 从Intel、AMD、海光、鲲鹏920、飞腾2500 等CPU在TPCC、sysbench下的性能对比来分析他们的性能差距，同时分析内存延迟对性能的影响"></a><a href="https://plantegg.github.io/2022/01/13/%E4%B8%8D%E5%90%8CCPU%E6%80%A7%E8%83%BD%E5%A4%A7PK/">国产CPU和Intel、AMD性能PK</a> 从Intel、AMD、海光、鲲鹏920、飞腾2500 等CPU在TPCC、sysbench下的性能对比来分析他们的性能差距，同时分析内存延迟对性能的影响</h4><p><img src="/images/951413iMgBlog/image-20220319115644219.png" alt="image-20220319115644219"></p>
<h4 id="CPU的制造和概念-从最底层的沙子开始用8篇文章来回答关于CPU的各种疑问以及大量的实验对比案例和测试数据来展示了CPU的各种原理，比如多核、超线程、NUMA、睿频、功耗、GPU、大小核再到分支预测、cache-line失效、加锁代价、IPC等各种指标（都有对应的代码和测试数据）。"><a href="#CPU的制造和概念-从最底层的沙子开始用8篇文章来回答关于CPU的各种疑问以及大量的实验对比案例和测试数据来展示了CPU的各种原理，比如多核、超线程、NUMA、睿频、功耗、GPU、大小核再到分支预测、cache-line失效、加锁代价、IPC等各种指标（都有对应的代码和测试数据）。" class="headerlink" title="CPU的制造和概念 从最底层的沙子开始用8篇文章来回答关于CPU的各种疑问以及大量的实验对比案例和测试数据来展示了CPU的各种原理，比如多核、超线程、NUMA、睿频、功耗、GPU、大小核再到分支预测、cache_line失效、加锁代价、IPC等各种指标（都有对应的代码和测试数据）。"></a><a href="https://plantegg.github.io/2021/06/01/CPU的制造和概念/">CPU的制造和概念</a> 从最底层的沙子开始用8篇文章来回答关于CPU的各种疑问以及大量的实验对比案例和测试数据来展示了CPU的各种原理，比如多核、超线程、NUMA、睿频、功耗、GPU、大小核再到分支预测、cache_line失效、加锁代价、IPC等各种指标（都有对应的代码和测试数据）。</h4><p><img src="/images/951413iMgBlog/image-20210802161410524-1011377.png" alt="image-20210802161410524"> </p>
<h4 id="在2010年前后MySQL、PG、Oracle数据库在使用NUMA的时候碰到了性能问题，流传最广的这篇-MySQL-–-The-MySQL-“swap-insanity”-problem-and-the-effects-of-the-NUMA-architecture-http-blog-jcole-us-2010-09-28-mysql-swap-insanity-and-the-numa-architecture-文章描述了性能问题的原因-文章中把原因找错了-以及解决方案：关闭NUMA。-实际这个原因是kernel实现的一个低级bug，这个Bug在2014年修复了https-github-com-torvalds-linux-commit-4f9b16a64753d0bb607454347036dc997fd03b82，但是修复这么多年后仍然以讹传讹，这篇文章希望正本清源、扭转错误的认识。"><a href="#在2010年前后MySQL、PG、Oracle数据库在使用NUMA的时候碰到了性能问题，流传最广的这篇-MySQL-–-The-MySQL-“swap-insanity”-problem-and-the-effects-of-the-NUMA-architecture-http-blog-jcole-us-2010-09-28-mysql-swap-insanity-and-the-numa-architecture-文章描述了性能问题的原因-文章中把原因找错了-以及解决方案：关闭NUMA。-实际这个原因是kernel实现的一个低级bug，这个Bug在2014年修复了https-github-com-torvalds-linux-commit-4f9b16a64753d0bb607454347036dc997fd03b82，但是修复这么多年后仍然以讹传讹，这篇文章希望正本清源、扭转错误的认识。" class="headerlink" title="在2010年前后MySQL、PG、Oracle数据库在使用NUMA的时候碰到了性能问题，流传最广的这篇  MySQL – The MySQL “swap insanity” problem and the effects of the NUMA architecture http://blog.jcole.us/2010/09/28/mysql-swap-insanity-and-the-numa-architecture/ 文章描述了性能问题的原因(文章中把原因找错了)以及解决方案：关闭NUMA。 实际这个原因是kernel实现的一个低级bug，这个Bug在2014年修复了https://github.com/torvalds/linux/commit/4f9b16a64753d0bb607454347036dc997fd03b82，但是修复这么多年后仍然以讹传讹，这篇文章希望正本清源、扭转错误的认识。"></a><a href="https://plantegg.github.io/2021/05/14/%E5%8D%81%E5%B9%B4%E5%90%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%98%E6%98%AF%E4%B8%8D%E6%95%A2%E6%8B%A5%E6%8A%B1NUMA/">在2010年前后MySQL、PG、Oracle数据库在使用NUMA的时候碰到了性能问题，流传最广的这篇  MySQL – The MySQL “swap insanity” problem and the effects of the NUMA architecture http://blog.jcole.us/2010/09/28/mysql-swap-insanity-and-the-numa-architecture/ 文章描述了性能问题的原因(文章中把原因找错了)以及解决方案：关闭NUMA。 实际这个原因是kernel实现的一个低级bug，这个Bug在2014年修复了https://github.com/torvalds/linux/commit/4f9b16a64753d0bb607454347036dc997fd03b82，但是修复这么多年后仍然以讹传讹，这篇文章希望正本清源、扭转错误的认识。</a></h4><p><img src="/images/951413iMgBlog/image-20210517082233798.png" alt="image-20210517082233798"></p>
<h4 id="《Intel-PAUSE指令变化是如何影响自旋锁以及MySQL的性能的》-从一个参数引起的rt抖动定位到OS锁等待再到CPU-Pause指令，以及不同CPU型号对Pause使用cycles不同的影响，最终反馈到应用层面的rt全过程。在MySQL内核开发的时候考虑了Pause，但是没有考虑不同的CPU型号，所以换了CPU型号后性能差异比较大"><a href="#《Intel-PAUSE指令变化是如何影响自旋锁以及MySQL的性能的》-从一个参数引起的rt抖动定位到OS锁等待再到CPU-Pause指令，以及不同CPU型号对Pause使用cycles不同的影响，最终反馈到应用层面的rt全过程。在MySQL内核开发的时候考虑了Pause，但是没有考虑不同的CPU型号，所以换了CPU型号后性能差异比较大" class="headerlink" title="《Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的》 从一个参数引起的rt抖动定位到OS锁等待再到CPU Pause指令，以及不同CPU型号对Pause使用cycles不同的影响，最终反馈到应用层面的rt全过程。在MySQL内核开发的时候考虑了Pause，但是没有考虑不同的CPU型号，所以换了CPU型号后性能差异比较大"></a><a href="https://plantegg.github.io/2019/12/16/Intel%20PAUSE%E6%8C%87%E4%BB%A4%E5%8F%98%E5%8C%96%E6%98%AF%E5%A6%82%E4%BD%95%E5%BD%B1%E5%93%8D%E8%87%AA%E6%97%8B%E9%94%81%E4%BB%A5%E5%8F%8AMySQL%E7%9A%84%E6%80%A7%E8%83%BD%E7%9A%84/">《Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的》 从一个参数引起的rt抖动定位到OS锁等待再到CPU Pause指令，以及不同CPU型号对Pause使用cycles不同的影响，最终反馈到应用层面的rt全过程。在MySQL内核开发的时候考虑了Pause，但是没有考虑不同的CPU型号，所以换了CPU型号后性能差异比较大</a></h4><p><img src="/images/oss/d567449fe52725a9d0b9d4ec9baa372c.png" alt="image.png"></p>
<h4 id="10倍性能提升全过程-在双11的紧张流程下，将系统tps从500优化到5500，从网络到snat、再到Spring和StackTrace，一次全栈性能优化过程的详细记录和分析。"><a href="#10倍性能提升全过程-在双11的紧张流程下，将系统tps从500优化到5500，从网络到snat、再到Spring和StackTrace，一次全栈性能优化过程的详细记录和分析。" class="headerlink" title="10倍性能提升全过程 在双11的紧张流程下，将系统tps从500优化到5500，从网络到snat、再到Spring和StackTrace，一次全栈性能优化过程的详细记录和分析。"></a><a href="https://plantegg.github.io/2018/01/23/10+%E5%80%8D%E6%80%A7%E8%83%BD%E6%8F%90%E5%8D%87%E5%85%A8%E8%BF%87%E7%A8%8B/">10倍性能提升全过程</a> 在双11的紧张流程下，将系统tps从500优化到5500，从网络到snat、再到Spring和StackTrace，一次全栈性能优化过程的详细记录和分析。</h4><p><img src="/images/oss/05703c168e63e96821ea9f921d83712b.png" alt="image.png"></p>
<h4 id="就是要你懂TCP–半连接队列和全连接队列：偶发性的连接reset异常、重启服务后短时间的连接异常，通过一篇文章阐明TCP连接的半连接队列和全连接队大小是怎么影响连接创建的，以及用什么工具来观察队列有没有溢出、连接为什么会RESET"><a href="#就是要你懂TCP–半连接队列和全连接队列：偶发性的连接reset异常、重启服务后短时间的连接异常，通过一篇文章阐明TCP连接的半连接队列和全连接队大小是怎么影响连接创建的，以及用什么工具来观察队列有没有溢出、连接为什么会RESET" class="headerlink" title="就是要你懂TCP–半连接队列和全连接队列：偶发性的连接reset异常、重启服务后短时间的连接异常，通过一篇文章阐明TCP连接的半连接队列和全连接队大小是怎么影响连接创建的，以及用什么工具来观察队列有没有溢出、连接为什么会RESET"></a><a href="https://plantegg.github.io/2017/06/07/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E5%8D%8A%E8%BF%9E%E6%8E%A5%E9%98%9F%E5%88%97%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5%E9%98%9F%E5%88%97/">就是要你懂TCP–半连接队列和全连接队列：偶发性的连接reset异常、重启服务后短时间的连接异常，通过一篇文章阐明TCP连接的半连接队列和全连接队大小是怎么影响连接创建的，以及用什么工具来观察队列有没有溢出、连接为什么会RESET</a></h4><p><img src="/images/oss/1579241362064-807d8378-6c54-4a2c-a888-ff2337df817c.png" alt="image.png" style="zoom:80%;"></p>
<h4 id="就是要你懂TCP–性能和发送接收Buffer的关系：发送窗口大小-Buffer-、接收窗口大小-Buffer-对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响。BDP、RT、带宽对传输速度又是怎么影响的"><a href="#就是要你懂TCP–性能和发送接收Buffer的关系：发送窗口大小-Buffer-、接收窗口大小-Buffer-对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响。BDP、RT、带宽对传输速度又是怎么影响的" class="headerlink" title="就是要你懂TCP–性能和发送接收Buffer的关系：发送窗口大小(Buffer)、接收窗口大小(Buffer)对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响。BDP、RT、带宽对传输速度又是怎么影响的"></a><a href="https://plantegg.github.io/2019/09/28/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E6%80%A7%E8%83%BD%E5%92%8C%E5%8F%91%E9%80%81%E6%8E%A5%E6%94%B6Buffer%E7%9A%84%E5%85%B3%E7%B3%BB/">就是要你懂TCP–性能和发送接收Buffer的关系：发送窗口大小(Buffer)、接收窗口大小(Buffer)对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响。BDP、RT、带宽对传输速度又是怎么影响的</a></h4><p><img src="/images/oss/e177d59ecb886daef5905ed80a84dfd2.png" alt=""></p>
<h4 id="就是要你懂网络–一个网络包的旅程：教科书式地阐述书本中的路由、网关、子网、Mac地址、IP地址是如何一起协作让网络包最终传输到目标机器上。-同时可以跟讲这块的RFC1180比较一下，RFC1180-写的确实很好，清晰简洁，图文并茂，结构逻辑合理，但是对于90-的程序员没有什么卵用，看完几周后就忘得差不多，因为他不是从实践的角度来阐述问题，中间没有很多为什么，所以一般资质的程序员看完当时感觉很好，实际还是不会灵活运用"><a href="#就是要你懂网络–一个网络包的旅程：教科书式地阐述书本中的路由、网关、子网、Mac地址、IP地址是如何一起协作让网络包最终传输到目标机器上。-同时可以跟讲这块的RFC1180比较一下，RFC1180-写的确实很好，清晰简洁，图文并茂，结构逻辑合理，但是对于90-的程序员没有什么卵用，看完几周后就忘得差不多，因为他不是从实践的角度来阐述问题，中间没有很多为什么，所以一般资质的程序员看完当时感觉很好，实际还是不会灵活运用" class="headerlink" title="就是要你懂网络–一个网络包的旅程：教科书式地阐述书本中的路由、网关、子网、Mac地址、IP地址是如何一起协作让网络包最终传输到目标机器上。  同时可以跟讲这块的RFC1180比较一下，RFC1180 写的确实很好，清晰简洁，图文并茂，结构逻辑合理，但是对于90%的程序员没有什么卵用，看完几周后就忘得差不多，因为他不是从实践的角度来阐述问题，中间没有很多为什么，所以一般资质的程序员看完当时感觉很好，实际还是不会灵活运用"></a><a href="https://plantegg.github.io/2019/05/15/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E7%BD%91%E7%BB%9C--%E4%B8%80%E4%B8%AA%E7%BD%91%E7%BB%9C%E5%8C%85%E7%9A%84%E6%97%85%E7%A8%8B/">就是要你懂网络–一个网络包的旅程：教科书式地阐述书本中的路由、网关、子网、Mac地址、IP地址是如何一起协作让网络包最终传输到目标机器上。</a>  同时可以跟讲这块的<a href="https://tools.ietf.org/html/rfc1180" target="_blank" rel="external">RFC1180</a>比较一下，RFC1180 写的确实很好，清晰简洁，图文并茂，结构逻辑合理，但是对于90%的程序员没有什么卵用，看完几周后就忘得差不多，因为他不是从实践的角度来阐述问题，中间没有很多为什么，所以一般资质的程序员看完当时感觉很好，实际还是不会灵活运用</h4><p><img src="/images/oss/8f5d8518c1d92ed68d23218028e3cd11.png" alt=""></p>
<h4 id="从网络路由连通性的原理上来看负载均衡lvs的DR、NAT、FullNAT到底搞了些什么鬼，以及为什么要这么搞，和带来的优缺点：《就是要你懂负载均衡–lvs和转发模式》"><a href="#从网络路由连通性的原理上来看负载均衡lvs的DR、NAT、FullNAT到底搞了些什么鬼，以及为什么要这么搞，和带来的优缺点：《就是要你懂负载均衡–lvs和转发模式》" class="headerlink" title="从网络路由连通性的原理上来看负载均衡lvs的DR、NAT、FullNAT到底搞了些什么鬼，以及为什么要这么搞，和带来的优缺点：《就是要你懂负载均衡–lvs和转发模式》"></a><a href="/2019/06/20/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1--lvs%E5%92%8C%E8%BD%AC%E5%8F%91%E6%A8%A1%E5%BC%8F/">从网络路由连通性的原理上来看负载均衡lvs的DR、NAT、FullNAT到底搞了些什么鬼，以及为什么要这么搞，和带来的优缺点：《就是要你懂负载均衡–lvs和转发模式》</a></h4><p><img src="/images/oss/94d55b926b5bb1573c4cab8353428712.png" alt=""></p>
<h4 id="LVS-20倍的负载不均衡，原来是内核的这个Bug，这个内核bug现在还在，可以稳定重现，有兴趣的话去重现一下，然后对照源代码以及抓包分析一下就清楚了。"><a href="#LVS-20倍的负载不均衡，原来是内核的这个Bug，这个内核bug现在还在，可以稳定重现，有兴趣的话去重现一下，然后对照源代码以及抓包分析一下就清楚了。" class="headerlink" title="LVS 20倍的负载不均衡，原来是内核的这个Bug，这个内核bug现在还在，可以稳定重现，有兴趣的话去重现一下，然后对照源代码以及抓包分析一下就清楚了。"></a><a href="/2019/07/19/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1--%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E5%92%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E5%9D%87%E8%A1%A1/">LVS 20倍的负载不均衡，原来是内核的这个Bug</a>，这个内核bug现在还在，可以稳定重现，有兴趣的话去重现一下，然后对照源代码以及抓包分析一下就清楚了。</h4><h4 id="就是要你懂TCP–握手和挥手，不是你想象中三次握手、四次挥手就理解了TCP，本文从握手的本质–握手都做了什么事情、连接的本质是什么等来阐述握手、挥手的原理"><a href="#就是要你懂TCP–握手和挥手，不是你想象中三次握手、四次挥手就理解了TCP，本文从握手的本质–握手都做了什么事情、连接的本质是什么等来阐述握手、挥手的原理" class="headerlink" title="就是要你懂TCP–握手和挥手，不是你想象中三次握手、四次挥手就理解了TCP，本文从握手的本质–握手都做了什么事情、连接的本质是什么等来阐述握手、挥手的原理"></a><a href="/2017/06/02/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E8%BF%9E%E6%8E%A5%E5%92%8C%E6%8F%A1%E6%89%8B/">就是要你懂TCP–握手和挥手，不是你想象中三次握手、四次挥手就理解了TCP，本文从握手的本质–握手都做了什么事情、连接的本质是什么等来阐述握手、挥手的原理</a></h4><p><img src="/images/oss/6d66dadecb72e11e3e5ab765c6c3ea2e.png" alt=""></p>
<h4 id="nslookup-OK-but-ping-fail–看看老司机是如何解决问题的，解决问题的方法肯定比知识点重要多了，同时透过一个问题怎么样通篇来理解一大块知识，让这块原理真正在你的只是提示中扎根下来"><a href="#nslookup-OK-but-ping-fail–看看老司机是如何解决问题的，解决问题的方法肯定比知识点重要多了，同时透过一个问题怎么样通篇来理解一大块知识，让这块原理真正在你的只是提示中扎根下来" class="headerlink" title="nslookup OK but ping fail–看看老司机是如何解决问题的，解决问题的方法肯定比知识点重要多了，同时透过一个问题怎么样通篇来理解一大块知识，让这块原理真正在你的只是提示中扎根下来"></a><a href="/2019/01/09/nslookup-OK-but-ping-fail/">nslookup OK but ping fail–看看老司机是如何解决问题的，解决问题的方法肯定比知识点重要多了，同时透过一个问题怎么样通篇来理解一大块知识，让这块原理真正在你的只是提示中扎根下来</a></h4><p><img src="/images/oss/ca466bb6430f1149958ceb41b9ffe591.png" alt=""></p>
<h4 id="如何在工作中学习-一篇很土但是很务实可以复制的方法论文章。不要讲举一反三、触类旁通，谁都知道要举一反三、触类旁通，但是为什么我总是不能够举一反三、触类旁通？"><a href="#如何在工作中学习-一篇很土但是很务实可以复制的方法论文章。不要讲举一反三、触类旁通，谁都知道要举一反三、触类旁通，但是为什么我总是不能够举一反三、触类旁通？" class="headerlink" title="如何在工作中学习 一篇很土但是很务实可以复制的方法论文章。不要讲举一反三、触类旁通，谁都知道要举一反三、触类旁通，但是为什么我总是不能够举一反三、触类旁通？"></a><a href="/2018/05/23/%E5%A6%82%E4%BD%95%E5%9C%A8%E5%B7%A5%E4%BD%9C%E4%B8%AD%E5%AD%A6%E4%B9%A0/">如何在工作中学习</a> 一篇很土但是很务实可以复制的方法论文章。不要讲举一反三、触类旁通，谁都知道要举一反三、触类旁通，但是为什么我总是不能够举一反三、触类旁通？</h4><h4 id="举三反一–从理论知识到实际问题的推导-坚决不让思路跑偏，如何从一个理论知识点推断可能的问题"><a href="#举三反一–从理论知识到实际问题的推导-坚决不让思路跑偏，如何从一个理论知识点推断可能的问题" class="headerlink" title="举三反一–从理论知识到实际问题的推导 坚决不让思路跑偏，如何从一个理论知识点推断可能的问题"></a><a href="/2020/11/02/举三反一--从理论知识到实际问题的推导/">举三反一–从理论知识到实际问题的推导</a> 坚决不让思路跑偏，如何从一个理论知识点推断可能的问题</h4><h2 id="性能相关（2015-2018年）"><a href="#性能相关（2015-2018年）" class="headerlink" title="性能相关（2015-2018年）"></a>性能相关（2015-2018年）</h2><h4 id="就是要你懂TCP–半连接队列和全连接队列-偶发性的连接reset异常、重启服务后短时间的连接异常"><a href="#就是要你懂TCP–半连接队列和全连接队列-偶发性的连接reset异常、重启服务后短时间的连接异常" class="headerlink" title="就是要你懂TCP–半连接队列和全连接队列  偶发性的连接reset异常、重启服务后短时间的连接异常"></a><a href="/2017/06/07/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E5%8D%8A%E8%BF%9E%E6%8E%A5%E9%98%9F%E5%88%97%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5%E9%98%9F%E5%88%97/">就是要你懂TCP–半连接队列和全连接队列</a>  偶发性的连接reset异常、重启服务后短时间的连接异常</h4><h4 id="就是要你懂TCP–性能和发送接收Buffer的关系：发送窗口大小-Buffer-、接收窗口大小-Buffer-对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响。BDP、RT、带宽对传输速度又是怎么影响的-发送窗口大小-Buffer-、接收窗口大小-Buffer-对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响"><a href="#就是要你懂TCP–性能和发送接收Buffer的关系：发送窗口大小-Buffer-、接收窗口大小-Buffer-对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响。BDP、RT、带宽对传输速度又是怎么影响的-发送窗口大小-Buffer-、接收窗口大小-Buffer-对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响" class="headerlink" title="就是要你懂TCP–性能和发送接收Buffer的关系：发送窗口大小(Buffer)、接收窗口大小(Buffer)对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响。BDP、RT、带宽对传输速度又是怎么影响的  发送窗口大小(Buffer)、接收窗口大小(Buffer)对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响"></a><a href="/2019/09/28/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E6%80%A7%E8%83%BD%E5%92%8C%E5%8F%91%E9%80%81%E6%8E%A5%E6%94%B6Buffer%E7%9A%84%E5%85%B3%E7%B3%BB/">就是要你懂TCP–性能和发送接收Buffer的关系：发送窗口大小(Buffer)、接收窗口大小(Buffer)对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响。BDP、RT、带宽对传输速度又是怎么影响的</a>  发送窗口大小(Buffer)、接收窗口大小(Buffer)对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响</h4><h4 id="就是要你懂TCP–性能优化大全"><a href="#就是要你懂TCP–性能优化大全" class="headerlink" title="就是要你懂TCP–性能优化大全"></a><a href="/2019/06/21/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%A4%A7%E5%85%A8/">就是要你懂TCP–性能优化大全</a></h4><h4 id="就是要你懂TCP–TCP性能问题-Nagle算法和delay-ack"><a href="#就是要你懂TCP–TCP性能问题-Nagle算法和delay-ack" class="headerlink" title="就是要你懂TCP–TCP性能问题 Nagle算法和delay ack"></a><a href="/2018/06/14/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E6%9C%80%E7%BB%8F%E5%85%B8%E7%9A%84TCP%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98/">就是要你懂TCP–TCP性能问题</a> Nagle算法和delay ack</h4><h4 id="10倍性能提升全过程-在双11的紧张流程下，将系统tps从500优化到5500，从网络到snat、再到Spring和StackTrace，看看一个性能全栈工程师如何在各种工具加持下发现各种问题的。"><a href="#10倍性能提升全过程-在双11的紧张流程下，将系统tps从500优化到5500，从网络到snat、再到Spring和StackTrace，看看一个性能全栈工程师如何在各种工具加持下发现各种问题的。" class="headerlink" title="10倍性能提升全过程 在双11的紧张流程下，将系统tps从500优化到5500，从网络到snat、再到Spring和StackTrace，看看一个性能全栈工程师如何在各种工具加持下发现各种问题的。"></a><a href="/2018/01/23/10+%E5%80%8D%E6%80%A7%E8%83%BD%E6%8F%90%E5%8D%87%E5%85%A8%E8%BF%87%E7%A8%8B/">10倍性能提升全过程</a> 在双11的紧张流程下，将系统tps从500优化到5500，从网络到snat、再到Spring和StackTrace，看看一个性能全栈工程师如何在各种工具加持下发现各种问题的。</h4><h2 id="CPU系列文章（2021年完成）"><a href="#CPU系列文章（2021年完成）" class="headerlink" title="CPU系列文章（2021年完成）"></a>CPU系列文章（2021年完成）</h2><h4 id="CPU的制造和概念"><a href="#CPU的制造和概念" class="headerlink" title="CPU的制造和概念"></a><a href="/2021/06/01/CPU的制造和概念/">CPU的制造和概念</a></h4><h4 id="十年后数据库还是不敢拥抱NUMA？"><a href="#十年后数据库还是不敢拥抱NUMA？" class="headerlink" title="十年后数据库还是不敢拥抱NUMA？"></a><a href="/2021/05/14/十年后数据库还是不敢拥抱NUMA/">十年后数据库还是不敢拥抱NUMA？</a></h4><h4 id="Intel-PAUSE指令变化是如何影响自旋锁以及MySQL的性能的"><a href="#Intel-PAUSE指令变化是如何影响自旋锁以及MySQL的性能的" class="headerlink" title="Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的"></a><a href="/2019/12/16/Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的/">Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的</a></h4><h4 id="Perf-IPC以及CPU性能"><a href="#Perf-IPC以及CPU性能" class="headerlink" title="Perf IPC以及CPU性能"></a><a href="/2021/05/16/Perf IPC以及CPU利用率/">Perf IPC以及CPU性能</a></h4><h4 id="CPU性能和CACHE"><a href="#CPU性能和CACHE" class="headerlink" title="CPU性能和CACHE"></a><a href="https://plantegg.github.io/2021/07/19/CPU性能和CACHE/">CPU性能和CACHE</a></h4><h4 id="CPU-性能和Cache-Line"><a href="#CPU-性能和Cache-Line" class="headerlink" title="CPU 性能和Cache Line"></a><a href="/2021/05/16/CPU Cache Line 和性能/">CPU 性能和Cache Line</a></h4><h4 id="AMD-Zen-CPU-架构-以及-AMD、海光、Intel、鲲鹏的性能对比"><a href="#AMD-Zen-CPU-架构-以及-AMD、海光、Intel、鲲鹏的性能对比" class="headerlink" title="AMD Zen CPU 架构 以及 AMD、海光、Intel、鲲鹏的性能对比"></a><a href="/2021/08/13/AMD_Zen_CPU架构/">AMD Zen CPU 架构 以及 AMD、海光、Intel、鲲鹏的性能对比</a></h4><h4 id="Intel、海光、鲲鹏920、飞腾2500-CPU性能对比"><a href="#Intel、海光、鲲鹏920、飞腾2500-CPU性能对比" class="headerlink" title="Intel、海光、鲲鹏920、飞腾2500 CPU性能对比"></a><a href="/2021/06/18/几款CPU性能对比/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></h4><h2 id="网络相关基础知识（2017年完成）"><a href="#网络相关基础知识（2017年完成）" class="headerlink" title="网络相关基础知识（2017年完成）"></a>网络相关基础知识（2017年完成）</h2><h4 id="就是要你懂网络–一个网络包的旅程"><a href="#就是要你懂网络–一个网络包的旅程" class="headerlink" title="就是要你懂网络–一个网络包的旅程"></a><a href="/2019/05/15/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E7%BD%91%E7%BB%9C--%E4%B8%80%E4%B8%AA%E7%BD%91%E7%BB%9C%E5%8C%85%E7%9A%84%E6%97%85%E7%A8%8B/">就是要你懂网络–一个网络包的旅程</a></h4><h4 id="通过案例来理解MSS、MTU等相关TCP概念"><a href="#通过案例来理解MSS、MTU等相关TCP概念" class="headerlink" title="通过案例来理解MSS、MTU等相关TCP概念"></a><a href="/2018/05/07/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E9%80%9A%E8%BF%87%E6%A1%88%E4%BE%8B%E6%9D%A5%E5%AD%A6%E4%B9%A0MSS%E3%80%81MTU/">通过案例来理解MSS、MTU等相关TCP概念</a></h4><h4 id="就是要你懂TCP–握手和挥手"><a href="#就是要你懂TCP–握手和挥手" class="headerlink" title="就是要你懂TCP–握手和挥手"></a><a href="/2017/06/02/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E8%BF%9E%E6%8E%A5%E5%92%8C%E6%8F%A1%E6%89%8B/">就是要你懂TCP–握手和挥手</a></h4><h4 id="wireshark-dup-ack-issue-and-keepalive"><a href="#wireshark-dup-ack-issue-and-keepalive" class="headerlink" title="wireshark-dup-ack-issue and keepalive"></a><a href="/2017/06/02/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--wireshark-dup-ack-issue/">wireshark-dup-ack-issue and keepalive</a></h4><h4 id="一个没有遵守tcp规则导致的问题"><a href="#一个没有遵守tcp规则导致的问题" class="headerlink" title="一个没有遵守tcp规则导致的问题"></a><a href="/2018/11/26/%E4%B8%80%E4%B8%AA%E6%B2%A1%E6%9C%89%E9%81%B5%E5%AE%88tcp%E8%A7%84%E5%88%99%E5%AF%BC%E8%87%B4%E7%9A%84%E9%97%AE%E9%A2%98/">一个没有遵守tcp规则导致的问题</a></h4><h4 id="kubernetes-service-和-kube-proxy详解"><a href="#kubernetes-service-和-kube-proxy详解" class="headerlink" title="kubernetes service 和 kube-proxy详解"></a><a href="/2020/09/22/kubernetes service 和 kube-proxy详解/">kubernetes service 和 kube-proxy详解</a></h4><h2 id="DNS相关"><a href="#DNS相关" class="headerlink" title="DNS相关"></a>DNS相关</h2><h4 id="就是要你懂DNS–一文搞懂域名解析相关问题"><a href="#就是要你懂DNS–一文搞懂域名解析相关问题" class="headerlink" title="就是要你懂DNS–一文搞懂域名解析相关问题"></a><a href="/2019/06/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/">就是要你懂DNS–一文搞懂域名解析相关问题</a></h4><h4 id="nslookup-OK-but-ping-fail"><a href="#nslookup-OK-but-ping-fail" class="headerlink" title="nslookup OK but ping fail"></a><a href="/2019/01/09/nslookup-OK-but-ping-fail/">nslookup OK but ping fail</a></h4><h4 id="Docker中的DNS解析过程"><a href="#Docker中的DNS解析过程" class="headerlink" title="Docker中的DNS解析过程"></a><a href="/2019/01/12/Docker%E4%B8%AD%E7%9A%84DNS%E8%A7%A3%E6%9E%90%E8%BF%87%E7%A8%8B/">Docker中的DNS解析过程</a></h4><h4 id="windows7的wifi总是报DNS域名异常无法上网"><a href="#windows7的wifi总是报DNS域名异常无法上网" class="headerlink" title="windows7的wifi总是报DNS域名异常无法上网"></a><a href="/2019/01/10/windows7%E7%9A%84wifi%E6%80%BB%E6%98%AF%E6%8A%A5DNS%E5%9F%9F%E5%90%8D%E5%BC%82%E5%B8%B8%E6%97%A0%E6%B3%95%E4%B8%8A%E7%BD%91/">windows7的wifi总是报DNS域名异常无法上网</a></h4><h2 id="LVS-负载均衡"><a href="#LVS-负载均衡" class="headerlink" title="LVS 负载均衡"></a>LVS 负载均衡</h2><h4 id="就是要你懂负载均衡–lvs和转发模式"><a href="#就是要你懂负载均衡–lvs和转发模式" class="headerlink" title="就是要你懂负载均衡–lvs和转发模式"></a><a href="/2019/06/20/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1--lvs%E5%92%8C%E8%BD%AC%E5%8F%91%E6%A8%A1%E5%BC%8F/">就是要你懂负载均衡–lvs和转发模式</a></h4><h4 id="就是要你懂负载均衡–负载均衡调度算法和为什么不均衡"><a href="#就是要你懂负载均衡–负载均衡调度算法和为什么不均衡" class="headerlink" title="就是要你懂负载均衡–负载均衡调度算法和为什么不均衡"></a><a href="/2019/07/19/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1--%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E5%92%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E5%9D%87%E8%A1%A1/">就是要你懂负载均衡–负载均衡调度算法和为什么不均衡</a></h4><h2 id="网络工具"><a href="#网络工具" class="headerlink" title="网络工具"></a>网络工具</h2><h4 id="就是要你懂Unix-Socket-进行抓包解析"><a href="#就是要你懂Unix-Socket-进行抓包解析" class="headerlink" title="就是要你懂Unix Socket 进行抓包解析"></a><a href="/2018/01/01/%E9%80%9A%E8%BF%87tcpdump%E5%AF%B9Unix%20Socket%20%E8%BF%9B%E8%A1%8C%E6%8A%93%E5%8C%85%E8%A7%A3%E6%9E%90/">就是要你懂Unix Socket 进行抓包解析</a></h4><h4 id="就是要你懂网络监控–ss用法大全"><a href="#就是要你懂网络监控–ss用法大全" class="headerlink" title="就是要你懂网络监控–ss用法大全"></a><a href="/2016/10/12/ss%E7%94%A8%E6%B3%95%E5%A4%A7%E5%85%A8/">就是要你懂网络监控–ss用法大全</a></h4><h4 id="就是要你懂抓包–WireShark之命令行版tshark"><a href="#就是要你懂抓包–WireShark之命令行版tshark" class="headerlink" title="就是要你懂抓包–WireShark之命令行版tshark"></a><a href="/2019/06/21/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E6%8A%93%E5%8C%85--WireShark%E4%B9%8B%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%89%88tshark/">就是要你懂抓包–WireShark之命令行版tshark</a></h4><h4 id="netstat-timer-keepalive-explain"><a href="#netstat-timer-keepalive-explain" class="headerlink" title="netstat timer keepalive explain"></a><a href="/2017/08/28/netstat%20%E7%AD%89%E7%BD%91%E7%BB%9C%E5%B7%A5%E5%85%B7/">netstat timer keepalive explain</a></h4><h4 id="Git-HTTP-Proxy-and-SSH-Proxy"><a href="#Git-HTTP-Proxy-and-SSH-Proxy" class="headerlink" title="Git HTTP Proxy and SSH Proxy"></a><a href="/2018/03/14/%E5%A6%82%E4%BD%95%E8%AE%BE%E7%BD%AEgit%20Proxy/">Git HTTP Proxy and SSH Proxy</a></h4>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2022/05/05/Netty和Disruptor的cache_line对齐实践/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/05/05/Netty和Disruptor的cache_line对齐实践/" itemprop="url">Netty和Disruptor的cache_line对齐实践</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-05-05T18:20:03+08:00">
                2022-05-05
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CPU/" itemprop="url" rel="index">
                    <span itemprop="name">CPU</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Netty和Disruptor的cache-line对齐实践"><a href="#Netty和Disruptor的cache-line对齐实践" class="headerlink" title="Netty和Disruptor的cache_line对齐实践"></a>Netty和Disruptor的cache_line对齐实践</h1><p>原理先看这篇：<a href="https://plantegg.github.io/2021/05/16/CPU_Cache_Line%E5%92%8C%E6%80%A7%E8%83%BD/">CPU 性能和Cache Line</a></p>
<p>写这篇文章的起因是这个 <a href="https://mp.weixin.qq.com/s/vkCskOVSpzxt3Umzc_GYrQ" target="_blank" rel="external">记一次 Netty PR 的提交</a>，然后我去看了下这次提交，发现Netty的这部分代码有问题、这次提交也有问题</p>
<h2 id="什么是-cache-line"><a href="#什么是-cache-line" class="headerlink" title="什么是 cache_line"></a>什么是 cache_line</h2><p>CPU从内存中读取数据的时候是一次读一个cache_line到 cache中以提升效率，一般情况下cache_line的大小是64 byte，也就是每次读取64byte到CPU cache中，按照热点逻辑这个cache line中的数据大概率会被访问到。</p>
<h3 id="cache-失效"><a href="#cache-失效" class="headerlink" title="cache 失效"></a>cache 失效</h3><p>假设CPU的两个核 A 和 B, 都在各自本地 Cache Line 里有同一个变量1的拷贝时，此时该 Cache Line 处于 Shared 状态。当 核A 在本地修改了变量2，除去把本地变量所属的 Cache Line 置为 Modified 状态以外，还必须在另一个 核B 读另一个变量2前，对该变量所在的 B 处理器本地 Cache Line 发起 Invaidate 操作，标记 B 处理器的那条 Cache Line 为 Invalidate 状态。随后，若处理器 B 在对变量做读写操作时，如果遇到这个标记为 Invalidate 的状态的 Cache Line，即会引发 Cache Miss，从而将内存中最新的数据拷贝到 Cache Line 里，然后处理器 B 再对此 Cache Line 对变量做读写操作。</p>
<p>上面这个过程也叫false-share, 即伪共享，因为变量1、2不是真的关联共享，本来变量1失效不应该导致变量2失效，但是因为cache line机制的存在导致 变量2也失效了，所以这里变量1、2叫false-share</p>
<h2 id="Disruptor中对cache-line的使用"><a href="#Disruptor中对cache-line的使用" class="headerlink" title="Disruptor中对cache_line的使用"></a>Disruptor中对cache_line的使用</h2><p>Disruptor中为了保护下面的那几个final 成员变量，前后都加了 p1-p7就是为了避免这4个final成员不要和别的变量放到同一个cache line中。</p>
<p>重点留意下面代码中的p1-p7这几个没有用的long变量，实际使用来占位，占住实际变量前后的位置，这样避免这些变量被其他变量的修改而失效。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">abstract class RingBufferPad</div><div class="line">&#123;</div><div class="line">    protected long p1, p2, p3, p4, p5, p6, p7;</div><div class="line">&#125;</div><div class="line">  </div><div class="line">abstract class RingBufferFields&lt;E&gt; extends RingBufferPad</div><div class="line">&#123;</div><div class="line">    ......    </div><div class="line">    private final long indexMask;</div><div class="line">    private final Object[] entries;</div><div class="line">    protected final int bufferSize;</div><div class="line">    protected final Sequencer sequencer;</div><div class="line">    ......    </div><div class="line">&#125;</div><div class="line"></div><div class="line">public final class RingBuffer&lt;E&gt; extends RingBufferFields&lt;E&gt; implements Cursored, EventSequencer&lt;E&gt;, EventSink&lt;E&gt;</div><div class="line">&#123;</div><div class="line">    ......    </div><div class="line">    protected long p1, p2, p3, p4, p5, p6, p7;</div><div class="line">    ......</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>结果如下图所示绿色部分很好地被保护起来一定是独占一个cache line，本来绿色部分都是final，也就是你理解成只读的，不会更改了，这样不会因为共享cache line的变量被修改导致他们所在的cache失效（完全没必要）</p>
<p><img src="/images/951413iMgBlog/1620984677390-81694fd0-0323-4052-98d1-32be39a02248-4505908.png" alt="image.png"></p>
<p>队列大部分时候都是空的（head挨着tail），也就导致head 和 tail在一个cache line中，读和写会造成没必要的cache ping-pong，一般可以通过将head 和 tail 中间填充其它内容来实现错开到不同的cache line中</p>
<p><img src="/images/951413iMgBlog/1577093636588-6b58c36c-1617-4f2c-aba9-156c52972689-1744256.png" alt="image"></p>
<p>数组(RingBuffer)基本能保证元素在内存中是连续的，但是Queue（链表）就不一定了，连续的话更利于CPU cache</p>
<h2 id="Netty中cache-line的对齐"><a href="#Netty中cache-line的对齐" class="headerlink" title="Netty中cache line的对齐"></a>Netty中cache line的对齐</h2><p><a href="https://github.com/arthur-zhang/netty/blob/e8250372cafe4cf5435a1dbc4c8e400072fb9791/common/src/main/java/io/netty/util/internal/InternalThreadLocalMap.java" target="_blank" rel="external">注意下图12行</a>的代码，重点也请注意下11行的注释</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">// String-related thread-locals</div><div class="line">private StringBuilder stringBuilder;</div><div class="line">private Map&lt;Charset, CharsetEncoder&gt; charsetEncoderCache;</div><div class="line">private Map&lt;Charset, CharsetDecoder&gt; charsetDecoderCache;</div><div class="line"></div><div class="line">// ArrayList-related thread-locals</div><div class="line">private ArrayList&lt;Object&gt; arrayList;</div><div class="line"></div><div class="line">private BitSet cleanerFlags;</div><div class="line"></div><div class="line">/** @deprecated These padding fields will be removed in the future. */</div><div class="line">public long rp1, rp2, rp3, rp4, rp5, rp6, rp7, rp8;</div><div class="line"></div><div class="line">static &#123;</div><div class="line">    STRING_BUILDER_INITIAL_SIZE =</div><div class="line">            SystemPropertyUtil.getInt(&quot;io.netty.threadLocalMap.stringBuilder.initialSize&quot;, 1024);</div><div class="line">    logger.debug(&quot;-Dio.netty.threadLocalMap.stringBuilder.initialSize: &#123;&#125;&quot;, STRING_BUILDER_INITIAL_SIZE);</div><div class="line"></div><div class="line">    STRING_BUILDER_MAX_SIZE = SystemPropertyUtil.getInt(&quot;io.netty.threadLocalMap.stringBuilder.maxSize&quot;, 1024 * 4);</div><div class="line">    logger.debug(&quot;-Dio.netty.threadLocalMap.stringBuilder.maxSize: &#123;&#125;&quot;, STRING_BUILDER_MAX_SIZE);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>一看这里也和Disruptor一样想保护某个变量尽量少失效，可是这个实现我看不出来想要保护哪个变量，因为这种保护办法只对齐了一边，还有一边是和别的变量共享cache line。</p>
<p>另外这个代码之前是9个long rp来对齐，这个<a href="https://github.com/netty/netty/pull/12309" target="_blank" rel="external">PR</a>改成了8个，9个就实在是迷惑了（9个long占72bytes了）对齐也是64bytes就好了</p>
<p>还是按照11行注释所说去掉这个对齐的rp吧，要不明确要保护哪些变量，前后夹击真正保护起来，并且做好对比测试</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Netty的这段代码纸上谈兵更多一点，Donald E. Knuth 告诉我们不要提前优化</p>
<h2 id="系列文章"><a href="#系列文章" class="headerlink" title="系列文章"></a>系列文章</h2><p><a href="/2021/06/01/CPU的制造和概念/">CPU的制造和概念</a></p>
<p><a href="/2021/05/16/Perf IPC以及CPU利用率/">Perf IPC以及CPU性能</a></p>
<p><a href="/2021/05/16/CPU Cache Line 和性能/">CPU 性能和Cache Line</a></p>
<p><a href="/2021/05/14/十年后数据库还是不敢拥抱NUMA/">十年后数据库还是不敢拥抱NUMA？</a></p>
<p><a href="/2019/12/16/Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的/">Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的</a></p>
<p><a href="/2021/06/18/几款CPU性能对比/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></p>
<p><a href="/2021/03/07/一次海光物理机资源竞争压测的记录/">一次海光物理机资源竞争压测的记录</a></p>
<p><a href="/2021/05/15/飞腾ARM芯片-FT2500的性能测试/">飞腾ARM芯片(FT2500)的性能测试</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2022/03/15/记一次听风扇声音来定位性能/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/03/15/记一次听风扇声音来定位性能/" itemprop="url">听风扇声音来定位性能瓶颈</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-03-15T17:30:03+08:00">
                2022-03-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CPU/" itemprop="url" rel="index">
                    <span itemprop="name">CPU</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="记一次听风扇声音来定位性能瓶颈"><a href="#记一次听风扇声音来定位性能瓶颈" class="headerlink" title="记一次听风扇声音来定位性能瓶颈"></a>记一次听风扇声音来定位性能瓶颈</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在一次POC测试过程中，测试机构提供了两台Intel压力机来压我们的集群</p>
<ul>
<li>压力机1：两路共72core intel 5XXX系列 CPU，主频2.2GHz， 128G内存</li>
<li>压力机2：四路共196core intel 8XXX系列 CPU，主频2.5GHz， 256G内存 （8系列比5系列 CPU的性能要好、要贵）</li>
</ul>
<p>从CPU硬件指标来看压力机2都是碾压压力机1，但是实际测试是压力机2只能跑到接近压力机1的能力，两台机器CPU基本都跑满，并且都是压测进程消耗了90%以上的CPU，内核态消耗不到5%CPU</p>
<p>所以接下来需要在调试我们集群性能前先把测试机优化好，才能把压力打上来。</p>
<h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>测试机构提供的机器上没有任何工具来评估CPU性能，也无法安装，只能<strong>仔细听196core机器的CPU风扇声音更小，说明196core的CPU出工不出力，大概是流水线在频繁地Stall</strong>（不管你信不信反正我是信的）</p>
<p>进一步分析，首先看到 业务消耗了90%以上的CPU，内核态消耗不到5%CPU，两台机器都是这样，这说明 196core 只跑出了 72core的水平，一定是CPU效率出了问题，top看到的CPU占用率不完全是全力在运算，其实cpu 流水线stall也是占用CPU的。</p>
<p>这个分析理论请参考我的文章<a href="https://plantegg.github.io/2021/05/16/Perf%20IPC%E4%BB%A5%E5%8F%8ACPU%E5%88%A9%E7%94%A8%E7%8E%87/">《Perf IPC以及CPU性能》</a></p>
<h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>通过stream测试读写内存的带宽和时延，得到如下数据：</p>
<p>72core机器，  本路时延1.1，跨路时延1.4，因为是2路所以有50%的概率跨路，性能下降30%</p>
<p>196core机器，本路时延1.2，跨路时延1.85，因为是4路所以有75%的概率跨路，性能下降50%</p>
<p>从以上测试数据可以明显看到虽然196core机器拥有更强的单核能力以及更多的核数，但是因为访问内存太慢严重拖累了CPU运算能力，导致大部分时间CPU都在等待内存，这里CPU和内存的速度差了2个数量级，所以内存延时才是整体的瓶颈。</p>
<p>测试数据和方法请参考我的文章<a href="https://plantegg.github.io/2021/06/18/%E5%87%A0%E6%AC%BECPU%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94/">《AMD Zen CPU 架构以及不同CPU性能大PK》</a></p>
<p>有了这个数据心里非常有底问题在哪里了，但是还要想清楚怎么解释给测试机构他们才会信服，因为第一次解释他们直接说不可能，怎么会196core打不过72core呢，再说从来没有集群是测试机构196core压力机打不满的，这台压力机用了几年从来没有人说过这个问题 :(</p>
<h2 id="内存信息"><a href="#内存信息" class="headerlink" title="内存信息"></a>内存信息</h2><p>接下来需要拿到更详细的硬件信息来说服测试机构了。</p>
<p>通过dmidecode 获取两台机器内存的速度，分别是2100（196core） VS 2900（72core），同时系统也吐出了内存延时分别是 0.5ns VS 0.3 ns，这两个时间对比很直观，普通人也能看懂。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div></pre></td><td class="code"><pre><div class="line">//以下硬件信息是从家里机器上获取，并非测试机构提供的机器，测试机构提供的机器不让拍照和采集</div><div class="line">#dmidecode -t memory</div><div class="line"># dmidecode 3.2</div><div class="line">Getting SMBIOS data from sysfs.</div><div class="line">SMBIOS 3.2.1 present.</div><div class="line"># SMBIOS implementations newer than version 3.2.0 are not</div><div class="line"># fully supported by this version of dmidecode.</div><div class="line"></div><div class="line">Handle 0x0033, DMI type 16, 23 bytes </div><div class="line">Physical Memory Array</div><div class="line">	Location: System Board Or Motherboard</div><div class="line">	Use: System Memory</div><div class="line">	Error Correction Type: Multi-bit ECC</div><div class="line">	Maximum Capacity: 2 TB  //最大支持2T</div><div class="line">	Error Information Handle: 0x0032</div><div class="line">	Number Of Devices: 32   //32个插槽</div><div class="line">	</div><div class="line">	Handle 0x0041, DMI type 17, 84 bytes</div><div class="line">Memory Device</div><div class="line">	Array Handle: 0x0033</div><div class="line">	Error Information Handle: 0x0040</div><div class="line">	Total Width: 72 bits</div><div class="line">	Data Width: 64 bits</div><div class="line">	Size: 32 GB</div><div class="line">	Form Factor: DIMM</div><div class="line">	Set: None</div><div class="line">	Locator: CPU0_DIMMA0</div><div class="line">	Bank Locator: P0 CHANNEL A</div><div class="line">	Type: DDR4</div><div class="line">	Type Detail: Synchronous Registered (Buffered)</div><div class="line">	Speed: 2933 MT/s                    //dmmi 内存插槽支持最大速度 ?</div><div class="line">	Manufacturer: SK Hynix</div><div class="line">	Serial Number: 220F9EC0</div><div class="line">	Asset Tag: Not Specified</div><div class="line">	Part Number: HMAA4GR7AJR8N-WM</div><div class="line">	Rank: 2</div><div class="line">	Configured Memory Speed: 2100 MT/s  //内存实际运行速度</div><div class="line">	Minimum Voltage: 1.2 V</div><div class="line">	Maximum Voltage: 1.2 V</div><div class="line">	Configured Voltage: 1.2 V</div><div class="line">	Memory Technology: DRAM</div><div class="line">	Memory Operating Mode Capability: Volatile memory</div><div class="line">	Module Manufacturer ID: Bank 1, Hex 0xAD</div><div class="line">	Non-Volatile Size: None</div><div class="line">	Volatile Size: 32 GB</div><div class="line">	</div><div class="line">	#lshw</div><div class="line">	*-bank:19  //主板插槽槽位</div><div class="line">             description: DIMM DDR4 Synchronous Registered (Buffered) 2933 MHz (0.3 ns) </div><div class="line">             product: HMAA4GR7AJR8N-WM</div><div class="line">             vendor: SK Hynix</div><div class="line">             physical id: 13</div><div class="line">             serial: 220F9F63</div><div class="line">             slot: CPU1_DIMMB0</div><div class="line">             size: 32GiB  //实际所插内存大小</div><div class="line">             width: 64 bits</div><div class="line">             clock: 2933MHz (0.3ns)</div></pre></td></tr></table></figure>
<blockquote>
<p>In <code>dmidecode</code>’s output for memory, “Speed” is the highest speed supported by the DIMM, as determined by <a href="https://en.wikipedia.org/wiki/JEDEC" target="_blank" rel="external">JEDEC</a> SPD information. “Configured Clock Speed” is the speed at which it is currently running (as set up during boot).</p>
</blockquote>
<h2 id="最终的运行方案"><a href="#最终的运行方案" class="headerlink" title="最终的运行方案"></a>最终的运行方案</h2><p>给196core的机器换上新的2933 MHz (0.3 ns)的内存条，速度一下子就上去了。</p>
<p>然后在196core的机器上起4个压力进程，每个进程分担25%的压力，避免跨路访问内存导致时延从1.2掉到1.8，实际测试也是只用196core中的48core性能和用全部196core是一样的，所以这里一定要起多个进程做内存亲和性绑定，充分使用全部196core。</p>
<p><strong>最终整机196core机器的打压能力达到了原来的3.6倍左右。</strong></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>程序员要保护好听力，关键时刻可能会用上 :)</p>
<p>你说196core机器用了这么强的CPU但是为什么搭配那么差的内存以及主板，我也不知道，大概是有人拿回扣吧。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2022/01/25/ssd_san和sas磁盘性能比较/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/01/25/ssd_san和sas磁盘性能比较/" itemprop="url">ssd/san/sas/磁盘/光纤性能比较</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-01-25T17:30:03+08:00">
                2022-01-25
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/performance/" itemprop="url" rel="index">
                    <span itemprop="name">performance</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="ssd-san-sas-磁盘-光纤-RAID性能比较"><a href="#ssd-san-sas-磁盘-光纤-RAID性能比较" class="headerlink" title="ssd/san/sas/磁盘/光纤/RAID性能比较"></a>ssd/san/sas/磁盘/光纤/RAID性能比较</h1><p>本文汇总HDD、SSD、SAN、LVM、软RAID等一些性能数据</p>
<h2 id="性能比较"><a href="#性能比较" class="headerlink" title="性能比较"></a>性能比较</h2><p>正好有机会用到一个san存储设备，跑了一把性能数据，记录一下</p>
<p><img src="/images/oss/d57a004c846e193126ca01398e394319.png" alt="image.png"></p>
<p>所使用的测试命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">fio -ioengine=libaio -bs=4k -direct=1 -thread -rw=randwrite -size=1000G -filename=/data/fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div></pre></td></tr></table></figure>
<p>ssd（Solid State Drive）和san的比较是在同一台物理机上，所以排除了其他因素的干扰。</p>
<p>简要的结论： </p>
<ul>
<li><p>本地ssd性能最好、sas机械盘(RAID10)性能最差</p>
</li>
<li><p>san存储走特定的光纤网络，不是走tcp的san（至少从网卡看不到san的流量），性能居中</p>
</li>
<li><p>从rt来看 ssd:san:sas 大概是 1:3:15</p>
</li>
<li><p>san比本地sas机械盘性能要好，这也许取决于san的网络传输性能和san存储中的设备（比如用的ssd而不是机械盘）</p>
</li>
</ul>
<h2 id="NVMe-SSD-和-HDD的性能比较"><a href="#NVMe-SSD-和-HDD的性能比较" class="headerlink" title="NVMe SSD 和 HDD的性能比较"></a>NVMe SSD 和 HDD的性能比较</h2><p><img src="/images/oss/d64a0f78ebf471ac69d447ecb46d90f1.png" alt="image.png"></p>
<p>表中性能差异比上面测试还要大，SSD 的随机 IO 延迟比传统硬盘快百倍以上，一般在微妙级别；IO 带宽也高很多倍，可以达到每秒几个 GB；随机 IOPS 更是快了上千倍，可以达到几十万。</p>
<p><strong>HDD只有一个磁头，并发没有意义，但是SSD支持高并发写入读取。SSD没有磁头、不需要旋转，所以随机读取和顺序读取基本没有差别。</strong></p>
<p><img src="/images/951413iMgBlog/1ab661ee2d3a71f54bae3ecf62982e7e.png" alt="img"></p>
<p>从上图可以看出如果是随机读写HDD性能极差，但是如果是顺序读写HDD和SDD、内存差异就不那么大了。</p>
<h2 id="磁盘类型查看"><a href="#磁盘类型查看" class="headerlink" title="磁盘类型查看"></a>磁盘类型查看</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">$cat /sys/block/vda/queue/rotational</div><div class="line">1  //1表示旋转，非ssd，0表示ssd</div><div class="line"></div><div class="line">或者</div><div class="line">lsblk -d -o name,rota,size,label,uuid</div></pre></td></tr></table></figure>
<h2 id="fio测试"><a href="#fio测试" class="headerlink" title="fio测试"></a>fio测试</h2><p>以下是两块测试的SSD磁盘测试前的基本情况</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line">/dev/sda	240.06G  SSD_SATA  //sata</div><div class="line">/dev/sfd0n1	3200G	 SSD_PCIE  //PCIE</div><div class="line"></div><div class="line">Filesystem      Size  Used Avail Use% Mounted on</div><div class="line">/dev/sda3        49G   29G   18G  63% / </div><div class="line">/dev/sfdv0n1p1  2.0T  803G  1.3T  40% /data</div><div class="line"></div><div class="line"># cat /sys/block/sda/queue/rotational </div><div class="line">0</div><div class="line"># cat /sys/block/sfdv0n1/queue/rotational </div><div class="line">0</div><div class="line"></div><div class="line">#测试前的iostat状态</div><div class="line"># iostat -d sfdv0n1 sda3 1 -x</div><div class="line">Linux 3.10.0-957.el7.x86_64 (nu4d01142.sqa.nu8) 	2021年02月23日 	_x86_64_	(104 CPU)</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">sda3              0.00    10.67    1.24   18.78     7.82   220.69    22.83     0.03    1.64    1.39    1.66   0.08   0.17</div><div class="line">sfdv0n1           0.00     0.21    9.91  841.42   128.15  8237.10    19.65     0.93    0.04    0.25    0.04   1.05  89.52</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">sda3              0.00    15.00    0.00   17.00     0.00   136.00    16.00     0.03    2.00    0.00    2.00   1.29   2.20</div><div class="line">sfdv0n1           0.00     0.00    0.00 11158.00     0.00 54448.00     9.76     1.03    0.02    0.00    0.02   0.09 100.00</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">sda3              0.00     5.00    0.00   18.00     0.00   104.00    11.56     0.01    0.61    0.00    0.61   0.61   1.10</div><div class="line">sfdv0n1           0.00     0.00    0.00 10970.00     0.00 53216.00     9.70     1.02    0.03    0.00    0.03   0.09 100.10</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">sda3              0.00     0.00    0.00   24.00     0.00   100.00     8.33     0.01    0.58    0.00    0.58   0.08   0.20</div><div class="line">sfdv0n1           0.00     0.00    0.00 11206.00     0.00 54476.00     9.72     1.03    0.03    0.00    0.03   0.09  99.90</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">sda3              0.00    14.00    0.00   21.00     0.00   148.00    14.10     0.01    0.48    0.00    0.48   0.33   0.70</div><div class="line">sfdv0n1           0.00     0.00    0.00 10071.00     0.00 49028.00     9.74     1.02    0.03    0.00    0.03   0.10  99.80</div></pre></td></tr></table></figure>
<h3 id="NVMe-SSD测试数据"><a href="#NVMe-SSD测试数据" class="headerlink" title="NVMe SSD测试数据"></a>NVMe SSD测试数据</h3><p>对一块ssd进行如下测试(挂载在/data 目录)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line">fio -ioengine=libaio -bs=4k -direct=1 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div><div class="line">EBS 4K randwrite test: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</div><div class="line">fio-3.7</div><div class="line">Starting 1 thread</div><div class="line">EBS 4K randwrite test: Laying out IO file (1 file / 16384MiB)</div><div class="line">Jobs: 1 (f=1): [w(1)][100.0%][r=0KiB/s,w=63.8MiB/s][r=0,w=16.3k IOPS][eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=258871: Tue Feb 23 14:12:23 2021</div><div class="line">  write: IOPS=18.9k, BW=74.0MiB/s (77.6MB/s)(4441MiB/60001msec)</div><div class="line">    slat (usec): min=4, max=6154, avg=48.82, stdev=56.38</div><div class="line">    clat (nsec): min=1049, max=12360k, avg=3326362.62, stdev=920683.43</div><div class="line">     lat (usec): min=68, max=12414, avg=3375.52, stdev=928.97</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[ 1483],  5.00th=[ 1811], 10.00th=[ 2114], 20.00th=[ 2376],</div><div class="line">     | 30.00th=[ 2704], 40.00th=[ 3130], 50.00th=[ 3523], 60.00th=[ 3785],</div><div class="line">     | 70.00th=[ 3949], 80.00th=[ 4080], 90.00th=[ 4293], 95.00th=[ 4490],</div><div class="line">     | 99.00th=[ 5604], 99.50th=[ 5997], 99.90th=[ 7111], 99.95th=[ 7832],</div><div class="line">     | 99.99th=[ 9634]</div><div class="line">   bw (  KiB/s): min=61024, max=118256, per=99.98%, avg=75779.58, stdev=12747.95, samples=120</div><div class="line">   iops        : min=15256, max=29564, avg=18944.88, stdev=3186.97, samples=120</div><div class="line">  lat (usec)   : 2=0.01%, 100=0.01%, 250=0.01%, 500=0.01%, 750=0.02%</div><div class="line">  lat (usec)   : 1000=0.06%</div><div class="line">  lat (msec)   : 2=7.40%, 4=66.19%, 10=26.32%, 20=0.01%</div><div class="line">  cpu          : usr=5.23%, sys=46.71%, ctx=846953, majf=0, minf=6</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued rwts: total=0,1136905,0,0 short=0,0,0,0 dropped=0,0,0,0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">  WRITE: bw=74.0MiB/s (77.6MB/s), 74.0MiB/s-74.0MiB/s (77.6MB/s-77.6MB/s), io=4441MiB (4657MB), run=60001-60001msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">  sfdv0n1: ios=0/1821771, merge=0/7335, ticks=0/39708, in_queue=78295, util=100.00%</div></pre></td></tr></table></figure>
<p>如上测试iops为：18944，测试期间的iostat，测试中一直有mysql在导入数据，所以测试开始前util就已经100%了，并且w/s到了13K左右</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"># iostat -d sfdv0n1 3 -x</div><div class="line">Linux 3.10.0-957.el7.x86_64 (nu4d01142.sqa.nu8) 	2021年02月23日 	_x86_64_	(104 CPU)</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">sfdv0n1           0.00     0.18    3.45  769.17   102.83  7885.16    20.68     0.93    0.04    0.26    0.04   1.16  89.46</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">sfdv0n1           0.00     0.00    0.00 13168.67     0.00 66244.00    10.06     1.05    0.03    0.00    0.03   0.08 100.10</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">sfdv0n1           0.00     0.00    0.00 12822.67     0.00 65542.67    10.22     1.04    0.02    0.00    0.02   0.08 100.07</div><div class="line"></div><div class="line">//增加压力</div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">sfdv0n1           0.00     0.00    0.00 27348.33     0.00 214928.00    15.72     1.27    0.02    0.00    0.02   0.04 100.17</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">sfdv0n1           0.00     1.00    0.00 32661.67     0.00 271660.00    16.63     1.32    0.02    0.00    0.02   0.03 100.37</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">sfdv0n1           0.00     0.00    0.00 31645.00     0.00 265988.00    16.81     1.33    0.02    0.00    0.02   0.03 100.37</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">sfdv0n1           0.00   574.00    0.00 31961.67     0.00 271094.67    16.96     1.36    0.02    0.00    0.02   0.03 100.13</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">sfdv0n1           0.00     0.00    0.00 27656.33     0.00 224586.67    16.24     1.28    0.02    0.00    0.02   0.04 100.37</div></pre></td></tr></table></figure>
<p>从iostat看出，测试开始前util已经100%（因为ssd，util失去参考意义），w/s 13K左右，压力跑起来后w/s能到30K，svctm、await均保持稳定</p>
<p>如下测试中direct=1和direct=0的write avg iops分别为42K、16K</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div></pre></td><td class="code"><pre><div class="line"># fio -ioengine=libaio -bs=4k -direct=1 -buffered=0 -thread -rw=randrw -rwmixread=70 -size=16G -filename=/data/fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60 </div><div class="line">EBS 4K randwrite test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</div><div class="line">fio-3.7</div><div class="line">Starting 1 thread</div><div class="line">Jobs: 1 (f=1): [m(1)][100.0%][r=507MiB/s,w=216MiB/s][r=130k,w=55.2k IOPS][eta 00m:00s] </div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=415921: Tue Feb 23 14:34:33 2021</div><div class="line">   read: IOPS=99.8k, BW=390MiB/s (409MB/s)(11.2GiB/29432msec)</div><div class="line">    slat (nsec): min=1043, max=917837, avg=4273.86, stdev=3792.17</div><div class="line">    clat (usec): min=2, max=4313, avg=459.80, stdev=239.61</div><div class="line">     lat (usec): min=4, max=4328, avg=464.16, stdev=241.81</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[  251],  5.00th=[  277], 10.00th=[  289], 20.00th=[  310],</div><div class="line">     | 30.00th=[  326], 40.00th=[  343], 50.00th=[  363], 60.00th=[  400],</div><div class="line">     | 70.00th=[  502], 80.00th=[  603], 90.00th=[  750], 95.00th=[  881],</div><div class="line">     | 99.00th=[ 1172], 99.50th=[ 1401], 99.90th=[ 3032], 99.95th=[ 3359],</div><div class="line">     | 99.99th=[ 3785]</div><div class="line">   bw (  KiB/s): min=182520, max=574856, per=99.24%, avg=395975.64, stdev=119541.78, samples=58</div><div class="line">   iops        : min=45630, max=143714, avg=98993.90, stdev=29885.42, samples=58</div><div class="line">  write: IOPS=42.8k, BW=167MiB/s (175MB/s)(4915MiB/29432msec)</div><div class="line">    slat (usec): min=3, max=263, avg= 9.34, stdev= 4.35</div><div class="line">    clat (usec): min=14, max=2057, avg=402.26, stdev=140.67</div><div class="line">     lat (usec): min=19, max=2070, avg=411.72, stdev=142.67</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[  237],  5.00th=[  281], 10.00th=[  293], 20.00th=[  314],</div><div class="line">     | 30.00th=[  330], 40.00th=[  343], 50.00th=[  359], 60.00th=[  379],</div><div class="line">     | 70.00th=[  404], 80.00th=[  457], 90.00th=[  586], 95.00th=[  717],</div><div class="line">     | 99.00th=[  930], 99.50th=[ 1004], 99.90th=[ 1254], 99.95th=[ 1385],</div><div class="line">     | 99.99th=[ 1532]</div><div class="line">   bw (  KiB/s): min=78104, max=244408, per=99.22%, avg=169671.52, stdev=51142.10, samples=58</div><div class="line">   iops        : min=19526, max=61102, avg=42417.86, stdev=12785.51, samples=58</div><div class="line">  lat (usec)   : 4=0.01%, 10=0.01%, 20=0.01%, 50=0.02%, 100=0.04%</div><div class="line">  lat (usec)   : 250=1.02%, 500=73.32%, 750=17.28%, 1000=6.30%</div><div class="line">  lat (msec)   : 2=1.83%, 4=0.19%, 10=0.01%</div><div class="line">  cpu          : usr=15.84%, sys=83.31%, ctx=13765, majf=0, minf=7</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued rwts: total=2936000,1258304,0,0 short=0,0,0,0 dropped=0,0,0,0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">   READ: bw=390MiB/s (409MB/s), 390MiB/s-390MiB/s (409MB/s-409MB/s), io=11.2GiB (12.0GB), run=29432-29432msec</div><div class="line">  WRITE: bw=167MiB/s (175MB/s), 167MiB/s-167MiB/s (175MB/s-175MB/s), io=4915MiB (5154MB), run=29432-29432msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">  sfdv0n1: ios=795793/1618341, merge=0/11, ticks=218710/27721, in_queue=264935, util=100.00%</div><div class="line">[root@nu4d01142 data]# </div><div class="line">[root@nu4d01142 data]# fio -ioengine=libaio -bs=4k -direct=0 -buffered=0 -thread -rw=randrw -rwmixread=70 -size=6G -filename=/data/fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60 </div><div class="line">EBS 4K randwrite test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</div><div class="line">fio-3.7</div><div class="line">Starting 1 thread</div><div class="line">Jobs: 1 (f=1): [m(1)][100.0%][r=124MiB/s,w=53.5MiB/s][r=31.7k,w=13.7k IOPS][eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=437523: Tue Feb 23 14:37:54 2021</div><div class="line">   read: IOPS=38.6k, BW=151MiB/s (158MB/s)(4300MiB/28550msec)</div><div class="line">    slat (nsec): min=1205, max=1826.7k, avg=13253.36, stdev=17173.87</div><div class="line">    clat (nsec): min=236, max=5816.8k, avg=1135969.25, stdev=337142.34</div><div class="line">     lat (nsec): min=1977, max=5831.2k, avg=1149404.84, stdev=341232.87</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[  461],  5.00th=[  627], 10.00th=[  717], 20.00th=[  840],</div><div class="line">     | 30.00th=[  938], 40.00th=[ 1029], 50.00th=[ 1123], 60.00th=[ 1221],</div><div class="line">     | 70.00th=[ 1319], 80.00th=[ 1434], 90.00th=[ 1565], 95.00th=[ 1680],</div><div class="line">     | 99.00th=[ 1893], 99.50th=[ 1975], 99.90th=[ 2671], 99.95th=[ 3261],</div><div class="line">     | 99.99th=[ 3851]</div><div class="line">   bw (  KiB/s): min=119304, max=216648, per=100.00%, avg=154273.07, stdev=29925.10, samples=57</div><div class="line">   iops        : min=29826, max=54162, avg=38568.25, stdev=7481.30, samples=57</div><div class="line">  write: IOPS=16.5k, BW=64.6MiB/s (67.7MB/s)(1844MiB/28550msec)</div><div class="line">    slat (usec): min=3, max=3565, avg=21.07, stdev=22.23</div><div class="line">    clat (usec): min=14, max=9983, avg=1164.21, stdev=459.66</div><div class="line">     lat (usec): min=21, max=10011, avg=1185.57, stdev=463.28</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[  498],  5.00th=[  619], 10.00th=[  709], 20.00th=[  832],</div><div class="line">     | 30.00th=[  930], 40.00th=[ 1020], 50.00th=[ 1123], 60.00th=[ 1237],</div><div class="line">     | 70.00th=[ 1336], 80.00th=[ 1450], 90.00th=[ 1598], 95.00th=[ 1713],</div><div class="line">     | 99.00th=[ 2311], 99.50th=[ 3851], 99.90th=[ 5932], 99.95th=[ 6456],</div><div class="line">     | 99.99th=[ 7701]</div><div class="line">   bw (  KiB/s): min=50800, max=92328, per=100.00%, avg=66128.47, stdev=12890.64, samples=57</div><div class="line">   iops        : min=12700, max=23082, avg=16532.07, stdev=3222.66, samples=57</div><div class="line">  lat (nsec)   : 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.01%</div><div class="line">  lat (usec)   : 2=0.01%, 4=0.01%, 10=0.01%, 20=0.02%, 50=0.03%</div><div class="line">  lat (usec)   : 100=0.04%, 250=0.18%, 500=1.01%, 750=11.05%, 1000=25.02%</div><div class="line">  lat (msec)   : 2=61.87%, 4=0.62%, 10=0.14%</div><div class="line">  cpu          : usr=10.87%, sys=61.98%, ctx=218415, majf=0, minf=7</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued rwts: total=1100924,471940,0,0 short=0,0,0,0 dropped=0,0,0,0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">   READ: bw=151MiB/s (158MB/s), 151MiB/s-151MiB/s (158MB/s-158MB/s), io=4300MiB (4509MB), run=28550-28550msec</div><div class="line">  WRITE: bw=64.6MiB/s (67.7MB/s), 64.6MiB/s-64.6MiB/s (67.7MB/s-67.7MB/s), io=1844MiB (1933MB), run=28550-28550msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">  sfdv0n1: ios=536103/822037, merge=0/1442, ticks=66507/17141, in_queue=99429, util=100.00%</div></pre></td></tr></table></figure>
<h3 id="SATA-SSD测试数据"><a href="#SATA-SSD测试数据" class="headerlink" title="SATA SSD测试数据"></a>SATA SSD测试数据</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"># cat /sys/block/sda/queue/rotational </div><div class="line">0</div><div class="line"># lsblk -d -o name,rota</div><div class="line">NAME     ROTA</div><div class="line">sda         0</div><div class="line">sfdv0n1     0</div></pre></td></tr></table></figure>
<p>-direct=0 -buffered=0读写iops分别为15.8K、6.8K 比ssd差了不少（都是direct=0），如果direct、buffered都是1的话，ESSD性能很差，读写iops分别为4312、1852</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div></pre></td><td class="code"><pre><div class="line"># fio -ioengine=libaio -bs=4k -direct=0 -buffered=0 -thread -rw=randrw -rwmixread=70 -size=2G -filename=/var/lib/docker/fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60 </div><div class="line">EBS 4K randwrite test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</div><div class="line">fio-3.7</div><div class="line">Starting 1 thread</div><div class="line">EBS 4K randwrite test: Laying out IO file (1 file / 2048MiB)</div><div class="line">Jobs: 1 (f=1): [m(1)][100.0%][r=68.7MiB/s,w=29.7MiB/s][r=17.6k,w=7594 IOPS][eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=13261: Tue Feb 23 14:42:41 2021</div><div class="line">   read: IOPS=15.8k, BW=61.8MiB/s (64.8MB/s)(1432MiB/23172msec)</div><div class="line">    slat (nsec): min=1266, max=7261.0k, avg=7101.88, stdev=20655.54</div><div class="line">    clat (usec): min=167, max=27670, avg=2832.68, stdev=1786.18</div><div class="line">     lat (usec): min=175, max=27674, avg=2839.93, stdev=1784.42</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[  437],  5.00th=[  668], 10.00th=[  873], 20.00th=[  988],</div><div class="line">     | 30.00th=[ 1401], 40.00th=[ 2442], 50.00th=[ 2835], 60.00th=[ 3195],</div><div class="line">     | 70.00th=[ 3523], 80.00th=[ 4047], 90.00th=[ 5014], 95.00th=[ 5866],</div><div class="line">     | 99.00th=[ 8160], 99.50th=[ 9372], 99.90th=[13829], 99.95th=[15008],</div><div class="line">     | 99.99th=[23725]</div><div class="line">   bw (  KiB/s): min=44183, max=149440, per=99.28%, avg=62836.17, stdev=26590.84, samples=46</div><div class="line">   iops        : min=11045, max=37360, avg=15709.02, stdev=6647.72, samples=46</div><div class="line">  write: IOPS=6803, BW=26.6MiB/s (27.9MB/s)(616MiB/23172msec)</div><div class="line">    slat (nsec): min=1566, max=11474k, avg=8460.17, stdev=38221.51</div><div class="line">    clat (usec): min=77, max=24047, avg=2789.68, stdev=2042.55</div><div class="line">     lat (usec): min=80, max=24054, avg=2798.29, stdev=2040.85</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[  265],  5.00th=[  433], 10.00th=[  635], 20.00th=[  840],</div><div class="line">     | 30.00th=[  979], 40.00th=[ 2212], 50.00th=[ 2671], 60.00th=[ 3130],</div><div class="line">     | 70.00th=[ 3523], 80.00th=[ 4228], 90.00th=[ 5342], 95.00th=[ 6456],</div><div class="line">     | 99.00th=[ 9241], 99.50th=[10421], 99.90th=[13960], 99.95th=[15533],</div><div class="line">     | 99.99th=[23725]</div><div class="line">   bw (  KiB/s): min=18435, max=63112, per=99.26%, avg=27012.57, stdev=11299.42, samples=46</div><div class="line">   iops        : min= 4608, max=15778, avg=6753.11, stdev=2824.87, samples=46</div><div class="line">  lat (usec)   : 100=0.01%, 250=0.23%, 500=3.14%, 750=5.46%, 1000=15.27%</div><div class="line">  lat (msec)   : 2=11.47%, 4=43.09%, 10=20.88%, 20=0.44%, 50=0.01%</div><div class="line">  cpu          : usr=3.53%, sys=18.08%, ctx=47448, majf=0, minf=6</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued rwts: total=366638,157650,0,0 short=0,0,0,0 dropped=0,0,0,0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">   READ: bw=61.8MiB/s (64.8MB/s), 61.8MiB/s-61.8MiB/s (64.8MB/s-64.8MB/s), io=1432MiB (1502MB), run=23172-23172msec</div><div class="line">  WRITE: bw=26.6MiB/s (27.9MB/s), 26.6MiB/s-26.6MiB/s (27.9MB/s-27.9MB/s), io=616MiB (646MB), run=23172-23172msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">  sda: ios=359202/155123, merge=299/377, ticks=946305/407820, in_queue=1354596, util=99.61%</div><div class="line">  </div><div class="line"># fio -ioengine=libaio -bs=4k -direct=1 -buffered=0 -thread -rw=randrw -rwmixread=70 -size=2G -filename=/var/lib/docker/fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60 </div><div class="line">EBS 4K randwrite test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</div><div class="line">fio-3.7</div><div class="line">Starting 1 thread</div><div class="line">Jobs: 1 (f=1): [m(1)][95.5%][r=57.8MiB/s,w=25.7MiB/s][r=14.8k,w=6568 IOPS][eta 00m:01s] </div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=26167: Tue Feb 23 14:44:40 2021</div><div class="line">   read: IOPS=16.9k, BW=65.9MiB/s (69.1MB/s)(1432MiB/21730msec)</div><div class="line">    slat (nsec): min=1312, max=4454.2k, avg=8489.99, stdev=15763.97</div><div class="line">    clat (usec): min=201, max=18856, avg=2679.38, stdev=1720.02</div><div class="line">     lat (usec): min=206, max=18860, avg=2688.03, stdev=1717.19</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[  635],  5.00th=[  832], 10.00th=[  914], 20.00th=[  971],</div><div class="line">     | 30.00th=[ 1090], 40.00th=[ 2114], 50.00th=[ 2704], 60.00th=[ 3064],</div><div class="line">     | 70.00th=[ 3392], 80.00th=[ 3851], 90.00th=[ 4817], 95.00th=[ 5735],</div><div class="line">     | 99.00th=[ 7767], 99.50th=[ 8979], 99.90th=[13698], 99.95th=[15139],</div><div class="line">     | 99.99th=[16581]</div><div class="line">   bw (  KiB/s): min=45168, max=127528, per=100.00%, avg=67625.19, stdev=26620.82, samples=43</div><div class="line">   iops        : min=11292, max=31882, avg=16906.28, stdev=6655.20, samples=43</div><div class="line">  write: IOPS=7254, BW=28.3MiB/s (29.7MB/s)(616MiB/21730msec)</div><div class="line">    slat (nsec): min=1749, max=3412.2k, avg=9816.22, stdev=14501.05</div><div class="line">    clat (usec): min=97, max=23473, avg=2556.02, stdev=1980.53</div><div class="line">     lat (usec): min=107, max=23477, avg=2566.01, stdev=1977.65</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[  277],  5.00th=[  486], 10.00th=[  693], 20.00th=[  824],</div><div class="line">     | 30.00th=[  881], 40.00th=[ 1205], 50.00th=[ 2442], 60.00th=[ 2868],</div><div class="line">     | 70.00th=[ 3326], 80.00th=[ 3949], 90.00th=[ 5080], 95.00th=[ 6128],</div><div class="line">     | 99.00th=[ 8717], 99.50th=[10159], 99.90th=[14484], 99.95th=[15926],</div><div class="line">     | 99.99th=[18744]</div><div class="line">   bw (  KiB/s): min=19360, max=55040, per=100.00%, avg=29064.05, stdev=11373.59, samples=43</div><div class="line">   iops        : min= 4840, max=13760, avg=7266.00, stdev=2843.41, samples=43</div><div class="line">  lat (usec)   : 100=0.01%, 250=0.17%, 500=1.66%, 750=3.74%, 1000=22.57%</div><div class="line">  lat (msec)   : 2=12.66%, 4=40.62%, 10=18.20%, 20=0.38%, 50=0.01%</div><div class="line">  cpu          : usr=4.17%, sys=22.27%, ctx=14314, majf=0, minf=7</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued rwts: total=366638,157650,0,0 short=0,0,0,0 dropped=0,0,0,0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">   READ: bw=65.9MiB/s (69.1MB/s), 65.9MiB/s-65.9MiB/s (69.1MB/s-69.1MB/s), io=1432MiB (1502MB), run=21730-21730msec</div><div class="line">  WRITE: bw=28.3MiB/s (29.7MB/s), 28.3MiB/s-28.3MiB/s (29.7MB/s-29.7MB/s), io=616MiB (646MB), run=21730-21730msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">  sda: ios=364744/157621, merge=779/473, ticks=851759/352008, in_queue=1204024, util=99.61%</div><div class="line"></div><div class="line"># fio -ioengine=libaio -bs=4k -direct=1 -buffered=1 -thread -rw=randrw -rwmixread=70 -size=2G -filename=/var/lib/docker/fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60 </div><div class="line">EBS 4K randwrite test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</div><div class="line">fio-3.7</div><div class="line">Starting 1 thread</div><div class="line">Jobs: 1 (f=1): [m(1)][100.0%][r=15.9MiB/s,w=7308KiB/s][r=4081,w=1827 IOPS][eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=31560: Tue Feb 23 14:46:10 2021</div><div class="line">   read: IOPS=4312, BW=16.8MiB/s (17.7MB/s)(1011MiB/60001msec)</div><div class="line">    slat (usec): min=63, max=14320, avg=216.76, stdev=430.61</div><div class="line">    clat (usec): min=5, max=778861, avg=10254.92, stdev=22345.40</div><div class="line">     lat (usec): min=1900, max=782277, avg=10472.16, stdev=22657.06</div><div class="line">    clat percentiles (msec):</div><div class="line">     |  1.00th=[    6],  5.00th=[    6], 10.00th=[    6], 20.00th=[    7],</div><div class="line">     | 30.00th=[    7], 40.00th=[    7], 50.00th=[    7], 60.00th=[    7],</div><div class="line">     | 70.00th=[    8], 80.00th=[    8], 90.00th=[    8], 95.00th=[   11],</div><div class="line">     | 99.00th=[  107], 99.50th=[  113], 99.90th=[  132], 99.95th=[  197],</div><div class="line">     | 99.99th=[  760]</div><div class="line">   bw (  KiB/s): min=  168, max=29784, per=100.00%, avg=17390.92, stdev=10932.90, samples=119</div><div class="line">   iops        : min=   42, max= 7446, avg=4347.71, stdev=2733.21, samples=119</div><div class="line">  write: IOPS=1852, BW=7410KiB/s (7588kB/s)(434MiB/60001msec)</div><div class="line">    slat (usec): min=3, max=666432, avg=23.59, stdev=2745.39</div><div class="line">    clat (msec): min=3, max=781, avg=10.14, stdev=20.50</div><div class="line">     lat (msec): min=3, max=781, avg=10.16, stdev=20.72</div><div class="line">    clat percentiles (msec):</div><div class="line">     |  1.00th=[    6],  5.00th=[    6], 10.00th=[    6], 20.00th=[    7],</div><div class="line">     | 30.00th=[    7], 40.00th=[    7], 50.00th=[    7], 60.00th=[    7],</div><div class="line">     | 70.00th=[    7], 80.00th=[    8], 90.00th=[    8], 95.00th=[   11],</div><div class="line">     | 99.00th=[  107], 99.50th=[  113], 99.90th=[  131], 99.95th=[  157],</div><div class="line">     | 99.99th=[  760]</div><div class="line">   bw (  KiB/s): min=   80, max=12328, per=100.00%, avg=7469.53, stdev=4696.69, samples=119</div><div class="line">   iops        : min=   20, max= 3082, avg=1867.34, stdev=1174.19, samples=119</div><div class="line">  lat (usec)   : 10=0.01%</div><div class="line">  lat (msec)   : 2=0.01%, 4=0.01%, 10=94.64%, 20=1.78%, 50=0.11%</div><div class="line">  lat (msec)   : 100=1.80%, 250=1.63%, 500=0.01%, 750=0.02%, 1000=0.01%</div><div class="line">  cpu          : usr=2.51%, sys=10.98%, ctx=260210, majf=0, minf=7</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued rwts: total=258768,111147,0,0 short=0,0,0,0 dropped=0,0,0,0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">   READ: bw=16.8MiB/s (17.7MB/s), 16.8MiB/s-16.8MiB/s (17.7MB/s-17.7MB/s), io=1011MiB (1060MB), run=60001-60001msec</div><div class="line">  WRITE: bw=7410KiB/s (7588kB/s), 7410KiB/s-7410KiB/s (7588kB/s-7588kB/s), io=434MiB (455MB), run=60001-60001msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">  sda: ios=258717/89376, merge=0/735, ticks=52540/564186, in_queue=616999, util=90.07%</div></pre></td></tr></table></figure>
<h3 id="ESSD磁盘测试数据"><a href="#ESSD磁盘测试数据" class="headerlink" title="ESSD磁盘测试数据"></a>ESSD磁盘测试数据</h3><p>这是一块虚拟的阿里云网络盘，不能算完整意义的SSD（承诺IOPS 4200），数据仅供参考，磁盘概况：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">$df -lh</div><div class="line">Filesystem      Size  Used Avail Use% Mounted on</div><div class="line">/dev/vda1        99G   30G   65G  32% /</div><div class="line"></div><div class="line">$cat /sys/block/vda/queue/rotational</div><div class="line">1</div></pre></td></tr></table></figure>
<p>测试数据：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div></pre></td><td class="code"><pre><div class="line">$fio -ioengine=libaio -bs=4k -direct=1 -buffered=1  -thread -rw=randrw  -size=4G -filename=/home/admin/fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div><div class="line">EBS 4K randwrite test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</div><div class="line">fio-3.1</div><div class="line">Starting 1 thread</div><div class="line">Jobs: 1 (f=1): [m(1)][100.0%][r=10.8MiB/s,w=11.2MiB/s][r=2757,w=2876 IOPS][eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=25641: Tue Feb 23 16:35:19 2021</div><div class="line">   read: IOPS=2136, BW=8545KiB/s (8750kB/s)(501MiB/60001msec)</div><div class="line">    slat (usec): min=190, max=830992, avg=457.20, stdev=3088.80</div><div class="line">    clat (nsec): min=1792, max=1721.3M, avg=14657528.60, stdev=63188988.75</div><div class="line">     lat (usec): min=344, max=1751.1k, avg=15115.20, stdev=65165.80</div><div class="line">    clat percentiles (msec):</div><div class="line">     |  1.00th=[    8],  5.00th=[    9], 10.00th=[    9], 20.00th=[   10],</div><div class="line">     | 30.00th=[   10], 40.00th=[   11], 50.00th=[   11], 60.00th=[   11],</div><div class="line">     | 70.00th=[   12], 80.00th=[   12], 90.00th=[   13], 95.00th=[   14],</div><div class="line">     | 99.00th=[   17], 99.50th=[   53], 99.90th=[ 1028], 99.95th=[ 1167],</div><div class="line">     | 99.99th=[ 1653]</div><div class="line">   bw (  KiB/s): min=   56, max=12648, per=100.00%, avg=8598.92, stdev=5289.40, samples=118</div><div class="line">   iops        : min=   14, max= 3162, avg=2149.73, stdev=1322.35, samples=118</div><div class="line">  write: IOPS=2137, BW=8548KiB/s (8753kB/s)(501MiB/60001msec)</div><div class="line">    slat (usec): min=2, max=181, avg= 6.67, stdev= 7.22</div><div class="line">    clat (usec): min=628, max=1721.1k, avg=14825.32, stdev=65017.66</div><div class="line">     lat (usec): min=636, max=1721.1k, avg=14832.10, stdev=65018.10</div><div class="line">    clat percentiles (msec):</div><div class="line">     |  1.00th=[    8],  5.00th=[    9], 10.00th=[    9], 20.00th=[   10],</div><div class="line">     | 30.00th=[   10], 40.00th=[   11], 50.00th=[   11], 60.00th=[   11],</div><div class="line">     | 70.00th=[   12], 80.00th=[   12], 90.00th=[   13], 95.00th=[   14],</div><div class="line">     | 99.00th=[   17], 99.50th=[   53], 99.90th=[ 1045], 99.95th=[ 1200],</div><div class="line">     | 99.99th=[ 1687]</div><div class="line">   bw (  KiB/s): min=   72, max=13304, per=100.00%, avg=8602.99, stdev=5296.31, samples=118</div><div class="line">   iops        : min=   18, max= 3326, avg=2150.75, stdev=1324.08, samples=118</div><div class="line">  lat (usec)   : 2=0.01%, 500=0.01%, 750=0.01%</div><div class="line">  lat (msec)   : 2=0.01%, 4=0.01%, 10=37.85%, 20=61.53%, 50=0.10%</div><div class="line">  lat (msec)   : 100=0.06%, 250=0.03%, 500=0.01%, 750=0.03%, 1000=0.25%</div><div class="line">  lat (msec)   : 2000=0.14%</div><div class="line">  cpu          : usr=0.70%, sys=4.01%, ctx=135029, majf=0, minf=4</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued rwt: total=128180,128223,0, short=0,0,0, dropped=0,0,0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">   READ: bw=8545KiB/s (8750kB/s), 8545KiB/s-8545KiB/s (8750kB/s-8750kB/s), io=501MiB (525MB), run=60001-60001msec</div><div class="line">  WRITE: bw=8548KiB/s (8753kB/s), 8548KiB/s-8548KiB/s (8753kB/s-8753kB/s), io=501MiB (525MB), run=60001-60001msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">  vda: ios=127922/87337, merge=0/237, ticks=55122/4269885, in_queue=2209125, util=94.29%</div><div class="line"></div><div class="line">$fio -ioengine=libaio -bs=4k -direct=1 -buffered=0  -thread -rw=randrw  -size=4G -filename=/home/admin/fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div><div class="line">EBS 4K randwrite test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</div><div class="line">fio-3.1</div><div class="line">Starting 1 thread</div><div class="line">Jobs: 1 (f=1): [m(1)][100.0%][r=9680KiB/s,w=9712KiB/s][r=2420,w=2428 IOPS][eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=25375: Tue Feb 23 16:33:03 2021</div><div class="line">   read: IOPS=2462, BW=9849KiB/s (10.1MB/s)(577MiB/60011msec)</div><div class="line">    slat (nsec): min=1558, max=10663k, avg=5900.28, stdev=46286.64</div><div class="line">    clat (usec): min=290, max=93493, avg=13054.57, stdev=4301.89</div><div class="line">     lat (usec): min=332, max=93497, avg=13060.60, stdev=4301.68</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[ 1844],  5.00th=[10159], 10.00th=[10290], 20.00th=[10421],</div><div class="line">     | 30.00th=[10552], 40.00th=[10552], 50.00th=[10683], 60.00th=[10814],</div><div class="line">     | 70.00th=[18482], 80.00th=[19006], 90.00th=[19006], 95.00th=[19268],</div><div class="line">     | 99.00th=[19530], 99.50th=[19792], 99.90th=[29492], 99.95th=[30278],</div><div class="line">     | 99.99th=[43779]</div><div class="line">   bw (  KiB/s): min= 9128, max=30392, per=100.00%, avg=9850.12, stdev=1902.00, samples=120</div><div class="line">   iops        : min= 2282, max= 7598, avg=2462.52, stdev=475.50, samples=120</div><div class="line">  write: IOPS=2465, BW=9864KiB/s (10.1MB/s)(578MiB/60011msec)</div><div class="line">    slat (usec): min=2, max=10586, avg= 6.92, stdev=67.34</div><div class="line">    clat (usec): min=240, max=69922, avg=12902.33, stdev=4307.92</div><div class="line">     lat (usec): min=244, max=69927, avg=12909.37, stdev=4307.03</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[ 1729],  5.00th=[10159], 10.00th=[10290], 20.00th=[10290],</div><div class="line">     | 30.00th=[10421], 40.00th=[10421], 50.00th=[10552], 60.00th=[10683],</div><div class="line">     | 70.00th=[18220], 80.00th=[18744], 90.00th=[19006], 95.00th=[19006],</div><div class="line">     | 99.00th=[19268], 99.50th=[19530], 99.90th=[21103], 99.95th=[35390],</div><div class="line">     | 99.99th=[50594]</div><div class="line">   bw (  KiB/s): min= 8496, max=31352, per=100.00%, avg=9862.92, stdev=1991.48, samples=120</div><div class="line">   iops        : min= 2124, max= 7838, avg=2465.72, stdev=497.87, samples=120</div><div class="line">  lat (usec)   : 250=0.01%, 500=0.03%, 750=0.02%, 1000=0.02%</div><div class="line">  lat (msec)   : 2=1.70%, 4=0.41%, 10=1.25%, 20=96.22%, 50=0.34%</div><div class="line">  lat (msec)   : 100=0.01%</div><div class="line">  cpu          : usr=0.89%, sys=4.09%, ctx=206337, majf=0, minf=4</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued rwt: total=147768,147981,0, short=0,0,0, dropped=0,0,0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">   READ: bw=9849KiB/s (10.1MB/s), 9849KiB/s-9849KiB/s (10.1MB/s-10.1MB/s), io=577MiB (605MB), run=60011-60011msec</div><div class="line">  WRITE: bw=9864KiB/s (10.1MB/s), 9864KiB/s-9864KiB/s (10.1MB/s-10.1MB/s), io=578MiB (606MB), run=60011-60011msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">  vda: ios=147515/148154, merge=0/231, ticks=1922378/1915751, in_queue=3780605, util=98.46%</div><div class="line">  </div><div class="line">$fio -ioengine=libaio -bs=4k -direct=0 -buffered=1  -thread -rw=randrw  -size=4G -filename=/home/admin/fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div><div class="line">EBS 4K randwrite test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</div><div class="line">fio-3.1</div><div class="line">Starting 1 thread</div><div class="line">Jobs: 1 (f=1): [m(1)][100.0%][r=132KiB/s,w=148KiB/s][r=33,w=37 IOPS][eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=25892: Tue Feb 23 16:37:41 2021</div><div class="line">   read: IOPS=1987, BW=7949KiB/s (8140kB/s)(467MiB/60150msec)</div><div class="line">    slat (usec): min=192, max=599873, avg=479.26, stdev=2917.52</div><div class="line">    clat (usec): min=15, max=1975.6k, avg=16004.22, stdev=76024.60</div><div class="line">     lat (msec): min=5, max=2005, avg=16.48, stdev=78.00</div><div class="line">    clat percentiles (msec):</div><div class="line">     |  1.00th=[    8],  5.00th=[    9], 10.00th=[    9], 20.00th=[   10],</div><div class="line">     | 30.00th=[   10], 40.00th=[   11], 50.00th=[   11], 60.00th=[   11],</div><div class="line">     | 70.00th=[   12], 80.00th=[   12], 90.00th=[   13], 95.00th=[   14],</div><div class="line">     | 99.00th=[   19], 99.50th=[  317], 99.90th=[ 1133], 99.95th=[ 1435],</div><div class="line">     | 99.99th=[ 1871]</div><div class="line">   bw (  KiB/s): min=   32, max=12672, per=100.00%, avg=8034.08, stdev=5399.63, samples=119</div><div class="line">   iops        : min=    8, max= 3168, avg=2008.52, stdev=1349.91, samples=119</div><div class="line">  write: IOPS=1984, BW=7937KiB/s (8127kB/s)(466MiB/60150msec)</div><div class="line">    slat (usec): min=2, max=839634, avg=18.39, stdev=2747.10</div><div class="line">    clat (msec): min=5, max=1975, avg=15.64, stdev=73.06</div><div class="line">     lat (msec): min=5, max=1975, avg=15.66, stdev=73.28</div><div class="line">    clat percentiles (msec):</div><div class="line">     |  1.00th=[    8],  5.00th=[    9], 10.00th=[    9], 20.00th=[   10],</div><div class="line">     | 30.00th=[   10], 40.00th=[   11], 50.00th=[   11], 60.00th=[   11],</div><div class="line">     | 70.00th=[   12], 80.00th=[   12], 90.00th=[   13], 95.00th=[   14],</div><div class="line">     | 99.00th=[   18], 99.50th=[  153], 99.90th=[ 1116], 99.95th=[ 1435],</div><div class="line">     | 99.99th=[ 1921]</div><div class="line">   bw (  KiB/s): min=   24, max=13160, per=100.00%, avg=8021.18, stdev=5405.12, samples=119</div><div class="line">   iops        : min=    6, max= 3290, avg=2005.29, stdev=1351.28, samples=119</div><div class="line">  lat (usec)   : 20=0.01%</div><div class="line">  lat (msec)   : 10=36.51%, 20=62.63%, 50=0.21%, 100=0.12%, 250=0.05%</div><div class="line">  lat (msec)   : 500=0.02%, 750=0.02%, 1000=0.19%, 2000=0.26%</div><div class="line">  cpu          : usr=0.62%, sys=4.04%, ctx=125974, majf=0, minf=3</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued rwt: total=119533,119347,0, short=0,0,0, dropped=0,0,0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">   READ: bw=7949KiB/s (8140kB/s), 7949KiB/s-7949KiB/s (8140kB/s-8140kB/s), io=467MiB (490MB), run=60150-60150msec</div><div class="line">  WRITE: bw=7937KiB/s (8127kB/s), 7937KiB/s-7937KiB/s (8127kB/s-8127kB/s), io=466MiB (489MB), run=60150-60150msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">  vda: ios=119533/108186, merge=0/214, ticks=54093/4937255, in_queue=2525052, util=93.99%</div><div class="line">  </div><div class="line">$fio -ioengine=libaio -bs=4k -direct=0 -buffered=0  -thread -rw=randrw  -size=4G -filename=/home/admin/fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div><div class="line">EBS 4K randwrite test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</div><div class="line">fio-3.1</div><div class="line">Starting 1 thread</div><div class="line">Jobs: 1 (f=1): [m(1)][100.0%][r=9644KiB/s,w=9792KiB/s][r=2411,w=2448 IOPS][eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=26139: Tue Feb 23 16:39:43 2021</div><div class="line">   read: IOPS=2455, BW=9823KiB/s (10.1MB/s)(576MiB/60015msec)</div><div class="line">    slat (nsec): min=1619, max=18282k, avg=5882.81, stdev=71214.52</div><div class="line">    clat (usec): min=281, max=64630, avg=13055.68, stdev=4233.17</div><div class="line">     lat (usec): min=323, max=64636, avg=13061.69, stdev=4232.79</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[ 2040],  5.00th=[10290], 10.00th=[10421], 20.00th=[10421],</div><div class="line">     | 30.00th=[10552], 40.00th=[10552], 50.00th=[10683], 60.00th=[10814],</div><div class="line">     | 70.00th=[18220], 80.00th=[19006], 90.00th=[19006], 95.00th=[19268],</div><div class="line">     | 99.00th=[19530], 99.50th=[20055], 99.90th=[28967], 99.95th=[29754],</div><div class="line">     | 99.99th=[30540]</div><div class="line">   bw (  KiB/s): min= 8776, max=27648, per=100.00%, avg=9824.29, stdev=1655.78, samples=120</div><div class="line">   iops        : min= 2194, max= 6912, avg=2456.05, stdev=413.95, samples=120</div><div class="line">  write: IOPS=2458, BW=9835KiB/s (10.1MB/s)(576MiB/60015msec)</div><div class="line">    slat (usec): min=2, max=10681, avg= 6.79, stdev=71.30</div><div class="line">    clat (usec): min=221, max=70411, avg=12909.50, stdev=4312.40</div><div class="line">     lat (usec): min=225, max=70414, avg=12916.40, stdev=4312.05</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[ 1909],  5.00th=[10159], 10.00th=[10290], 20.00th=[10290],</div><div class="line">     | 30.00th=[10421], 40.00th=[10421], 50.00th=[10552], 60.00th=[10683],</div><div class="line">     | 70.00th=[18220], 80.00th=[18744], 90.00th=[19006], 95.00th=[19006],</div><div class="line">     | 99.00th=[19268], 99.50th=[19530], 99.90th=[28705], 99.95th=[40109],</div><div class="line">     | 99.99th=[60031]</div><div class="line">   bw (  KiB/s): min= 8568, max=28544, per=100.00%, avg=9836.03, stdev=1737.29, samples=120</div><div class="line">   iops        : min= 2142, max= 7136, avg=2458.98, stdev=434.32, samples=120</div><div class="line">  lat (usec)   : 250=0.01%, 500=0.03%, 750=0.02%, 1000=0.02%</div><div class="line">  lat (msec)   : 2=1.03%, 4=1.10%, 10=0.98%, 20=96.43%, 50=0.38%</div><div class="line">  lat (msec)   : 100=0.01%</div><div class="line">  cpu          : usr=0.82%, sys=4.32%, ctx=212008, majf=0, minf=4</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued rwt: total=147386,147564,0, short=0,0,0, dropped=0,0,0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">   READ: bw=9823KiB/s (10.1MB/s), 9823KiB/s-9823KiB/s (10.1MB/s-10.1MB/s), io=576MiB (604MB), run=60015-60015msec</div><div class="line">  WRITE: bw=9835KiB/s (10.1MB/s), 9835KiB/s-9835KiB/s (10.1MB/s-10.1MB/s), io=576MiB (604MB), run=60015-60015msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">  vda: ios=147097/147865, merge=0/241, ticks=1916703/1915836, in_queue=3791443, util=98.68%</div></pre></td></tr></table></figure>
<p>各类型云盘的性能比较如下表所示。</p>
<table>
<thead>
<tr>
<th style="text-align:left">性能类别</th>
<th style="text-align:left">ESSD AutoPL云盘（邀测）</th>
<th style="text-align:left">ESSD PL-X云盘（邀测）</th>
<th style="text-align:left">ESSD云盘 PL3</th>
<th style="text-align:left">ESSD云盘 PL0</th>
<th style="text-align:left">ESSD云盘 PL1</th>
<th style="text-align:left">ESSD云盘 PL0</th>
<th>SSD云盘</th>
<th>高效云盘</th>
<th>普通云盘</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">单盘容量范围（GiB）</td>
<td style="text-align:left">40~32,768</td>
<td style="text-align:left">40~32,768</td>
<td style="text-align:left">1261~32,768</td>
<td style="text-align:left">461~32,768</td>
<td style="text-align:left">20~32,768</td>
<td style="text-align:left">40~32,768</td>
<td>20~32,768</td>
<td>20~32,768</td>
<td>5~2,000</td>
</tr>
<tr>
<td style="text-align:left">最大IOPS</td>
<td style="text-align:left">100,000</td>
<td style="text-align:left">3,000,000</td>
<td style="text-align:left">1,000,000</td>
<td style="text-align:left">100,000</td>
<td style="text-align:left">50,000</td>
<td style="text-align:left">10,000</td>
<td>25,000</td>
<td>5,000</td>
<td>数百</td>
</tr>
<tr>
<td style="text-align:left">最大吞吐量（MB/s）</td>
<td style="text-align:left">1,131</td>
<td style="text-align:left">12,288</td>
<td style="text-align:left">4,000</td>
<td style="text-align:left">750</td>
<td style="text-align:left">350</td>
<td style="text-align:left">180</td>
<td>300</td>
<td>140</td>
<td>30~40</td>
</tr>
<tr>
<td style="text-align:left">单盘IOPS性能计算公式</td>
<td style="text-align:left">min{1,800+50*容量, 50,000}</td>
<td style="text-align:left">预配置IOPS</td>
<td style="text-align:left">min{1,800+50*容量, 1,000,000}</td>
<td style="text-align:left">min{1,800+50*容量, 100,000}</td>
<td style="text-align:left">min{1,800+50*容量, 50,000}</td>
<td style="text-align:left">min{ 1,800+12*容量, 10,000 }</td>
<td>min{1,800+30*容量, 25,000}</td>
<td>min{1,800+8*容量, 5,000}</td>
<td>无</td>
</tr>
<tr>
<td style="text-align:left">单盘吞吐量性能计算公式（MB/s）</td>
<td style="text-align:left">min{120+0.5*容量, 350}</td>
<td style="text-align:left">4 KB*预配置IOPS/1024</td>
<td style="text-align:left">min{120+0.5*容量, 4,000}</td>
<td style="text-align:left">min{120+0.5*容量, 750}</td>
<td style="text-align:left">min{120+0.5*容量, 350}</td>
<td style="text-align:left">min{100+0.25*容量, 180}</td>
<td>min{120+0.5*容量, 300}</td>
<td>min{100+0.15*容量, 140}</td>
<td>无</td>
</tr>
<tr>
<td style="text-align:left">单路随机写平均时延（ms），Block Size=4K</td>
<td style="text-align:left">0.2</td>
<td style="text-align:left">0.03</td>
<td style="text-align:left">0.2</td>
<td style="text-align:left">0.2</td>
<td style="text-align:left">0.2</td>
<td style="text-align:left">0.3~0.5</td>
<td>0.5~2</td>
<td>1~3</td>
<td>5~10</td>
</tr>
<tr>
<td style="text-align:left">API参数取值</td>
<td style="text-align:left">cloud_auto</td>
<td style="text-align:left">cloud_plx</td>
<td style="text-align:left">cloud_essd</td>
<td style="text-align:left">cloud_essd</td>
<td style="text-align:left">cloud_essd</td>
<td style="text-align:left">cloud_essd</td>
<td>cloud_ssd</td>
<td>cloud_efficiency</td>
<td>cloud</td>
</tr>
</tbody>
</table>
<h4 id="ESSD-PL3测试"><a href="#ESSD-PL3测试" class="headerlink" title="ESSD PL3测试"></a>ESSD PL3测试</h4><p>测试命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">fio -ioengine=libaio -bs=4k -buffered=1 -thread -rw=randwrite -rwmixread=70 -size=160G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div></pre></td></tr></table></figure>
<p>ESSD 是PL3，LVM是海光物理机下两块本地NVMe SSD做的LVM，测试基于ext4文件系统，阿里云官方提供ESSD的IOPS是裸盘（不含文件系统的）</p>
<table>
<thead>
<tr>
<th></th>
<th>本地LVM</th>
<th>ESSD</th>
</tr>
</thead>
<tbody>
<tr>
<td>fio -ioengine=libaio -bs=4k -buffered=1 read</td>
<td>bw=36636KB/s, iops=9159<br>nvme0n1:util=42.31%<br>nvme1n1: util=41.63%</td>
<td>IOPS=3647, BW=14.2MiB/s<br>util=88.08%</td>
</tr>
<tr>
<td>fio -ioengine=libaio -bs=4k -buffered=1 write</td>
<td>bw=383626KB/s, iops=95906<br>nvme0n1:util=37.16%<br>nvme1n1: util=33.58%</td>
<td>IOPS=104k, BW=406MiB/s<br>util=39.06%</td>
</tr>
<tr>
<td>fio -ioengine=libaio -bs=4k -buffered=1 randrw rwmixread=70</td>
<td>write: bw=12765KB/s, iops=3191<br>read : bw=29766KB/s, iops=7441<br>nvme0n1:util=35.18%<br>nvme1n1: util=35.04%</td>
<td>write:IOPS=1701, BW=6808KiB/s<br>read: IOPS=3962, BW=15.5MiB/s<br> nvme7n1: util=99.35%</td>
</tr>
<tr>
<td>fio -ioengine=libaio -bs=4k -direct=1 -buffered=0 read</td>
<td>bw=67938KB/s, iops=16984<br>nvme0n1:util=43.17%<br>nvme1n1: util=39.18%</td>
<td>IOPS=4687, BW=18.3MiB/s<br>util=99.75%</td>
</tr>
<tr>
<td>fio -ioengine=libaio -bs=4k -direct=1 -buffered=0 write</td>
<td>bw=160775KB/s, iops=40193<br>nvme0n1:util=28.66%<br>nvme1n1: util=21.67%</td>
<td>IOPS=7153, BW=27.9MiB/s<br>util=99.85%</td>
</tr>
<tr>
<td>fio -ioengine=libaio -bs=4k -direct=1 -buffered=0 randrw rwmixread=70</td>
<td>write: bw=23087KB/s, iops=5771<br>read : bw=53849KB/s, iops=13462</td>
<td>write:IOPS=1511, BW=6045KiB/s<br>read: IOPS=3534, BW=13.8MiB/s</td>
</tr>
</tbody>
</table>
<p>结论：</p>
<ul>
<li>ESSD只要有随机读性能就很差,纯读是本地盘（LVM）的40%，纯写和本地盘差不多</li>
<li>direct 读是本地盘的四分之一</li>
<li>direct 写是本地盘的六分之一，写16K Page差距缩小到五分之一（5749/25817）</li>
<li>intel direct 写本地intel SSDPE2KX040T8 iops=55826（比海光好40%，海光是memblaze）</li>
<li>ESSD带buffer读写抖动很大</li>
<li>ESSD出现过多次ESSD卡死，表现就是磁盘不响应任何操作，大概N分钟后恢复，原因未知</li>
</ul>
<p>PL3单盘IOPS性能计算公式  min{1800+50*容量, 1000000}</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div></pre></td><td class="code"><pre><div class="line">[essd_pl3]# fio -ioengine=libaio -bs=4k -direct=1 -buffered=1 -thread -rw=randwrite -rwmixread=70 -size=160G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div><div class="line">EBS 4K randwrite test: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</div><div class="line">fio-3.7</div><div class="line">Starting 1 thread</div><div class="line">Jobs: 1 (f=1): [w(1)][100.0%][r=0KiB/s,w=566MiB/s][r=0,w=145k IOPS][eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=2416234: Thu Apr  7 17:03:07 2022</div><div class="line">  write: IOPS=96.2k, BW=376MiB/s (394MB/s)(22.0GiB/60000msec)</div><div class="line">    slat (usec): min=2, max=530984, avg= 8.27, stdev=1104.96</div><div class="line">    clat (usec): min=2, max=944103, avg=599.25, stdev=9230.93</div><div class="line">     lat (usec): min=7, max=944111, avg=607.60, stdev=9308.81</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[   392],  5.00th=[   400], 10.00th=[   404], 20.00th=[   408],</div><div class="line">     | 30.00th=[   412], 40.00th=[   416], 50.00th=[   420], 60.00th=[   424],</div><div class="line">     | 70.00th=[   433], 80.00th=[   441], 90.00th=[   457], 95.00th=[   482],</div><div class="line">     | 99.00th=[   627], 99.50th=[   766], 99.90th=[  1795], 99.95th=[  4228],</div><div class="line">     | 99.99th=[488637]</div><div class="line">   bw (  KiB/s): min=  168, max=609232, per=100.00%, avg=422254.17, stdev=257181.75, samples=108</div><div class="line">   iops        : min=   42, max=152308, avg=105563.63, stdev=64295.48, samples=108</div><div class="line">  lat (usec)   : 4=0.01%, 10=0.01%, 50=0.01%, 100=0.01%, 250=0.01%</div><div class="line">  lat (usec)   : 500=96.35%, 750=3.11%, 1000=0.26%</div><div class="line">  lat (msec)   : 2=0.19%, 4=0.03%, 10=0.02%, 250=0.01%, 500=0.03%</div><div class="line">  lat (msec)   : 750=0.01%, 1000=0.01%</div><div class="line">  cpu          : usr=13.56%, sys=60.78%, ctx=1455, majf=0, minf=9743</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued rwts: total=0,5771972,0,0 short=0,0,0,0 dropped=0,0,0,0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">  WRITE: bw=376MiB/s (394MB/s), 376MiB/s-376MiB/s (394MB/s-394MB/s), io=22.0GiB (23.6GB), run=60000-60000msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">  vdb: ios=0/1463799, merge=0/7373, ticks=0/2011879, in_queue=2011879, util=27.85%</div><div class="line">  </div><div class="line">[essd_pl3]# fio -ioengine=libaio -bs=4k -direct=1 -buffered=1 -thread -rw=randread -rwmixread=70 -size=160G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div><div class="line">EBS 4K randwrite test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</div><div class="line">fio-3.7</div><div class="line">Starting 1 thread</div><div class="line">Jobs: 1 (f=1): [r(1)][100.0%][r=15.9MiB/s,w=0KiB/s][r=4058,w=0 IOPS][eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=2441598: Thu Apr  7 17:05:10 2022</div><div class="line">   read: IOPS=3647, BW=14.2MiB/s (14.9MB/s)(855MiB/60001msec)</div><div class="line">    slat (usec): min=183, max=10119, avg=239.01, stdev=110.20</div><div class="line">    clat (usec): min=2, max=54577, avg=15170.17, stdev=1324.10</div><div class="line">     lat (usec): min=237, max=55110, avg=15409.34, stdev=1338.09</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[13960],  5.00th=[14091], 10.00th=[14222], 20.00th=[14484],</div><div class="line">     | 30.00th=[14615], 40.00th=[14746], 50.00th=[14877], 60.00th=[15139],</div><div class="line">     | 70.00th=[15270], 80.00th=[15533], 90.00th=[16057], 95.00th=[16712],</div><div class="line">     | 99.00th=[20317], 99.50th=[22152], 99.90th=[26346], 99.95th=[30802],</div><div class="line">     | 99.99th=[52691]</div><div class="line">   bw (  KiB/s): min= 6000, max=17272, per=100.00%, avg=16511.28, stdev=1140.64, samples=105</div><div class="line">   iops        : min= 1500, max= 4318, avg=4127.81, stdev=285.16, samples=105</div><div class="line">  lat (usec)   : 4=0.01%, 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.01%</div><div class="line">  lat (msec)   : 2=0.01%, 4=0.01%, 10=0.01%, 20=98.91%, 50=1.05%</div><div class="line">  lat (msec)   : 100=0.02%</div><div class="line">  cpu          : usr=0.18%, sys=17.18%, ctx=219041, majf=0, minf=4215</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued rwts: total=218835,0,0,0 short=0,0,0,0 dropped=0,0,0,0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">   READ: bw=14.2MiB/s (14.9MB/s), 14.2MiB/s-14.2MiB/s (14.9MB/s-14.9MB/s), io=855MiB (896MB), run=60001-60001msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">  vdb: ios=218343/7992, merge=0/8876, ticks=50566/3749, in_queue=54315, util=88.08%  </div><div class="line"> </div><div class="line">[essd_pl3]# fio -ioengine=libaio -bs=4k -direct=1 -buffered=1 -thread -rw=randrw -rwmixread=70 -size=160G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div><div class="line">EBS 4K randwrite test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64</div><div class="line">fio-3.7</div><div class="line">Starting 1 thread</div><div class="line">Jobs: 1 (f=1): [m(1)][100.0%][r=15.7MiB/s,w=7031KiB/s][r=4007,w=1757 IOPS][eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=2641414: Thu Apr  7 17:21:10 2022</div><div class="line">   read: IOPS=3962, BW=15.5MiB/s (16.2MB/s)(929MiB/60001msec)</div><div class="line">    slat (usec): min=182, max=7194, avg=243.23, stdev=116.87</div><div class="line">    clat (usec): min=2, max=235715, avg=11020.01, stdev=3366.61</div><div class="line">     lat (usec): min=253, max=235991, avg=11263.40, stdev=3375.49</div><div class="line">    clat percentiles (msec):</div><div class="line">     |  1.00th=[    9],  5.00th=[   10], 10.00th=[   10], 20.00th=[   11],</div><div class="line">     | 30.00th=[   11], 40.00th=[   11], 50.00th=[   11], 60.00th=[   12],</div><div class="line">     | 70.00th=[   12], 80.00th=[   12], 90.00th=[   13], 95.00th=[   14],</div><div class="line">     | 99.00th=[   16], 99.50th=[   18], 99.90th=[   31], 99.95th=[   36],</div><div class="line">     | 99.99th=[  234]</div><div class="line">   bw (  KiB/s): min=10808, max=17016, per=100.00%, avg=15977.89, stdev=895.35, samples=118</div><div class="line">   iops        : min= 2702, max= 4254, avg=3994.47, stdev=223.85, samples=118</div><div class="line">  write: IOPS=1701, BW=6808KiB/s (6971kB/s)(399MiB/60001msec)</div><div class="line">    slat (usec): min=3, max=221631, avg=10.16, stdev=693.59</div><div class="line">    clat (usec): min=486, max=235772, avg=11029.42, stdev=3590.93</div><div class="line">     lat (usec): min=493, max=235780, avg=11039.67, stdev=3659.04</div><div class="line">    clat percentiles (msec):</div><div class="line">     |  1.00th=[    9],  5.00th=[   10], 10.00th=[   10], 20.00th=[   11],</div><div class="line">     | 30.00th=[   11], 40.00th=[   11], 50.00th=[   11], 60.00th=[   12],</div><div class="line">     | 70.00th=[   12], 80.00th=[   12], 90.00th=[   13], 95.00th=[   14],</div><div class="line">     | 99.00th=[   16], 99.50th=[   18], 99.90th=[   31], 99.95th=[   37],</div><div class="line">     | 99.99th=[  234]</div><div class="line">   bw (  KiB/s): min= 4480, max= 7728, per=100.00%, avg=6862.60, stdev=475.79, samples=118</div><div class="line">   iops        : min= 1120, max= 1932, avg=1715.64, stdev=118.97, samples=118</div><div class="line">  lat (usec)   : 4=0.01%, 500=0.01%, 750=0.01%</div><div class="line">  lat (msec)   : 2=0.01%, 4=0.01%, 10=20.77%, 20=78.89%, 50=0.31%</div><div class="line">  lat (msec)   : 100=0.01%, 250=0.02%</div><div class="line">  cpu          : usr=0.65%, sys=7.20%, ctx=239089, majf=0, minf=8292</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued rwts: total=237743,102115,0,0 short=0,0,0,0 dropped=0,0,0,0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">   READ: bw=15.5MiB/s (16.2MB/s), 15.5MiB/s-15.5MiB/s (16.2MB/s-16.2MB/s), io=929MiB (974MB), run=60001-60001msec</div><div class="line">  WRITE: bw=6808KiB/s (6971kB/s), 6808KiB/s-6808KiB/s (6971kB/s-6971kB/s), io=399MiB (418MB), run=60001-60001msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">  vdb: ios=237216/118960, merge=0/8118, ticks=55191/148225, in_queue=203416, util=99.35%</div><div class="line">  </div><div class="line">[essd_pl3]# fio  -bs=4k -direct=1 -buffered=0 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=30</div><div class="line">EBS 4K randwrite test: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=psync, iodepth=64</div><div class="line">fio-3.7</div><div class="line">Starting 1 thread</div><div class="line">Jobs: 1 (f=1): [w(1)][100.0%][r=0KiB/s,w=28.3MiB/s][r=0,w=7249 IOPS][eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=2470117: Fri Apr  8 15:35:20 2022</div><div class="line">  write: IOPS=7222, BW=28.2MiB/s (29.6MB/s)(846MiB/30001msec)</div><div class="line">    clat (usec): min=115, max=7155, avg=137.29, stdev=68.48</div><div class="line">     lat (usec): min=115, max=7156, avg=137.36, stdev=68.49</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[  121],  5.00th=[  123], 10.00th=[  125], 20.00th=[  126],</div><div class="line">     | 30.00th=[  127], 40.00th=[  129], 50.00th=[  130], 60.00th=[  133],</div><div class="line">     | 70.00th=[  135], 80.00th=[  139], 90.00th=[  149], 95.00th=[  163],</div><div class="line">     | 99.00th=[  255], 99.50th=[  347], 99.90th=[  668], 99.95th=[  947],</div><div class="line">     | 99.99th=[ 3589]</div><div class="line">   bw (  KiB/s): min=23592, max=30104, per=99.95%, avg=28873.29, stdev=1084.49, samples=59</div><div class="line">   iops        : min= 5898, max= 7526, avg=7218.32, stdev=271.12, samples=59</div><div class="line">  lat (usec)   : 250=98.95%, 500=0.81%, 750=0.17%, 1000=0.03%</div><div class="line">  lat (msec)   : 2=0.02%, 4=0.02%, 10=0.01%</div><div class="line">  cpu          : usr=0.72%, sys=5.08%, ctx=216767, majf=0, minf=148</div><div class="line">  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, &gt;=64=0.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     issued rwts: total=0,216677,0,0 short=0,0,0,0 dropped=0,0,0,0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">  WRITE: bw=28.2MiB/s (29.6MB/s), 28.2MiB/s-28.2MiB/s (29.6MB/s-29.6MB/s), io=846MiB (888MB), run=30001-30001msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">  vdb: ios=0/219122, merge=0/3907, ticks=0/29812, in_queue=29812, util=99.52% </div><div class="line">  </div><div class="line">[root@hygon8 14:44 /polarx/lvm]</div><div class="line">#fio  -bs=4k -direct=1 -buffered=0 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=30</div><div class="line">EBS 4K randwrite test: (g=0): rw=randwrite, bs=4K-4K/4K-4K/4K-4K, ioengine=sync, iodepth=64</div><div class="line">fio-2.2.8</div><div class="line">Starting 1 thread</div><div class="line">Jobs: 1 (f=1): [w(1)] [100.0% done] [0KB/157.2MB/0KB /s] [0/40.3K/0 iops] [eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=3486352: Fri Apr  8 14:45:43 2022</div><div class="line">  write: io=4710.4MB, bw=160775KB/s, iops=40193, runt= 30001msec</div><div class="line">    clat (usec): min=18, max=4164, avg=22.05, stdev= 7.33</div><div class="line">     lat (usec): min=19, max=4165, avg=22.59, stdev= 7.36</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[   20],  5.00th=[   20], 10.00th=[   21], 20.00th=[   21],</div><div class="line">     | 30.00th=[   21], 40.00th=[   21], 50.00th=[   21], 60.00th=[   22],</div><div class="line">     | 70.00th=[   22], 80.00th=[   22], 90.00th=[   23], 95.00th=[   25],</div><div class="line">     | 99.00th=[   36], 99.50th=[   40], 99.90th=[   62], 99.95th=[   99],</div><div class="line">     | 99.99th=[  157]</div><div class="line">    bw (KB  /s): min=147568, max=165400, per=100.00%, avg=160803.12, stdev=2704.22</div><div class="line">    lat (usec) : 20=0.08%, 50=99.70%, 100=0.17%, 250=0.04%, 500=0.01%</div><div class="line">    lat (usec) : 750=0.01%, 1000=0.01%</div><div class="line">    lat (msec) : 2=0.01%, 10=0.01%</div><div class="line">  cpu          : usr=6.95%, sys=31.18%, ctx=1205994, majf=0, minf=1573</div><div class="line">  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, &gt;=64=0.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     issued    : total=r=0/w=1205849/d=0, short=r=0/w=0/d=0, drop=r=0/w=0/d=0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">  WRITE: io=4710.4MB, aggrb=160774KB/s, minb=160774KB/s, maxb=160774KB/s, mint=30001msec, maxt=30001msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">    dm-2: ios=0/1204503, merge=0/0, ticks=0/15340, in_queue=15340, util=50.78%, aggrios=0/603282, aggrmerge=0/463, aggrticks=0/8822, aggrin_queue=0, aggrutil=28.66%</div><div class="line">  nvme0n1: ios=0/683021, merge=0/474, ticks=0/9992, in_queue=0, util=28.66%</div><div class="line">  nvme1n1: ios=0/523543, merge=0/452, ticks=0/7652, in_queue=0, util=21.67%</div><div class="line">  </div><div class="line">[root@x86.170 /polarx/lvm]</div><div class="line">#/usr/sbin/nvme list</div><div class="line">Node             SN                   Model                                    Namespace Usage                      Format           FW Rev</div><div class="line">---------------- -------------------- ---------------------------------------- --------- -------------------------- ---------------- --------</div><div class="line">/dev/nvme0n1     BTLJ932205P44P0DGN   INTEL SSDPE2KX040T8                      1           3.84  TB /   3.84  TB    512   B +  0 B   VDV10131</div><div class="line">/dev/nvme1n1     BTLJ932207H04P0DGN   INTEL SSDPE2KX040T8                      1           3.84  TB /   3.84  TB    512   B +  0 B   VDV10131</div><div class="line">/dev/nvme2n1     BTLJ932205AS4P0DGN   INTEL SSDPE2KX040T8                      1           3.84  TB /   3.84  TB    512   B +  0 B   VDV10131</div><div class="line">[root@x86.170 /polarx/lvm]</div><div class="line">#fio  -bs=4k  -direct=1 -buffered=0 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=30</div><div class="line">EBS 4K randwrite test: (g=0): rw=randwrite, bs=4K-4K/4K-4K/4K-4K, ioengine=sync, iodepth=64</div><div class="line">fio-2.2.8</div><div class="line">Starting 1 thread</div><div class="line">Jobs: 1 (f=1): [w(1)] [100.0% done] [0KB/240.2MB/0KB /s] [0/61.5K/0 iops] [eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=11516: Fri Apr  8 15:44:36 2022</div><div class="line">  write: io=7143.3MB, bw=243813KB/s, iops=60953, runt= 30001msec</div><div class="line">    clat (usec): min=10, max=818, avg=14.96, stdev= 4.14</div><div class="line">     lat (usec): min=10, max=818, avg=15.14, stdev= 4.15</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[   11],  5.00th=[   12], 10.00th=[   12], 20.00th=[   14],</div><div class="line">     | 30.00th=[   15], 40.00th=[   15], 50.00th=[   15], 60.00th=[   15],</div><div class="line">     | 70.00th=[   15], 80.00th=[   16], 90.00th=[   16], 95.00th=[   16],</div><div class="line">     | 99.00th=[   20], 99.50th=[   32], 99.90th=[   78], 99.95th=[   84],</div><div class="line">     | 99.99th=[  105]</div><div class="line">    bw (KB  /s): min=236768, max=246424, per=99.99%, avg=243794.17, stdev=1736.82</div><div class="line">    lat (usec) : 20=98.96%, 50=0.73%, 100=0.29%, 250=0.01%, 500=0.01%</div><div class="line">    lat (usec) : 750=0.01%, 1000=0.01%</div><div class="line">  cpu          : usr=10.65%, sys=42.66%, ctx=1828699, majf=0, minf=7</div><div class="line">  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, &gt;=64=0.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     issued    : total=r=0/w=1828662/d=0, short=r=0/w=0/d=0, drop=r=0/w=0/d=0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">  WRITE: io=7143.3MB, aggrb=243813KB/s, minb=243813KB/s, maxb=243813KB/s, mint=30001msec, maxt=30001msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">    dm-0: ios=0/1823575, merge=0/0, ticks=0/13666, in_queue=13667, util=45.56%, aggrios=0/609558, aggrmerge=0/2, aggrticks=0/4280, aggrin_queue=4198, aggrutil=14.47%</div><div class="line">  nvme0n1: ios=0/609144, merge=0/6, ticks=0/4438, in_queue=4353, util=14.47%</div><div class="line">  nvme1n1: ios=0/609470, merge=0/0, ticks=0/4186, in_queue=4109, util=13.65%</div><div class="line">  nvme2n1: ios=0/610060, merge=0/0, ticks=0/4216, in_queue=4134, util=13.74%</div></pre></td></tr></table></figure>
<h3 id="HDD性能测试数据"><a href="#HDD性能测试数据" class="headerlink" title="HDD性能测试数据"></a>HDD性能测试数据</h3><p><img src="/images/951413iMgBlog/0868d560-067f-4302-bc60-bffc3d4460ed.png" alt="img"></p>
<p>从上图可以看到这个磁盘的IOPS 读 935 写 400，读rt 10731nsec 大约10us, 写 17us。如果IOPS是1000的话，rt应该是1ms，实际比1ms小两个数量级，<del>应该是cache、磁盘阵列在起作用。</del></p>
<p>SATA硬盘，10K转</p>
<p>万转机械硬盘组成RAID5阵列，在顺序条件最好的情况下，带宽可以达到1GB/s以上，平均延时也非常低，最低只有20多us。但是在随机IO的情况下，机械硬盘的短板就充分暴露了，零点几兆的带宽，将近5ms的延迟，IOPS只有200左右。其原因是因为</p>
<ul>
<li>随机访问直接让RAID卡缓存成了个摆设</li>
<li>磁盘不能并行工作，因为我的机器RAID宽度Strip Size为128 KB</li>
<li>机械轴也得在各个磁道之间跳来跳去。</li>
</ul>
<p>理解了磁盘顺序IO时候的几十M甚至一个GB的带宽，随机IO这个真的是太可怜了。</p>
<p>从上面的测试数据中我们看到了机械硬盘在顺序IO和随机IO下的巨大性能差异。在顺序IO情况下，磁盘是最擅长的顺序IO,再加上Raid卡缓存命中率也高。这时带宽表现有几十、几百M，最好条件下甚至能达到1GB。IOPS这时候能有2-3W左右。到了随机IO的情形下，机械轴也被逼的跳来跳去寻道，RAID卡缓存也失效了。带宽跌到了1MB以下，最低只有100K，IOPS也只有可怜巴巴的200左右。</p>
<h2 id="测试数据总结"><a href="#测试数据总结" class="headerlink" title="测试数据总结"></a>测试数据总结</h2><table>
<thead>
<tr>
<th></th>
<th>-direct=1 -buffered=1</th>
<th>-direct=0 -buffered=1</th>
<th>-direct=1 -buffered=0</th>
<th>-direct=0 -buffered=0</th>
</tr>
</thead>
<tbody>
<tr>
<td>NVMe SSD</td>
<td>R=10.6k W=4544</td>
<td>R=10.8K W=4642</td>
<td>R=99.8K W=42.8K</td>
<td>R=38.6k W=16.5k</td>
</tr>
<tr>
<td>SATA SSD</td>
<td>R=4312 W=1852</td>
<td>R=5389 W=2314</td>
<td>R=16.9k W=7254</td>
<td>R=15.8k W=6803</td>
</tr>
<tr>
<td>ESSD</td>
<td>R=2149 W=2150</td>
<td>R=1987 W=1984</td>
<td>R=2462 W=2465</td>
<td>R=2455 W=2458</td>
</tr>
</tbody>
</table>
<p>看起来，<strong>对于SSD如果buffered为1的话direct没啥用，如果buffered为0那么direct为1性能要好很多</strong></p>
<p><strong>SATA SSD的IOPS比NVMe性能差很多</strong>。</p>
<p>SATA SSD当-buffered=1参数下SATA SSD的latency在7-10us之间。 </p>
<p>NVMe SSD以及SATA SSD当buffered=0的条件下latency均为2-3us,  NVMe SSD latency参考文章第一个表格， 和本次NVMe测试结果一致.  </p>
<p>ESSD的latency基本是13-16us。</p>
<p>以上NVMe SSD测试数据是在测试过程中还有mysql在全力导入数据的情况下，用fio测试所得。所以空闲情况下测试结果会更好。</p>
<h3 id="网上测试数据参考"><a href="#网上测试数据参考" class="headerlink" title="网上测试数据参考"></a><a href="https://zhuanlan.zhihu.com/p/40497397" target="_blank" rel="external">网上测试数据参考</a></h3><p>我们来一起看一下具体的数据。首先来看NVＭe如何减小了协议栈本身的时间消耗，我们用<em>blktrace</em>工具来分析一组传输在应用程序层、操作系统层、驱动层和硬件层消耗的时间和占比，来了解AHCI和NVMe协议的性能区别：</p>
<p><img src="/images/951413iMgBlog/v2-8b37f236d5c754efabe17aa9706f99a3_720w.jpg" alt="img"></p>
<p>硬盘HDD作为一个参考基准，它的时延是非常大的，达到14ms，而AHCI SATA为125us，NVMe为111us。我们从图中可以看出，NVMe相对AHCI，协议栈及之下所占用的时间比重明显减小，应用程序层面等待的时间占比很高，这是因为SSD物理硬盘速度不够快，导致应用空转。NVMe也为将来Optane硬盘这种低延迟介质的速度提高留下了广阔的空间。</p>
<h2 id="对比LVM-、RAID0和-一块NVMe-SSD"><a href="#对比LVM-、RAID0和-一块NVMe-SSD" class="headerlink" title="对比LVM 、RAID0和 一块NVMe SSD"></a>对比LVM 、RAID0和 一块NVMe SSD</h2><p>曙光H620-G30A机型下测试</p>
<p>各拿两块nvme，分别作LVM和RAID0，另外单独拿一块nvme直接读写，条带用的是4块nvme做的，然后比较顺序、随机读写，测试结果如下：</p>
<table>
<thead>
<tr>
<th></th>
<th>RAID0（2块盘）</th>
<th>NVMe</th>
<th>LVM</th>
<th>RAID0（4块盘）</th>
<th>条带（4块 linear）</th>
</tr>
</thead>
<tbody>
<tr>
<td>dd write bs=1M count=10240 conv=fsync</td>
<td>10.9秒</td>
<td>23秒</td>
<td>24.6秒</td>
<td>10.9秒</td>
<td>11.9秒</td>
</tr>
<tr>
<td>fio -ioengine=libaio -bs=4k  -buffered=1</td>
<td>bw=346744KB/s, iops=86686 <br> nvme6n1: util=38.43%<br> nvme7n1: util=38.96%</td>
<td>bw=380816KB/s, iops=95203<br>nvme2n1: util=68.31%</td>
<td>bw=175704KB/s, iops=43925<br>nvme0n1:util=29.60%<br>nvme1n1: util=25.64%</td>
<td>bw=337495KB/s, iops=84373<br> nvme6n1: util=20.93%<br> nvme5n1: util=21.30%<br> nvme4n1: util=21.12%<br> nvme7n1: util=20.95%</td>
<td>bw=329721KB/s, iops=82430<br> nvme0n1: util=67.22%<br> nvme3n1: util=0%<br>条带每次只写一块盘</td>
</tr>
<tr>
<td>fio -ioengine=libaio -bs=4k -direct=1 -buffered=0</td>
<td>bw=121556KB/s, iops=30389 <br> nvme6n1: util=18.70%<br> nvme7n1: util=18.91%</td>
<td>bw=126215KB/s, iops=31553<br>nvme2n1: util=37.27%</td>
<td>bw=117192KB/s, iops=29297<br>nvme0n1:util=21.16%<br>nvme1n1: util=13.35%</td>
<td>bw=119145KB/s, iops=29786<br> nvme6n1: util=9.19%<br> nvme5n1: util=9.45%<br> nvme4n1: util=9.45%<br> nvme7n1: util=9.30%</td>
<td>bw=116688KB/s, iops=29171<br> nvme0n1: util=37.87%<br> nvme3n1: util=0%<br>条带每次只写一块盘</td>
</tr>
<tr>
<td>fio -bs=4k -direct=1 -buffered=0</td>
<td>bw=104107KB/s, iops=26026 <br> nvme6n1: util=15.55%<br> nvme7n1: util=15.00%</td>
<td>bw=105115KB/s, iops=26278<br>nvme2n1: util=31.25%</td>
<td>bw=101936KB/s, iops=25484<br>nvme0n1:util=17.76%<br>nvme1n1: util=12.07%</td>
<td>bw=102517KB/s, iops=25629<br> nvme6n1: util=8.13%<br> nvme5n1: util=7.65%<br> nvme4n1: util=7.57%<br> nvme7n1: util=7.75%</td>
<td>bw=87280KB/s, iops=21820<br> nvme0n1: util=31.27%<br> nvme3n1: util=0%<br>条带每次只写一块盘</td>
</tr>
</tbody>
</table>
<ul>
<li>整体看 nvme 最好(顺序写除外)，raid0性能接近nvme，LVM最差</li>
<li>顺序写raid0是nvme、LVM的两倍</li>
<li>随机读写带buffered的话 nvme最好，raid0略差（猜测是软件消耗），LVM只有前两者的一半</li>
<li>关掉buffered 三者性能下降都很大，最终差异变小</li>
<li>raid0下两块盘非常均衡，LVM下两块盘负载差异比较大</li>
<li>性能不在单块盘到了瓶颈，当阵列中盘数变多后，软件实现的LVM、RAID性能都有下降</li>
<li>开buffer对性能提升非常大</li>
<li>每次测试前都会echo 3 &gt; /proc/sys/vm/drop_caches ; rm -f ./fio.test ;测试跑多次，取稳定值</li>
</ul>
<h3 id="顺序读写"><a href="#顺序读写" class="headerlink" title="顺序读写"></a>顺序读写</h3><p>然后同时做dd写入测试</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">time taskset -c 0 dd if=/dev/zero of=./tempfile2 bs=1M count=40240 &amp;</div></pre></td></tr></table></figure>
<p>下图上面两块nvme做的LVM，下面两块nvme做成RAID0，同时开始测试，可以看到RAID0的两块盘写入速度更快</p>
<p><img src="/images/951413iMgBlog/image-20211231205730735.png" alt="image-20211231205730735"></p>
<p>测试结果</p>
<p><img src="/images/951413iMgBlog/image-20211231205842753.png" alt="image-20211231205842753"></p>
<p>实际单独写一块nvme也比写两块nvme做的LVM要快一倍，对dd这样的顺序读写，软RAID0还是能提升一倍速度的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line">[root@hygon33 14:02 /nvme]</div><div class="line">#echo 3 &gt; /proc/sys/vm/drop_caches ; rm -f ./tempfile2 ; time taskset -c 16 dd if=/dev/zero of=./tempfile2 bs=1M count=10240 conv=fsync</div><div class="line">记录了10240+0 的读入</div><div class="line">记录了10240+0 的写出</div><div class="line">10737418240字节（11 GB，10 GiB）已复制，23.0399 s，466 MB/s</div><div class="line"></div><div class="line">real	0m23.046s</div><div class="line">user	0m0.004s</div><div class="line">sys	0m8.033s</div><div class="line"></div><div class="line">[root@hygon33 14:08 /nvme]</div><div class="line">#cd ../md0/</div><div class="line"></div><div class="line">[root@hygon33 14:08 /md0]</div><div class="line">#echo 3 &gt; /proc/sys/vm/drop_caches ; rm -f ./tempfile2 ; time taskset -c 16 dd if=/dev/zero of=./tempfile2 bs=1M count=10240 conv=fsync</div><div class="line">记录了10240+0 的读入</div><div class="line">记录了10240+0 的写出</div><div class="line">10737418240字节（11 GB，10 GiB）已复制，10.9632 s，979 MB/s</div><div class="line"></div><div class="line">real	0m10.967s</div><div class="line">user	0m0.004s</div><div class="line">sys	0m10.899s</div><div class="line"></div><div class="line">[root@hygon33 14:08 /md0]</div><div class="line">#cd /polarx/</div><div class="line"></div><div class="line">[root@hygon33 14:08 /polarx]</div><div class="line">#echo 3 &gt; /proc/sys/vm/drop_caches ; rm -f ./tempfile2 ; time taskset -c 16 dd if=/dev/zero of=./tempfile2 bs=1M count=10240 conv=fsync</div><div class="line">记录了10240+0 的读入</div><div class="line">记录了10240+0 的写出</div><div class="line">10737418240字节（11 GB，10 GiB）已复制，24.6481 s，436 MB/s</div><div class="line"></div><div class="line">real	0m24.653s</div><div class="line">user	0m0.008s</div><div class="line">sys	0m24.557s</div></pre></td></tr></table></figure>
<h3 id="随机读写"><a href="#随机读写" class="headerlink" title="随机读写"></a>随机读写</h3><p>SSD单独的随机读IOPS大概是随机写IOPS的10%, 应该是因为write有cache</p>
<p>RAID0是使用mdadm做的软raid，系统层面还是有消耗，没法和RAID卡硬件比较</p>
<p>左边是一块nvme，中间是两块nvme做了LVM，右边是两块nvme做RAID0，看起来速度差不多，一块nvme似乎要好一点点</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">fio -ioengine=libaio -bs=4k -buffered=1 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div></pre></td></tr></table></figure>
<p><img src="/images/951413iMgBlog/image-20220101104145331.png" alt="image-20220101104145331"></p>
<p>从观察来看，RAID0的两块盘读写、iops都非常均衡，LVM的两块盘</p>
<p>三个测试分开跑，独立nvme性能最好，LVM最差并且不均衡</p>
<p><img src="/images/951413iMgBlog/image-20220101110016074.png" alt="image-20220101110016074"></p>
<p>三个测试分开跑，去掉 aio，性能都只有原来的一半</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">fio  -bs=4k -direct=1 -buffered=0 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div></pre></td></tr></table></figure>
<p><img src="/images/951413iMgBlog/image-20220101110708888.png" alt="image-20220101110708888"></p>
<p>修改fio参数，用最快的 direct=0 buffered=1 aio 结论是raid0最快，直接写nvme略慢，LVM只有raid0的一半</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div></pre></td><td class="code"><pre><div class="line">[root@hygon33 13:43 /md0]</div><div class="line">#echo 3 &gt; /proc/sys/vm/drop_caches ; rm -f ./fio.test; fio -ioengine=libaio -bs=4k -direct=0 -buffered=1 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div><div class="line">EBS 4K randwrite test: (g=0): rw=randwrite, bs=4K-4K/4K-4K/4K-4K, ioengine=libaio, iodepth=64</div><div class="line">fio-2.2.8</div><div class="line">Starting 1 thread</div><div class="line">EBS 4K randwrite test: Laying out IO file(s) (1 file(s) / 16384MB)</div><div class="line">Jobs: 1 (f=1): [w(1)] [98.1% done] [0KB/394.3MB/0KB /s] [0/101K/0 iops] [eta 00m:01s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=21016: Sat Jan  1 13:45:25 2022</div><div class="line">  write: io=16384MB, bw=329974KB/s, iops=82493, runt= 50844msec</div><div class="line">    slat (usec): min=3, max=1496, avg= 9.00, stdev= 2.76</div><div class="line">    clat (usec): min=5, max=2272, avg=764.73, stdev=101.63</div><div class="line">     lat (usec): min=10, max=2282, avg=774.19, stdev=103.15</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[  510],  5.00th=[  612], 10.00th=[  644], 20.00th=[  684],</div><div class="line">     | 30.00th=[  700], 40.00th=[  716], 50.00th=[  772], 60.00th=[  820],</div><div class="line">     | 70.00th=[  844], 80.00th=[  860], 90.00th=[  884], 95.00th=[  908],</div><div class="line">     | 99.00th=[  932], 99.50th=[  940], 99.90th=[  988], 99.95th=[ 1064],</div><div class="line">     | 99.99th=[ 1336]</div><div class="line">    bw (KB  /s): min=277928, max=490720, per=99.84%, avg=329447.45, stdev=40386.54</div><div class="line">    lat (usec) : 10=0.01%, 20=0.01%, 50=0.01%, 100=0.01%, 250=0.01%</div><div class="line">    lat (usec) : 500=0.17%, 750=48.67%, 1000=51.08%</div><div class="line">    lat (msec) : 2=0.08%, 4=0.01%</div><div class="line">  cpu          : usr=17.79%, sys=81.97%, ctx=113, majf=0, minf=5526</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued    : total=r=0/w=4194304/d=0, short=r=0/w=0/d=0, drop=r=0/w=0/d=0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">  WRITE: io=16384MB, aggrb=329974KB/s, minb=329974KB/s, maxb=329974KB/s, mint=50844msec, maxt=50844msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">    md0: ios=0/2883541, merge=0/0, ticks=0/0, in_queue=0, util=0.00%, aggrios=0/1232592, aggrmerge=0/219971, aggrticks=0/44029, aggrin_queue=0, aggrutil=38.91%</div><div class="line">  nvme6n1: ios=0/1228849, merge=0/219880, ticks=0/43940, in_queue=0, util=37.19%</div><div class="line">  nvme7n1: ios=0/1236335, merge=0/220062, ticks=0/44119, in_queue=0, util=38.91%</div><div class="line">  </div><div class="line">[root@hygon33 13:46 /nvme]</div><div class="line">#echo 3 &gt; /proc/sys/vm/drop_caches ; rm -f ./fio.test; fio -ioengine=libaio -bs=4k -direct=0 -buffered=1 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div><div class="line">EBS 4K randwrite test: (g=0): rw=randwrite, bs=4K-4K/4K-4K/4K-4K, ioengine=libaio, iodepth=64</div><div class="line">fio-2.2.8</div><div class="line">Starting 1 thread</div><div class="line">EBS 4K randwrite test: Laying out IO file(s) (1 file(s) / 16384MB)</div><div class="line">Jobs: 1 (f=1): [w(1)] [100.0% done] [0KB/314.3MB/0KB /s] [0/80.5K/0 iops] [eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=21072: Sat Jan  1 13:47:32 2022</div><div class="line">  write: io=16384MB, bw=309554KB/s, iops=77388, runt= 54198msec</div><div class="line">    slat (usec): min=3, max=88800, avg= 9.83, stdev=44.88</div><div class="line">    clat (usec): min=5, max=89662, avg=815.09, stdev=381.75</div><div class="line">     lat (usec): min=27, max=89748, avg=825.38, stdev=385.05</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[  470],  5.00th=[  612], 10.00th=[  652], 20.00th=[  684],</div><div class="line">     | 30.00th=[  716], 40.00th=[  756], 50.00th=[  796], 60.00th=[  836],</div><div class="line">     | 70.00th=[  876], 80.00th=[  932], 90.00th=[ 1012], 95.00th=[ 1096],</div><div class="line">     | 99.00th=[ 1272], 99.50th=[ 1368], 99.90th=[ 1688], 99.95th=[ 1912],</div><div class="line">     | 99.99th=[ 3920]</div><div class="line">    bw (KB  /s): min=247208, max=523840, per=99.99%, avg=309507.85, stdev=34709.01</div><div class="line">    lat (usec) : 10=0.01%, 50=0.01%, 100=0.01%, 250=0.01%, 500=1.73%</div><div class="line">    lat (usec) : 750=37.71%, 1000=49.60%</div><div class="line">    lat (msec) : 2=10.91%, 4=0.03%, 10=0.01%, 100=0.01%</div><div class="line">  cpu          : usr=16.00%, sys=79.36%, ctx=138668, majf=0, minf=5522</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued    : total=r=0/w=4194304/d=0, short=r=0/w=0/d=0, drop=r=0/w=0/d=0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">  WRITE: io=16384MB, aggrb=309554KB/s, minb=309554KB/s, maxb=309554KB/s, mint=54198msec, maxt=54198msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">    dm-0: ios=77/1587455, merge=0/0, ticks=184/244940, in_queue=245124, util=98.23%, aggrios=77/1584444, aggrmerge=0/5777, aggrticks=183/193531, aggrin_queue=76, aggrutil=81.60%</div><div class="line">  sda: ios=77/1584444, merge=0/5777, ticks=183/193531, in_queue=76, util=81.60%</div><div class="line">  </div><div class="line">[root@hygon33 13:50 /polarx]</div><div class="line">#echo 3 &gt; /proc/sys/vm/drop_caches ; rm -f ./fio.test; fio -ioengine=libaio -bs=4k -direct=0 -buffered=1 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div><div class="line">EBS 4K randwrite test: (g=0): rw=randwrite, bs=4K-4K/4K-4K/4K-4K, ioengine=libaio, iodepth=64</div><div class="line">fio-2.2.8</div><div class="line">Starting 1 thread</div><div class="line">EBS 4K randwrite test: Laying out IO file(s) (1 file(s) / 16384MB)</div><div class="line">Jobs: 1 (f=1): [w(1)] [100.0% done] [0KB/293.2MB/0KB /s] [0/75.1K/0 iops] [eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=22787: Sat Jan  1 13:51:16 2022</div><div class="line">  write: io=10270MB, bw=175269KB/s, iops=43817, runt= 60001msec</div><div class="line">    slat (usec): min=4, max=2609, avg=19.43, stdev=19.84</div><div class="line">    clat (usec): min=4, max=6420, avg=1438.87, stdev=483.15</div><div class="line">     lat (usec): min=17, max=6718, avg=1458.80, stdev=490.29</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[  700],  5.00th=[  788], 10.00th=[  852], 20.00th=[  964],</div><div class="line">     | 30.00th=[ 1080], 40.00th=[ 1208], 50.00th=[ 1368], 60.00th=[ 1560],</div><div class="line">     | 70.00th=[ 1752], 80.00th=[ 1944], 90.00th=[ 2128], 95.00th=[ 2224],</div><div class="line">     | 99.00th=[ 2416], 99.50th=[ 2480], 99.90th=[ 2672], 99.95th=[ 3248],</div><div class="line">     | 99.99th=[ 5088]</div><div class="line">    bw (KB  /s): min=109992, max=308016, per=99.40%, avg=174219.83, stdev=56844.59</div><div class="line">    lat (usec) : 10=0.01%, 20=0.01%, 50=0.01%, 100=0.01%, 250=0.01%</div><div class="line">    lat (usec) : 500=0.01%, 750=2.87%, 1000=20.63%</div><div class="line">    lat (msec) : 2=59.43%, 4=17.03%, 10=0.03%</div><div class="line">  cpu          : usr=9.11%, sys=57.07%, ctx=762410, majf=0, minf=1769</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued    : total=r=0/w=2629079/d=0, short=r=0/w=0/d=0, drop=r=0/w=0/d=0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">  WRITE: io=10270MB, aggrb=175269KB/s, minb=175269KB/s, maxb=175269KB/s, mint=60001msec, maxt=60001msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">    dm-2: ios=1/3185487, merge=0/0, ticks=0/86364, in_queue=86364, util=46.24%, aggrios=0/1576688, aggrmerge=0/16344, aggrticks=0/40217, aggrin_queue=0, aggrutil=29.99%</div><div class="line">  nvme0n1: ios=0/1786835, merge=0/16931, ticks=0/44447, in_queue=0, util=29.99%</div><div class="line">  nvme1n1: ios=1/1366541, merge=0/15758, ticks=0/35987, in_queue=0, util=25.44%</div></pre></td></tr></table></figure>
<p>将RAID0从两块nvme改成四块后，整体性能略微下降</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line">#fio  -bs=4k -direct=1 -buffered=0 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div><div class="line">EBS 4K randwrite test: (g=0): rw=randwrite, bs=4K-4K/4K-4K/4K-4K, ioengine=sync, iodepth=64</div><div class="line">fio-2.2.8</div><div class="line">Starting 1 thread</div><div class="line">EBS 4K randwrite test: Laying out IO file(s) (1 file(s) / 16384MB)</div><div class="line">Jobs: 1 (f=1): [w(1)] [100.0% done] [0KB/99756KB/0KB /s] [0/24.1K/0 iops] [eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=30608: Sat Jan  1 12:09:29 2022</div><div class="line">  write: io=5733.9MB, bw=97857KB/s, iops=24464, runt= 60001msec</div><div class="line">    clat (usec): min=29, max=2885, avg=37.95, stdev=12.19</div><div class="line">     lat (usec): min=30, max=2886, avg=38.49, stdev=12.20</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[   32],  5.00th=[   33], 10.00th=[   34], 20.00th=[   35],</div><div class="line">     | 30.00th=[   36], 40.00th=[   36], 50.00th=[   37], 60.00th=[   37],</div><div class="line">     | 70.00th=[   38], 80.00th=[   39], 90.00th=[   40], 95.00th=[   49],</div><div class="line">     | 99.00th=[   65], 99.50th=[   76], 99.90th=[  109], 99.95th=[  125],</div><div class="line">     | 99.99th=[  203]</div><div class="line">    bw (KB  /s): min=92968, max=108344, per=99.99%, avg=97846.18, stdev=2085.73</div><div class="line">    lat (usec) : 50=95.20%, 100=4.61%, 250=0.18%, 500=0.01%, 750=0.01%</div><div class="line">    lat (usec) : 1000=0.01%</div><div class="line">    lat (msec) : 2=0.01%, 4=0.01%</div><div class="line">  cpu          : usr=4.67%, sys=56.35%, ctx=1467919, majf=0, minf=1144</div><div class="line">  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, &gt;=64=0.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     issued    : total=r=0/w=1467872/d=0, short=r=0/w=0/d=0, drop=r=0/w=0/d=0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">  WRITE: io=5733.9MB, aggrb=97856KB/s, minb=97856KB/s, maxb=97856KB/s, mint=60001msec, maxt=60001msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">    md0: ios=0/1553786, merge=0/0, ticks=0/0, in_queue=0, util=0.00%, aggrios=0/370860, aggrmerge=0/17733, aggrticks=0/6539, aggrin_queue=0, aggrutil=8.41%</div><div class="line">  nvme6n1: ios=0/369576, merge=0/17648, ticks=0/6439, in_queue=0, util=7.62%</div><div class="line">  nvme5n1: ios=0/370422, merge=0/17611, ticks=0/6600, in_queue=0, util=7.72%</div><div class="line">  nvme4n1: ios=0/371559, merge=0/18092, ticks=0/6511, in_queue=0, util=8.41%</div><div class="line">  nvme7n1: ios=0/371886, merge=0/17584, ticks=0/6606, in_queue=0, util=8.17%</div></pre></td></tr></table></figure>
<h3 id="raid6测试"><a href="#raid6测试" class="headerlink" title="raid6测试"></a>raid6测试</h3><p>raid6开buffer性能比raid0还要好10-20%，实际是将刷盘延迟异步在做，如果用-buffer=0 raid6的性能只有raid0的一半</p>
<p><img src="/images/951413iMgBlog/image-20220105173206915.png" alt="image-20220105173206915"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div></pre></td><td class="code"><pre><div class="line">[root@hygon33 17:19 /md6]</div><div class="line">#echo 3 &gt; /proc/sys/vm/drop_caches ; rm -f ./fio.test; fio -ioengine=libaio -bs=4k -direct=1 -buffered=1 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div><div class="line">EBS 4K randwrite test: (g=0): rw=randwrite, bs=4K-4K/4K-4K/4K-4K, ioengine=libaio, iodepth=64</div><div class="line">fio-2.2.8</div><div class="line">Starting 1 thread</div><div class="line">EBS 4K randwrite test: Laying out IO file(s) (1 file(s) / 16384MB)</div><div class="line">Jobs: 1 (f=1): [w(1)] [100.0% done] [0KB/424.9MB/0KB /s] [0/109K/0 iops] [eta 00m:00s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=117679: Wed Jan  5 17:21:13 2022</div><div class="line">  write: io=16384MB, bw=432135KB/s, iops=108033, runt= 38824msec</div><div class="line">    slat (usec): min=4, max=7289, avg= 6.06, stdev= 5.28</div><div class="line">    clat (usec): min=3, max=7973, avg=584.23, stdev=45.35</div><div class="line">     lat (usec): min=10, max=7986, avg=590.77, stdev=45.75</div><div class="line">    clat percentiles (usec):</div><div class="line">     |  1.00th=[  548],  5.00th=[  556], 10.00th=[  564], 20.00th=[  572],</div><div class="line">     | 30.00th=[  580], 40.00th=[  580], 50.00th=[  580], 60.00th=[  588],</div><div class="line">     | 70.00th=[  588], 80.00th=[  596], 90.00th=[  604], 95.00th=[  612],</div><div class="line">     | 99.00th=[  636], 99.50th=[  660], 99.90th=[  796], 99.95th=[  820],</div><div class="line">     | 99.99th=[  916]</div><div class="line">    bw (KB  /s): min=423896, max=455400, per=99.97%, avg=432015.17, stdev=6404.92</div><div class="line">    lat (usec) : 4=0.01%, 20=0.01%, 50=0.01%, 100=0.01%, 250=0.01%</div><div class="line">    lat (usec) : 500=0.01%, 750=99.78%, 1000=0.21%</div><div class="line">    lat (msec) : 2=0.01%, 4=0.01%, 10=0.01%</div><div class="line">  cpu          : usr=21.20%, sys=78.56%, ctx=57, majf=0, minf=1769</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued    : total=r=0/w=4194304/d=0, short=r=0/w=0/d=0, drop=r=0/w=0/d=0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">  WRITE: io=16384MB, aggrb=432135KB/s, minb=432135KB/s, maxb=432135KB/s, mint=38824msec, maxt=38824msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">    md6: ios=0/162790, merge=0/0, ticks=0/0, in_queue=0, util=0.00%, aggrios=83058/153522, aggrmerge=1516568/962072, aggrticks=29792/16802, aggrin_queue=2425, aggrutil=44.71%</div><div class="line">  nvme0n1: ios=83410/144109, merge=1517412/995022, ticks=31218/16718, in_queue=2416, util=43.62%</div><div class="line">  nvme3n1: ios=83301/162626, merge=1517086/927594, ticks=24190/17067, in_queue=2364, util=34.14%</div><div class="line">  nvme2n1: ios=81594/144341, merge=1514750/992273, ticks=32204/16646, in_queue=2504, util=44.71%</div><div class="line">  nvme1n1: ios=83929/163013, merge=1517025/933399, ticks=31559/16780, in_queue=2416, util=42.83%</div><div class="line"></div><div class="line">[root@hygon33 17:21 /md6]</div><div class="line">#echo 3 &gt; /proc/sys/vm/drop_caches ; rm -f ./fio.test; fio -ioengine=libaio -bs=4k -direct=1 -buffered=0 -thread -rw=randwrite -rwmixread=70 -size=16G -filename=./fio.test -name=&quot;EBS 4K randwrite test&quot; -iodepth=64 -runtime=60</div><div class="line">EBS 4K randwrite test: (g=0): rw=randwrite, bs=4K-4K/4K-4K/4K-4K, ioengine=libaio, iodepth=64</div><div class="line">fio-2.2.8</div><div class="line">Starting 1 thread</div><div class="line">EBS 4K randwrite test: Laying out IO file(s) (1 file(s) / 16384MB)</div><div class="line">Jobs: 1 (f=0): [w(1)] [22.9% done] [0KB/51034KB/0KB /s] [0/12.8K/0 iops] [eta 03m:25s]</div><div class="line">EBS 4K randwrite test: (groupid=0, jobs=1): err= 0: pid=164871: Wed Jan  5 17:25:17 2022</div><div class="line">  write: io=3743.6MB, bw=63887KB/s, iops=15971, runt= 60003msec</div><div class="line">    slat (usec): min=11, max=123152, avg=29.39, stdev=283.93</div><div class="line">    clat (usec): min=261, max=196197, avg=3975.22, stdev=3526.29</div><div class="line">     lat (usec): min=300, max=196223, avg=4005.13, stdev=3554.65</div><div class="line">    clat percentiles (msec):</div><div class="line">     |  1.00th=[    3],  5.00th=[    3], 10.00th=[    4], 20.00th=[    4],</div><div class="line">     | 30.00th=[    4], 40.00th=[    4], 50.00th=[    4], 60.00th=[    4],</div><div class="line">     | 70.00th=[    5], 80.00th=[    5], 90.00th=[    5], 95.00th=[    6],</div><div class="line">     | 99.00th=[    7], 99.50th=[    7], 99.90th=[   39], 99.95th=[   88],</div><div class="line">     | 99.99th=[  167]</div><div class="line">    bw (KB  /s): min=41520, max=78176, per=100.00%, avg=64093.14, stdev=6896.65</div><div class="line">    lat (usec) : 500=0.02%, 750=0.03%, 1000=0.02%</div><div class="line">    lat (msec) : 2=0.73%, 4=64.28%, 10=34.72%, 20=0.06%, 50=0.08%</div><div class="line">    lat (msec) : 100=0.02%, 250=0.05%</div><div class="line">  cpu          : usr=4.11%, sys=48.69%, ctx=357564, majf=0, minf=2653</div><div class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%</div><div class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</div><div class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%</div><div class="line">     issued    : total=r=0/w=958349/d=0, short=r=0/w=0/d=0, drop=r=0/w=0/d=0</div><div class="line">     latency   : target=0, window=0, percentile=100.00%, depth=64</div><div class="line"></div><div class="line">Run status group 0 (all jobs):</div><div class="line">  WRITE: io=3743.6MB, aggrb=63886KB/s, minb=63886KB/s, maxb=63886KB/s, mint=60003msec, maxt=60003msec</div><div class="line"></div><div class="line">Disk stats (read/write):</div><div class="line">    md6: ios=0/1022450, merge=0/0, ticks=0/0, in_queue=0, util=0.00%, aggrios=262364/764703, aggrmerge=430291/192464, aggrticks=38687/55432, aggrin_queue=317, aggrutil=42.63%</div><div class="line">  nvme0n1: ios=262282/759874, merge=430112/209613, ticks=43304/55197, in_queue=324, util=42.63%</div><div class="line">  nvme3n1: ios=260535/771153, merge=430415/176326, ticks=25263/55664, in_queue=280, util=26.11%</div><div class="line">  nvme2n1: ios=263663/758974, merge=430349/208189, ticks=42754/55761, in_queue=280, util=42.14%</div><div class="line">  nvme1n1: ios=262976/768813, merge=430289/175731, ticks=43430/55109, in_queue=384, util=42.00%</div></pre></td></tr></table></figure>
<p>测试完成很久后ssd还维持高水位的读写</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</div><div class="line">           0.28    0.00    1.15    0.05    0.00   98.51</div><div class="line"></div><div class="line">Device            r/s     rkB/s   rrqm/s  %rrqm r_await rareq-sz     w/s     wkB/s   wrqm/s  %wrqm w_await wareq-sz     d/s     dkB/s   drqm/s  %drqm d_await dareq-sz  aqu-sz  %util</div><div class="line">dm-0             5.00     56.00     0.00   0.00    0.53    11.20   39.00    292.33     0.00   0.00    0.00     7.50    0.00      0.00     0.00   0.00    0.00     0.00    0.00   0.27</div><div class="line">md6              0.00      0.00     0.00   0.00    0.00     0.00   14.00   1794.67     0.00   0.00    0.00   128.19    0.00      0.00     0.00   0.00    0.00     0.00    0.00   0.00</div><div class="line">nvme0n1       1164.67 144488.00 34935.33  96.77    0.74   124.06 3203.67  53877.83 10267.00  76.22    0.16    16.82    0.00      0.00     0.00   0.00    0.00     0.00    0.32  32.13</div><div class="line">nvme1n1       1172.33 144402.67 34925.00  96.75    0.74   123.18 3888.67  46635.17  7771.33  66.65    0.13    11.99    0.00      0.00     0.00   0.00    0.00     0.00    0.33  29.60</div><div class="line">nvme2n1       1166.67 144372.00 34914.00  96.77    0.74   123.75 3263.00  53699.17 10162.67  75.70    0.14    16.46    0.00      0.00     0.00   0.00    0.00     0.00    0.33  27.87</div><div class="line">nvme3n1       1157.67 144414.67 34934.33  96.79    0.64   124.75 3894.33  47073.83  7875.00  66.91    0.13    12.09    0.00      0.00     0.00   0.00    0.00     0.00    0.31  20.80</div><div class="line">sda              5.00     56.00     0.00   0.00    0.13    11.20   39.00    204.17     0.00   0.00    0.12     5.24    0.00      0.00     0.00   0.00    0.00     0.00    0.00   0.27</div></pre></td></tr></table></figure>
<h2 id="fio-结果解读"><a href="#fio-结果解读" class="headerlink" title="fio 结果解读"></a>fio 结果解读</h2><p>slat，异步场景下才有</p>
<blockquote>
<p>其中slat指的是发起IO的时间，在异步IO模式下，发起IO以后，IO会异步完成。例如调用一个异步的write，虽然write返回成功了，但是IO还未完成，slat约等于发起write的耗时；</p>
<p>slat (usec): min=4, max=6154, avg=48.82, stdev=56.38： The first latency metric you’ll see is the ‘slat’ or submission latency. It is pretty much what it sounds like, meaning “how long did it take to submit this IO to the kernel for processing?”</p>
</blockquote>
<p>clat</p>
<blockquote>
<p>clat指的是完成时间，从发起IO后到完成IO的时间，在同步IO模式下，clat是指整个写动作完成时间</p>
</blockquote>
<p>lat</p>
<blockquote>
<p>lat是总延迟时间，指的是IO单元创建到完成的总时间，通常这项数据关注较多。同步场景几乎等于clat，异步场景等于clat+slat<br>这项数据需要关注的是max，看看有没有极端的高延迟IO；另外还需要关注stdev，这项数据越大说明，IO响应时间波动越大，反之越小，波动越小</p>
</blockquote>
<p>clat percentiles (usec)：处于某个百分位的io操作时延</p>
<p>cpu          : usr=9.11%, sys=57.07%, ctx=762410, majf=0, minf=1769  //用户和系统的CPU占用时间百分比，线程切换次数，major以及minor页面错误的数量。</p>
<p>direct和buffered参数是冲突的，用一个就行，应该是direct=0性能更好，实际不是这样，这里还需要找资料求证下</p>
<blockquote>
<ul>
<li><p><code>direct``=bool</code></p>
<p>If value is true, use non-buffered I/O. This is usually O_DIRECT. Note that OpenBSD and ZFS on Solaris don’t support direct I/O. On Windows the synchronous ioengines don’t support direct I/O. Default: false.</p>
</li>
<li><p><code>buffered``=bool</code></p>
<p>If value is true, use buffered I/O. This is the opposite of the <a href="https://fio.readthedocs.io/en/latest/fio_man.html#cmdoption-arg-direct" target="_blank" rel="external"><code>direct</code></a> option. Defaults to true.</p>
</li>
</ul>
</blockquote>
<h2 id="iostat-结果解读"><a href="#iostat-结果解读" class="headerlink" title="iostat 结果解读"></a><a href="linuxtools-rst.readthedocs.io/zh_CN/latest/tool/iostat.html">iostat 结果解读</a></h2><p>Dm-0就是lvm</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</div><div class="line">           0.32    0.00    3.34    0.13    0.00   96.21</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">sda               0.00    11.40   66.00    7.20  1227.20    74.40    35.56     0.03    0.43    0.47    0.08   0.12   0.88</div><div class="line">nvme0n1           0.00  8612.00    0.00 51749.60     0.00 241463.20     9.33     4.51    0.09    0.00    0.09   0.02  78.56</div><div class="line">dm-0              0.00     0.00    0.00 60361.80     0.00 241463.20     8.00   152.52    2.53    0.00    2.53   0.01  78.26</div><div class="line"></div><div class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</div><div class="line">           0.36    0.00    3.46    0.17    0.00   96.00</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">sda               0.00     8.80    9.20    5.20  1047.20    67.20   154.78     0.01    0.36    0.46    0.19   0.33   0.48</div><div class="line">nvme0n1           0.00 11354.20    0.00 50876.80     0.00 248944.00     9.79     5.25    0.10    0.00    0.10   0.02  80.06</div><div class="line">dm-0              0.00     0.00    0.00 62231.00     0.00 248944.80     8.00   199.49    3.21    0.00    3.21   0.01  78.86</div></pre></td></tr></table></figure>
<p>avgqu_sz，是iostat的一项比较重要的数据。如果队列过长，则表示有大量IO在处理或等待，但是这还不足以说明后端的存储系统达到了处理极限。例如后端存储的并发能力是4096，客户端并发发送了256个IO下去，那么队列长度就是256。即使长时间队列长度是256，也不能说明什么，仅仅表明队列长度是256，有256个IO在处理或者排队。</p>
<p>那么怎么判断IO是在调度队列排队等待，还是在设备上处理呢？iostat有两项数据可以给出一个大致的判断。svctime，这项数据的指的是IO在设备处理中耗费的时间。另外一项数据await，指的是IO从排队到完成的时间，包括了svctime和排队等待的时间。那么通过对比这两项数据，如果两项数据差不多，则说明IO基本没有排队等待，耗费的时间都是设备处理。如果await远大于svctime，则说明有大量的IO在排队，并没有发送给设备处理。</p>
<h2 id="不同厂家SSD性能对比"><a href="#不同厂家SSD性能对比" class="headerlink" title="不同厂家SSD性能对比"></a>不同厂家SSD性能对比</h2><p>国产SSD指的是AliFlash</p>
<p><img src="/images/951413iMgBlog/1638359029693-73b42c13-2649-4f20-9112-a7c4c5dd5432.png" alt="img"></p>
<p><img src="/images/951413iMgBlog/1638358969626-507f34aa-201b-4fd3-91de-66c88c6ce04a.png" alt="img"></p>
<h2 id="rq-affinity"><a href="#rq-affinity" class="headerlink" title="rq_affinity"></a>rq_affinity</h2><p>参考<a href="https://help.aliyun.com/knowledge_detail/65077.html#title-x10-2c0-yll" target="_blank" rel="external">aliyun测试文档</a> , rq_affinity增加2的commit： git show 5757a6d76c</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line">function RunFio</div><div class="line">&#123;</div><div class="line"> numjobs=$1   # 实例中的测试线程数，例如示例中的10</div><div class="line"> iodepth=$2   # 同时发出I/O数的上限，例如示例中的64</div><div class="line"> bs=$3        # 单次I/O的块文件大小，例如示例中的4k</div><div class="line"> rw=$4        # 测试时的读写策略，例如示例中的randwrite</div><div class="line"> filename=$5  # 指定测试文件的名称，例如示例中的/dev/your_device</div><div class="line"> nr_cpus=`cat /proc/cpuinfo |grep &quot;processor&quot; |wc -l`</div><div class="line"> if [ $nr_cpus -lt $numjobs ];then</div><div class="line">     echo “Numjobs is more than cpu cores, exit!”</div><div class="line">     exit -1</div><div class="line"> fi</div><div class="line"> let nu=$numjobs+1</div><div class="line"> cpulist=&quot;&quot;</div><div class="line"> for ((i=1;i&lt;10;i++))</div><div class="line"> do</div><div class="line">     list=`cat /sys/block/your_device/mq/*/cpu_list | awk &apos;&#123;if(i&lt;=NF) print $i;&#125;&apos; i=&quot;$i&quot; | tr -d &apos;,&apos; | tr &apos;\n&apos; &apos;,&apos;`</div><div class="line">     if [ -z $list ];then</div><div class="line">         break</div><div class="line">     fi</div><div class="line">     cpulist=$&#123;cpulist&#125;$&#123;list&#125;</div><div class="line"> done</div><div class="line"> spincpu=`echo $cpulist | cut -d &apos;,&apos; -f 2-$&#123;nu&#125;`</div><div class="line"> echo $spincpu</div><div class="line"> fio --ioengine=libaio --runtime=30s --numjobs=$&#123;numjobs&#125; --iodepth=$&#123;iodepth&#125; --bs=$&#123;bs&#125; --rw=$&#123;rw&#125; --filename=$&#123;filename&#125; --time_based=1 --direct=1 --name=test --group_reporting --cpus_allowed=$spincpu --cpus_allowed_policy=split</div><div class="line">&#125;</div><div class="line">echo 2 &gt; /sys/block/your_device/queue/rq_affinity</div><div class="line">sleep 5</div><div class="line">RunFio 10 64 4k randwrite filename</div></pre></td></tr></table></figure>
<p>对NVME SSD进行测试，左边rq_affinity是2，右边rq_affinity为1，在这个测试参数下rq_affinity为1的性能要好(后许多次测试两者性能差不多)</p>
<p><img src="/images/951413iMgBlog/image-20210607113709945.png" alt="image-20210607113709945"></p>
<h2 id="磁盘挂载参数"><a href="#磁盘挂载参数" class="headerlink" title="磁盘挂载参数"></a>磁盘挂载参数</h2><p>内核一般配置的脏页回写超时时间是30s，理论上page cache能buffer住所有的脏页，但是ext4文件系统的默认挂载参数开始支持日志（journal），文件的inode被修改后，需要刷到journal里，这样系统crash了文件系统能恢复过来，内核配置默认5s刷一次journal。</p>
<p>ext4还有一个配置项叫挂载方式，有<code>ordered</code>和<code>writeback</code>两个选项，区别是ordered在把inode刷到journal里之前，会把inode的所有脏页先回写到磁盘里，如果不希望inode这么快写回到磁盘则可以用writeback参数。当SSD开始写盘的时候会严重影响SSD读能力</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># 编辑/etc/fstab，挂载参数设置为defaults,noatime,nodiratime,delalloc,nobarrier,data=writeback</div><div class="line">/dev/lvm1 /data    ext4    defaults,noatime,nodiratime,delalloc,nobarrier,data=writeback 0 0</div></pre></td></tr></table></figure>
<p><code>noatime</code> 读取文件时，将禁用对元数据的更新。它还启用了 nodiratime 行为，该行为会在读取目录时禁用对元数据的更新</p>
<p><code>nodelalloc</code> 参数是关闭了ext4的delayed  allocation 特性。所谓delayed allocation 是指，把磁盘block的分配推后到真正要写数据的时候，比如写入文件的时候，先写内存，当数据需要落盘的时候，再由文件系统分配磁盘块，这有利于文件系统做出更佳的磁盘块分配决策，比如可以分配大片连续的磁盘块。显然 nodelalloc 性能要差些</p>
<p><code>nobarrier</code> 参数是不保证先写入文件系统日志然后才写入数据，也就是不保证系统崩溃后文件系统恢复的正确性,但是对写入性能有提升</p>
<h3 id="优化case"><a href="#优化case" class="headerlink" title="优化case"></a>优化case</h3><p>10个GB的原始文件里面都是随机数，如何快速建索引支持分页查询top(k,n)场景，机器配置是24核，JVM堆内存限制2.5G，磁盘读写为490-500MB/s左右。</p>
<p>最后成绩在22.9s，去掉评测方法引入的1.1s，5次查询含建索引总时间21.8s，因为读10GB文件就需要21.5s时间。当向SSD开始写索引文件后SSD读取性能下降厉害，实际期望的是写出索引到SSD的时候会被PageCache，没触发刷脏。但是这里的刷盘就是ext4挂载参数 ordered 导致了刷盘。</p>
<p>整个方案是：原始文件切割成小分片，喂给24个worker；每个worker读数据，处理数据，定期批量写索引出去；最后查询会去读每个worker生成的所有索引文件，通过跳表快速seek。</p>
<p><img src="/images/951413iMgBlog/586fef765e3f08f6183907f311a76259.png" alt="img"></p>
<h2 id="LVM性能对比"><a href="#LVM性能对比" class="headerlink" title="LVM性能对比"></a>LVM性能对比</h2><p>磁盘信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">#lsblk</div><div class="line">NAME         MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT</div><div class="line">sda            8:0    0 223.6G  0 disk</div><div class="line">├─sda1         8:1    0     3M  0 part</div><div class="line">├─sda2         8:2    0     1G  0 part /boot</div><div class="line">├─sda3         8:3    0    96G  0 part /</div><div class="line">├─sda4         8:4    0    10G  0 part /tmp</div><div class="line">└─sda5         8:5    0 116.6G  0 part /home</div><div class="line">nvme0n1      259:4    0   2.7T  0 disk</div><div class="line">└─nvme0n1p1  259:5    0   2.7T  0 part</div><div class="line">  └─vg1-drds 252:0    0   5.4T  0 lvm  /drds</div><div class="line">nvme1n1      259:0    0   2.7T  0 disk</div><div class="line">└─nvme1n1p1  259:2    0   2.7T  0 part /u02</div><div class="line">nvme2n1      259:1    0   2.7T  0 disk</div><div class="line">└─nvme2n1p1  259:3    0   2.7T  0 part</div><div class="line">  └─vg1-drds 252:0    0   5.4T  0 lvm  /drds</div></pre></td></tr></table></figure>
<p>单块nvme SSD盘跑mysql server，运行sysbench导入测试数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div></pre></td><td class="code"><pre><div class="line">#iostat -x nvme1n1 1</div><div class="line">Linux 3.10.0-327.ali2017.alios7.x86_64 (k28a11352.eu95sqa) 	05/13/2021 	_x86_64_	(64 CPU)</div><div class="line"></div><div class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</div><div class="line">           0.32    0.00    0.17    0.07    0.00   99.44</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">nvme1n1           0.00    47.19    0.19  445.15     2.03 43110.89   193.62     0.31    0.70    0.03    0.70   0.06   2.85</div><div class="line"></div><div class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</div><div class="line">           1.16    0.00    0.36    0.17    0.00   98.31</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">nvme1n1           0.00   122.00    0.00 3290.00     0.00 271052.00   164.77     1.65    0.50    0.00    0.50   0.05  17.00</div><div class="line"></div><div class="line">#iostat 1</div><div class="line">Linux 3.10.0-327.ali2017.alios7.x86_64 (k28a11352.eu95sqa) 	05/13/2021 	_x86_64_	(64 CPU)</div><div class="line"></div><div class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</div><div class="line">           0.14    0.00    0.13    0.05    0.00   99.67</div><div class="line"></div><div class="line">Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn</div><div class="line">sda              49.21       554.51      2315.83    1416900    5917488</div><div class="line">nvme1n1           5.65         2.34       844.73       5989    2158468</div><div class="line">nvme2n1           0.06         1.13         0.00       2896          0</div><div class="line">nvme0n1           0.06         1.13         0.00       2900          0</div><div class="line">dm-0              0.02         0.41         0.00       1036          0</div><div class="line"></div><div class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</div><div class="line">           1.39    0.00    0.23    0.08    0.00   98.30</div><div class="line"></div><div class="line">Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn</div><div class="line">sda               8.00         0.00        60.00          0         60</div><div class="line">nvme1n1         868.00         0.00    132100.00          0     132100</div><div class="line">nvme2n1           0.00         0.00         0.00          0          0</div><div class="line">nvme0n1           0.00         0.00         0.00          0          0</div><div class="line">dm-0              0.00         0.00         0.00          0          0</div><div class="line"></div><div class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</div><div class="line">           1.44    0.00    0.14    0.09    0.00   98.33</div><div class="line"></div><div class="line">Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn</div><div class="line">sda               0.00         0.00         0.00          0          0</div><div class="line">nvme1n1         766.00         0.00    132780.00          0     132780</div><div class="line">nvme2n1           0.00         0.00         0.00          0          0</div><div class="line">nvme0n1           0.00         0.00         0.00          0          0</div><div class="line">dm-0              0.00         0.00         0.00          0          0</div><div class="line"></div><div class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</div><div class="line">           1.41    0.00    0.16    0.09    0.00   98.34</div><div class="line"></div><div class="line">Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn</div><div class="line">sda             105.00         0.00       532.00          0        532</div><div class="line">nvme1n1         760.00         0.00    122236.00          0     122236</div><div class="line">nvme2n1           0.00         0.00         0.00          0          0</div><div class="line">nvme0n1           0.00         0.00         0.00          0          0</div><div class="line">dm-0              0.00         0.00         0.00          0          0</div></pre></td></tr></table></figure>
<p>如果同样写lvm，由两块nvme组成</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div></pre></td><td class="code"><pre><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">nvme2n1           0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00</div><div class="line">nvme0n1           0.00   137.00    0.00 5730.00     0.00 421112.00   146.98     2.95    0.52    0.00    0.52   0.05  27.30</div><div class="line"></div><div class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</div><div class="line">           1.17    0.00    0.34    0.19    0.00   98.30</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">nvme2n1           0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00</div><div class="line">nvme0n1           0.00   109.00    0.00 2533.00     0.00 271236.00   214.16     1.08    0.43    0.00    0.43   0.06  15.90</div><div class="line"></div><div class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</div><div class="line">           1.38    0.00    0.42    0.20    0.00   98.00</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">nvme2n1           0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00</div><div class="line">nvme0n1           0.00   118.00    0.00 3336.00     0.00 320708.00   192.27     1.50    0.45    0.00    0.45   0.06  20.00</div><div class="line"></div><div class="line">[root@k28a11352.eu95sqa /var/lib]</div><div class="line">#iostat  1</div><div class="line">Linux 3.10.0-327.ali2017.alios7.x86_64 (k28a11352.eu95sqa) 	05/13/2021 	_x86_64_	(64 CPU)</div><div class="line"></div><div class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</div><div class="line">           0.40    0.00    0.20    0.07    0.00   99.33</div><div class="line"></div><div class="line">Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn</div><div class="line">sda              38.96       334.64      1449.68    1419236    6148304</div><div class="line">nvme1n1         324.95         1.43     31201.30       6069  132329072</div><div class="line">nvme2n1           0.07         0.90         0.00       3808          0</div><div class="line">nvme0n1         256.24         1.60     22918.46       6801   97200388</div><div class="line">dm-0            266.98         1.38     22918.46       5849   97200388</div><div class="line"></div><div class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</div><div class="line">           1.20    0.00    0.42    0.25    0.00   98.12</div><div class="line"></div><div class="line">Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn</div><div class="line">sda               0.00         0.00         0.00          0          0</div><div class="line">nvme1n1           0.00         0.00         0.00          0          0</div><div class="line">nvme2n1           0.00         0.00         0.00          0          0</div><div class="line">nvme0n1        4460.00         0.00    332288.00          0     332288</div><div class="line">dm-0           4608.00         0.00    332288.00          0     332288</div><div class="line"></div><div class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</div><div class="line">           1.35    0.00    0.38    0.22    0.00   98.06</div><div class="line"></div><div class="line">Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn</div><div class="line">sda              48.00         0.00       200.00          0        200</div><div class="line">nvme1n1           0.00         0.00         0.00          0          0</div><div class="line">nvme2n1           0.00         0.00         0.00          0          0</div><div class="line">nvme0n1        4187.00         0.00    332368.00          0     332368</div><div class="line">dm-0           4348.00         0.00    332368.00          0     332368</div></pre></td></tr></table></figure>
<h2 id="数据总结"><a href="#数据总结" class="headerlink" title="数据总结"></a>数据总结</h2><ul>
<li>性能排序 NVMe SSD &gt; SATA SSD &gt; SAN &gt; ESSD &gt; HDD</li>
<li>本地ssd性能最好、sas机械盘(RAID10)性能最差</li>
<li>san存储走特定的光纤网络，不是走tcp的san（至少从网卡看不到san的流量），性能居中</li>
<li>从rt来看 ssd:san:sas 大概是 1:3:15</li>
<li>san比本地sas机械盘性能要好，这也许取决于san的网络传输性能和san存储中的设备（比如用的ssd而不是机械盘）</li>
<li>NVMe SSD比SATA SSD快很多，latency更稳定</li>
<li>阿里云的云盘ESSD比本地SAS RAID10阵列性能还好</li>
<li>软RAID、LVM等阵列都会导致性能损耗，即使多盘一起读写也不如单盘性能</li>
<li>不同测试场景(4K/8K/ 读写、随机与否)会导致不同品牌性能数据差异较大</li>
</ul>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="http://cizixs.com/2017/01/03/how-slow-is-disk-and-network" target="_blank" rel="external">http://cizixs.com/2017/01/03/how-slow-is-disk-and-network</a></p>
<p><a href="https://tobert.github.io/post/2014-04-17-fio-output-explained.html" target="_blank" rel="external">https://tobert.github.io/post/2014-04-17-fio-output-explained.html</a> </p>
<p><a href="https://zhuanlan.zhihu.com/p/40497397" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/40497397</a></p>
<p><a href="https://www.atatech.org/articles/167736?spm=ata.home.0.0.11fd75362qwsg7&amp;flag_data_from=home_algorithm_article" target="_blank" rel="external">块存储NVMe云盘原型实践</a></p>
<p><a href="https://mp.weixin.qq.com/s?__biz=MjM5Njg5NDgwNA==&amp;mid=2247483999&amp;idx=1&amp;sn=238d3d1a8cf24443db0da4aa00c9fb7e&amp;chksm=a6e3036491948a72704e0b114790483f227b7ce82f5eece5dd870ef88a8391a03eca27e8ff61&amp;scene=178&amp;cur_album_id=1371808335259090944#rd" target="_blank" rel="external">机械硬盘随机IO慢的超乎你的想象</a></p>
<p><a href="https://mp.weixin.qq.com/s?__biz=MjM5Njg5NDgwNA==&amp;mid=2247484023&amp;idx=1&amp;sn=1946b4c286ed72da023b402cc30908b6&amp;chksm=a6e3034c91948a5aa3b0e6beb31c1d3804de9a11c668400d598c2a6b12462e179cf9f1dc33e2&amp;scene=178&amp;cur_album_id=1371808335259090944#rd" target="_blank" rel="external">搭载固态硬盘的服务器究竟比搭机械硬盘快多少？</a></p>
<p><a href="http://www.360doc.com/content/15/0318/15/16824943_456186965.shtml" target="_blank" rel="external">SSD基本工作原理</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/347599423" target="_blank" rel="external">SSD原理解读</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2022/01/19/kubernetes calico网络/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/01/19/kubernetes calico网络/" itemprop="url">kubernetes calico网络</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-01-19T11:30:03+08:00">
                2022-01-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/docker/" itemprop="url" rel="index">
                    <span itemprop="name">docker</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="kubernetes-calico网络"><a href="#kubernetes-calico网络" class="headerlink" title="kubernetes calico网络"></a>kubernetes calico网络</h1><h2 id="cni-网络"><a href="#cni-网络" class="headerlink" title="cni 网络"></a>cni 网络</h2><blockquote>
<p> <strong>cni0</strong> is a Linux network bridge device, all <strong>veth</strong> devices will connect to this bridge, so all Pods on the same node can communicate with each other, as explained in <strong>Kubernetes Network Model</strong> and the hotel analogy above.</p>
</blockquote>
<h3 id="cni（Container-Network-Interface）"><a href="#cni（Container-Network-Interface）" class="headerlink" title="cni（Container Network Interface）"></a>cni（Container Network Interface）</h3><p>CNI 全称为 Container Network Interface，是用来定义容器网络的一个 <a href="https://github.com/containernetworking/cni/blob/master/SPEC.md" target="_blank" rel="external">规范</a>。<a href="https://github.com/containernetworking/cni" target="_blank" rel="external">containernetworking/cni</a> 是一个 CNCF 的 CNI 实现项目，包括基本额 bridge,macvlan等基本网络插件。</p>
<p>一般将cni各种网络插件的可执行文件二进制放到 <code>/opt/cni/bin</code> ，在 <code>/etc/cni/net.d/</code> 下创建配置文件，剩下的就交给 K8s 或者 containerd 了，我们不关心也不了解其实现。</p>
<p>比如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">#ls -lh /opt/cni/bin/</div><div class="line">总用量 90M</div><div class="line">-rwxr-x--- 1 root root 4.0M 12月 23 09:39 bandwidth</div><div class="line">-rwxr-x--- 1 root root  35M 12月 23 09:39 calico</div><div class="line">-rwxr-x--- 1 root root  35M 12月 23 09:39 calico-ipam</div><div class="line">-rwxr-x--- 1 root root 3.0M 12月 23 09:39 flannel</div><div class="line">-rwxr-x--- 1 root root 3.5M 12月 23 09:39 host-local</div><div class="line">-rwxr-x--- 1 root root 3.1M 12月 23 09:39 loopback</div><div class="line">-rwxr-x--- 1 root root 3.8M 12月 23 09:39 portmap</div><div class="line">-rwxr-x--- 1 root root 3.3M 12月 23 09:39 tuning</div><div class="line"></div><div class="line">[root@hygon3 15:55 /root]</div><div class="line">#ls -lh /etc/cni/net.d/</div><div class="line">总用量 12K</div><div class="line">-rw-r--r-- 1 root root  607 12月 23 09:39 10-calico.conflist</div><div class="line">-rw-r----- 1 root root  292 12月 23 09:47 10-flannel.conflist</div><div class="line">-rw------- 1 root root 2.6K 12月 23 09:39 calico-kubeconfig</div></pre></td></tr></table></figure>
<p>CNI 插件都是直接通过 exec 的方式调用，而不是通过 socket 这样 C/S 方式，所有参数都是通过环境变量、标准输入输出来实现的。</p>
<p>Step-by-step communication from <strong>Pod 1</strong> to <strong>Pod 6</strong>:</p>
<ol>
<li><em>Package leaves</em> <strong><em>Pod 1 netns\</em></strong> <em>through the</em> <strong><em>eth1\</em></strong> <em>interface and reaches the</em> <strong><em>root netns\</em></strong> <em>through the virtual interface</em> <strong><em>veth1*</em></strong>;*</li>
<li><em>Package leaves</em> <strong><em>veth1\</em></strong> <em>and reaches</em> <strong><em>cni0*</em></strong>, looking for<em> **</em>Pod 6*<em>**’s</em> <em>address;</em></li>
<li><em>Package leaves</em> <strong><em>cni0\</em></strong> <em>and is redirected to</em> <strong><em>eth0*</em></strong>;*</li>
<li><em>Package leaves</em> <strong><em>eth0\</em></strong> <em>from</em> <strong><em>Master 1\</em></strong> <em>and reaches the</em> <strong><em>gateway*</em></strong>;*</li>
<li><em>Package leaves the</em> <strong><em>gateway\</em></strong> <em>and reaches the</em> <strong><em>root netns\</em></strong> <em>through the</em> <strong><em>eth0\</em></strong> <em>interface on</em> <strong><em>Worker 1*</em></strong>;*</li>
<li><em>Package leaves</em> <strong><em>eth0\</em></strong> <em>and reaches</em> <strong><em>cni0*</em></strong>, looking for<em> **</em>Pod 6*<em>**’s</em> <em>address;</em></li>
<li><em>Package leaves</em> <strong><em>cni0\</em></strong> <em>and is redirected to the</em> <strong><em>veth6\</em></strong> <em>virtual interface;</em></li>
<li><em>Package leaves the</em> <strong><em>root netns\</em></strong> <em>through</em> <strong><em>veth6\</em></strong> <em>and reaches the</em> <strong><em>Pod 6 netns\</em></strong> <em>though the</em> <strong><em>eth6\</em></strong> <em>interface;</em></li>
</ol>
<p><img src="/images/951413iMgBlog/image-20220115124747936.png" alt="image-20220115124747936"></p>
<h2 id="kubernetes-calico-网络"><a href="#kubernetes-calico-网络" class="headerlink" title="kubernetes calico 网络"></a>kubernetes calico 网络</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml</div><div class="line"></div><div class="line">#或者老版本的calico</div><div class="line">curl https://docs.projectcalico.org/v3.15/manifests/calico.yaml -o calico.yaml</div></pre></td></tr></table></figure>
<p>默认calico用的是ipip封包（这个性能跟原生网络差多少有待验证，本质也是overlay网络，比flannel那种要好很多吗？）</p>
<p>跨宿主机的两个容器之间的流量链路是：</p>
<blockquote>
<p>cali-容器eth0-&gt;宿主机cali27dce37c0e8-&gt;tunl0-&gt;内核ipip模块封包-&gt;物理网卡（ipip封包后）—远程–&gt; 物理网卡-&gt;内核ipip模块解包-&gt;tunl0-&gt;cali-容器</p>
</blockquote>
<p><img src="/images/oss/a1767a5f2cbc2c48c1a35da9f3232a2c.png" alt="image.png"></p>
<p>Calico IPIP模式对物理网络无侵入，符合云原生容器网络要求；使用IPIP封包，性能略低于Calico BGP模式；无法使用传统防火墙管理、也无法和存量网络直接打通。Pod在Node做SNAT访问外部，Pod流量不易被监控。</p>
<h2 id="calico-ipip网络不通"><a href="#calico-ipip网络不通" class="headerlink" title="calico ipip网络不通"></a>calico ipip网络不通</h2><p>集群有五台机器192.168.0.110-114, 同时每个node都有另外一个ip：192.168.3.110-114，部分节点之间不通。每台机器部署好calico网络后，会分配一个 /26 CIRD 子网（64个ip）。</p>
<h3 id="案例1"><a href="#案例1" class="headerlink" title="案例1"></a>案例1</h3><p>目标机是10.122.127.128（宿主机ip 192.168.3.112），如果从10.122.17.64（宿主机ip 192.168.3.110） ping 10.122.127.128不通，查看10.122.127.128路由表：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[root@az3-k8s-13 ~]# ip route |grep tunl0</div><div class="line">10.122.17.64/26 via 10.122.127.128 dev tunl0  //这条路由不通</div><div class="line">[root@az3-k8s-13 ~]# ip route del 10.122.17.64/26 via 10.122.127.128 dev tunl0 ; ip route add 10.122.17.64/26 via 192.168.3.110 dev tunl0 proto bird onlink</div><div class="line"></div><div class="line">[root@az3-k8s-13 ~]# ip route |grep tunl0</div><div class="line">10.122.17.64/26 via 192.168.3.110 dev tunl0 proto bird onlink //这样就通了</div></pre></td></tr></table></figure>
<p>在10.122.127.128抓包如下，明显可以看到icmp request到了 tunl0网卡，tunl0网卡也回复了，但是回复包没有经过kernel ipip模块封装后发到eth1上：</p>
<p><img src="/images/oss/d3111417ce646ca1475def5bea01e6b9.png" alt="image.png"></p>
<p>正常机器应该是这样，上图不正常的时候缺少红框中的reply：</p>
<p><img src="/images/oss/9ea9041af1211b2a5b8de4e216044465.png" alt="image.png"></p>
<p>解决：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">ip route del 10.122.17.64/26 via 10.122.127.128 dev tunl0 ; </div><div class="line">ip route add 10.122.17.64/26 via 192.168.3.110 dev tunl0 proto bird onlink</div></pre></td></tr></table></figure>
<p>删除错误路由增加新的路由就可以了，新增路由的意思是从tunl0发给10.122.17.64/26的包下一跳是 192.168.3.110。</p>
<p> via 192.168.3.110 表示下一跳的ip</p>
<p>onlink参数的作用：<br>使用这个参数将会告诉内核，不必检查网关是否可达。因为在linux内核中，网关与本地的网段不同是被认为不可达的，从而拒绝执行添加路由的操作。</p>
<p>因为tunl0网卡ip的 CIDR 是32，也就是不属于任何子网，那么这个网卡上的路由没有网关，配置路由的话必须是onlink, 内核存也没法根据子网来选择到这块网卡，所以还会加上 dev 指定网卡。</p>
<h3 id="案例2"><a href="#案例2" class="headerlink" title="案例2"></a>案例2</h3><p>集群有五台机器192.168.0.110-114, 同时每个node都有另外一个ip：192.168.3.110-114，只有node2没有192.168.3.111这个ip，结果node2跟其他节点都不通：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">#calicoctl node status</div><div class="line">Calico process is running.</div><div class="line"></div><div class="line">IPv4 BGP status</div><div class="line">+---------------+-------------------+-------+------------+-------------+</div><div class="line">| PEER ADDRESS  |     PEER TYPE     | STATE |   SINCE    |    INFO     |</div><div class="line">+---------------+-------------------+-------+------------+-------------+</div><div class="line">| 192.168.0.111 | node-to-node mesh | up    | 2020-08-29 | Established |</div><div class="line">| 192.168.3.112 | node-to-node mesh | up    | 2020-08-29 | Established |</div><div class="line">| 192.168.3.113 | node-to-node mesh | up    | 2020-08-29 | Established |</div><div class="line">| 192.168.3.114 | node-to-node mesh | up    | 2020-08-29 | Established |</div><div class="line">+---------------+-------------------+-------+------------+-------------+</div></pre></td></tr></table></figure>
<p>从node4 ping node2，然后在node2上抓包，可以看到 icmp request都发到了node2上，但是node2收到后没有发给tunl0：</p>
<p><img src="/images/oss/16fda9322e9a59c37c11629acc611bf3.png" alt="image.png"></p>
<p>所以icmp没有回复，这里的问题在于<strong>kernel收到包后为什么不给tunl0</strong></p>
<p>同样，在node2上ping node4，同时在node2上抓包，可以看到发给node4的request包和reply包：</p>
<p><img src="/images/oss/c6d1706b6f8162cfac528ddf5319c8e2.png" alt="image.png"></p>
<p>从request包可以看到src ip 是0.111， dest ip是 3.113，<strong>因为 node2 没有192.168.3.111这个ip</strong></p>
<p>非常关键的我们看到node4的回复包 src ip 不是3.113，而是0.113（根据node4的路由就应该是0.113）</p>
<p><img src="/images/oss/5c7172e2422579eb99c66e881d47bf99.png" alt="image.png"></p>
<p>这就是问题所在，从node4过来的ipip包src ip都是0.113，实际这里ipip能认识的只是3.113. </p>
<p>如果这个时候在3.113机器上把0.113网卡down掉，那么3.113上的：</p>
<p>10.122.124.128/26 via 192.168.0.111 dev tunl0 proto bird onlink 路由被自动删除，3.113将不再回复request。这是因为calico记录的node2的ip是192.168.0.111，所以会自动增加</p>
<p>解决办法，在node4上删除这条路由记录，也就是强制让回复包走3.113网卡，这样收发的ip就能对应上了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">ip route del 192.168.0.0/24 dev eth0 proto kernel scope link src 192.168.0.113</div><div class="line">//同时将默认路由改到3.113</div><div class="line">ip route del default via 192.168.0.253 dev eth0; </div><div class="line">ip route add default via 192.168.3.253 dev eth1</div></pre></td></tr></table></figure>
<p>最终OK后，node4上的ip route是这样的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">[root@az3-k8s-14 ~]# ip route</div><div class="line">default via 192.168.3.253 dev eth1 </div><div class="line">10.122.17.64/26 via 192.168.3.110 dev tunl0 proto bird onlink </div><div class="line">10.122.124.128/26 via 192.168.0.111 dev tunl0 proto bird onlink </div><div class="line">10.122.127.128/26 via 192.168.3.112 dev tunl0 proto bird onlink </div><div class="line">blackhole 10.122.157.128/26 proto bird </div><div class="line">10.122.157.129 dev cali19f6ea143e3 scope link </div><div class="line">10.122.157.130 dev cali09e016ead53 scope link </div><div class="line">10.122.157.131 dev cali0ad3225816d scope link </div><div class="line">10.122.157.132 dev cali55a5ff1a4aa scope link </div><div class="line">10.122.157.133 dev cali01cf8687c65 scope link </div><div class="line">10.122.157.134 dev cali65232d7ada6 scope link </div><div class="line">10.122.173.128/26 via 192.168.3.114 dev tunl0 proto bird onlink </div><div class="line">172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 </div><div class="line">192.168.3.0/24 dev eth1 proto kernel scope link src 192.168.3.113</div></pre></td></tr></table></figure>
<p>正常后的抓包, 注意这里drequest的est ip 和reply的 src ip终于一致了：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">//request</div><div class="line">00:16:3e:02:06:1e &gt; ee:ff:ff:ff:ff:ff, ethertype IPv4 (0x0800), length 118: (tos 0x0, ttl 64, id 57971, offset 0, flags [DF], proto IPIP (4), length 104)</div><div class="line">    192.168.0.111 &gt; 192.168.3.110: (tos 0x0, ttl 64, id 18953, offset 0, flags [DF], proto ICMP (1), length 84)</div><div class="line">    10.122.124.128 &gt; 10.122.17.64: ICMP echo request, id 22001, seq 4, length 64</div><div class="line">    </div><div class="line">//reply    </div><div class="line">ee:ff:ff:ff:ff:ff &gt; 00:16:3e:02:06:1e, ethertype IPv4 (0x0800), length 118: (tos 0x0, ttl 64, id 2565, offset 0, flags [none], proto IPIP (4), length 104)</div><div class="line">    192.168.3.110 &gt; 192.168.0.111: (tos 0x0, ttl 64, id 26374, offset 0, flags [none], proto ICMP (1), length 84)</div><div class="line">    10.122.17.64 &gt; 10.122.124.128: ICMP echo reply, id 22001, seq 4, length 64</div></pre></td></tr></table></figure>
<p>总结下来这两个案例都还是对路由不够了解，特别是案例2，因为有了多个网卡后导致路由更复杂。calico ipip的基本原理就是利用内核进行ipip封包，然后修改路由来保证网络的畅通。</p>
<h2 id="netns-操作"><a href="#netns-操作" class="headerlink" title="netns 操作"></a><a href="https://mp.weixin.qq.com/s/lscMpc5BWAEzjgYw6H0wBw" target="_blank" rel="external">netns 操作</a></h2><p>以下case创建一个名为 ren 的netns，然后在里面增加一对虚拟网卡veth1 veth1_p,  veth1放置在ren里面，veth1_p 放在物理机上，给他们配置上ip并up就能通了。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div></pre></td><td class="code"><pre><div class="line"> 1004  [2021-10-27 10:49:08] ip netns add ren</div><div class="line"> 1005  [2021-10-27 10:49:12] ip netns show</div><div class="line"> 1006  [2021-10-27 10:49:22] ip netns exec ren route   //为空</div><div class="line"> 1007  [2021-10-27 10:49:29] ip netns exec ren iptables -L</div><div class="line"> 1008  [2021-10-27 10:49:55] ip link add veth1 type veth peer name veth1_p //此时宿主机上能看到这两块网卡</div><div class="line"> 1009  [2021-10-27 10:50:07] ip link set veth1 netns ren //将veth1从宿主机默认网络空间挪到ren中，宿主机中看不到veth1了</div><div class="line"> 1010  [2021-10-27 10:50:18] ip netns exec ren route  </div><div class="line"> 1011  [2021-10-27 10:50:25] ip netns exec ren iptables -L</div><div class="line"> 1012  [2021-10-27 10:50:39] ifconfig</div><div class="line"> 1013  [2021-10-27 10:50:51] ip link list</div><div class="line"> 1014  [2021-10-27 10:51:29] ip netns exec ren ip link list</div><div class="line"> 1017  [2021-10-27 10:53:27] ip netns exec ren ip addr add 172.19.0.100/24 dev veth1 </div><div class="line"> 1018  [2021-10-27 10:53:31] ip netns exec ren ip link list</div><div class="line"> 1019  [2021-10-27 10:53:39] ip netns exec ren ifconfig</div><div class="line"> 1020  [2021-10-27 10:53:42] ip netns exec ren ifconfig -a</div><div class="line"> 1021  [2021-10-27 10:54:13] ip netns exec ren ip link set dev veth1 up</div><div class="line"> 1022  [2021-10-27 10:54:16] ip netns exec ren ifconfig</div><div class="line"> 1023  [2021-10-27 10:54:22] ping 172.19.0.100</div><div class="line"> 1024  [2021-10-27 10:54:35] ifconfig -a</div><div class="line"> 1025  [2021-10-27 10:55:03] ip netns exec ren ip addr add 172.19.0.101/24 dev veth1_p</div><div class="line"> 1026  [2021-10-27 10:55:10] ip addr add 172.19.0.101/24 dev veth1_p</div><div class="line"> 1027  [2021-10-27 10:55:16] ifconfig veth1_p</div><div class="line"> 1028  [2021-10-27 10:55:30] ip link set dev veth1_p up</div><div class="line"> 1029  [2021-10-27 10:55:32] ifconfig veth1_p</div><div class="line"> 1030  [2021-10-27 10:55:38] ping 172.19.0.101</div><div class="line"> 1031  [2021-10-27 10:55:43] ping 172.19.0.100</div><div class="line"> 1032  [2021-10-27 10:55:53] ip link set dev veth1_p down</div><div class="line"> 1033  [2021-10-27 10:55:54] ping 172.19.0.100</div><div class="line"> 1034  [2021-10-27 10:55:58] ping 172.19.0.101</div><div class="line"> 1035  [2021-10-27 10:56:08] ifconfig veth1_p</div><div class="line"> 1036  [2021-10-27 10:56:32] ping 172.19.0.101</div><div class="line"> 1037  [2021-10-27 10:57:04] ip netns exec ren route</div><div class="line"> 1038  [2021-10-27 10:57:52] ip netns exec ren ping 172.19.0.101</div><div class="line"> 1039  [2021-10-27 10:57:58] ip link set dev veth1_p up</div><div class="line"> 1040  [2021-10-27 10:57:59] ip netns exec ren ping 172.19.0.101</div><div class="line"> 1041  [2021-10-27 10:58:06] ip netns exec ren ping 172.19.0.100</div><div class="line"> 1042  [2021-10-27 10:58:14] ip netns exec ren ifconfig</div><div class="line"> 1043  [2021-10-27 10:58:19] ip netns exec ren route</div><div class="line"> 1044  [2021-10-27 10:58:26] ip netns exec ren ping 172.19.0.100 -I veth1</div><div class="line"> 1045  [2021-10-27 10:58:58] ifconfig veth1_p</div><div class="line"> 1046  [2021-10-27 10:59:10] ping 172.19.0.100</div><div class="line"> 1047  [2021-10-27 10:59:26] ip netns exec ren ping 172.19.0.101 -I veth1</div><div class="line"> </div><div class="line"> 把网卡加入到docker0的bridge下</div><div class="line"> 1160  [2021-10-27 12:17:37] brctl show</div><div class="line"> 1161  [2021-10-27 12:18:05] ip link set dev veth3_p master docker0</div><div class="line"> 1162  [2021-10-27 12:18:09] ip link set dev veth1_p master docker0</div><div class="line"> 1163  [2021-10-27 12:18:13] ip link set dev veth2 master docker0</div><div class="line"> 1164  [2021-10-27 12:18:15] brctl show</div><div class="line"> </div><div class="line">brctl showmacs br0</div><div class="line">brctl show cni0</div><div class="line">brctl addif cni0 veth1 veth2 veth3  //往cni bridge添加多个容器peer 网卡</div></pre></td></tr></table></figure>
<p>Linux 上存在一个默认的网络命名空间，Linux 中的 1 号进程初始使用该默认空间。Linux 上其它所有进程都是由 1 号进程派生出来的，在派生 clone 的时候如果没有额外特别指定，所有的进程都将共享这个默认网络空间。</p>
<p>所有的网络设备刚创建出来都是在宿主机默认网络空间下的。可以通过 <code>ip link set 设备名 netns 网络空间名</code> 将设备移动到另外一个空间里去，socket也是归属在某一个网络命名空间下的，由创建socket进程所在的netns来决定socket所在的netns</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//file: net/socket.c</span></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">sock_create</span><span class="params">(<span class="keyword">int</span> family, <span class="keyword">int</span> type, <span class="keyword">int</span> protocol, struct socket **res)</span></span></div><div class="line">&#123;</div><div class="line"> <span class="keyword">return</span> __sock_create(current-&gt;nsproxy-&gt;net_ns, family, type, protocol, res, <span class="number">0</span>);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//file: include/net/sock.h</span></div><div class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span></span></div><div class="line"><span class="keyword">void</span> <span class="title">sock_net_set</span><span class="params">(struct sock *sk, struct net *net)</span></div><div class="line">&#123;</div><div class="line"> write_pnet(&amp;sk-&gt;sk_net, net);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>内核提供了三种操作命名空间的方式，分别是 clone、setns 和 unshare。ip netns add 使用的是 unshare，原理和 clone 是类似的。</p>
<p><img src="/images/951413iMgBlog/640-5304524." alt="Image"></p>
<p>每个 net 下都包含了自己的路由表、iptable 以及内核参数配置等等</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://morven.life/notes/networking-3-ipip/" target="_blank" rel="external">https://morven.life/notes/networking-3-ipip/</a></p>
<p><a href="https://www.cnblogs.com/bakari/p/10564347.html" target="_blank" rel="external">https://www.cnblogs.com/bakari/p/10564347.html</a></p>
<p><a href="https://www.cnblogs.com/goldsunshine/p/10701242.html" target="_blank" rel="external">https://www.cnblogs.com/goldsunshine/p/10701242.html</a></p>
<p><a href="https://docker-k8s-lab.readthedocs.io/en/latest/docker/docker-flannel.html" target="_blank" rel="external">手工拉起flannel网络</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2022/01/19/kubernetes_Flannel网络剖析/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/01/19/kubernetes_Flannel网络剖析/" itemprop="url">kubernetes Flannel网络剖析</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-01-19T11:30:03+08:00">
                2022-01-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/docker/" itemprop="url" rel="index">
                    <span itemprop="name">docker</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="kubernetes-Flannel网络剖析"><a href="#kubernetes-Flannel网络剖析" class="headerlink" title="kubernetes Flannel网络剖析"></a>kubernetes Flannel网络剖析</h1><h2 id="cni（Container-Network-Interface）"><a href="#cni（Container-Network-Interface）" class="headerlink" title="cni（Container Network Interface）"></a>cni（Container Network Interface）</h2><p>CNI 全称为 Container Network Interface，是用来定义容器网络的一个 <a href="https://github.com/containernetworking/cni/blob/master/SPEC.md" target="_blank" rel="external">规范</a>。<a href="https://github.com/containernetworking/cni" target="_blank" rel="external">containernetworking/cni</a> 是一个 CNCF 的 CNI 实现项目，包括基本额 bridge,macvlan等基本网络插件。</p>
<p>一般将cni各种网络插件的可执行文件二进制放到 <code>/opt/cni/bin</code> ，在 <code>/etc/cni/net.d/</code> 下创建配置文件，剩下的就交给 K8s 或者 containerd 了，我们不关心也不了解其实现。</p>
<p>比如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">#ls -lh /opt/cni/bin/</div><div class="line">总用量 90M</div><div class="line">-rwxr-x--- 1 root root 4.0M 12月 23 09:39 bandwidth</div><div class="line">-rwxr-x--- 1 root root  35M 12月 23 09:39 calico</div><div class="line">-rwxr-x--- 1 root root  35M 12月 23 09:39 calico-ipam</div><div class="line">-rwxr-x--- 1 root root 3.0M 12月 23 09:39 flannel</div><div class="line">-rwxr-x--- 1 root root 3.5M 12月 23 09:39 host-local</div><div class="line">-rwxr-x--- 1 root root 3.1M 12月 23 09:39 loopback</div><div class="line">-rwxr-x--- 1 root root 3.8M 12月 23 09:39 portmap</div><div class="line">-rwxr-x--- 1 root root 3.3M 12月 23 09:39 tuning</div><div class="line"></div><div class="line">[root@hygon3 15:55 /root]</div><div class="line">#ls -lh /etc/cni/net.d/</div><div class="line">总用量 12K</div><div class="line">-rw-r--r-- 1 root root  607 12月 23 09:39 10-calico.conflist</div><div class="line">-rw-r----- 1 root root  292 12月 23 09:47 10-flannel.conflist</div><div class="line">-rw------- 1 root root 2.6K 12月 23 09:39 calico-kubeconfig</div></pre></td></tr></table></figure>
<p>CNI 插件都是直接通过 exec 的方式调用，而不是通过 socket 这样 C/S 方式，所有参数都是通过环境变量、标准输入输出来实现的。</p>
<h2 id="跨主机通信流程"><a href="#跨主机通信流程" class="headerlink" title="跨主机通信流程"></a>跨主机通信流程</h2><p>Step-by-step communication from <strong>Pod 1</strong> to <strong>Pod 6</strong>:</p>
<ol>
<li><em>Package leaves</em> <strong><em>Pod 1 netns\</em></strong> <em>through the</em> <strong><em>eth1\</em></strong> <em>interface and reaches the</em> <strong><em>root netns\</em></strong> <em>through the virtual interface</em> <strong><em>veth1*</em></strong>;*</li>
<li><em>Package leaves</em> <strong><em>veth1\</em></strong> <em>and reaches</em> <strong><em>cni0*</em></strong>, looking for<em> **</em>Pod 6*<em>**’s</em> <em>address;</em></li>
<li><em>Package leaves</em> <strong><em>cni0\</em></strong> <em>and is redirected to</em> <strong><em>eth0*</em></strong>;*</li>
<li><em>Package leaves</em> <strong><em>eth0\</em></strong> <em>from</em> <strong><em>Master 1\</em></strong> <em>and reaches the</em> <strong><em>gateway*</em></strong>;*</li>
<li><em>Package leaves the</em> <strong><em>gateway\</em></strong> <em>and reaches the</em> <strong><em>root netns\</em></strong> <em>through the</em> <strong><em>eth0\</em></strong> <em>interface on</em> <strong><em>Worker 1*</em></strong>;*</li>
<li><em>Package leaves</em> <strong><em>eth0\</em></strong> <em>and reaches</em> <strong><em>cni0*</em></strong>, looking for<em> **</em>Pod 6*<em>**’s</em> <em>address;</em></li>
<li><em>Package leaves</em> <strong><em>cni0\</em></strong> <em>and is redirected to the</em> <strong><em>veth6\</em></strong> <em>virtual interface;</em></li>
<li><em>Package leaves the</em> <strong><em>root netns\</em></strong> <em>through</em> <strong><em>veth6\</em></strong> <em>and reaches the</em> <strong><em>Pod 6 netns\</em></strong> <em>though the</em> <strong><em>eth6\</em></strong> <em>interface;</em></li>
</ol>
<p><img src="/images/951413iMgBlog/image-20220115124747936.png" alt="image-20220115124747936"></p>
<blockquote>
<p><strong>cni0</strong> is a Linux network bridge device, all <strong>veth</strong> devices will connect to this bridge, so all Pods on the same node can communicate with each other, as explained in <strong>Kubernetes Network Model</strong> and the hotel analogy above.</p>
</blockquote>
<p>默认cni 网络是没法跨宿主机的，跨宿主机需要走overlay（比如flannel的vxlan）或者仅限宿主机全在一个二层网络可达（比如用flannel的host-gw模式）</p>
<h2 id="flannel-vxlan网络"><a href="#flannel-vxlan网络" class="headerlink" title="flannel vxlan网络"></a>flannel vxlan网络</h2><p>核心原理就是将pod网络包通过vxlan协议封装成一个udp包，udp包的ip是数据ip，内层是pod原始网络通信包。</p>
<p>假如POD1访问POD4：</p>
<ol>
<li>从POD1中出来的包先到Bridge cni0上（因为POD1对应的veth挂在了cni0上），目标mac地址是cni0的Mac</li>
<li>然后进入到宿主机网络，宿主机有路由 10.244.2.0/24 via 10.244.2.0 dev flannel.1 onlink ，也就是目标ip 10.244.2.3的包交由 flannel.1 来处理，目标mac地址是POD4所在机器的flannel.1的Mac</li>
<li>flanneld 进程将包封装成vxlan 丢到eth0从宿主机1离开（封装后的目标ip是192.168.2.91，现在都是由内核来完成flanneld这个封包过程，性能好）</li>
<li>这个封装后的vxlan udp包正确路由到宿主机2</li>
<li>然后经由 flanneld 解包成 10.244.2.3 ，命中宿主机2上的路由：10.244.2.0/24 dev cni0 proto kernel scope link src 10.244.2.1 ，交给cni0（<strong>这里会过宿主机iptables</strong>）</li>
<li>cni0将包送给POD4</li>
</ol>
<p><img src="/images/951413iMgBlog/image-20220115132938290.png" alt="image-20220115132938290"></p>
<p>flannel容器启动的时候会给自己所在的node注入一些信息：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">#kubectl describe node hygon4  |grep -i flannel</div><div class="line">Annotations:        flannel.alpha.coreos.com/backend-data: &#123;&quot;VNI&quot;:1,&quot;VtepMAC&quot;:&quot;66:c6:ba:a2:8f:a1&quot;&#125;</div><div class="line">                    flannel.alpha.coreos.com/backend-type: vxlan</div><div class="line">                    flannel.alpha.coreos.com/kube-subnet-manager: true</div><div class="line">                    flannel.alpha.coreos.com/public-ip: 10.176.4.245  ---宿主机ip，vxlan封包所用</div><div class="line">                    </div><div class="line"> &quot;VtepMAC&quot;:&quot;66:c6:ba:a2:8f:a1&quot;----宿主机网卡 flannel.1的mac</div></pre></td></tr></table></figure>
<h3 id="抓包演示packet流转以及封包解包"><a href="#抓包演示packet流转以及封包解包" class="headerlink" title="抓包演示packet流转以及封包解包"></a>抓包演示packet流转以及封包解包</h3><p>一次完整的抓包过程演示包的流转，从hygon3上的pod 192.168.0.4（22:d8:63:6c:e8:96） 访问 hygon4上的pod 192.168.2.56（52:e6:8e:02:80:35）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div></pre></td><td class="code"><pre><div class="line">//hygon3上的pod 192.168.0.4（22:d8:63:6c:e8:96） 访问 hygon4上的pod 192.168.2.56（52:e6:8e:02:80:35），在cni0（a2:99:4f:dc:9d:5c）上抓包，跨机不走peer veth</div><div class="line">[root@hygon3 11:08 /root]</div><div class="line">#tcpdump -i cni0 host 192.168.2.56 -nnetvv</div><div class="line">dropped privs to tcpdump</div><div class="line">tcpdump: listening on cni0, link-type EN10MB (Ethernet), capture size 262144 bytes</div><div class="line">22:d8:63:6c:e8:96 &gt; a2:99:4f:dc:9d:5c, ethertype IPv4 (0x0800), length 614: (tos 0x0, ttl 64, id 53303, offset 0, flags [DF], proto TCP (6), length 600)</div><div class="line">    192.168.0.4.40712 &gt; 192.168.2.56.3100: Flags [P.], cksum 0x85d7 (incorrect -&gt; 0x801a), seq 150533649:150534197, ack 3441674662, win 507, options [nop,nop,TS val 1239838869 ecr 2297983667], length 548</div><div class="line"></div><div class="line">//hygon3上的pod 192.168.0.4 访问 hygon4上的pod 192.168.2.56，在本机flannel.1（a2:06:5e:83:44:78）上抓包</div><div class="line">[root@hygon3 10:53 /root]</div><div class="line">#tcpdump -i  flannel.1 host 192.168.0.4 -nnetvv </div><div class="line">dropped privs to tcpdump</div><div class="line">tcpdump: listening on flannel.1, link-type EN10MB (Ethernet), capture size 262144 bytes</div><div class="line">a2:06:5e:83:44:78 &gt; 66:c6:ba:a2:8f:a1, ethertype IPv4 (0x0800), length 729: (tos 0x0, ttl 63, id 52997, offset 0, flags [DF], proto TCP (6), length 715)</div><div class="line">    192.168.0.4.40712 &gt; 192.168.2.56.3100: Flags [P.], cksum 0x864a (incorrect -&gt; 0x02ae), seq 150429115:150429778, ack 3441664870, win 507, options [nop,nop,TS val 1239381169 ecr 2297525566], length 663</div><div class="line">       </div><div class="line"> [root@hygon3 11:13 /root] //通过arp 可以看到对端 flannel.1 的mac地址被缓存到了本地</div><div class="line">#arp -n |grep 66:c6:ba:a2:8f:a1</div><div class="line">192.168.2.0              ether   66:c6:ba:a2:8f:a1   CM                    flannel.1</div><div class="line">#ip route</div><div class="line">default via 10.176.3.247 dev p1p1</div><div class="line">172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1</div><div class="line">192.168.0.0/24 dev cni0 proto kernel scope link src 192.168.0.1</div><div class="line">192.168.1.0/24 via 192.168.1.0 dev flannel.1 onlink</div><div class="line">192.168.2.0/24 via 192.168.2.0 dev flannel.1 onlink</div><div class="line">192.168.3.0/24 via 192.168.3.0 dev flannel.1 onlink</div><div class="line">#ip a</div><div class="line">18: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN group default</div><div class="line">    link/ether a2:06:5e:83:44:78 brd ff:ff:ff:ff:ff:ff</div><div class="line">    inet 192.168.0.0/32 brd 192.168.0.0 scope global flannel.1</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line">19: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP group default qlen 1000</div><div class="line">    link/ether a2:99:4f:dc:9d:5c brd ff:ff:ff:ff:ff:ff</div><div class="line">    inet 192.168.0.1/24 brd 192.168.0.255 scope global cni0</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line"></div><div class="line">//宿主机物理网卡抓包，被封成了udp的vxlan包    </div><div class="line">[root@hygon3 11:12 /root]</div><div class="line">#tcpdump -i p1p1 udp and port 8472 -nnetvv</div><div class="line">0c:42:a1:db:b1:a8 &gt; 88:66:39:89:9b:cc, ethertype IPv4 (0x0800), length 967: (tos 0x0, ttl 64, id 33722, offset 0, flags [none], proto UDP (17), length 953)</div><div class="line">    10.176.3.245.45173 &gt; 10.176.4.245.8472: [bad udp cksum 0x88c6 -&gt; 0xe4db!] OTV, flags [I] (0x08), overlay 0, instance 1</div><div class="line">a2:06:5e:83:44:78 &gt; 66:c6:ba:a2:8f:a1, ethertype IPv4 (0x0800), length 917: (tos 0x0, ttl 63, id 53539, offset 0, flags [DF], proto TCP (6), length 903)</div><div class="line">    192.168.0.4.40712 &gt; 192.168.2.56.3100: Flags [P.], cksum 0x8706 (incorrect -&gt; 0xe31b), seq 150613328:150614179, ack 3441682214, win 507, options [nop,nop,TS val 1240166469 ecr 2298311268], length 851</div><div class="line"></div><div class="line">---------跨机分割线--------</div><div class="line"></div><div class="line">[root@hygon4 11:15 /root] //udp ttl为61，经过了3跳(icmp ttl为63)，不过这些都和vxlan内容无关了</div><div class="line">#tcpdump -i p1p1 udp and port 8472 -nnetvv</div><div class="line">88:66:39:2b:3f:ec &gt; 0c:42:a1:e9:77:2c, ethertype IPv4 (0x0800), length 736: (tos 0x0, ttl 61, id 49748, offset 0, flags [none], proto UDP (17), length 722)</div><div class="line">    10.176.3.245.45173 &gt; 10.176.4.245.8472: [udp sum ok] OTV, flags [I] (0x08), overlay 0, instance 1</div><div class="line">a2:06:5e:83:44:78 &gt; 66:c6:ba:a2:8f:a1, ethertype IPv4 (0x0800), length 686: (tos 0x0, ttl 63, id 53631, offset 0, flags [DF], proto TCP (6), length 672)</div><div class="line">    192.168.0.4.40712 &gt; 192.168.2.56.3100: Flags [P.], cksum 0x7f0c (correct), seq 150646020:150646640, ack 3441685158, win 507, options [nop,nop,TS val 1240301769 ecr 2298444568], length 620</div><div class="line">0c:42:a1:e9:77:2c &gt; 88:66:39:2b:3f:ec, ethertype IPv4 (0x0800), length 180: (tos 0x0, ttl 64, id 57062, offset 0, flags [none], proto UDP (17), length 166)</div><div class="line">    10.176.4.245.41515 &gt; 10.176.3.245.8472: [bad udp cksum 0x9a23 -&gt; 0x8e11!] OTV, flags [I] (0x08), overlay 0, instance 1</div><div class="line">66:c6:ba:a2:8f:a1 &gt; a2:06:5e:83:44:78, ethertype IPv4 (0x0800), length 130: (tos 0x0, ttl 63, id 12391, offset 0, flags [DF], proto TCP (6), length 116)</div><div class="line">    192.168.2.56.3100 &gt; 192.168.0.4.40712: Flags [P.], cksum 0x83f3 (incorrect -&gt; 0x77e1), seq 1:65, ack 620, win 501, options [nop,nop,TS val 2298447868 ecr 1240301769], length 64</div><div class="line">    </div><div class="line">//到对端hygon4上抓包, 因为途中都是vxlan，所以ttl、mac地址都不变</div><div class="line">[root@hygon4 10:55 /root]</div><div class="line">#tcpdump -i flannel.1 host 192.168.2.56 -nnetvv</div><div class="line">dropped privs to tcpdump</div><div class="line">tcpdump: listening on flannel.1, link-type EN10MB (Ethernet), capture size 262144 bytes</div><div class="line">a2:06:5e:83:44:78 &gt; 66:c6:ba:a2:8f:a1, ethertype IPv4 (0x0800), length 933: (tos 0x0, ttl 63, id 52807, offset 0, flags [DF], proto TCP (6), length 919)</div><div class="line">    192.168.0.4.40712 &gt; 192.168.2.56.3100: Flags [P.], cksum 0x8d0d (correct), seq 150361706:150362573, ack 3441658790, win 507, options [nop,nop,TS val 1239073069 ecr 2297216169], length 867</div><div class="line">    </div><div class="line">#ip a //only for flannel.1 and cni0</div><div class="line">10: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN group default</div><div class="line">    link/ether 66:c6:ba:a2:8f:a1 brd ff:ff:ff:ff:ff:ff</div><div class="line">    inet 192.168.2.0/32 brd 192.168.2.0 scope global flannel.1</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line">11: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP group default qlen 1000</div><div class="line">    link/ether 16:97:3a:7b:53:00 brd ff:ff:ff:ff:ff:ff</div><div class="line">    inet 192.168.2.1/24 brd 192.168.2.255 scope global cni0</div><div class="line">       valid_lft forever preferred_lft forever       </div><div class="line"></div><div class="line">[root@hygon4 11:24 /root]</div><div class="line">#arp -n | grep 44:78</div><div class="line">192.168.0.0              ether   a2:06:5e:83:44:78   CM                    flannel.1   </div><div class="line"> </div><div class="line"> //mac地址替换，ttl减1</div><div class="line"> [root@hygon4 10:55 /root]</div><div class="line">#tcpdump -i cni0 host 192.168.2.56 -nnetvv</div><div class="line">dropped privs to tcpdump</div><div class="line">tcpdump: listening on cni0, link-type EN10MB (Ethernet), capture size 262144 bytes</div><div class="line">16:97:3a:7b:53:00 &gt; 52:e6:8e:02:80:35, ethertype IPv4 (0x0800), length 935: (tos 0x0, ttl 62, id 52829, offset 0, flags [DF], proto TCP (6), length 921)</div><div class="line">    192.168.0.4.40712 &gt; 192.168.2.56.3100: Flags [P.], cksum 0x7aa8 (correct), seq 150369440:150370309, ack 3441659494, win 507, options [nop,nop,TS val 1239115869 ecr 2297259166], length 869</div></pre></td></tr></table></figure>
<p>对应宿主机查询到的ip、路由信息（和上图不是对应的）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">#ip -d -4 addr show cni0</div><div class="line">475: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP group default qlen 1000</div><div class="line">    link/ether 8e:34:ba:e2:a4:c6 brd ff:ff:ff:ff:ff:ff promiscuity 0 minmtu 68 maxmtu 65535</div><div class="line">    bridge forward_delay 1500 hello_time 200 max_age 2000 ageing_time 30000 stp_state 0 priority 32768 vlan_filtering 0 vlan_protocol 802.1Q bridge_id 8000.8e:34:ba:e2:a4:c6 designated_root 8000.8e:34:ba:e2:a4:c6 root_port 0 root_path_cost 0 topology_change 0 topology_change_detected 0 hello_timer    0.00 tcn_timer    0.00 topology_change_timer    0.00 gc_timer  161.46 vlan_default_pvid 1 vlan_stats_enabled 0 group_fwd_mask 0 group_address 01:80:c2:00:00:00 mcast_snooping 1 mcast_router 1 mcast_query_use_ifaddr 0 mcast_querier 0 mcast_hash_elasticity 4 mcast_hash_max 512 mcast_last_member_count 2 mcast_startup_query_count 2 mcast_last_member_interval 100 mcast_membership_interval 26000 mcast_querier_interval 25500 mcast_query_interval 12500 mcast_query_response_interval 1000 mcast_startup_query_interval 3124 mcast_stats_enabled 0 mcast_igmp_version 2 mcast_mld_version 1 nf_call_iptables 0 nf_call_ip6tables 0 nf_call_arptables 0 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535</div><div class="line">    inet 192.168.3.1/24 brd 192.168.3.255 scope global cni0</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line"></div><div class="line">#ip -d -4 addr show flannel.1</div><div class="line">474: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN group default</div><div class="line">    link/ether fe:49:64:ae:36:af brd ff:ff:ff:ff:ff:ff promiscuity 0 minmtu 68 maxmtu 65535</div><div class="line">    vxlan id 1 local 10.133.2.252 dev bond0 srcport 0 0 dstport 8472 nolearning ttl auto ageing 300 udpcsum noudp6zerocsumtx noudp6zerocsumrx numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535</div><div class="line">    inet 192.168.3.0/32 brd 192.168.3.0 scope global flannel.1</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line">       </div><div class="line">[root@hygon239 20:06 /root]</div><div class="line">#kubectl describe node hygon252 | grep -C5 -i vtep  //可以看到VetpMAC 以及对应的宿主机IP（vxlan封包后的IP）</div><div class="line">Labels:             beta.kubernetes.io/arch=amd64</div><div class="line">                    beta.kubernetes.io/os=linux</div><div class="line">                    kubernetes.io/arch=amd64</div><div class="line">                    kubernetes.io/hostname=hygon252</div><div class="line">                    kubernetes.io/os=linux</div><div class="line">Annotations:        flannel.alpha.coreos.com/backend-data: &#123;&quot;VNI&quot;:1,&quot;VtepMAC&quot;:&quot;fe:49:64:ae:36:af&quot;&#125;</div><div class="line">                    flannel.alpha.coreos.com/backend-type: vxlan</div><div class="line">                    flannel.alpha.coreos.com/kube-subnet-manager: true</div><div class="line">                    flannel.alpha.coreos.com/public-ip: 10.133.2.252</div><div class="line">                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock</div><div class="line">                    node.alpha.kubernetes.io/ttl: 0</div></pre></td></tr></table></figure>
<p>包流转<a href="https://blog.laputa.io/kubernetes-flannel-networking-6a1cb1f8ec7c" target="_blank" rel="external">示意图</a></p>
<p><img src="/images/951413iMgBlog/image-20220119114929034.png" alt="image-20220119114929034"></p>
<h2 id="flannel网络不通排查案例"><a href="#flannel网络不通排查案例" class="headerlink" title="flannel网络不通排查案例"></a>flannel网络不通排查案例</h2><p>当网络不通时，可以根据以上演示的包流转路径在不同的网络设备上抓包来定位哪个环节不通</p>
<h3 id="firewalld"><a href="#firewalld" class="headerlink" title="firewalld"></a>firewalld</h3><p>在麒麟系统的物理机上通过kubeadm setup集群，发现有的环境flannel网络不通，在宿主机上ping 其它物理机flannel.0网卡的ip，通过在对端宿主机抓包发现icmp收到后被防火墙扔掉了，抓包中可以看到错误信息：icmp unreachable - admin prohibited</p>
<p>下图中正常的icmp是直接ping 物理机ip</p>
<p><img src="/images/951413iMgBlog/image-20211228203650921.png" alt="image-20211228203650921"></p>
<blockquote>
<p>The “admin prohibited filter” seen in the tcpdump output means there is a firewall blocking a connection. It does it by sending back an ICMP packet meaning precisely that: the admin of that firewall doesn’t want those packets to get through. It could be a firewall at the destination site. It could be a firewall in between. It could be iptables on the Linux system.</p>
</blockquote>
<p>发现有问题的环境中宿主机的防火墙设置报错了：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">12月 28 23:35:08 hygon253 firewalld[10493]: WARNING: COMMAND_FAILED: &apos;/usr/sbin/iptables -w10 -t filter -X DOCKER-ISOLATION-STAGE-1&apos; failed: iptables: No chain/target/match by that name.</div><div class="line">12月 28 23:35:08 hygon253 firewalld[10493]: WARNING: COMMAND_FAILED: &apos;/usr/sbin/iptables -w10 -t filter -F DOCKER-ISOLATION-STAGE-2&apos; failed: iptables: No chain/target/match by that name.</div></pre></td></tr></table></figure>
<p>应该是因为启动docker的时候 firewalld 是运行着的</p>
<blockquote>
<p>Do you have firewalld enabled, and was it (re)started after docker was started? If so, then it’s likely that firewalld wiped docker’s IPTables rules. Restarting the docker daemon should re-create those rules.</p>
</blockquote>
<p><strong>停掉 firewalld 服务可以解决这个问题</strong>，k8s集群</p>
<h3 id="flannel网络不通"><a href="#flannel网络不通" class="headerlink" title="flannel网络不通"></a><a href="https://github.com/flannel-io/flannel/issues/799" target="_blank" rel="external">flannel网络不通</a></h3><p>flannel能收到包，但是cni0收不到包，说明包进到了目标宿主机，但是从flannel解开udp转送到cni的时候出了问题，大概率是iptables 拦截了包</p>
<blockquote>
<p>Starting from Docker 1.13 default iptables policy for FORWARDING is DROP</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">It seems docker version &gt;=1.13 will add iptables rule like below,and it make this issue happen:</div><div class="line">iptables -P FORWARD DROP </div><div class="line"></div><div class="line">All you need to do is add a rule below:</div><div class="line">iptables -P FORWARD ACCEPT //将FORWARD 默认规则(没有匹配到其它规则的话）改成ACCEPT</div></pre></td></tr></table></figure>
<h2 id="抓包和调试-–-nsenter"><a href="#抓包和调试-–-nsenter" class="headerlink" title="抓包和调试 – nsenter"></a>抓包和调试 – nsenter</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line">获取pid：docker inspect -f &#123;&#123;.State.Pid&#125;&#125; c8f874efea06</div><div class="line"></div><div class="line">进入namespace：nsenter --target 17277 --net --pid –mount</div><div class="line"></div><div class="line">//只进入network namespace，这样看到的文件还是宿主机的，能直接用tcpdump，但是看到的网卡是容器的</div><div class="line">nsenter --target 17277 --net </div><div class="line"></div><div class="line">// ip netns 获取容器网络信息</div><div class="line"> 1022  [2021-04-14 15:53:06] docker inspect -f &apos;&#123;&#123;.State.Pid&#125;&#125;&apos; ab4e471edf50   //获取容器进程id</div><div class="line"> 1023  [2021-04-14 15:53:30] ls /proc/79828/ns/net</div><div class="line"> 1024  [2021-04-14 15:53:57] ln -sfT /proc/79828/ns/net /var/run/netns/ab4e471edf50 //link 以便ip netns List能访问</div><div class="line"> </div><div class="line">// 宿主机上查看容器ip</div><div class="line"> 1026  [2021-04-14 15:54:11] ip netns list</div><div class="line"> 1028  [2021-04-14 15:55:19] ip netns exec ab4e471edf50 ifconfig</div><div class="line"> </div><div class="line"> //nsenter调试网络</div><div class="line"> Get the pause container&apos;s sandboxkey: </div><div class="line">root@worker01:~# docker inspect k8s_POD_ubuntu-5846f86795-bcbqv_default_ea44489d-3dd4-11e8-bb37-02ecc586c8d5_0 | grep SandboxKey</div><div class="line">            &quot;SandboxKey&quot;: &quot;/var/run/docker/netns/82ec9e32d486&quot;,</div><div class="line">root@worker01:~#</div><div class="line">Now, using nsenter you can see the container&apos;s information.</div><div class="line">root@worker01:~# nsenter --net=/var/run/docker/netns/82ec9e32d486 ip addr show</div><div class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1</div><div class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</div><div class="line">    inet 127.0.0.1/8 scope host lo</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line">3: eth0@if7: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP group default</div><div class="line">   link/ether 0a:58:0a:f4:01:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0</div><div class="line">   inet 10.244.1.2/24 scope global eth0</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line">Identify the peer_ifindex, and finally you can see the veth pair endpoint in root namespace.</div><div class="line">root@worker01:~# nsenter --net=/var/run/docker/netns/82ec9e32d486 ethtool -S eth0</div><div class="line">NIC statistics:</div><div class="line">     peer_ifindex: 7</div><div class="line">root@worker01:~#</div><div class="line">root@worker01:~# ip -d link show | grep &apos;7: veth&apos;</div><div class="line">7: veth5e43ca47@if3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default</div><div class="line">root@worker01:~#</div></pre></td></tr></table></figure>
<p>nsenter相当于在setns的示例程序之上做了一层封装，使我们无需指定命名空间的文件描述符，而是指定进程号即可，<a href="https://medium.com/@anilkreddyr/kubernetes-with-flannel-understanding-the-networking-part-2-78b53e5364c7" target="_blank" rel="external">详细case</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">#docker inspect cb7b05d82153 | grep -i SandboxKey   //根据 pause 容器id找network namespace</div><div class="line">            &quot;SandboxKey&quot;: &quot;/var/run/docker/netns/d6b2ef3cf886&quot;,</div><div class="line"></div><div class="line">[root@hygon252 19:00 /root]</div><div class="line">#nsenter --net=/var/run/docker/netns/d6b2ef3cf886 ip addr show</div><div class="line">3: eth0@if496: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP group default  //496对应宿主机上的veth编号</div><div class="line">    link/ether 1e:95:dd:d9:88:bd brd ff:ff:ff:ff:ff:ff link-netnsid 0</div><div class="line">    inet 192.168.3.22/24 brd 192.168.3.255 scope global eth0</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line">#nsenter --net=/var/run/docker/netns/d6b2ef3cf886 ethtool -S eth0</div><div class="line">NIC statistics:</div><div class="line">     peer_ifindex: 496</div><div class="line">     </div><div class="line">#ip -d -4 addr show cni0</div><div class="line">475: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP group default qlen 1000</div><div class="line">    link/ether 8e:34:ba:e2:a4:c6 brd ff:ff:ff:ff:ff:ff promiscuity 0 minmtu 68 maxmtu 65535</div><div class="line">    bridge forward_delay 1500 hello_time 200 max_age 2000 ageing_time 30000 stp_state 0 priority 32768 vlan_filtering 0 vlan_protocol 802.1Q bridge_id 8000.8e:34:ba:e2:a4:c6 designated_root 8000.8e:34:ba:e2:a4:c6 root_port 0 root_path_cost 0 topology_change 0 topology_change_detected 0 hello_timer    0.00 tcn_timer    0.00 topology_change_timer    0.00 gc_timer   43.31 vlan_default_pvid 1 vlan_stats_enabled 0 group_fwd_mask 0 group_address 01:80:c2:00:00:00 mcast_snooping 1 mcast_router 1 mcast_query_use_ifaddr 0 mcast_querier 0 mcast_hash_elasticity 4 mcast_hash_max 512 mcast_last_member_count 2 mcast_startup_query_count 2 mcast_last_member_interval 100 mcast_membership_interval 26000 mcast_querier_interval 25500 mcast_query_interval 12500 mcast_query_response_interval 1000 mcast_startup_query_interval 3124 mcast_stats_enabled 0 mcast_igmp_version 2 mcast_mld_version 1 nf_call_iptables 0 nf_call_ip6tables 0 nf_call_arptables 0 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535</div><div class="line">    inet 192.168.3.1/24 brd 192.168.3.255 scope global cni0</div><div class="line">       valid_lft forever preferred_lft forever</div></pre></td></tr></table></figure>
<h2 id="清理"><a href="#清理" class="headerlink" title="清理"></a><a href="https://serverfault.com/questions/247767/cannot-delete-gre-tunnel" target="_blank" rel="external">清理</a></h2><p>cni信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">/etc/cni/net.d/*</div><div class="line">/var/lib/cni/ 下存放有ip分配信息</div><div class="line"></div><div class="line">#cat /run/flannel/subnet.env</div><div class="line">FLANNEL_NETWORK=192.168.0.0/16</div><div class="line">FLANNEL_SUBNET=192.168.0.1/24</div><div class="line">FLANNEL_MTU=1450</div><div class="line">FLANNEL_IPMASQ=true</div></pre></td></tr></table></figure>
<p>calico创建的tunl0网卡是个tunnel，可以通过 ip tunnel show来查看，清理不掉（重启可以清理掉tunl0）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">ip link set dev tunl0 name tunl0_fallback</div><div class="line">或者</div><div class="line">/sbin/ip link set eth1 down</div><div class="line">/sbin/ip link set eth1 name eth123</div><div class="line">/sbin/ip link set eth123 up</div></pre></td></tr></table></figure>
<h3 id="清理和创建flannel网络"><a href="#清理和创建flannel网络" class="headerlink" title="清理和创建flannel网络"></a>清理和创建flannel网络</h3><p>清理</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">ip link delete cni0</div><div class="line">ip link delete flannel.1</div></pre></td></tr></table></figure>
<p>创建</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">ip link add cni0 type bridge</div><div class="line">ip addr add dev cni0 172.30.0.0/24</div><div class="line"></div><div class="line">查看A simpler solution:</div><div class="line">ip -details link show</div><div class="line">ls -l /sys/class/net/ - virtual ones will show all in virtual and lan is on the PCI bus.</div><div class="line"></div><div class="line">brctl show cni0</div><div class="line">brctl addif cni0 veth1 veth2 veth3  //往cni bridge添加多个容器peer 网卡</div></pre></td></tr></table></figure>
<p>完全可以手工创建cni0、flannel.1等网络设备，然后将 veth添加到cni0网桥上，再在宿主机配置ip route，基本一个纯手工版本打造的flannel vxlan网络就实现了，深入理解到此任何flannel网络问题都可以解决了。</p>
<h3 id="flannel-ip在多个node之间分配错乱"><a href="#flannel-ip在多个node之间分配错乱" class="headerlink" title="flannel ip在多个node之间分配错乱"></a>flannel ip在多个node之间分配错乱</h3><p>可以铲掉网卡重新分配</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">ip link set cni0 down &amp;&amp; ip link set flannel.1 down </div><div class="line">ip link delete cni0 &amp;&amp; ip link delete flannel.1</div><div class="line">systemctl restart containerd &amp;&amp; systemctl restart kubelet</div></pre></td></tr></table></figure>
<h2 id="host-gw"><a href="#host-gw" class="headerlink" title="host-gw"></a>host-gw</h2><p>实现超级简单，就是在宿主机上配置路由规则，把其它宿主机ip当成其上所有pod的下一跳，不用封包解包，所以性能奇好，但是要求所有宿主机在一个2层网络，因为ip路由规则要求是直达其它宿主机。</p>
<p>手工配置实现就是vxlan的超级精简版，略！</p>
<h2 id="netns-操作"><a href="#netns-操作" class="headerlink" title="netns 操作"></a><a href="https://mp.weixin.qq.com/s/lscMpc5BWAEzjgYw6H0wBw" target="_blank" rel="external">netns 操作</a></h2><p>以下case创建一个名为 ren 的netns，然后在里面增加一对虚拟网卡veth1 veth1_p,  veth1放置在ren里面，veth1_p 放在物理机上，给他们配置上ip并up就能通了。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div></pre></td><td class="code"><pre><div class="line"> 1004  [2021-10-27 10:49:08] ip netns add ren</div><div class="line"> 1005  [2021-10-27 10:49:12] ip netns show</div><div class="line"> 1006  [2021-10-27 10:49:22] ip netns exec ren route   //为空</div><div class="line"> 1007  [2021-10-27 10:49:29] ip netns exec ren iptables -L</div><div class="line"> 1008  [2021-10-27 10:49:55] ip link add veth1 type veth peer name veth1_p //此时宿主机上能看到这两块网卡</div><div class="line"> 1009  [2021-10-27 10:50:07] ip link set veth1 netns ren //将veth1从宿主机默认网络空间挪到ren中，宿主机中看不到veth1了</div><div class="line"> 1010  [2021-10-27 10:50:18] ip netns exec ren route  </div><div class="line"> 1011  [2021-10-27 10:50:25] ip netns exec ren iptables -L</div><div class="line"> 1012  [2021-10-27 10:50:39] ifconfig</div><div class="line"> 1013  [2021-10-27 10:50:51] ip link list</div><div class="line"> 1014  [2021-10-27 10:51:29] ip netns exec ren ip link list</div><div class="line"> 1017  [2021-10-27 10:53:27] ip netns exec ren ip addr add 172.19.0.100/24 dev veth1 </div><div class="line"> 1018  [2021-10-27 10:53:31] ip netns exec ren ip link list</div><div class="line"> 1019  [2021-10-27 10:53:39] ip netns exec ren ifconfig</div><div class="line"> 1020  [2021-10-27 10:53:42] ip netns exec ren ifconfig -a</div><div class="line"> 1021  [2021-10-27 10:54:13] ip netns exec ren ip link set dev veth1 up</div><div class="line"> 1022  [2021-10-27 10:54:16] ip netns exec ren ifconfig</div><div class="line"> 1023  [2021-10-27 10:54:22] ping 172.19.0.100</div><div class="line"> 1024  [2021-10-27 10:54:35] ifconfig -a</div><div class="line"> 1025  [2021-10-27 10:55:03] ip netns exec ren ip addr add 172.19.0.101/24 dev veth1_p</div><div class="line"> 1026  [2021-10-27 10:55:10] ip addr add 172.19.0.101/24 dev veth1_p</div><div class="line"> 1027  [2021-10-27 10:55:16] ifconfig veth1_p</div><div class="line"> 1028  [2021-10-27 10:55:30] ip link set dev veth1_p up</div><div class="line"> 1029  [2021-10-27 10:55:32] ifconfig veth1_p</div><div class="line"> 1030  [2021-10-27 10:55:38] ping 172.19.0.101</div><div class="line"> 1031  [2021-10-27 10:55:43] ping 172.19.0.100</div><div class="line"> 1032  [2021-10-27 10:55:53] ip link set dev veth1_p down</div><div class="line"> 1033  [2021-10-27 10:55:54] ping 172.19.0.100</div><div class="line"> 1034  [2021-10-27 10:55:58] ping 172.19.0.101</div><div class="line"> 1035  [2021-10-27 10:56:08] ifconfig veth1_p</div><div class="line"> 1036  [2021-10-27 10:56:32] ping 172.19.0.101</div><div class="line"> 1037  [2021-10-27 10:57:04] ip netns exec ren route</div><div class="line"> 1038  [2021-10-27 10:57:52] ip netns exec ren ping 172.19.0.101</div><div class="line"> 1039  [2021-10-27 10:57:58] ip link set dev veth1_p up</div><div class="line"> 1040  [2021-10-27 10:57:59] ip netns exec ren ping 172.19.0.101</div><div class="line"> 1041  [2021-10-27 10:58:06] ip netns exec ren ping 172.19.0.100</div><div class="line"> 1042  [2021-10-27 10:58:14] ip netns exec ren ifconfig</div><div class="line"> 1043  [2021-10-27 10:58:19] ip netns exec ren route</div><div class="line"> 1044  [2021-10-27 10:58:26] ip netns exec ren ping 172.19.0.100 -I veth1</div><div class="line"> 1045  [2021-10-27 10:58:58] ifconfig veth1_p</div><div class="line"> 1046  [2021-10-27 10:59:10] ping 172.19.0.100</div><div class="line"> 1047  [2021-10-27 10:59:26] ip netns exec ren ping 172.19.0.101 -I veth1</div><div class="line"> </div><div class="line"> 把网卡加入到docker0的bridge下</div><div class="line"> 1160  [2021-10-27 12:17:37] brctl show</div><div class="line"> 1161  [2021-10-27 12:18:05] ip link set dev veth3_p master docker0</div><div class="line"> 1162  [2021-10-27 12:18:09] ip link set dev veth1_p master docker0</div><div class="line"> 1163  [2021-10-27 12:18:13] ip link set dev veth2 master docker0</div><div class="line"> 1164  [2021-10-27 12:18:15] brctl show</div><div class="line"> </div><div class="line">brctl showmacs br0</div><div class="line">brctl show cni0</div><div class="line">brctl addif cni0 veth1 veth2 veth3  //往cni bridge添加多个容器peer 网卡</div></pre></td></tr></table></figure>
<p>Linux 上存在一个默认的网络命名空间，Linux 中的 1 号进程初始使用该默认空间。Linux 上其它所有进程都是由 1 号进程派生出来的，在派生 clone 的时候如果没有额外特别指定，所有的进程都将共享这个默认网络空间。</p>
<p>所有的网络设备刚创建出来都是在宿主机默认网络空间下的。可以通过 <code>ip link set 设备名 netns 网络空间名</code> 将设备移动到另外一个空间里去，socket也是归属在某一个网络命名空间下的，由创建socket进程所在的netns来决定socket所在的netns</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//file: net/socket.c</span></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">sock_create</span><span class="params">(<span class="keyword">int</span> family, <span class="keyword">int</span> type, <span class="keyword">int</span> protocol, struct socket **res)</span></span></div><div class="line">&#123;</div><div class="line"> <span class="keyword">return</span> __sock_create(current-&gt;nsproxy-&gt;net_ns, family, type, protocol, res, <span class="number">0</span>);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//file: include/net/sock.h</span></div><div class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span></span></div><div class="line"><span class="keyword">void</span> <span class="title">sock_net_set</span><span class="params">(struct sock *sk, struct net *net)</span></div><div class="line">&#123;</div><div class="line"> write_pnet(&amp;sk-&gt;sk_net, net);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>内核提供了三种操作命名空间的方式，分别是 clone、setns 和 unshare。ip netns add 使用的是 unshare，原理和 clone 是类似的。</p>
<p><img src="/images/951413iMgBlog/640-5304524." alt="Image"></p>
<p>每个 net 下都包含了自己的路由表、iptable 以及内核参数配置等等</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>通过无论是对flannel还是calico的学习，不管是使用vxlan还是host-gw发现这些所谓的overlay网络不过是披着一层udp的皮而已，只要我们对ip route/mac地址足够了解，这些新技术剖析下来仍然逃不过 <a href="https://datatracker.ietf.org/doc/html/rfc1180" target="_blank" rel="external">RFC1180</a> 描述的几个最基础的知识点（基础知识的力量）的使用而已，这一切硬核的基础知识无比简单，只要你多看看我这篇旧文<a href="https://plantegg.github.io/2019/05/15/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E7%BD%91%E7%BB%9C--%E4%B8%80%E4%B8%AA%E7%BD%91%E7%BB%9C%E5%8C%85%E7%9A%84%E6%97%85%E7%A8%8B/">《就是要你懂网络–一个网络包的旅程》</a></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://morven.life/notes/networking-3-ipip/" target="_blank" rel="external">https://morven.life/notes/networking-3-ipip/</a></p>
<p><a href="https://www.cnblogs.com/bakari/p/10564347.html" target="_blank" rel="external">https://www.cnblogs.com/bakari/p/10564347.html</a></p>
<p><a href="https://www.cnblogs.com/goldsunshine/p/10701242.html" target="_blank" rel="external">https://www.cnblogs.com/goldsunshine/p/10701242.html</a></p>
<p><a href="https://docker-k8s-lab.readthedocs.io/en/latest/docker/docker-flannel.html" target="_blank" rel="external">手工拉起flannel网络</a></p>
<p><a href="https://plantegg.github.io/2019/05/15/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E7%BD%91%E7%BB%9C--%E4%B8%80%E4%B8%AA%E7%BD%91%E7%BB%9C%E5%8C%85%E7%9A%84%E6%97%85%E7%A8%8B/">《就是要你懂网络–一个网络包的旅程》</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2022/01/19/kubernetes_calico网络/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/01/19/kubernetes_calico网络/" itemprop="url">kubernetes calico网络</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-01-19T11:30:03+08:00">
                2022-01-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/docker/" itemprop="url" rel="index">
                    <span itemprop="name">docker</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="kubernetes-calico网络"><a href="#kubernetes-calico网络" class="headerlink" title="kubernetes calico网络"></a>kubernetes calico网络</h1><h2 id="cni-网络"><a href="#cni-网络" class="headerlink" title="cni 网络"></a>cni 网络</h2><blockquote>
<p> <strong>cni0</strong> is a Linux network bridge device, all <strong>veth</strong> devices will connect to this bridge, so all Pods on the same node can communicate with each other, as explained in <strong>Kubernetes Network Model</strong> and the hotel analogy above.</p>
</blockquote>
<h3 id="cni（Container-Network-Interface）"><a href="#cni（Container-Network-Interface）" class="headerlink" title="cni（Container Network Interface）"></a>cni（Container Network Interface）</h3><p>CNI 全称为 Container Network Interface，是用来定义容器网络的一个 <a href="https://github.com/containernetworking/cni/blob/master/SPEC.md" target="_blank" rel="external">规范</a>。<a href="https://github.com/containernetworking/cni" target="_blank" rel="external">containernetworking/cni</a> 是一个 CNCF 的 CNI 实现项目，包括基本额 bridge,macvlan等基本网络插件。</p>
<p>一般将cni各种网络插件的可执行文件二进制放到 <code>/opt/cni/bin</code> ，在 <code>/etc/cni/net.d/</code> 下创建配置文件，剩下的就交给 K8s 或者 containerd 了，我们不关心也不了解其实现。</p>
<p>比如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">#ls -lh /opt/cni/bin/</div><div class="line">总用量 90M</div><div class="line">-rwxr-x--- 1 root root 4.0M 12月 23 09:39 bandwidth</div><div class="line">-rwxr-x--- 1 root root  35M 12月 23 09:39 calico</div><div class="line">-rwxr-x--- 1 root root  35M 12月 23 09:39 calico-ipam</div><div class="line">-rwxr-x--- 1 root root 3.0M 12月 23 09:39 flannel</div><div class="line">-rwxr-x--- 1 root root 3.5M 12月 23 09:39 host-local</div><div class="line">-rwxr-x--- 1 root root 3.1M 12月 23 09:39 loopback</div><div class="line">-rwxr-x--- 1 root root 3.8M 12月 23 09:39 portmap</div><div class="line">-rwxr-x--- 1 root root 3.3M 12月 23 09:39 tuning</div><div class="line"></div><div class="line">[root@hygon3 15:55 /root]</div><div class="line">#ls -lh /etc/cni/net.d/</div><div class="line">总用量 12K</div><div class="line">-rw-r--r-- 1 root root  607 12月 23 09:39 10-calico.conflist</div><div class="line">-rw-r----- 1 root root  292 12月 23 09:47 10-flannel.conflist</div><div class="line">-rw------- 1 root root 2.6K 12月 23 09:39 calico-kubeconfig</div></pre></td></tr></table></figure>
<p>CNI 插件都是直接通过 exec 的方式调用，而不是通过 socket 这样 C/S 方式，所有参数都是通过环境变量、标准输入输出来实现的。</p>
<p>Step-by-step communication from <strong>Pod 1</strong> to <strong>Pod 6</strong>:</p>
<ol>
<li><em>Package leaves</em> <strong><em>Pod 1 netns\</em></strong> <em>through the</em> <strong><em>eth1\</em></strong> <em>interface and reaches the</em> <strong><em>root netns\</em></strong> <em>through the virtual interface</em> <strong><em>veth1*</em></strong>;*</li>
<li><em>Package leaves</em> <strong><em>veth1\</em></strong> <em>and reaches</em> <strong><em>cni0*</em></strong>, looking for<em> **</em>Pod 6*<em>**’s</em> <em>address;</em></li>
<li><em>Package leaves</em> <strong><em>cni0\</em></strong> <em>and is redirected to</em> <strong><em>eth0*</em></strong>;*</li>
<li><em>Package leaves</em> <strong><em>eth0\</em></strong> <em>from</em> <strong><em>Master 1\</em></strong> <em>and reaches the</em> <strong><em>gateway*</em></strong>;*</li>
<li><em>Package leaves the</em> <strong><em>gateway\</em></strong> <em>and reaches the</em> <strong><em>root netns\</em></strong> <em>through the</em> <strong><em>eth0\</em></strong> <em>interface on</em> <strong><em>Worker 1*</em></strong>;*</li>
<li><em>Package leaves</em> <strong><em>eth0\</em></strong> <em>and reaches</em> <strong><em>cni0*</em></strong>, looking for<em> **</em>Pod 6*<em>**’s</em> <em>address;</em></li>
<li><em>Package leaves</em> <strong><em>cni0\</em></strong> <em>and is redirected to the</em> <strong><em>veth6\</em></strong> <em>virtual interface;</em></li>
<li><em>Package leaves the</em> <strong><em>root netns\</em></strong> <em>through</em> <strong><em>veth6\</em></strong> <em>and reaches the</em> <strong><em>Pod 6 netns\</em></strong> <em>though the</em> <strong><em>eth6\</em></strong> <em>interface;</em></li>
</ol>
<p><img src="/images/951413iMgBlog/image-20220115124747936.png" alt="image-20220115124747936"></p>
<h2 id="kubernetes-calico-网络"><a href="#kubernetes-calico-网络" class="headerlink" title="kubernetes calico 网络"></a>kubernetes calico 网络</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml</div><div class="line"></div><div class="line">#或者老版本的calico</div><div class="line">curl https://docs.projectcalico.org/v3.15/manifests/calico.yaml -o calico.yaml</div></pre></td></tr></table></figure>
<p>默认calico用的是ipip封包（这个性能跟原生网络差多少有待验证，本质也是overlay网络，比flannel那种要好很多吗？）</p>
<p>跨宿主机的两个容器之间的流量链路是：</p>
<blockquote>
<p>cali-容器eth0-&gt;宿主机cali27dce37c0e8-&gt;tunl0-&gt;内核ipip模块封包-&gt;物理网卡（ipip封包后）—远程–&gt; 物理网卡-&gt;内核ipip模块解包-&gt;tunl0-&gt;cali-容器</p>
</blockquote>
<p><img src="/images/oss/a1767a5f2cbc2c48c1a35da9f3232a2c.png" alt="image.png"></p>
<p>Calico IPIP模式对物理网络无侵入，符合云原生容器网络要求；使用IPIP封包，性能略低于Calico BGP模式；无法使用传统防火墙管理、也无法和存量网络直接打通。Pod在Node做SNAT访问外部，Pod流量不易被监控。</p>
<h2 id="calico-ipip网络不通"><a href="#calico-ipip网络不通" class="headerlink" title="calico ipip网络不通"></a>calico ipip网络不通</h2><p>集群有五台机器192.168.0.110-114, 同时每个node都有另外一个ip：192.168.3.110-114，部分节点之间不通。每台机器部署好calico网络后，会分配一个 /26 CIRD 子网（64个ip）。</p>
<h3 id="案例1"><a href="#案例1" class="headerlink" title="案例1"></a>案例1</h3><p>目标机是10.122.127.128（宿主机ip 192.168.3.112），如果从10.122.17.64（宿主机ip 192.168.3.110） ping 10.122.127.128不通，查看10.122.127.128路由表：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[root@az3-k8s-13 ~]# ip route |grep tunl0</div><div class="line">10.122.17.64/26 via 10.122.127.128 dev tunl0  //这条路由不通</div><div class="line">[root@az3-k8s-13 ~]# ip route del 10.122.17.64/26 via 10.122.127.128 dev tunl0 ; ip route add 10.122.17.64/26 via 192.168.3.110 dev tunl0 proto bird onlink</div><div class="line"></div><div class="line">[root@az3-k8s-13 ~]# ip route |grep tunl0</div><div class="line">10.122.17.64/26 via 192.168.3.110 dev tunl0 proto bird onlink //这样就通了</div></pre></td></tr></table></figure>
<p>在10.122.127.128抓包如下，明显可以看到icmp request到了 tunl0网卡，tunl0网卡也回复了，但是回复包没有经过kernel ipip模块封装后发到eth1上：</p>
<p><img src="/images/oss/d3111417ce646ca1475def5bea01e6b9.png" alt="image.png"></p>
<p>正常机器应该是这样，上图不正常的时候缺少红框中的reply：</p>
<p><img src="/images/oss/9ea9041af1211b2a5b8de4e216044465.png" alt="image.png"></p>
<p>解决：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">ip route del 10.122.17.64/26 via 10.122.127.128 dev tunl0 ; </div><div class="line">ip route add 10.122.17.64/26 via 192.168.3.110 dev tunl0 proto bird onlink</div></pre></td></tr></table></figure>
<p>删除错误路由增加新的路由就可以了，新增路由的意思是从tunl0发给10.122.17.64/26的包下一跳是 192.168.3.110。</p>
<p> via 192.168.3.110 表示下一跳的ip</p>
<p>onlink参数的作用：<br>使用这个参数将会告诉内核，不必检查网关是否可达。因为在linux内核中，网关与本地的网段不同是被认为不可达的，从而拒绝执行添加路由的操作。</p>
<p>因为tunl0网卡ip的 CIDR 是32，也就是不属于任何子网，那么这个网卡上的路由没有网关，配置路由的话必须是onlink, 内核存也没法根据子网来选择到这块网卡，所以还会加上 dev 指定网卡。</p>
<h3 id="案例2"><a href="#案例2" class="headerlink" title="案例2"></a>案例2</h3><p>集群有五台机器192.168.0.110-114, 同时每个node都有另外一个ip：192.168.3.110-114，只有node2没有192.168.3.111这个ip，结果node2跟其他节点都不通：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">#calicoctl node status</div><div class="line">Calico process is running.</div><div class="line"></div><div class="line">IPv4 BGP status</div><div class="line">+---------------+-------------------+-------+------------+-------------+</div><div class="line">| PEER ADDRESS  |     PEER TYPE     | STATE |   SINCE    |    INFO     |</div><div class="line">+---------------+-------------------+-------+------------+-------------+</div><div class="line">| 192.168.0.111 | node-to-node mesh | up    | 2020-08-29 | Established |</div><div class="line">| 192.168.3.112 | node-to-node mesh | up    | 2020-08-29 | Established |</div><div class="line">| 192.168.3.113 | node-to-node mesh | up    | 2020-08-29 | Established |</div><div class="line">| 192.168.3.114 | node-to-node mesh | up    | 2020-08-29 | Established |</div><div class="line">+---------------+-------------------+-------+------------+-------------+</div></pre></td></tr></table></figure>
<p>从node4 ping node2，然后在node2上抓包，可以看到 icmp request都发到了node2上，但是node2收到后没有发给tunl0：</p>
<p><img src="/images/oss/16fda9322e9a59c37c11629acc611bf3.png" alt="image.png"></p>
<p>所以icmp没有回复，这里的问题在于<strong>kernel收到包后为什么不给tunl0</strong></p>
<p>同样，在node2上ping node4，同时在node2上抓包，可以看到发给node4的request包和reply包：</p>
<p><img src="/images/oss/c6d1706b6f8162cfac528ddf5319c8e2.png" alt="image.png"></p>
<p>从request包可以看到src ip 是0.111， dest ip是 3.113，<strong>因为 node2 没有192.168.3.111这个ip</strong></p>
<p>非常关键的我们看到node4的回复包 src ip 不是3.113，而是0.113（根据node4的路由就应该是0.113）</p>
<p><img src="/images/oss/5c7172e2422579eb99c66e881d47bf99.png" alt="image.png"></p>
<p>这就是问题所在，从node4过来的ipip包src ip都是0.113，实际这里ipip能认识的只是3.113. </p>
<p>如果这个时候在3.113机器上把0.113网卡down掉，那么3.113上的：</p>
<p>10.122.124.128/26 via 192.168.0.111 dev tunl0 proto bird onlink 路由被自动删除，3.113将不再回复request。这是因为calico记录的node2的ip是192.168.0.111，所以会自动增加</p>
<p>解决办法，在node4上删除这条路由记录，也就是强制让回复包走3.113网卡，这样收发的ip就能对应上了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">ip route del 192.168.0.0/24 dev eth0 proto kernel scope link src 192.168.0.113</div><div class="line">//同时将默认路由改到3.113</div><div class="line">ip route del default via 192.168.0.253 dev eth0; </div><div class="line">ip route add default via 192.168.3.253 dev eth1</div></pre></td></tr></table></figure>
<p>最终OK后，node4上的ip route是这样的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">[root@az3-k8s-14 ~]# ip route</div><div class="line">default via 192.168.3.253 dev eth1 </div><div class="line">10.122.17.64/26 via 192.168.3.110 dev tunl0 proto bird onlink </div><div class="line">10.122.124.128/26 via 192.168.0.111 dev tunl0 proto bird onlink </div><div class="line">10.122.127.128/26 via 192.168.3.112 dev tunl0 proto bird onlink </div><div class="line">blackhole 10.122.157.128/26 proto bird </div><div class="line">10.122.157.129 dev cali19f6ea143e3 scope link </div><div class="line">10.122.157.130 dev cali09e016ead53 scope link </div><div class="line">10.122.157.131 dev cali0ad3225816d scope link </div><div class="line">10.122.157.132 dev cali55a5ff1a4aa scope link </div><div class="line">10.122.157.133 dev cali01cf8687c65 scope link </div><div class="line">10.122.157.134 dev cali65232d7ada6 scope link </div><div class="line">10.122.173.128/26 via 192.168.3.114 dev tunl0 proto bird onlink </div><div class="line">172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 </div><div class="line">192.168.3.0/24 dev eth1 proto kernel scope link src 192.168.3.113</div></pre></td></tr></table></figure>
<p>正常后的抓包, 注意这里reques dest ip 和reply的 src ip终于一致了：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">//request</div><div class="line">00:16:3e:02:06:1e &gt; ee:ff:ff:ff:ff:ff, ethertype IPv4 (0x0800), length 118: (tos 0x0, ttl 64, id 57971, offset 0, flags [DF], proto IPIP (4), length 104)</div><div class="line">    192.168.0.111 &gt; 192.168.3.110: (tos 0x0, ttl 64, id 18953, offset 0, flags [DF], proto ICMP (1), length 84)</div><div class="line">    10.122.124.128 &gt; 10.122.17.64: ICMP echo request, id 22001, seq 4, length 64</div><div class="line">    </div><div class="line">//reply    </div><div class="line">ee:ff:ff:ff:ff:ff &gt; 00:16:3e:02:06:1e, ethertype IPv4 (0x0800), length 118: (tos 0x0, ttl 64, id 2565, offset 0, flags [none], proto IPIP (4), length 104)</div><div class="line">    192.168.3.110 &gt; 192.168.0.111: (tos 0x0, ttl 64, id 26374, offset 0, flags [none], proto ICMP (1), length 84)</div><div class="line">    10.122.17.64 &gt; 10.122.124.128: ICMP echo reply, id 22001, seq 4, length 64</div></pre></td></tr></table></figure>
<p>总结下来这两个案例都还是对路由不够了解，特别是案例2，因为有了多个网卡后导致路由更复杂。calico ipip的基本原理就是利用内核进行ipip封包，然后修改路由来保证网络的畅通。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://morven.life/notes/networking-3-ipip/" target="_blank" rel="external">https://morven.life/notes/networking-3-ipip/</a></p>
<p><a href="https://www.cnblogs.com/bakari/p/10564347.html" target="_blank" rel="external">https://www.cnblogs.com/bakari/p/10564347.html</a></p>
<p><a href="https://www.cnblogs.com/goldsunshine/p/10701242.html" target="_blank" rel="external">https://www.cnblogs.com/goldsunshine/p/10701242.html</a></p>
<p><a href="https://docker-k8s-lab.readthedocs.io/en/latest/docker/docker-flannel.html" target="_blank" rel="external">手工拉起flannel网络</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2022/01/13/不同CPU性能大PK/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/01/13/不同CPU性能大PK/" itemprop="url">不同CPU性能大PK</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-01-13T17:30:03+08:00">
                2022-01-13
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CPU/" itemprop="url" rel="index">
                    <span itemprop="name">CPU</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="不同CPU性能大PK"><a href="#不同CPU性能大PK" class="headerlink" title="不同CPU性能大PK"></a>不同CPU性能大PK</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>比较Hygon7280、Intel、AMD、鲲鹏920、飞腾2500的性能情况</p>
<table>
<thead>
<tr>
<th>CPU型号</th>
<th>Hygon 7280</th>
<th>AMD EPYC 7H12</th>
<th>Intel 8163</th>
<th>鲲鹏920</th>
<th>飞腾2500</th>
</tr>
</thead>
<tbody>
<tr>
<td>物理核数</td>
<td>32</td>
<td>32</td>
<td>24</td>
<td>48</td>
<td>64</td>
</tr>
<tr>
<td>超线程</td>
<td>2</td>
<td>2</td>
<td>2</td>
<td></td>
<td></td>
</tr>
<tr>
<td>路</td>
<td>2</td>
<td>2</td>
<td>2</td>
<td>2</td>
<td>2</td>
</tr>
<tr>
<td>NUMA Node</td>
<td>8</td>
<td>2</td>
<td>2</td>
<td>4</td>
<td>16</td>
</tr>
<tr>
<td>L1d</td>
<td>32K</td>
<td>32K</td>
<td>32K</td>
<td>64K</td>
<td>32K</td>
</tr>
<tr>
<td>L2</td>
<td>512K</td>
<td>512K</td>
<td>1024K</td>
<td>512K</td>
<td>2048K</td>
</tr>
</tbody>
</table>
<p><img src="/images/951413iMgBlog/image-20220528105526139.png" alt="image-20220528105526139"></p>
<h2 id="参与比较的几款CPU参数"><a href="#参与比较的几款CPU参数" class="headerlink" title="参与比较的几款CPU参数"></a>参与比较的几款CPU参数</h2><p>IPC的说明：</p>
<blockquote>
<p>IPC: insns per cycle  insn/cycles  也就是每个时钟周期能执行的指令数量，越大程序跑的越快</p>
<p>程序的执行时间 = 指令数/(主频*IPC) //单核下，多核的话再除以核数</p>
</blockquote>
<h3 id="Hygon-7280"><a href="#Hygon-7280" class="headerlink" title="Hygon 7280"></a>Hygon 7280</h3><p>Hygon 7280 就是AMD Zen架构，最大IPC能到5. </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">架构：                           x86_64</div><div class="line">CPU 运行模式：                   32-bit, 64-bit</div><div class="line">字节序：                         Little Endian</div><div class="line">Address sizes:                   43 bits physical, 48 bits virtual</div><div class="line">CPU:                             128</div><div class="line">在线 CPU 列表：                  0-127</div><div class="line">每个核的线程数：                 2</div><div class="line">每个座的核数：                   32</div><div class="line">座：                             2</div><div class="line">NUMA 节点：                      8</div><div class="line">厂商 ID：                        HygonGenuine</div><div class="line">CPU 系列：                       24</div><div class="line">型号：                           1</div><div class="line">型号名称：                       Hygon C86 7280 32-core Processor</div><div class="line">步进：                           1</div><div class="line">CPU MHz：                        2194.586</div><div class="line">BogoMIPS：                       3999.63</div><div class="line">虚拟化：                         AMD-V</div><div class="line">L1d 缓存：                       2 MiB</div><div class="line">L1i 缓存：                       4 MiB</div><div class="line">L2 缓存：                        32 MiB</div><div class="line">L3 缓存：                        128 MiB</div><div class="line">NUMA 节点0 CPU：                 0-7,64-71</div><div class="line">NUMA 节点1 CPU：                 8-15,72-79</div><div class="line">NUMA 节点2 CPU：                 16-23,80-87</div><div class="line">NUMA 节点3 CPU：                 24-31,88-95</div><div class="line">NUMA 节点4 CPU：                 32-39,96-103</div><div class="line">NUMA 节点5 CPU：                 40-47,104-111</div><div class="line">NUMA 节点6 CPU：                 48-55,112-119</div><div class="line">NUMA 节点7 CPU：                 56-63,120-127</div></pre></td></tr></table></figure>
<p>曙光H620-G30A 机型硬件结构，CPU是hygon 7280（截图只截取了Socket0）</p>
<p><img src="/images/951413iMgBlog/image-20211231202402561.png" alt="image-20211231202402561"></p>
<h3 id="AMD-EPYC-7H12"><a href="#AMD-EPYC-7H12" class="headerlink" title="AMD EPYC 7H12"></a>AMD EPYC 7H12</h3><p>AMD EPYC 7H12 64-Core（ECS，非物理机），最大IPC能到5. </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span> lscpu</div><div class="line">Architecture:          x86_64</div><div class="line">CPU op-mode(s):        32-bit, 64-bit</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                64</div><div class="line">On-line CPU(s) list:   0-63</div><div class="line">Thread(s) per core:    2</div><div class="line">Core(s) per socket:    16</div><div class="line">座：                 2</div><div class="line">NUMA 节点：         2</div><div class="line">厂商 ID：           AuthenticAMD</div><div class="line">CPU 系列：          23</div><div class="line">型号：              49</div><div class="line">型号名称：        AMD EPYC 7H12 64-Core Processor</div><div class="line">步进：              0</div><div class="line">CPU MHz：             2595.124</div><div class="line">BogoMIPS：            5190.24</div><div class="line">虚拟化：           AMD-V</div><div class="line">超管理器厂商：  KVM</div><div class="line">虚拟化类型：     完全</div><div class="line">L1d 缓存：          32K</div><div class="line">L1i 缓存：          32K</div><div class="line">L2 缓存：           512K</div><div class="line">L3 缓存：           16384K</div><div class="line">NUMA 节点0 CPU：    0-31</div><div class="line">NUMA 节点1 CPU：    32-63</div></pre></td></tr></table></figure>
<p>AMD EPYC 7T83 ECS </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line">[root@bugu88 cpu0]# cat cache/index0/size</div><div class="line">32K</div><div class="line">[root@bugu88 cpu0]# cat cache/index1/size</div><div class="line">32K</div><div class="line">[root@bugu88 cpu0]# cat cache/index2/size</div><div class="line">512K</div><div class="line">[root@bugu88 cpu0]# cat cache/index3/size</div><div class="line">32768K</div><div class="line">[root@bugu88 cpu0]# lscpu</div><div class="line">Architecture:          x86_64</div><div class="line">CPU op-mode(s):        32-bit, 64-bit</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                16</div><div class="line">On-line CPU(s) list:   0-15</div><div class="line">Thread(s) per core:    2</div><div class="line">Core(s) per socket:    8</div><div class="line">座：                 1</div><div class="line">NUMA 节点：         1</div><div class="line">厂商 ID：           AuthenticAMD</div><div class="line">CPU 系列：          25</div><div class="line">型号：              1</div><div class="line">型号名称：        AMD EPYC 7T83 64-Core Processor</div><div class="line">步进：              1</div><div class="line">CPU MHz：             2545.218</div><div class="line">BogoMIPS：            5090.43</div><div class="line">超管理器厂商：  KVM</div><div class="line">虚拟化类型：     完全</div><div class="line">L1d 缓存：          32K</div><div class="line">L1i 缓存：          32K</div><div class="line">L2 缓存：           512K</div><div class="line">L3 缓存：           32768K</div><div class="line">NUMA 节点0 CPU：    0-15</div></pre></td></tr></table></figure>
<p>stream：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">[root@bugu88 lmbench-master]# for i in $(seq 0 15); do echo $i; numactl -C $i -m 0 ./bin/stream -W 5 -N 5 -M 64M; done</div><div class="line">0</div><div class="line">STREAM copy latency: 0.68 nanoseconds</div><div class="line">STREAM copy bandwidth: 23509.84 MB/sec</div><div class="line">STREAM scale latency: 0.69 nanoseconds</div><div class="line">STREAM scale bandwidth: 23285.51 MB/sec</div><div class="line">STREAM add latency: 0.96 nanoseconds</div><div class="line">STREAM add bandwidth: 25043.73 MB/sec</div><div class="line">STREAM triad latency: 1.40 nanoseconds</div><div class="line">STREAM triad bandwidth: 17121.79 MB/sec</div><div class="line">1</div><div class="line">STREAM copy latency: 0.68 nanoseconds</div><div class="line">STREAM copy bandwidth: 23513.96 MB/sec</div><div class="line">STREAM scale latency: 0.68 nanoseconds</div><div class="line">STREAM scale bandwidth: 23580.06 MB/sec</div><div class="line">STREAM add latency: 0.96 nanoseconds</div><div class="line">STREAM add bandwidth: 25049.96 MB/sec</div><div class="line">STREAM triad latency: 1.35 nanoseconds</div><div class="line">STREAM triad bandwidth: 17741.93 MB/sec</div></pre></td></tr></table></figure>
<h3 id="Intel-8163"><a href="#Intel-8163" class="headerlink" title="Intel 8163"></a>Intel 8163</h3><p>这次对比测试的Intel 8163 CPU信息如下，最大IPC 是4：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span>lscpu</div><div class="line">Architecture:          x86_64</div><div class="line">CPU op-mode(s):        32-bit, 64-bit</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                96</div><div class="line">On-line CPU(s) list:   0-95</div><div class="line">Thread(s) per core:    2</div><div class="line">Core(s) per socket:    24</div><div class="line">Socket(s):             2</div><div class="line">NUMA node(s):          1</div><div class="line">Vendor ID:             GenuineIntel</div><div class="line">CPU family:            6</div><div class="line">Model:                 85</div><div class="line">Model name:            Intel(R) Xeon(R) Platinum 8163 CPU @ 2.50GHz</div><div class="line">Stepping:              4</div><div class="line">CPU MHz:               2499.121</div><div class="line">CPU max MHz:           3100.0000</div><div class="line">CPU min MHz:           1000.0000</div><div class="line">BogoMIPS:              4998.90</div><div class="line">Virtualization:        VT-x</div><div class="line">L1d cache:             32K</div><div class="line">L1i cache:             32K</div><div class="line">L2 cache:              1024K</div><div class="line">L3 cache:              33792K</div><div class="line">NUMA node0 CPU(s):     0-95</div><div class="line"></div><div class="line">-----8269CY</div><div class="line"><span class="meta">#</span>lscpu</div><div class="line">Architecture:          x86_64</div><div class="line">CPU op-mode(s):        32-bit, 64-bit</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                104</div><div class="line">On-line CPU(s) list:   0-103</div><div class="line">Thread(s) per core:    2</div><div class="line">Core(s) per socket:    26</div><div class="line">Socket(s):             2</div><div class="line">NUMA node(s):          2</div><div class="line">Vendor ID:             GenuineIntel</div><div class="line">CPU family:            6</div><div class="line">Model:                 85</div><div class="line">Model name:            Intel(R) Xeon(R) Platinum 8269CY CPU @ 2.50GHz</div><div class="line">Stepping:              7</div><div class="line">CPU MHz:               3200.000</div><div class="line">CPU max MHz:           3800.0000</div><div class="line">CPU min MHz:           1200.0000</div><div class="line">BogoMIPS:              4998.89</div><div class="line">Virtualization:        VT-x</div><div class="line">L1d cache:             32K</div><div class="line">L1i cache:             32K</div><div class="line">L2 cache:              1024K</div><div class="line">L3 cache:              36608K</div><div class="line">NUMA node0 CPU(s):     0-25,52-77</div><div class="line">NUMA node1 CPU(s):     26-51,78-103</div></pre></td></tr></table></figure>
<h3 id="鲲鹏920"><a href="#鲲鹏920" class="headerlink" title="鲲鹏920"></a>鲲鹏920</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line">[root@ARM 19:15 /root/lmbench3]</div><div class="line">#numactl -H</div><div class="line">available: 4 nodes (0-3)</div><div class="line">node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23</div><div class="line">node 0 size: 192832 MB</div><div class="line">node 0 free: 146830 MB</div><div class="line">node 1 cpus: 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47</div><div class="line">node 1 size: 193533 MB</div><div class="line">node 1 free: 175354 MB</div><div class="line">node 2 cpus: 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71</div><div class="line">node 2 size: 193533 MB</div><div class="line">node 2 free: 175718 MB</div><div class="line">node 3 cpus: 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95</div><div class="line">node 3 size: 193532 MB</div><div class="line">node 3 free: 183643 MB</div><div class="line">node distances:</div><div class="line">node   0   1   2   3</div><div class="line">  0:  10  12  20  22</div><div class="line">  1:  12  10  22  24</div><div class="line">  2:  20  22  10  12</div><div class="line">  3:  22  24  12  10</div><div class="line">  </div><div class="line">  #lscpu</div><div class="line">Architecture:          aarch64</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                96</div><div class="line">On-line CPU(s) list:   0-95</div><div class="line">Thread(s) per core:    1</div><div class="line">Core(s) per socket:    48</div><div class="line">Socket(s):             2</div><div class="line">NUMA node(s):          4</div><div class="line">Model:                 0</div><div class="line">CPU max MHz:           2600.0000</div><div class="line">CPU min MHz:           200.0000</div><div class="line">BogoMIPS:              200.00</div><div class="line">L1d cache:             64K</div><div class="line">L1i cache:             64K</div><div class="line">L2 cache:              512K</div><div class="line">L3 cache:              24576K</div><div class="line">NUMA node0 CPU(s):     0-23</div><div class="line">NUMA node1 CPU(s):     24-47</div><div class="line">NUMA node2 CPU(s):     48-71</div><div class="line">NUMA node3 CPU(s):     72-95</div><div class="line">Flags:                 fp asimd evtstrm aes pmull sha1 sha2 crc32 atomics fphp asimdhp cpuid asimdrdm jscvt fcma dcpop asimddp asimdfhm</div></pre></td></tr></table></figure>
<h3 id="飞腾2500"><a href="#飞腾2500" class="headerlink" title="飞腾2500"></a>飞腾2500</h3><p>飞腾2500用nop去跑IPC的话，只能到1，但是跑其它代码能到2.33</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span>lscpu</div><div class="line">Architecture:          aarch64</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                128</div><div class="line">On-line CPU(s) list:   0-127</div><div class="line">Thread(s) per core:    1</div><div class="line">Core(s) per socket:    64</div><div class="line">Socket(s):             2</div><div class="line">NUMA node(s):          16</div><div class="line">Model:                 3</div><div class="line">BogoMIPS:              100.00</div><div class="line">L1d cache:             32K</div><div class="line">L1i cache:             32K</div><div class="line">L2 cache:              2048K</div><div class="line">L3 cache:              65536K</div><div class="line">NUMA node0 CPU(s):     0-7</div><div class="line">NUMA node1 CPU(s):     8-15</div><div class="line">NUMA node2 CPU(s):     16-23</div><div class="line">NUMA node3 CPU(s):     24-31</div><div class="line">NUMA node4 CPU(s):     32-39</div><div class="line">NUMA node5 CPU(s):     40-47</div><div class="line">NUMA node6 CPU(s):     48-55</div><div class="line">NUMA node7 CPU(s):     56-63</div><div class="line">NUMA node8 CPU(s):     64-71</div><div class="line">NUMA node9 CPU(s):     72-79</div><div class="line">NUMA node10 CPU(s):    80-87</div><div class="line">NUMA node11 CPU(s):    88-95</div><div class="line">NUMA node12 CPU(s):    96-103</div><div class="line">NUMA node13 CPU(s):    104-111</div><div class="line">NUMA node14 CPU(s):    112-119</div><div class="line">NUMA node15 CPU(s):    120-127</div><div class="line">Flags:                 fp asimd evtstrm aes pmull sha1 sha2 crc32 cpuid</div><div class="line"><span class="meta"></span></div><div class="line">#perf stat ./nop</div><div class="line">failed to read counter stalled-cycles-frontend</div><div class="line">failed to read counter stalled-cycles-backend</div><div class="line">failed to read counter branches</div><div class="line"></div><div class="line"> Performance counter stats for './nop':</div><div class="line"></div><div class="line">      78638.700540      task-clock (msec)         #    0.999 CPUs utilized</div><div class="line">              1479      context-switches          #    0.019 K/sec</div><div class="line">                55      cpu-migrations            #    0.001 K/sec</div><div class="line">                37      page-faults               #    0.000 K/sec</div><div class="line">      165127619524      cycles                    #    2.100 GHz</div><div class="line">   &lt;not supported&gt;      stalled-cycles-frontend</div><div class="line">   &lt;not supported&gt;      stalled-cycles-backend</div><div class="line">      165269372437      instructions              #    1.00  insns per cycle</div><div class="line">   &lt;not supported&gt;      branches</div><div class="line">           3057191      branch-misses             #    0.00% of all branches</div><div class="line"></div><div class="line">      78.692839007 seconds time elapsed</div><div class="line">      </div><div class="line"><span class="meta">#</span>dmidecode -t processor</div><div class="line"><span class="meta">#</span> dmidecode 3.0</div><div class="line">Getting SMBIOS data from sysfs.</div><div class="line">SMBIOS 3.2.0 present.</div><div class="line"><span class="meta">#</span> SMBIOS implementations newer than version 3.0 are not</div><div class="line"><span class="meta">#</span> fully supported by this version of dmidecode.</div><div class="line"></div><div class="line">Handle 0x0004, DMI type 4, 48 bytes</div><div class="line">Processor Information</div><div class="line">	Socket Designation: BGA3576</div><div class="line">	Type: Central Processor</div><div class="line">	Family: &lt;OUT OF SPEC&gt;</div><div class="line">	Manufacturer: PHYTIUM</div><div class="line">	ID: 00 00 00 00 70 1F 66 22</div><div class="line">	Version: S2500</div><div class="line">	Voltage: 0.8 V</div><div class="line">	External Clock: 50 MHz</div><div class="line">	Max Speed: 2100 MHz</div><div class="line">	Current Speed: 2100 MHz</div><div class="line">	Status: Populated, Enabled</div><div class="line">	Upgrade: Other</div><div class="line">	L1 Cache Handle: 0x0005</div><div class="line">	L2 Cache Handle: 0x0007</div><div class="line">	L3 Cache Handle: 0x0008</div><div class="line">	Serial Number: N/A</div><div class="line">	Asset Tag: No Asset Tag</div><div class="line">	Part Number: NULL</div><div class="line">	Core Count: 64</div><div class="line">	Core Enabled: 64</div><div class="line">	Thread Count: 64</div><div class="line">	Characteristics:</div><div class="line">		64-bit capable</div><div class="line">		Multi-Core</div><div class="line">		Hardware Thread</div><div class="line">		Execute Protection</div><div class="line">		Enhanced Virtualization</div><div class="line">		Power/Performance Control</div></pre></td></tr></table></figure>
<h2 id="单核以及HT计算Prime性能比较"><a href="#单核以及HT计算Prime性能比较" class="headerlink" title="单核以及HT计算Prime性能比较"></a>单核以及HT计算Prime性能比较</h2><p>以上两款CPU但从物理上的指标来看似乎AMD要好很多，从工艺上AMD也要领先一代(2年），从单核参数上来说是2.0 VS 2.5GHz，但是IPC 是5 VS 4，算下来理想的单核性能刚好一致（2<em>5=2.5 </em>4）。</p>
<p>从外面的一些跑分结果显示也是AMD 要好，但是实际性能怎么样呢？</p>
<p>测试命令，这个测试命令无论在哪个CPU下，用2个物理核用时都是一个物理核的一半，所以这个计算是可以完全并行的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">taskset -c 1 /usr/bin/sysbench --num-threads=1 --test=cpu --cpu-max-prime=50000 run //单核用一个threads，绑核; HT用2个threads，绑一对HT</div></pre></td></tr></table></figure>
<p>测试结果为耗时，单位秒</p>
<table>
<thead>
<tr>
<th style="text-align:left">测试项</th>
<th>AMD EPYC 7H12 2.5G CentOS 7.9</th>
<th>Hygon 7280 2.1GHz CentOS</th>
<th style="text-align:left">Hygon 7280 2.1GHz 麒麟</th>
<th>Intel 8269 2.50G</th>
<th style="text-align:left">Intel 8163 CPU @ 2.50GHz</th>
<th style="text-align:left">Intel E5-2682 v4 @ 2.50GHz</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">单核  prime 50000 耗时</td>
<td>59秒  IPC 0.56</td>
<td>77秒 IPC 0.55</td>
<td style="text-align:left">89秒  IPC 0.56;</td>
<td>83 0.41</td>
<td style="text-align:left">105秒  IPC 0.41</td>
<td style="text-align:left">109秒  IPC 0.39</td>
</tr>
<tr>
<td style="text-align:left">HT  prime 50000 耗时</td>
<td>57秒  IPC 0.31</td>
<td>74秒 IPC 0.29</td>
<td style="text-align:left">87秒  IPC 0.29</td>
<td>48 0.35</td>
<td style="text-align:left">60秒   IPC 0.36</td>
<td style="text-align:left">74秒    IPC 0.29</td>
</tr>
</tbody>
</table>
<p>相同CPU下的 指令数 基本= 耗时 <em> IPC </em> 核数</p>
<p>以上测试结果显示Hygon 7280单核计算能力是要强过Intel 8163的，但是超线程在这个场景下太不给力，相当于没有。</p>
<p>当然上面的计算Prime太单纯了，代表不了复杂的业务场景，所以接下来用MySQL的查询场景来看看。</p>
<p>如果是arm芯片在计算prime上明显要好过x86，猜测是除法取余指令上有优化</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">#taskset -c 11 sysbench cpu --threads=1 --events=50000  run</div><div class="line">sysbench 1.0.20 (using bundled LuaJIT 2.1.0-beta2)</div></pre></td></tr></table></figure>
<p>测试结果为10秒钟的event</p>
<table>
<thead>
<tr>
<th style="text-align:left">测试项</th>
<th>FT2500 2.1G</th>
<th>鲲鹏920-4826 2.6GHz</th>
<th style="text-align:left">Intel 8163 CPU @ 2.50GHz</th>
<th>Hygon C86 7280 2.1GHz</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">单核  prime 10秒 events</td>
<td>21626  IPC 0.89</td>
<td>30299 IPC 1.01</td>
<td style="text-align:left">8435  IPC 0.41</td>
<td>10349  IPC 0.63</td>
</tr>
</tbody>
</table>
<h2 id="对比MySQL-sysbench和tpcc性能"><a href="#对比MySQL-sysbench和tpcc性能" class="headerlink" title="对比MySQL sysbench和tpcc性能"></a>对比MySQL sysbench和tpcc性能</h2><p>分别将MySQL 5.7.34社区版部署到intel+AliOS以及hygon 7280+CentOS上，将mysqld绑定到单核，一样的压力配置均将CPU跑到100%，然后用sysbench测试点查， HT表示将mysqld绑定到一对HT核。</p>
<h3 id="sysbench点查"><a href="#sysbench点查" class="headerlink" title="sysbench点查"></a>sysbench点查</h3><p> 测试命令类似如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sysbench --test=&apos;/usr/share/doc/sysbench/tests/db/select.lua&apos; --oltp_tables_count=1 --report-interval=1 --oltp-table-size=10000000  --mysql-port=3307 --mysql-db=sysbench_single --mysql-user=root --mysql-password=&apos;Bj6f9g96!@#&apos;  --max-requests=0   --oltp_skip_trx=on --oltp_auto_inc=on  --oltp_range_size=5  --mysql-table-engine=innodb --rand-init=on   --max-time=300 --mysql-host=x86.51 --num-threads=4 run</div></pre></td></tr></table></figure>
<p>测试结果(测试中的差异AMD、Hygon CPU跑在CentOS7.9， intel CPU、Kunpeng 920 跑在AliOS上, xdb表示用集团的xdb替换社区的MySQL Server， 麒麟是国产OS)：</p>
<table>
<thead>
<tr>
<th style="text-align:left">测试核数</th>
<th>AMD EPYC 7H12 2.5G</th>
<th style="text-align:left">Hygon 7280 2.1G</th>
<th>Hygon 7280 2.1GHz 麒麟</th>
<th>Intel 8269 2.50G</th>
<th style="text-align:left">Intel 8163 2.50G</th>
<th style="text-align:left">Intel 8163 2.50G XDB5.7</th>
<th>鲲鹏 920-4826 2.6G</th>
<th>鲲鹏 920-4826 2.6G XDB8.0</th>
<th>FT2500 alisql 8.0 本地–socket</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">单核</td>
<td>24674  0.54</td>
<td style="text-align:left">13441  0.46</td>
<td>10236  0.39</td>
<td>28208 0.75</td>
<td style="text-align:left">25474   0.84</td>
<td style="text-align:left">29376    0.89</td>
<td>9694  0.49</td>
<td>8301  0.46</td>
<td>3602 0.53</td>
</tr>
<tr>
<td style="text-align:left">一对HT</td>
<td>36157 0.42</td>
<td style="text-align:left">21747  0.38</td>
<td>19417  0.37</td>
<td>36754 0.49</td>
<td style="text-align:left">35894  0.6</td>
<td style="text-align:left">40601  0.65</td>
<td>无HT</td>
<td>无HT</td>
<td>无HT</td>
</tr>
<tr>
<td style="text-align:left">4物理核</td>
<td>94132 0.52</td>
<td style="text-align:left">49822 0.46</td>
<td>38033  0.37</td>
<td>90434 0.69 350%</td>
<td style="text-align:left">87254  0.73</td>
<td style="text-align:left">106472  0.83</td>
<td>34686  0.42</td>
<td>28407  0.39</td>
<td>14232 0.53</td>
</tr>
<tr>
<td style="text-align:left">16物理核</td>
<td>325409 0.48</td>
<td style="text-align:left">171630 0.38</td>
<td>134980  0.34</td>
<td>371718 0.69 1500%</td>
<td style="text-align:left">332967  0.72</td>
<td style="text-align:left">446290  0.85 //16核比4核好！</td>
<td>116122  0.35</td>
<td>94697  0.33</td>
<td>59199  0.6  8core:31210 0.59</td>
</tr>
<tr>
<td style="text-align:left">32物理核</td>
<td>542192 0.43</td>
<td style="text-align:left">298716 0.37</td>
<td>255586  0.33</td>
<td>642548 0.64 2700%</td>
<td style="text-align:left">588318  0.67</td>
<td style="text-align:left">598637  0.81 CPU 2400%</td>
<td>228601  0.36</td>
<td>177424  0.32</td>
<td>114020 0.65</td>
</tr>
</tbody>
</table>
<ul>
<li>麒麟OS下CPU很难跑满，大致能跑到90%-95%左右，麒麟上装的社区版MySQL-5.7.29；飞腾要特别注意mysqld所在socket，同时以上飞腾数据都是走–socket压测锁的，32core走网络压测QPS为：99496（15%的网络损耗）[^说明]</li>
</ul>
<h3 id="Mysqld-二进制代码所在-page-cache带来的性能影响"><a href="#Mysqld-二进制代码所在-page-cache带来的性能影响" class="headerlink" title="Mysqld 二进制代码所在 page cache带来的性能影响"></a>Mysqld 二进制代码所在 page cache带来的性能影响</h3><p>如果是飞腾跨socket影响很大，mysqld二进制跨socket性能会下降30%以上</p>
<p>对于鲲鹏920，双路服务器上测试，mysqld绑在node0, 但是分别将mysqld二进制load进不同的node上的page cache，然后执行点查</p>
<table>
<thead>
<tr>
<th>mysqld</th>
<th>node0</th>
<th>node1</th>
<th>node2</th>
<th>node3</th>
</tr>
</thead>
<tbody>
<tr>
<td>QPS</td>
<td>190120 IPC 0.40</td>
<td>182518 IPC 0.39</td>
<td>189046 IPC 0.40</td>
<td>186533 IPC 0.40</td>
</tr>
</tbody>
</table>
<p>以上数据可以看出这里node0到node1还是很慢的，居然比跨socket还慢，反过来说鲲鹏跨socket性能很好</p>
<p>绑定mysqld到不同node的page cache操作</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">#systemctl stop mysql-server</div><div class="line"></div><div class="line">[root@poc65 /root/vmtouch]</div><div class="line">#vmtouch -e /usr/local/mysql/bin/mysqld</div><div class="line">           Files: 1</div><div class="line">     Directories: 0</div><div class="line">   Evicted Pages: 5916 (23M)</div><div class="line">         Elapsed: 0.00322 seconds</div><div class="line"></div><div class="line">#vmtouch -v /usr/local/mysql/bin/mysqld</div><div class="line">/usr/local/mysql/bin/mysqld</div><div class="line">[                                                            ] 0/5916</div><div class="line"></div><div class="line">           Files: 1</div><div class="line">     Directories: 0</div><div class="line">  Resident Pages: 0/5916  0/23M  0%</div><div class="line">         Elapsed: 0.000204 seconds</div><div class="line"></div><div class="line">#taskset -c 24 md5sum /usr/local/mysql/bin/mysqld</div><div class="line"></div><div class="line">#grep mysqld /proc/`pidof mysqld`/numa_maps  //检查mysqld具体绑定在哪个node上</div><div class="line">00400000 default file=/usr/local/mysql/bin/mysqld mapped=3392 active=1 N0=3392 kernelpagesize_kB=4</div><div class="line">0199b000 default file=/usr/local/mysql/bin/mysqld anon=10 dirty=10 mapped=134 active=10 N0=134 kernelpagesize_kB=4</div><div class="line">01a70000 default file=/usr/local/mysql/bin/mysqld anon=43 dirty=43 mapped=120 active=43 N0=120 kernelpagesize_kB=4</div></pre></td></tr></table></figure>
<h3 id="网卡以及node距离带来的性能差异"><a href="#网卡以及node距离带来的性能差异" class="headerlink" title="网卡以及node距离带来的性能差异"></a>网卡以及node距离带来的性能差异</h3><p>在鲲鹏920+mysql5.7+alios，将内存分配锁在node0上，然后分别绑核在1、24、48、72core，进行sysbench点查对比</p>
<table>
<thead>
<tr>
<th></th>
<th>Core1</th>
<th>Core24</th>
<th>Core48</th>
<th>Core72</th>
</tr>
</thead>
<tbody>
<tr>
<td>QPS</td>
<td>10800</td>
<td>10400</td>
<td>7700</td>
<td>7700</td>
</tr>
</tbody>
</table>
<p>以上测试的时候业务进程分配的内存全限制在node0上（下面的网卡中断测试也是同样内存结构）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">#/root/numa-maps-summary.pl &lt;/proc/123853/numa_maps</div><div class="line">N0        :      5085548 ( 19.40 GB)</div><div class="line">N1        :         4479 (  0.02 GB)</div><div class="line">N2        :            1 (  0.00 GB)</div><div class="line">active    :            0 (  0.00 GB)</div><div class="line">anon      :      5085455 ( 19.40 GB)</div><div class="line">dirty     :      5085455 ( 19.40 GB)</div><div class="line">kernelpagesize_kB:         2176 (  0.01 GB)</div><div class="line">mapmax    :          348 (  0.00 GB)</div><div class="line">mapped    :         4626 (  0.02 GB)</div></pre></td></tr></table></figure>
<p>对比测试，将内存锁在node3上，重复进行以上测试结果如下：</p>
<table>
<thead>
<tr>
<th></th>
<th>Core1</th>
<th>Core24</th>
<th>Core48</th>
<th>Core72</th>
</tr>
</thead>
<tbody>
<tr>
<td>QPS</td>
<td>10500</td>
<td>10000</td>
<td>8100</td>
<td>8000</td>
</tr>
</tbody>
</table>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">#/root/numa-maps-summary.pl &lt;/proc/54478/numa_maps</div><div class="line">N0        :           16 (  0.00 GB)</div><div class="line">N1        :         4401 (  0.02 GB)</div><div class="line">N2        :            1 (  0.00 GB)</div><div class="line">N3        :      1779989 (  6.79 GB)</div><div class="line">active    :            0 (  0.00 GB)</div><div class="line">anon      :      1779912 (  6.79 GB)</div><div class="line">dirty     :      1779912 (  6.79 GB)</div><div class="line">kernelpagesize_kB:         1108 (  0.00 GB)</div><div class="line">mapmax    :          334 (  0.00 GB)</div><div class="line">mapped    :         4548 (  0.02 GB)</div></pre></td></tr></table></figure>
<p>机器上网卡eth1插在node0上，由以上两组对比测试发现网卡影响比内存跨node影响更大，网卡影响有20%。而内存的影响基本看不到（就近好那么一点点，但是不明显，只能解释为cache命中率很高了）</p>
<p>此时软中断都在node0上，如果将软中断绑定到node3上，第72core的QPS能提升到8500，并且非常稳定。同时core0的QPS下降到10000附近。</p>
<h4 id="网卡软中断以及网卡远近的测试结论"><a href="#网卡软中断以及网卡远近的测试结论" class="headerlink" title="网卡软中断以及网卡远近的测试结论"></a>网卡软中断以及网卡远近的测试结论</h4><p>测试机器只是用了一块网卡，网卡插在node0上。</p>
<p>一般网卡中断会占用一些CPU，如果把网卡中断挪到其它node的core上，在鲲鹏920上测试，业务跑在node3（使用全部24core），网卡中断分别在node0和node3，QPS分别是：179000 VS 175000 （此时把中断放到node0或者是和node3最近的node2上差别不大）</p>
<p>如果将业务跑在node0上（全部24core），网卡中断分别在node0和node1上得到的QPS分别是：204000 VS 212000 </p>
<h3 id="tpcc-1000仓"><a href="#tpcc-1000仓" class="headerlink" title="tpcc 1000仓"></a>tpcc 1000仓</h3><p>测试结果(测试中Hygon 7280分别跑在CentOS7.9和麒麟上， 鲲鹏/intel CPU 跑在AliOS、麒麟是国产OS)：</p>
<p>tpcc测试数据，结果为1000仓，tpmC (NewOrders) ，未标注CPU 则为跑满了</p>
<table>
<thead>
<tr>
<th>测试核数</th>
<th>Intel 8269 2.50G</th>
<th>Intel 8163 2.50G</th>
<th>Hygon 7280 2.1GHz 麒麟</th>
<th>Hygon 7280 2.1G CentOS 7.9</th>
<th>鲲鹏 920-4826 2.6G</th>
<th>鲲鹏 920-4826 2.6G XDB8.0</th>
</tr>
</thead>
<tbody>
<tr>
<td>1物理核</td>
<td>12392</td>
<td>9902</td>
<td>4706</td>
<td>7011</td>
<td>6619</td>
<td>4653</td>
</tr>
<tr>
<td>一对HT</td>
<td>17892</td>
<td>15324</td>
<td>8950</td>
<td>11778</td>
<td>无HT</td>
<td>无HT</td>
</tr>
<tr>
<td>4物理核</td>
<td>51525</td>
<td>40877</td>
<td>19387 380%</td>
<td>30046</td>
<td>23959</td>
<td>20101</td>
</tr>
<tr>
<td>8物理核</td>
<td>100792</td>
<td>81799</td>
<td>39664 750%</td>
<td>60086</td>
<td>42368</td>
<td>40572</td>
</tr>
<tr>
<td>16物理核</td>
<td>160798 抖动</td>
<td>140488 CPU抖动</td>
<td>75013 1400%</td>
<td>106419 1300-1550%</td>
<td>70581  1200%</td>
<td>79844</td>
</tr>
<tr>
<td>24物理核</td>
<td>188051</td>
<td>164757 1600-2100%</td>
<td>100841 1800-2000%</td>
<td>130815 1600-2100%</td>
<td>88204  1600%</td>
<td>115355</td>
</tr>
<tr>
<td>32物理核</td>
<td>195292</td>
<td>185171 2000-2500%</td>
<td>116071 1900-2400%</td>
<td>142746 1800-2400%</td>
<td>102089  1900%</td>
<td>143567</td>
</tr>
<tr>
<td>48物理核</td>
<td>19969l</td>
<td>195730 2100-2600%</td>
<td>128188  2100-2800%</td>
<td>149782 2000-2700%</td>
<td>116374  2500%</td>
<td>206055  4500%</td>
</tr>
</tbody>
</table>
<p>tpcc并发到一定程度后主要是锁导致性能上不去，所以超多核意义不大。</p>
<p>如果在Hygon 7280 2.1GHz 麒麟上起两个MySQLD实例，每个实例各绑定32物理core，性能刚好翻倍：<img src="/images/951413iMgBlog/image-20210823082702539.png" alt="image-20210823082702539"></p>
<p>测试过程CPU均跑满（未跑满的话会标注出来），IPC跑不起来性能就必然低，超线程虽然总性能好了但是会导致IPC降低(参考前面的公式)。可以看到对本来IPC比较低的场景，启用超线程后一般对性能会提升更大一些。</p>
<p>CPU核数增加到32核后，MySQL社区版性能追平xdb， 此时sysbench使用120线程压性能较好（AMD得240线程压）</p>
<p>32核的时候对比下MySQL 社区版在Hygon7280和Intel 8163下的表现：</p>
<p><img src="/images/951413iMgBlog/image-20210817181752243.png" alt="image-20210817181752243"></p>
<h2 id="三款CPU的性能指标"><a href="#三款CPU的性能指标" class="headerlink" title="三款CPU的性能指标"></a>三款CPU的性能指标</h2><table>
<thead>
<tr>
<th style="text-align:left">测试项</th>
<th>AMD EPYC 7H12 2.5G</th>
<th style="text-align:left">Hygon 7280 2.1GHz</th>
<th style="text-align:left">Intel 8163 CPU @ 2.50GHz</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">内存带宽(MiB/s)</td>
<td>12190.50</td>
<td style="text-align:left">6206.06</td>
<td style="text-align:left">7474.45</td>
</tr>
<tr>
<td style="text-align:left">内存延时(遍历很大一个数组)</td>
<td>0.334ms</td>
<td style="text-align:left">0.336ms</td>
<td style="text-align:left">0.429ms</td>
</tr>
</tbody>
</table>
<h2 id="在lmbench上的测试数据"><a href="#在lmbench上的测试数据" class="headerlink" title="在lmbench上的测试数据"></a>在lmbench上的测试数据</h2><p>stream主要用于测试带宽，对应的时延是在带宽跑满情况下的带宽。</p>
<p>lat_mem_rd用来测试操作不同数据大小的时延。总的来说带宽看stream、时延看lat_mem_rd</p>
<h3 id="飞腾2500-1"><a href="#飞腾2500-1" class="headerlink" title="飞腾2500"></a>飞腾2500</h3><p>用stream测试带宽和latency，可以看到带宽随着numa距离不断减少、对应的latency不断增加，到最近的numa node有10%的损耗，这个损耗和numactl给出的距离完全一致。跨socket访问内存latency是node内的3倍，带宽是三分之一，但是socket1性能和socket0性能完全一致</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div></pre></td><td class="code"><pre><div class="line">time for i in $(seq 7 8 128); do echo $i; numactl -C $i -m 0 ./bin/stream -W 5 -N 5 -M 64M; done</div><div class="line"></div><div class="line">#numactl -C 7 -m 0 ./bin/stream  -W 5 -N 5 -M 64M</div><div class="line">STREAM copy latency: 2.84 nanoseconds</div><div class="line">STREAM copy bandwidth: 5638.21 MB/sec</div><div class="line">STREAM scale latency: 2.72 nanoseconds</div><div class="line">STREAM scale bandwidth: 5885.97 MB/sec</div><div class="line">STREAM add latency: 2.26 nanoseconds</div><div class="line">STREAM add bandwidth: 10615.13 MB/sec</div><div class="line">STREAM triad latency: 4.53 nanoseconds</div><div class="line">STREAM triad bandwidth: 5297.93 MB/sec</div><div class="line"></div><div class="line">#numactl -C 7 -m 1 ./bin/stream  -W 5 -N 5 -M 64M</div><div class="line">STREAM copy latency: 3.16 nanoseconds</div><div class="line">STREAM copy bandwidth: 5058.71 MB/sec</div><div class="line">STREAM scale latency: 3.15 nanoseconds</div><div class="line">STREAM scale bandwidth: 5074.78 MB/sec</div><div class="line">STREAM add latency: 2.35 nanoseconds</div><div class="line">STREAM add bandwidth: 10197.36 MB/sec</div><div class="line">STREAM triad latency: 5.12 nanoseconds</div><div class="line">STREAM triad bandwidth: 4686.37 MB/sec</div><div class="line"></div><div class="line">#numactl -C 7 -m 2 ./bin/stream  -W 5 -N 5 -M 64M</div><div class="line">STREAM copy latency: 3.85 nanoseconds</div><div class="line">STREAM copy bandwidth: 4150.98 MB/sec</div><div class="line">STREAM scale latency: 3.95 nanoseconds</div><div class="line">STREAM scale bandwidth: 4054.30 MB/sec</div><div class="line">STREAM add latency: 2.64 nanoseconds</div><div class="line">STREAM add bandwidth: 9100.12 MB/sec</div><div class="line">STREAM triad latency: 6.39 nanoseconds</div><div class="line">STREAM triad bandwidth: 3757.70 MB/sec</div><div class="line"></div><div class="line">#numactl -C 7 -m 3 ./bin/stream  -W 5 -N 5 -M 64M</div><div class="line">STREAM copy latency: 3.69 nanoseconds</div><div class="line">STREAM copy bandwidth: 4340.24 MB/sec</div><div class="line">STREAM scale latency: 3.62 nanoseconds</div><div class="line">STREAM scale bandwidth: 4422.18 MB/sec</div><div class="line">STREAM add latency: 2.47 nanoseconds</div><div class="line">STREAM add bandwidth: 9704.82 MB/sec</div><div class="line">STREAM triad latency: 5.74 nanoseconds</div><div class="line">STREAM triad bandwidth: 4177.85 MB/sec</div><div class="line"></div><div class="line">[root@101a05001.cloud.a05.am11 /root/lmbench3]</div><div class="line">#numactl -C 7 -m 7 ./bin/stream  -W 5 -N 5 -M 64M</div><div class="line">STREAM copy latency: 3.95 nanoseconds</div><div class="line">STREAM copy bandwidth: 4051.51 MB/sec</div><div class="line">STREAM scale latency: 3.94 nanoseconds</div><div class="line">STREAM scale bandwidth: 4060.63 MB/sec</div><div class="line">STREAM add latency: 2.54 nanoseconds</div><div class="line">STREAM add bandwidth: 9434.51 MB/sec</div><div class="line">STREAM triad latency: 6.13 nanoseconds</div><div class="line">STREAM triad bandwidth: 3913.36 MB/sec</div><div class="line"></div><div class="line">[root@101a05001.cloud.a05.am11 /root/lmbench3]</div><div class="line">#numactl -C 7 -m 10 ./bin/stream  -W 5 -N 5 -M 64M</div><div class="line">STREAM copy latency: 8.80 nanoseconds</div><div class="line">STREAM copy bandwidth: 1817.78 MB/sec</div><div class="line">STREAM scale latency: 8.59 nanoseconds</div><div class="line">STREAM scale bandwidth: 1861.65 MB/sec</div><div class="line">STREAM add latency: 5.55 nanoseconds</div><div class="line">STREAM add bandwidth: 4320.68 MB/sec</div><div class="line">STREAM triad latency: 13.94 nanoseconds</div><div class="line">STREAM triad bandwidth: 1721.76 MB/sec</div><div class="line"></div><div class="line">[root@101a05001.cloud.a05.am11 /root/lmbench3]</div><div class="line">#numactl -C 7 -m 11 ./bin/stream  -W 5 -N 5 -M 64M</div><div class="line">STREAM copy latency: 9.27 nanoseconds</div><div class="line">STREAM copy bandwidth: 1726.52 MB/sec</div><div class="line">STREAM scale latency: 9.31 nanoseconds</div><div class="line">STREAM scale bandwidth: 1718.10 MB/sec</div><div class="line">STREAM add latency: 5.65 nanoseconds</div><div class="line">STREAM add bandwidth: 4250.89 MB/sec</div><div class="line">STREAM triad latency: 14.09 nanoseconds</div><div class="line">STREAM triad bandwidth: 1703.66 MB/sec</div><div class="line"></div><div class="line">[root@101a05001.cloud.a05.am11 /root/lmbench3]</div><div class="line">#numactl -C 88 -m 11 ./bin/stream  -W 5 -N 5 -M 64M //在另外一个socket上测试本numa，和node0性能完全一致</div><div class="line">STREAM copy latency: 2.93 nanoseconds</div><div class="line">STREAM copy bandwidth: 5454.67 MB/sec</div><div class="line">STREAM scale latency: 2.96 nanoseconds</div><div class="line">STREAM scale bandwidth: 5400.03 MB/sec</div><div class="line">STREAM add latency: 2.28 nanoseconds</div><div class="line">STREAM add bandwidth: 10543.42 MB/sec</div><div class="line">STREAM triad latency: 4.52 nanoseconds</div><div class="line">STREAM triad bandwidth: 5308.40 MB/sec</div><div class="line"></div><div class="line">[root@101a05001.cloud.a05.am11 /root/lmbench3]</div><div class="line">#numactl -C 7 -m 15 ./bin/stream  -W 5 -N 5 -M 64M</div><div class="line">STREAM copy latency: 8.73 nanoseconds</div><div class="line">STREAM copy bandwidth: 1831.77 MB/sec</div><div class="line">STREAM scale latency: 8.81 nanoseconds</div><div class="line">STREAM scale bandwidth: 1815.13 MB/sec</div><div class="line">STREAM add latency: 5.63 nanoseconds</div><div class="line">STREAM add bandwidth: 4265.21 MB/sec</div><div class="line">STREAM triad latency: 13.09 nanoseconds</div><div class="line">STREAM triad bandwidth: 1833.68 MB/sec</div></pre></td></tr></table></figure>
<p>Lat_mem_rd 用cpu7访问node0和node15对比结果，随着数据的加大，延时在加大，64M时能有3倍差距，和上面测试一致</p>
<p>下图 第一列 表示读写数据的大小（单位M），第二列表示访问延时（单位纳秒），一般可以看到在L1/L2/L3 cache大小的地方延时会有跳跃，远超过L3大小后，延时就是内存延时了</p>
<p><img src="/images/951413iMgBlog/image-20210924185044090.png" alt="image-20210924185044090"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">numactl -C 7 -m 0 ./bin/lat_mem_rd -W 5 -N 5 -t 64M  //-C 7 cpu 7, -m 0 node0, -W 热身 -t stride</div></pre></td></tr></table></figure>
<p>同样的机型，开关numa的测试结果，关numa 时延、带宽都差了几倍</p>
<p><img src="/images/951413iMgBlog/image-20220323153507557.png" alt="image-20220323153507557"></p>
<p>关闭numa的机器上测试结果随机性很强，这应该是和内存分配在那里有关系，不过如果机器一直保持这个状态反复测试的话，快的core一直快，慢的core一直慢，这是因为物理地址分配有一定的规律，在物理内存没怎么变化的情况下，快的core恰好分到的内存比较近。</p>
<p>同时不同机器状态（内存使用率）测试结果也不一样</p>
<h3 id="鲲鹏920-1"><a href="#鲲鹏920-1" class="headerlink" title="鲲鹏920"></a>鲲鹏920</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line">#for i in $(seq 0 15); do echo core:$i; numactl -N $i -m 7 ./bin/stream  -W 5 -N 5 -M 64M; done</div><div class="line">STREAM copy latency: 1.84 nanoseconds</div><div class="line">STREAM copy bandwidth: 8700.75 MB/sec</div><div class="line">STREAM scale latency: 1.86 nanoseconds</div><div class="line">STREAM scale bandwidth: 8623.60 MB/sec</div><div class="line">STREAM add latency: 2.18 nanoseconds</div><div class="line">STREAM add bandwidth: 10987.04 MB/sec</div><div class="line">STREAM triad latency: 3.03 nanoseconds</div><div class="line">STREAM triad bandwidth: 7926.87 MB/sec</div><div class="line"></div><div class="line">#numactl -C 7 -m 1 ./bin/stream  -W 5 -N 5 -M 64M</div><div class="line">STREAM copy latency: 2.05 nanoseconds</div><div class="line">STREAM copy bandwidth: 7802.45 MB/sec</div><div class="line">STREAM scale latency: 2.08 nanoseconds</div><div class="line">STREAM scale bandwidth: 7681.87 MB/sec</div><div class="line">STREAM add latency: 2.19 nanoseconds</div><div class="line">STREAM add bandwidth: 10954.76 MB/sec</div><div class="line">STREAM triad latency: 3.17 nanoseconds</div><div class="line">STREAM triad bandwidth: 7559.86 MB/sec</div><div class="line"></div><div class="line">#numactl -C 7 -m 2 ./bin/stream  -W 5 -N 5 -M 64M</div><div class="line">STREAM copy latency: 3.51 nanoseconds</div><div class="line">STREAM copy bandwidth: 4556.86 MB/sec</div><div class="line">STREAM scale latency: 3.58 nanoseconds</div><div class="line">STREAM scale bandwidth: 4463.66 MB/sec</div><div class="line">STREAM add latency: 2.71 nanoseconds</div><div class="line">STREAM add bandwidth: 8869.79 MB/sec</div><div class="line">STREAM triad latency: 5.92 nanoseconds</div><div class="line">STREAM triad bandwidth: 4057.12 MB/sec</div><div class="line"></div><div class="line">[root@ARM 19:14 /root/lmbench3]</div><div class="line">#numactl -C 7 -m 3 ./bin/stream  -W 5 -N 5 -M 64M</div><div class="line">STREAM copy latency: 3.94 nanoseconds</div><div class="line">STREAM copy bandwidth: 4064.25 MB/sec</div><div class="line">STREAM scale latency: 3.82 nanoseconds</div><div class="line">STREAM scale bandwidth: 4188.67 MB/sec</div><div class="line">STREAM add latency: 2.86 nanoseconds</div><div class="line">STREAM add bandwidth: 8390.70 MB/sec</div><div class="line">STREAM triad latency: 4.78 nanoseconds</div><div class="line">STREAM triad bandwidth: 5024.25 MB/sec</div><div class="line"></div><div class="line">#numactl -C 24 -m 3 ./bin/stream  -W 5 -N 5 -M 64M</div><div class="line">STREAM copy latency: 4.10 nanoseconds</div><div class="line">STREAM copy bandwidth: 3904.63 MB/sec</div><div class="line">STREAM scale latency: 4.03 nanoseconds</div><div class="line">STREAM scale bandwidth: 3969.41 MB/sec</div><div class="line">STREAM add latency: 3.07 nanoseconds</div><div class="line">STREAM add bandwidth: 7816.08 MB/sec</div><div class="line">STREAM triad latency: 5.06 nanoseconds</div><div class="line">STREAM triad bandwidth: 4738.66 MB/sec</div></pre></td></tr></table></figure>
<h3 id="海光7280"><a href="#海光7280" class="headerlink" title="海光7280"></a>海光7280</h3><p>可以看到跨numa（一个numa也就是一个socket，等同于跨socket）RT从1.5上升到2.5，这个数据比鲲鹏920要好很多</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div></pre></td><td class="code"><pre><div class="line">[root@hygon8 14:32 /root/lmbench-master]</div><div class="line">#lscpu</div><div class="line">架构：                           x86_64</div><div class="line">CPU 运行模式：                   32-bit, 64-bit</div><div class="line">字节序：                         Little Endian</div><div class="line">Address sizes:                   43 bits physical, 48 bits virtual</div><div class="line">CPU:                             128</div><div class="line">在线 CPU 列表：                  0-127</div><div class="line">每个核的线程数：                 2</div><div class="line">每个座的核数：                   32</div><div class="line">座：                             2</div><div class="line">NUMA 节点：                      8</div><div class="line">厂商 ID：                        HygonGenuine</div><div class="line">CPU 系列：                       24</div><div class="line">型号：                           1</div><div class="line">型号名称：                       Hygon C86 7280 32-core Processor</div><div class="line">步进：                           1</div><div class="line">CPU MHz：                        2194.586</div><div class="line">BogoMIPS：                       3999.63</div><div class="line">虚拟化：                         AMD-V</div><div class="line">L1d 缓存：                       2 MiB</div><div class="line">L1i 缓存：                       4 MiB</div><div class="line">L2 缓存：                        32 MiB</div><div class="line">L3 缓存：                        128 MiB</div><div class="line">NUMA 节点0 CPU：                 0-7,64-71</div><div class="line">NUMA 节点1 CPU：                 8-15,72-79</div><div class="line">NUMA 节点2 CPU：                 16-23,80-87</div><div class="line">NUMA 节点3 CPU：                 24-31,88-95</div><div class="line">NUMA 节点4 CPU：                 32-39,96-103</div><div class="line">NUMA 节点5 CPU：                 40-47,104-111</div><div class="line">NUMA 节点6 CPU：                 48-55,112-119</div><div class="line">NUMA 节点7 CPU：                 56-63,120-127</div><div class="line"></div><div class="line">//可以看到7号core比15、23、31号core明显要快，就近访问node 0的内存，跨numa node（跨Die）没有内存交织分配</div><div class="line">[root@hygon8 14:32 /root/lmbench-master]</div><div class="line">#time for i in $(seq 7 8 64); do echo $i; numactl -C $i -m 0 ./bin/stream -W 5 -N 5 -M 64M; done</div><div class="line">7</div><div class="line">STREAM copy latency: 1.38 nanoseconds    </div><div class="line">STREAM copy bandwidth: 11559.53 MB/sec</div><div class="line">STREAM scale latency: 1.16 nanoseconds</div><div class="line">STREAM scale bandwidth: 13815.87 MB/sec</div><div class="line">STREAM add latency: 1.40 nanoseconds</div><div class="line">STREAM add bandwidth: 17145.85 MB/sec</div><div class="line">STREAM triad latency: 1.44 nanoseconds</div><div class="line">STREAM triad bandwidth: 16637.18 MB/sec</div><div class="line">15</div><div class="line">STREAM copy latency: 1.67 nanoseconds</div><div class="line">STREAM copy bandwidth: 9591.77 MB/sec</div><div class="line">STREAM scale latency: 1.56 nanoseconds</div><div class="line">STREAM scale bandwidth: 10242.50 MB/sec</div><div class="line">STREAM add latency: 1.45 nanoseconds</div><div class="line">STREAM add bandwidth: 16581.00 MB/sec</div><div class="line">STREAM triad latency: 2.00 nanoseconds</div><div class="line">STREAM triad bandwidth: 12028.83 MB/sec</div><div class="line">23</div><div class="line">STREAM copy latency: 1.65 nanoseconds</div><div class="line">STREAM copy bandwidth: 9701.49 MB/sec</div><div class="line">STREAM scale latency: 1.53 nanoseconds</div><div class="line">STREAM scale bandwidth: 10427.98 MB/sec</div><div class="line">STREAM add latency: 1.42 nanoseconds</div><div class="line">STREAM add bandwidth: 16846.10 MB/sec</div><div class="line">STREAM triad latency: 1.97 nanoseconds</div><div class="line">STREAM triad bandwidth: 12189.72 MB/sec</div><div class="line">31</div><div class="line">STREAM copy latency: 1.64 nanoseconds</div><div class="line">STREAM copy bandwidth: 9742.86 MB/sec</div><div class="line">STREAM scale latency: 1.52 nanoseconds</div><div class="line">STREAM scale bandwidth: 10510.80 MB/sec</div><div class="line">STREAM add latency: 1.45 nanoseconds</div><div class="line">STREAM add bandwidth: 16559.86 MB/sec</div><div class="line">STREAM triad latency: 1.92 nanoseconds</div><div class="line">STREAM triad bandwidth: 12490.01 MB/sec</div><div class="line">39</div><div class="line">STREAM copy latency: 2.55 nanoseconds</div><div class="line">STREAM copy bandwidth: 6286.25 MB/sec</div><div class="line">STREAM scale latency: 2.51 nanoseconds</div><div class="line">STREAM scale bandwidth: 6383.11 MB/sec</div><div class="line">STREAM add latency: 1.76 nanoseconds</div><div class="line">STREAM add bandwidth: 13660.83 MB/sec</div><div class="line">STREAM triad latency: 3.68 nanoseconds</div><div class="line">STREAM triad bandwidth: 6523.02 MB/sec</div></pre></td></tr></table></figure>
<p>如果这种芯片在bios里设置Die interleaving，4块die当成一个numa node吐出来给OS</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div></pre></td><td class="code"><pre><div class="line">#lscpu</div><div class="line">架构：                           x86_64</div><div class="line">CPU 运行模式：                   32-bit, 64-bit</div><div class="line">字节序：                         Little Endian</div><div class="line">Address sizes:                   43 bits physical, 48 bits virtual</div><div class="line">CPU:                             128</div><div class="line">在线 CPU 列表：                  0-127</div><div class="line">每个核的线程数：                 2</div><div class="line">每个座的核数：                   32</div><div class="line">座：                             2</div><div class="line">NUMA 节点：                      2</div><div class="line">厂商 ID：                        HygonGenuine</div><div class="line">CPU 系列：                       24</div><div class="line">型号：                           1</div><div class="line">型号名称：                       Hygon C86 7280 32-core Processor</div><div class="line">步进：                           1</div><div class="line">CPU MHz：                        2108.234</div><div class="line">BogoMIPS：                       3999.45</div><div class="line">虚拟化：                         AMD-V</div><div class="line">L1d 缓存：                       2 MiB</div><div class="line">L1i 缓存：                       4 MiB</div><div class="line">L2 缓存：                        32 MiB</div><div class="line">L3 缓存：                        128 MiB</div><div class="line">//注意这里和真实物理架构不一致，bios配置了Die Interleaving Enable</div><div class="line">//表示每路内多个Die内存交织分配，这样整个一路就是一个大Die</div><div class="line">NUMA 节点0 CPU：                 0-31,64-95  </div><div class="line">NUMA 节点1 CPU：                 32-63,96-127</div><div class="line"></div><div class="line"></div><div class="line">//enable die interleaving 后继续streaming测试</div><div class="line">//最终测试结果表现就是7/15/23/31 core性能一致，因为默认一个numa内内存交织分配</div><div class="line">//可以看到同一路下的四个die内存交织访问，所以4个node内存延时一样了（被平均），都不如就近快</div><div class="line">[root@hygon3 16:09 /root/lmbench-master]</div><div class="line">#time for i in $(seq 7 8 64); do echo $i; numactl -C $i -m 0 ./bin/stream -W 5 -N 5 -M 64M; done</div><div class="line">7</div><div class="line">STREAM copy latency: 1.48 nanoseconds</div><div class="line">STREAM copy bandwidth: 10782.58 MB/sec</div><div class="line">STREAM scale latency: 1.20 nanoseconds</div><div class="line">STREAM scale bandwidth: 13364.38 MB/sec</div><div class="line">STREAM add latency: 1.46 nanoseconds</div><div class="line">STREAM add bandwidth: 16408.32 MB/sec</div><div class="line">STREAM triad latency: 1.53 nanoseconds</div><div class="line">STREAM triad bandwidth: 15696.00 MB/sec</div><div class="line">15</div><div class="line">STREAM copy latency: 1.51 nanoseconds</div><div class="line">STREAM copy bandwidth: 10601.25 MB/sec</div><div class="line">STREAM scale latency: 1.24 nanoseconds</div><div class="line">STREAM scale bandwidth: 12855.87 MB/sec</div><div class="line">STREAM add latency: 1.46 nanoseconds</div><div class="line">STREAM add bandwidth: 16382.42 MB/sec</div><div class="line">STREAM triad latency: 1.53 nanoseconds</div><div class="line">STREAM triad bandwidth: 15691.48 MB/sec</div><div class="line">23</div><div class="line">STREAM copy latency: 1.50 nanoseconds</div><div class="line">STREAM copy bandwidth: 10700.61 MB/sec</div><div class="line">STREAM scale latency: 1.27 nanoseconds</div><div class="line">STREAM scale bandwidth: 12634.63 MB/sec</div><div class="line">STREAM add latency: 1.47 nanoseconds</div><div class="line">STREAM add bandwidth: 16370.67 MB/sec</div><div class="line">STREAM triad latency: 1.55 nanoseconds</div><div class="line">STREAM triad bandwidth: 15455.75 MB/sec</div><div class="line">31</div><div class="line">STREAM copy latency: 1.50 nanoseconds</div><div class="line">STREAM copy bandwidth: 10637.39 MB/sec</div><div class="line">STREAM scale latency: 1.25 nanoseconds</div><div class="line">STREAM scale bandwidth: 12778.99 MB/sec</div><div class="line">STREAM add latency: 1.46 nanoseconds</div><div class="line">STREAM add bandwidth: 16420.65 MB/sec</div><div class="line">STREAM triad latency: 1.61 nanoseconds</div><div class="line">STREAM triad bandwidth: 14946.80 MB/sec</div><div class="line">39</div><div class="line">STREAM copy latency: 2.35 nanoseconds</div><div class="line">STREAM copy bandwidth: 6807.09 MB/sec</div><div class="line">STREAM scale latency: 2.32 nanoseconds</div><div class="line">STREAM scale bandwidth: 6906.93 MB/sec</div><div class="line">STREAM add latency: 1.63 nanoseconds</div><div class="line">STREAM add bandwidth: 14729.23 MB/sec</div><div class="line">STREAM triad latency: 3.36 nanoseconds</div><div class="line">STREAM triad bandwidth: 7151.67 MB/sec</div><div class="line">47</div><div class="line">STREAM copy latency: 2.31 nanoseconds</div><div class="line">STREAM copy bandwidth: 6938.47 MB/sec</div></pre></td></tr></table></figure>
<p><a href="https://support.huawei.com/enterprise/zh/doc/EDOC1100088653/32aa8773" target="_blank" rel="external">以华为泰山服务器(鲲鹏920芯片)配置为例</a>：<img src="/images/951413iMgBlog/image-20211228165542167.png" alt="image-20211228165542167"></p>
<blockquote>
<p>Die Interleaving 控制是否使能DIE交织。使能DIE交织能充分利用系统的DDR带宽，并尽量保证各DDR通道的带宽均衡，提升DDR的利用率</p>
</blockquote>
<h3 id="hygon5280测试数据"><a href="#hygon5280测试数据" class="headerlink" title="hygon5280测试数据"></a>hygon5280测试数据</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div></pre></td><td class="code"><pre><div class="line">-----hygon5280测试数据</div><div class="line">[root@localhost lmbench-master]# for i in $(seq 0 8 24); do echo $i; numactl -C $i -m 0 ./bin/stream -W 5 -N 5 -M 64M; done</div><div class="line">0</div><div class="line">STREAM copy latency: 1.22 nanoseconds</div><div class="line">STREAM copy bandwidth: 13166.34 MB/sec</div><div class="line">STREAM scale latency: 1.13 nanoseconds</div><div class="line">STREAM scale bandwidth: 14166.95 MB/sec</div><div class="line">STREAM add latency: 1.15 nanoseconds</div><div class="line">STREAM add bandwidth: 20818.63 MB/sec</div><div class="line">STREAM triad latency: 1.39 nanoseconds</div><div class="line">STREAM triad bandwidth: 17211.81 MB/sec</div><div class="line">8</div><div class="line">STREAM copy latency: 1.56 nanoseconds</div><div class="line">STREAM copy bandwidth: 10273.07 MB/sec</div><div class="line">STREAM scale latency: 1.50 nanoseconds</div><div class="line">STREAM scale bandwidth: 10701.89 MB/sec</div><div class="line">STREAM add latency: 1.20 nanoseconds</div><div class="line">STREAM add bandwidth: 19996.68 MB/sec</div><div class="line">STREAM triad latency: 1.93 nanoseconds</div><div class="line">STREAM triad bandwidth: 12443.70 MB/sec</div><div class="line">16</div><div class="line">STREAM copy latency: 2.52 nanoseconds</div><div class="line">STREAM copy bandwidth: 6357.71 MB/sec</div><div class="line">STREAM scale latency: 2.48 nanoseconds</div><div class="line">STREAM scale bandwidth: 6454.95 MB/sec</div><div class="line">STREAM add latency: 1.67 nanoseconds</div><div class="line">STREAM add bandwidth: 14362.51 MB/sec</div><div class="line">STREAM triad latency: 3.65 nanoseconds</div><div class="line">STREAM triad bandwidth: 6572.85 MB/sec</div><div class="line">24</div><div class="line">STREAM copy latency: 2.44 nanoseconds</div><div class="line">STREAM copy bandwidth: 6554.24 MB/sec</div><div class="line">STREAM scale latency: 2.41 nanoseconds</div><div class="line">STREAM scale bandwidth: 6642.80 MB/sec</div><div class="line">STREAM add latency: 1.44 nanoseconds</div><div class="line">STREAM add bandwidth: 16695.82 MB/sec</div><div class="line">STREAM triad latency: 3.61 nanoseconds</div><div class="line">STREAM triad bandwidth: 6639.18 MB/sec</div><div class="line">[root@localhost lmbench-master]# lscpu</div><div class="line">架构：                           x86_64</div><div class="line">CPU 运行模式：                   32-bit, 64-bit</div><div class="line">字节序：                         Little Endian</div><div class="line">Address sizes:                   43 bits physical, 48 bits virtual</div><div class="line">CPU:                             64</div><div class="line">在线 CPU 列表：                  0-63</div><div class="line">每个核的线程数：                 2</div><div class="line">每个座的核数：                   16</div><div class="line">座：                             2</div><div class="line">NUMA 节点：                      4</div><div class="line">厂商 ID：                        HygonGenuine</div><div class="line">CPU 系列：                       24</div><div class="line">型号：                           1</div><div class="line">型号名称：                       Hygon C86 5280 16-core Processor</div><div class="line">步进：                           1</div><div class="line">Frequency boost:                 enabled</div><div class="line">CPU MHz：                        2799.311</div><div class="line">CPU 最大 MHz：                   2500.0000</div><div class="line">CPU 最小 MHz：                   1600.0000</div><div class="line">BogoMIPS：                       4999.36</div><div class="line">虚拟化：                         AMD-V</div><div class="line">L1d 缓存：                       1 MiB</div><div class="line">L1i 缓存：                       2 MiB</div><div class="line">L2 缓存：                        16 MiB</div><div class="line">L3 缓存：                        64 MiB</div><div class="line">NUMA 节点0 CPU：                 0-7,32-39</div><div class="line">NUMA 节点1 CPU：                 8-15,40-47</div><div class="line">NUMA 节点2 CPU：                 16-23,48-55</div><div class="line">NUMA 节点3 CPU：                 24-31,56-63</div><div class="line">Vulnerability Itlb multihit:     Not affected</div><div class="line">Vulnerability L1tf:              Not affected</div><div class="line">Vulnerability Mds:               Not affected</div><div class="line">Vulnerability Meltdown:          Not affected</div><div class="line">Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl and seccomp</div><div class="line">Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization</div><div class="line">Vulnerability Spectre v2:        Mitigation; Full AMD retpoline, IBPB conditional, STIBP disabled, RSB</div><div class="line">                                 filling</div><div class="line">Vulnerability Srbds:             Not affected</div><div class="line">Vulnerability Tsx async abort:   Not affected</div><div class="line">标记：                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse3</div><div class="line">                                 6 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdts</div><div class="line">                                 cp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid amd_dcm</div><div class="line">                                  aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 movbe p</div><div class="line">                                 opcnt xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy</div><div class="line">                                 abm sse4a misalignsse 3dnowprefetch osvw skinit wdt tce topoext perfct</div><div class="line">                                 r_core perfctr_nb bpext perfctr_llc mwaitx cpb hw_pstate sme ssbd sev</div><div class="line">                                 ibpb vmmcall fsgsbase bmi1 avx2 smep bmi2 rdseed adx smap clflushopt s</div><div class="line">                                 ha_ni xsaveopt xsavec xgetbv1 xsaves clzero irperf xsaveerptr arat npt</div><div class="line">                                  lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassist</div><div class="line">                                 s pausefilter pfthreshold avic v_vmsave_vmload vgif overflow_recov suc</div><div class="line">                                 cor smca</div></pre></td></tr></table></figure>
<h3 id="intel-8269CY"><a href="#intel-8269CY" class="headerlink" title="intel 8269CY"></a>intel 8269CY</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div></pre></td><td class="code"><pre><div class="line">lscpu</div><div class="line">Architecture:          x86_64</div><div class="line">CPU op-mode(s):        32-bit, 64-bit</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                104</div><div class="line">On-line CPU(s) list:   0-103</div><div class="line">Thread(s) per core:    2</div><div class="line">Core(s) per socket:    26</div><div class="line">Socket(s):             2</div><div class="line">NUMA node(s):          2</div><div class="line">Vendor ID:             GenuineIntel</div><div class="line">CPU family:            6</div><div class="line">Model:                 85</div><div class="line">Model name:            Intel(R) Xeon(R) Platinum 8269CY CPU @ 2.50GHz</div><div class="line">Stepping:              7</div><div class="line">CPU MHz:               3200.000</div><div class="line">CPU max MHz:           3800.0000</div><div class="line">CPU min MHz:           1200.0000</div><div class="line">BogoMIPS:              4998.89</div><div class="line">Virtualization:        VT-x</div><div class="line">L1d cache:             32K</div><div class="line">L1i cache:             32K</div><div class="line">L2 cache:              1024K</div><div class="line">L3 cache:              36608K</div><div class="line">NUMA node0 CPU(s):     0-25,52-77</div><div class="line">NUMA node1 CPU(s):     26-51,78-103</div><div class="line"></div><div class="line">[root@numaopen.cloud.et93 /home/ren/lmbench3]</div><div class="line">#time for i in $(seq 0 8 51); do echo $i; numactl -C $i -m 0 ./bin/stream -W 5 -N 5 -M 64M; done</div><div class="line">0</div><div class="line">STREAM copy latency: 1.15 nanoseconds</div><div class="line">STREAM copy bandwidth: 13941.80 MB/sec</div><div class="line">STREAM scale latency: 1.16 nanoseconds</div><div class="line">STREAM scale bandwidth: 13799.89 MB/sec</div><div class="line">STREAM add latency: 1.31 nanoseconds</div><div class="line">STREAM add bandwidth: 18318.23 MB/sec</div><div class="line">STREAM triad latency: 1.56 nanoseconds</div><div class="line">STREAM triad bandwidth: 15356.72 MB/sec</div><div class="line">16</div><div class="line">STREAM copy latency: 1.12 nanoseconds</div><div class="line">STREAM copy bandwidth: 14293.68 MB/sec</div><div class="line">STREAM scale latency: 1.13 nanoseconds</div><div class="line">STREAM scale bandwidth: 14162.47 MB/sec</div><div class="line">STREAM add latency: 1.31 nanoseconds</div><div class="line">STREAM add bandwidth: 18293.27 MB/sec</div><div class="line">STREAM triad latency: 1.53 nanoseconds</div><div class="line">STREAM triad bandwidth: 15692.47 MB/sec</div><div class="line">32</div><div class="line">STREAM copy latency: 1.52 nanoseconds</div><div class="line">STREAM copy bandwidth: 10551.71 MB/sec</div><div class="line">STREAM scale latency: 1.52 nanoseconds</div><div class="line">STREAM scale bandwidth: 10508.33 MB/sec</div><div class="line">STREAM add latency: 1.38 nanoseconds</div><div class="line">STREAM add bandwidth: 17363.22 MB/sec</div><div class="line">STREAM triad latency: 2.00 nanoseconds</div><div class="line">STREAM triad bandwidth: 12024.52 MB/sec</div><div class="line">40</div><div class="line">STREAM copy latency: 1.49 nanoseconds</div><div class="line">STREAM copy bandwidth: 10758.50 MB/sec</div><div class="line">STREAM scale latency: 1.50 nanoseconds</div><div class="line">STREAM scale bandwidth: 10680.17 MB/sec</div><div class="line">STREAM add latency: 1.34 nanoseconds</div><div class="line">STREAM add bandwidth: 17948.34 MB/sec</div><div class="line">STREAM triad latency: 1.98 nanoseconds</div><div class="line">STREAM triad bandwidth: 12133.22 MB/sec</div><div class="line">48</div><div class="line">STREAM copy latency: 1.49 nanoseconds</div><div class="line">STREAM copy bandwidth: 10736.56 MB/sec</div><div class="line">STREAM scale latency: 1.50 nanoseconds</div><div class="line">STREAM scale bandwidth: 10692.93 MB/sec</div><div class="line">STREAM add latency: 1.34 nanoseconds</div><div class="line">STREAM add bandwidth: 17902.85 MB/sec</div><div class="line">STREAM triad latency: 1.96 nanoseconds</div><div class="line">STREAM triad bandwidth: 12239.44 MB/sec</div></pre></td></tr></table></figure>
<h3 id="Intel-R-Xeon-R-CPU-E5-2682-v4"><a href="#Intel-R-Xeon-R-CPU-E5-2682-v4" class="headerlink" title="Intel(R) Xeon(R) CPU E5-2682 v4"></a>Intel(R) Xeon(R) CPU E5-2682 v4</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div></pre></td><td class="code"><pre><div class="line">#time for i in $(seq 0 8 51); do echo $i; numactl -C $i -m 0 ./bin/stream -W 5 -N 5 -M 64M; done</div><div class="line">0</div><div class="line">STREAM copy latency: 1.59 nanoseconds</div><div class="line">STREAM copy bandwidth: 10092.31 MB/sec</div><div class="line">STREAM scale latency: 1.57 nanoseconds</div><div class="line">STREAM scale bandwidth: 10169.16 MB/sec</div><div class="line">STREAM add latency: 1.31 nanoseconds</div><div class="line">STREAM add bandwidth: 18360.83 MB/sec</div><div class="line">STREAM triad latency: 2.28 nanoseconds</div><div class="line">STREAM triad bandwidth: 10503.81 MB/sec</div><div class="line">8</div><div class="line">STREAM copy latency: 1.55 nanoseconds</div><div class="line">STREAM copy bandwidth: 10312.14 MB/sec</div><div class="line">STREAM scale latency: 1.56 nanoseconds</div><div class="line">STREAM scale bandwidth: 10283.70 MB/sec</div><div class="line">STREAM add latency: 1.30 nanoseconds</div><div class="line">STREAM add bandwidth: 18416.26 MB/sec</div><div class="line">STREAM triad latency: 2.23 nanoseconds</div><div class="line">STREAM triad bandwidth: 10777.08 MB/sec</div><div class="line">16</div><div class="line">STREAM copy latency: 2.02 nanoseconds</div><div class="line">STREAM copy bandwidth: 7914.25 MB/sec</div><div class="line">STREAM scale latency: 2.02 nanoseconds</div><div class="line">STREAM scale bandwidth: 7919.85 MB/sec</div><div class="line">STREAM add latency: 1.39 nanoseconds</div><div class="line">STREAM add bandwidth: 17276.06 MB/sec</div><div class="line">STREAM triad latency: 2.92 nanoseconds</div><div class="line">STREAM triad bandwidth: 8231.18 MB/sec</div><div class="line">24</div><div class="line">STREAM copy latency: 1.99 nanoseconds</div><div class="line">STREAM copy bandwidth: 8032.18 MB/sec</div><div class="line">STREAM scale latency: 1.98 nanoseconds</div><div class="line">STREAM scale bandwidth: 8061.12 MB/sec</div><div class="line">STREAM add latency: 1.39 nanoseconds</div><div class="line">STREAM add bandwidth: 17313.94 MB/sec</div><div class="line">STREAM triad latency: 2.88 nanoseconds</div><div class="line">STREAM triad bandwidth: 8318.93 MB/sec</div><div class="line"></div><div class="line">#lscpu</div><div class="line">Architecture:          x86_64</div><div class="line">CPU op-mode(s):        32-bit, 64-bit</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                64</div><div class="line">On-line CPU(s) list:   0-63</div><div class="line">Thread(s) per core:    2</div><div class="line">Core(s) per socket:    16</div><div class="line">Socket(s):             2</div><div class="line">NUMA node(s):          2</div><div class="line">Vendor ID:             GenuineIntel</div><div class="line">CPU family:            6</div><div class="line">Model:                 79</div><div class="line">Model name:            Intel(R) Xeon(R) CPU E5-2682 v4 @ 2.50GHz</div><div class="line">Stepping:              1</div><div class="line">CPU MHz:               2500.000</div><div class="line">CPU max MHz:           3000.0000</div><div class="line">CPU min MHz:           1200.0000</div><div class="line">BogoMIPS:              5000.06</div><div class="line">Virtualization:        VT-x</div><div class="line">L1d cache:             32K</div><div class="line">L1i cache:             32K</div><div class="line">L2 cache:              256K</div><div class="line">L3 cache:              40960K</div><div class="line">NUMA node0 CPU(s):     0-15,32-47</div><div class="line">NUMA node1 CPU(s):     16-31,48-63</div></pre></td></tr></table></figure>
<h3 id="stream对比数据"><a href="#stream对比数据" class="headerlink" title="stream对比数据"></a>stream对比数据</h3><p>总结下几个CPU用stream测试访问内存的RT以及抖动和带宽对比数据</p>
<table>
<thead>
<tr>
<th></th>
<th>最小RT</th>
<th>最大RT</th>
<th>最大copy bandwidth</th>
<th>最小copy bandwidth</th>
</tr>
</thead>
<tbody>
<tr>
<td>申威3231(2numa node)</td>
<td>7.09</td>
<td>8.75</td>
<td>2256.59 MB/sec</td>
<td>1827.88 MB/sec</td>
</tr>
<tr>
<td>飞腾2500(16 numa node)</td>
<td>2.84</td>
<td>10.34</td>
<td>5638.21 MB/sec</td>
<td>1546.68 MB/sec</td>
</tr>
<tr>
<td>鲲鹏920(4 numa node)</td>
<td>1.84</td>
<td>3.87</td>
<td>8700.75 MB/sec</td>
<td>4131.81 MB/sec</td>
</tr>
<tr>
<td>海光7280(8 numa node)</td>
<td>1.38</td>
<td>2.58</td>
<td>11591.48 MB/sec</td>
<td>6206.99 MB/sec</td>
</tr>
<tr>
<td>海光5280(4 numa node)</td>
<td>1.22</td>
<td>2.52</td>
<td>13166.34 MB/sec</td>
<td>6357.71 MB/sec</td>
</tr>
<tr>
<td>Intel8269CY(2 numa node)</td>
<td>1.12</td>
<td>1.52</td>
<td>14293.68 MB/sec</td>
<td>10551.71 MB/sec</td>
</tr>
<tr>
<td>Intel E5-2682(2 numa node)</td>
<td>1.58</td>
<td>2.02</td>
<td>10092.31 MB/sec</td>
<td>7914.25 MB/sec</td>
</tr>
<tr>
<td>倚天710</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>从以上数据可以看出这5款CPU性能一款比一款好，飞腾2500慢的core上延时快到intel 8269的10倍了，平均延时5倍以上了。延时数据基本和单核上测试sysbench TPS一致。性能差不多就是：常数*主频/RT</p>
<h3 id="lat-mem-rd对比数据"><a href="#lat-mem-rd对比数据" class="headerlink" title="lat_mem_rd对比数据"></a>lat_mem_rd对比数据</h3><p>用不同的node上的core 跑lat_mem_rd测试访问node0内存的RT，只取最大64M的时延，时延和node距离完全一致</p>
<table>
<thead>
<tr>
<th></th>
<th>RT变化</th>
</tr>
</thead>
<tbody>
<tr>
<td>飞腾2500(16 numa node)</td>
<td>core:0      149.976<br>core:8      168.805<br>core:16     191.415<br>core:24     178.283<br>core:32     170.814<br>core:40     185.699<br>core:48     212.281<br>core:56     202.479<br>core:64     426.176<br>core:72     444.367<br>core:80     465.894<br>core:88     452.245<br>core:96     448.352<br>core:104   460.603<br>core:112   485.989<br>core:120    490.402</td>
</tr>
<tr>
<td>鲲鹏920(4 numa node)</td>
<td>core:0 117.323<br>core:24 135.337<br>core:48 197.782<br>core:72 219.416</td>
</tr>
<tr>
<td>海光7280(8 numa node)</td>
<td>numa0    106.839<br>numa1    168.583<br>numa2    163.925<br>numa3    163.690<br>numa4    289.628<br>numa5    288.632<br>numa6    236.615<br>numa7    291.880<br>分割行<br>enabled die interleaving <br>core:0 153.005<br>core:16 152.458<br>core:32 272.057<br>core:48 269.441</td>
</tr>
<tr>
<td>海光5280(4 numa node)</td>
<td>core:0   102.574<br>core:8   160.989<br>core:16  286.850<br>core:24  231.197</td>
</tr>
<tr>
<td>Intel 8269CY(2 numa node)</td>
<td>core:0        69.792<br>core:26      93.107</td>
</tr>
<tr>
<td>申威3231(2numa node)</td>
<td>core:0     215.146<br>core:32   282.443</td>
</tr>
<tr>
<td>倚天710（2Die）</td>
<td>133ns 205ns （待测）</td>
</tr>
</tbody>
</table>
<p>测试命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">for i in $(seq 0 8 127); do echo core:$i; numactl -C $i -m 0 ./bin/lat_mem_rd -W 5 -N 5 -t 64M; done &gt;lat.log 2&gt;&amp;1</div></pre></td></tr></table></figure>
<p>测试结果和numactl -H 看到的node distance完全一致，芯片厂家应该就是这样测试然后把这个延迟当做距离写进去了</p>
<h3 id="龙芯测试数据"><a href="#龙芯测试数据" class="headerlink" title="龙芯测试数据"></a>龙芯测试数据</h3><p>3A5000为龙芯，执行的命令为./lat_mem_rd 128M 4096，其中 4096 参数为跳步大小。其基本原理是，通过按 给定间隔去循环读一定大小的内存区域，测量每个读平均的时间。如果区域大小小于 L1 Cache 大 小，时间应该接近 L1 的访问延迟;如果大于 L1 小于 L2，则接近 L2 访问延迟;依此类推。图中横坐 标为访问的字节数，纵坐标为访存的拍数(cycles)。</p>
<p><img src="/images/951413iMgBlog/image-20220221113929547.png" alt="image-20220221113929547"></p>
<p>基于跳步访问的 3A5000 和 Zen1、Skylake 各级延迟的比较(cycles)</p>
<p><img src="/images/951413iMgBlog/image-20220221112527936.png" alt="image-20220221112527936"></p>
<p>下图给出了 LMbench 测试得到的访存操作的并发性，执行的命令为./par_mem。访存操作的并 发性是各级 Cache 和内存所支持并发访问的能力。在 LMbench 中，访存操作并发性的测试是设计一 个链表，不断地遍历访问下一个链表中的元素，链表所跳的距离和需要测量的 Cache 容量相关，在 一段时间能并发的发起对链表的追逐操作，也就是同时很多链表在遍历，如果发现这一段时间内 能同时完成 N 个链表的追逐操作，就认为访存的并发操作是 N。</p>
<p><img src="/images/951413iMgBlog/image-20220221112727377.png" alt="image-20220221112727377"></p>
<p>下图列出了三款处理器的功能部件操作延迟数据，使用的命令是./lat_ops。</p>
<p><img src="/images/951413iMgBlog/image-20220221112853404.png" alt="image-20220221112853404"></p>
<h4 id="龙芯stream数据"><a href="#龙芯stream数据" class="headerlink" title="龙芯stream数据"></a>龙芯stream数据</h4><p>LMbench 包含了 STREAM 带宽测试工具，可以用来测试可持续的内存访问带宽情况。图表12.25列 出了三款处理器的 STREAM 带宽数据，其中 STREAM 数组大小设置为 1 亿个元素，采用 OpenMP 版本 同时运行四个线程来测试满载带宽;相应测试平台均为 CPU 的两个内存控制器各接一根内存条， 3A5000 和 Zen1 用 DDR4 3200 内存条，Skylake 用 DDR4 2400 内存条(它最高只支持这个规格)。</p>
<p><img src="/images/951413iMgBlog/image-20220221113037332.png" alt="image-20220221113037332"></p>
<p>从数据可以看到，虽然硬件上 3A5000 和 Zen1 都实现了 DDR4 3200，但 3A5000 的实测可持续带宽 还是有一定差距。用户程序看到的内存带宽不仅仅和内存的物理频率有关系，也和处理器内部的 各种访存队列、内存控制器的调度策略、预取器和内存时序参数设置等相关，需要进行更多分析 来定位具体的瓶颈点。像 STREAM 这样的软件测试工具，能够更好地反映某个子系统的综合能力， 因而被广泛采用。</p>
<h2 id="对比结论"><a href="#对比结论" class="headerlink" title="对比结论"></a>对比结论</h2><ul>
<li>AMD单核跑分数据比较好</li>
<li>MySQL 查询场景下Intel的性能好很多</li>
<li>xdb比社区版性能要好</li>
<li>MySQL8.0比5.7在多核锁竞争场景下性能要好</li>
<li>intel最好，AMD接近Intel，海光差的比较远但是又比鲲鹏好很多，飞腾最差，尤其是跨socket简直是灾难</li>
<li>麒麟OS性能也比CentOS略差一些</li>
</ul>
<p>整体来说AMD用领先了一代的工艺（7nm VS 14nm)，在MySQL查询场景中终于可以接近Intel了，但是海光、鲲鹏、飞腾还是不给力。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="/2021/06/01/CPU的制造和概念/">CPU的制造和概念</a></p>
<p><a href="/2021/05/16/CPU Cache Line 和性能/">CPU 性能和Cache Line</a></p>
<p><a href="/2021/05/16/Perf IPC以及CPU利用率/">Perf IPC以及CPU性能</a></p>
<p><a href="/2021/06/18/几款CPU性能对比/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></p>
<p><a href="/2021/05/15/飞腾ARM芯片(FT2500">飞腾ARM芯片(FT2500)的性能测试</a>的性能测试/)</p>
<p><a href="/2021/05/14/十年后数据库还是不敢拥抱NUMA/">十年后数据库还是不敢拥抱NUMA？</a></p>
<p><a href="/2021/03/07/一次海光物理机资源竞争压测的记录/">一次海光物理机资源竞争压测的记录</a></p>
<p><a href="/2019/12/16/Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的/">Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的</a></p>
<p><a href="https://blog.csdn.net/xuanjian_bjtu/article/details/107178226" target="_blank" rel="external">lmbench测试要考虑cache等</a> </p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2022/01/01/网络抓包常用命令/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/01/01/网络抓包常用命令/" itemprop="url">网络抓包常用命令</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-01-01T14:30:03+08:00">
                2022-01-01
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/tcpdump/" itemprop="url" rel="index">
                    <span itemprop="name">tcpdump</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="网络抓包常用命令"><a href="#网络抓包常用命令" class="headerlink" title="网络抓包常用命令"></a>网络抓包常用命令</h1><p>参考阅读：<a href="https://plantegg.github.io/2019/06/21/就是要你懂抓包--WireShark之命令行版tshark/">就是要你懂抓包–WireShark之命令行版tshark</a></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div></pre></td><td class="code"><pre><div class="line">用tcpdump抓取并保存包：</div><div class="line">sudo tcpdump -i eth0 port 3306 -w plantegg.cap</div><div class="line"></div><div class="line">抓到的包存储在plantegg.cap中，可以用作wireshark、tshark详细分析</div><div class="line">如果明确知道目的ip、端口等可以通过指定条件来明确只抓取某个连接的包</div><div class="line"></div><div class="line"></div><div class="line">抓取详细SQL语句：</div><div class="line">sudo tshark -i eth0 -Y "mysql.command==3" -T fields -e mysql.query</div><div class="line">sudo tshark -i eth0 -R mysql.query        -T fields -e mysql.query</div><div class="line"></div><div class="line">sudo tshark -i any -f 'port 8527' -s 0 -l -w - |strings</div><div class="line"><span class="meta"></span></div><div class="line">#parse 8507/4444 as mysql protocol, default only parse 3306 as mysql.</div><div class="line">sudo tshark -i eth0 -d tcp.port==8507,mysql -T fields -e mysql.query 'port 8507'</div><div class="line">sudo tshark -i any -c 50 -d tcp.port==4444,mysql -Y " ((tcp.port eq 4444 )  )" -o tcp.calculate_timestamps:true -T fields -e frame.number -e frame.time_epoch  -e frame.time_delta_displayed  -e ip.src -e tcp.srcport -e tcp.dstport -e ip.dst -e tcp.time_delta -e tcp.stream -e tcp.len -e mysql.query</div><div class="line"></div><div class="line">sudo tshark -i eth0 -R "ip.addr==11.163.182.137" -d tcp.port==3306,mysql -T fields -e mysql.query 'port 3306'</div><div class="line">sudo tshark -i eth0 -R "tcp.srcport==62877" -d tcp.port==3001,mysql -T fields -e tcp.srcport -e mysql.query 'port 3001'</div><div class="line"></div><div class="line">如果MySQL开启了SSL，那么抓包后的内容tshark/wireshark分析不到MySQL的具体内容，可以强制关闭：connectionProperties里加上useSSL=false</div><div class="line"></div><div class="line">查看SQL具体内容</div><div class="line">sudo tshark -r gege_plantegg.cap -Y "mysql.query or (  tcp.stream==1)" -o tcp.calculate_timestamps:true -T fields -e frame.number -e frame.time_epoch  -e frame.time_delta_displayed  -e ip.src -e tcp.srcport -e tcp.dstport -e ip.dst -e tcp.time_delta -e frame.time_delta_displayed  -e tcp.stream -e tcp.len -e mysql.query </div><div class="line"></div><div class="line"></div><div class="line">按mysql查询分析响应时间</div><div class="line">对于rt分析，要注意一个query多个response情况（response结果多，分包了），分析这种rt的时候只看query之后的第一个response，其它连续response需要忽略掉。</div><div class="line"></div><div class="line">以上抓包结果文件可以用tshark进行详细分析</div><div class="line"></div><div class="line">分析MySQL rt，倒数第四列基本就是rt</div><div class="line">tshark -r gege_plantegg.pcap -Y " ((tcp.srcport eq 3306 ) and tcp.len&gt;0 )" -o tcp.calculate_timestamps:true -T fields -e frame.number -e frame.time_epoch  -e frame.time_delta_displayed  -e ip.src -e tcp.srcport -e tcp.dstport -e ip.dst -e tcp.time_delta -e tcp.stream -e tcp.len -e tcp.analysis.ack_rtt   </div><div class="line"></div><div class="line">或者排序一下</div><div class="line">tshark -r 213_php.cap -Y "mysql.query or (  tcp.srcport==3306)" -o tcp.calculate_timestamps:true -T fields -e frame.number -e frame.time_epoch  -e frame.time_delta_displayed  -e ip.src -e tcp.srcport -e tcp.dstport -e ip.dst -e tcp.time_delta -e tcp.stream -e tcp.len -e mysql.query |sort -nk9 -nk1</div><div class="line"></div><div class="line">MySQL响应时间直方图【第八列的含义-- Time since previous frame in this TCP stream: seconds】：</div><div class="line">tshark -r gege_plantegg.pcap -Y "mysql.query or (tcp.srcport3306 and tcp.len&gt;60)" -o tcp.calculate_timestamps:true -T fields -e frame.number -e frame.time_epoch  -e frame.time_delta_displayed  -e ip.src -e tcp.srcport -e tcp.dstport -e ip.dst -e tcp.time_delta -e tcp.stream -e tcp.len | awk 'BEGIN &#123;sum0=0;sum3=0;sum10=0;sum30=0;sum50=0;sum100=0;sum300=0;sum500=0;sum1000=0;sumo=0;count=0;sum=0&#125; &#123;rt=$8; if(rt&gt;=0.000) sum=sum+rt; count=count+1; if(rt&lt;=0.000) sum0=sum0+1; else if(rt&lt;0.003) sum3=sum3+1 ; else if(rt&lt;0.01) sum10=sum10+1; else if(rt&lt;0.03) sum30=sum30+1; else if(rt&lt;0.05) sum50=sum50+1; else if(rt &lt; 0.1) sum100=sum100+1; else if(rt &lt; 0.3) sum300=sum300+1; else if(rt &lt; 0.5) sum500=sum500+1; else if(rt &lt; 1) sum1000=sum1000+1; else sum=sum+1 ;&#125; END&#123;printf "-------------\n3ms:\t%s \n10ms:\t%s \n30ms:\t%s \n50ms:\t%s \n100ms:\t%s \n300ms:\t%s \n500ms:\t%s \n1000ms:\t%s \n&gt;1s:\t %s\n-------------\navg: %.6f \n" , sum3,sum10,sum30,sum50,sum100,sum300,sum500,sum1000,sumo,sum/count;&#125;'</div><div class="line"></div><div class="line">按http response分析响应时间</div><div class="line">tshark -nr 213_php.cap -o tcp.calculate_timestamps:true  -Y "http.request or http.response" -T fields -e frame.number -e frame.time_epoch  -e frame.time_delta_displayed  -e ip.src -e ip.dst -e tcp.stream  -e http.request.full_uri -e http.response.code -e http.response.phrase | sort -nk6 -nk1</div><div class="line"></div><div class="line">分析rtt、丢包、deplicate等等，可以得到整体网络状态</div><div class="line"><span class="meta">$</span> tshark -r retrans.cap -q -z io,stat,1,"AVG(tcp.analysis.ack_rtt)tcp.analysis.ack_rtt","COUNT(tcp.analysis.retransmission)  tcp.analysis.retransmission","COUNT(tcp.analysis.fast_retransmission) tcp.analysis.fast_retransmission","COUNT(tcp.analysis.duplicate_ack) tcp.analysis.duplicate_ack","COUNT(tcp.analysis.lost_segment) tcp.analysis.lost_segment","MIN(tcp.window_size)tcp.window_size"</div><div class="line"></div><div class="line">===================================================================================</div><div class="line">| IO Statistics                                                                   |</div><div class="line">|                                                                                 |</div><div class="line">| Duration: 89.892365 secs                                                        |</div><div class="line">| Interval:  2 secs                                                               |</div><div class="line">|                                                                                 |</div><div class="line">| Col 1: AVG(tcp.analysis.ack_rtt)tcp.analysis.ack_rtt                            |</div><div class="line">|     2: COUNT(tcp.analysis.retransmission)  tcp.analysis.retransmission          |</div><div class="line">|     3: COUNT(tcp.analysis.fast_retransmission) tcp.analysis.fast_retransmission |</div><div class="line">|     4: COUNT(tcp.analysis.duplicate_ack) tcp.analysis.duplicate_ack             |</div><div class="line">|     5: COUNT(tcp.analysis.lost_segment) tcp.analysis.lost_segment               |</div><div class="line">|     6: AVG(tcp.window_size)tcp.window_size                                      |</div><div class="line">|---------------------------------------------------------------------------------|</div><div class="line">|          |1         |2      |3      |4      |5      |6      |                   |</div><div class="line">| Interval |    AVG   | COUNT | COUNT | COUNT | COUNT |  AVG  |                   |</div><div class="line">|-------------------------------------------------------------|                   |</div><div class="line">|  0 &lt;&gt;  2 | 0.001152 |     0 |     0 |     0 |     0 |  4206 |                   |</div><div class="line">|  2 &lt;&gt;  4 | 0.002088 |     0 |     0 |     0 |     1 |  6931 |                   |</div><div class="line">|  4 &lt;&gt;  6 | 0.001512 |     0 |     0 |     0 |     0 |  7099 |                   |</div><div class="line">|  6 &lt;&gt;  8 | 0.002859 |     0 |     0 |     0 |     0 |  7171 |                   |</div><div class="line">|  8 &lt;&gt; 10 | 0.001716 |     0 |     0 |     0 |     0 |  6472 |                   |</div><div class="line">| 10 &lt;&gt; 12 | 0.000319 |     0 |     0 |     0 |     2 |  5575 |                   |</div><div class="line">| 12 &lt;&gt; 14 | 0.002030 |     0 |     0 |     0 |     0 |  6922 |                   |</div><div class="line">| 14 &lt;&gt; 16 | 0.003371 |     0 |     0 |     0 |     2 |  5884 |                   |</div><div class="line">| 16 &lt;&gt; 18 | 0.000138 |     0 |     0 |     0 |     1 |  3480 |                   |</div><div class="line">| 18 &lt;&gt; 20 | 0.000999 |     0 |     0 |     0 |     4 |  6665 |                   |</div><div class="line">| 20 &lt;&gt; 22 | 0.000682 |     0 |     0 |    41 |     2 |  5484 |                   |</div><div class="line">| 22 &lt;&gt; 24 | 0.002302 |     2 |     0 |    19 |     0 |  7127 |                   |</div><div class="line">| 24 &lt;&gt; 26 | 0.000156 |     1 |     0 |    22 |     0 |  3042 |                   |</div><div class="line">| 26 &lt;&gt; 28 | 0.000000 |     1 |     0 |    19 |     1 |   152 |                   |</div><div class="line">| 28 &lt;&gt; 30 | 0.001498 |     1 |     0 |    24 |     0 |  5615 |                   |</div><div class="line">| 30 &lt;&gt; 32 | 0.000235 |     0 |     0 |    44 |     0 |  1880 |                   |</div><div class="line">1</div><div class="line">===================================================================================</div><div class="line">2</div><div class="line">| IO Statistics                                                                   |</div><div class="line">3</div><div class="line">|                                                                                 |</div><div class="line">4</div><div class="line">| Duration: 89.892365 secs                                                        |</div><div class="line">5</div><div class="line">| Interval:  2 secs                                                               |</div><div class="line">6</div><div class="line">|                                                                                 |</div><div class="line">7</div><div class="line">| Col 1: AVG(tcp.analysis.ack_rtt)tcp.analysis.ack_rtt                            |</div><div class="line">8</div><div class="line">|     2: COUNT(tcp.analysis.retransmission)  tcp.analysis.retransmission          |</div><div class="line">9</div><div class="line">|     3: COUNT(tcp.analysis.fast_retransmission) tcp.analysis.fast_retransmission |</div><div class="line">10</div><div class="line">|     4: COUNT(tcp.analysis.duplicate_ack) tcp.analysis.duplicate_ack             |</div><div class="line">11</div><div class="line">|     5: COUNT(tcp.analysis.lost_segment) tcp.analysis.lost_segment               |</div><div class="line">12</div><div class="line">|     6: AVG(tcp.window_size)tcp.window_size                                      |</div><div class="line">13</div><div class="line">|---------------------------------------------------------------------------------|</div><div class="line">14</div><div class="line">|          |1         |2      |3      |4      |5      |6      |                   |</div><div class="line">15</div><div class="line">| Interval |    AVG   | COUNT | COUNT | COUNT | COUNT |  AVG  |                   |</div><div class="line">16</div><div class="line">|-------------------------------------------------------------|                   |</div><div class="line">17</div><div class="line">|  0 &lt;&gt;  2 | 0.001152 |     0 |     0 |     0 |     0 |  4206 |                   |</div><div class="line">18</div><div class="line">|  2 &lt;&gt;  4 | 0.002088 |     0 |     0 |     0 |     1 |  6931 |                   |</div><div class="line">19</div><div class="line">|  4 &lt;&gt;  6 | 0.001512 |     0 |     0 |     0 |     0 |  7099 |                   |</div><div class="line">20</div><div class="line">|  6 &lt;&gt;  8 | 0.002859 |     0 |     0 |     0 |     0 |  7171 |                   |</div><div class="line">21</div><div class="line">|  8 &lt;&gt; 10 | 0.001716 |     0 |     0 |     0 |     0 |  6472 |                   |</div><div class="line">22</div><div class="line">| 10 &lt;&gt; 12 | 0.000319 |     0 |     0 |     0 |     2 |  5575 |                   |</div><div class="line">23</div><div class="line">| 12 &lt;&gt; 14 | 0.002030 |     0 |     0 |     0 |     0 |  6922 |                   |</div><div class="line">24</div><div class="line">| 14 &lt;&gt; 16 | 0.003371 |     0 |     0 |     0 |     2 |  5884 |                   |</div><div class="line">25</div><div class="line">| 16 &lt;&gt; 18 | 0.000138 |     0 |     0 |     0 |     1 |  3480 |                   |</div><div class="line">26</div><div class="line">| 18 &lt;&gt; 20 | 0.000999 |     0 |     0 |     0 |     4 |  6665 |                   |</div><div class="line">27</div><div class="line">| 20 &lt;&gt; 22 | 0.000682 |     0 |     0 |    41 |     2 |  5484 |                   |</div><div class="line">28</div><div class="line">| 22 &lt;&gt; 24 | 0.002302 |     2 |     0 |    19 |     0 |  7127 |                   |</div><div class="line">29</div><div class="line">| 24 &lt;&gt; 26 | 0.000156 |     1 |     0 |    22 |     0 |  3042 |                   |</div><div class="line">30</div><div class="line">| 26 &lt;&gt; 28 | 0.000000 |     1 |     0 |    19 |     1 |   152 |                   |</div><div class="line">31</div><div class="line">| 28 &lt;&gt; 30 | 0.001498 |     1 |     0 |    24 |     0 |  5615 |                   |</div><div class="line">32</div><div class="line">| 30 &lt;&gt; 32 | 0.000235 |     0 |     0 |    44 |     0 |  1880 |                   |</div><div class="line"><span class="meta"></span></div><div class="line"></div><div class="line">#tshark</div><div class="line">tshark -r ./mysql-compress.cap -o tcp.calculate_timestamps:true -T fields -e mysql.caps.cp -e frame.number -e frame.time_epoch  -e frame.time_delta_displayed  -e ip.src -e tcp.srcport -e tcp.dstport -e ip.dst -e tcp.time_delta -e frame.time_delta_displayed  -e tcp.stream -e tcp.len -e mysql.query </div><div class="line"><span class="meta"></span></div><div class="line">#用tcpdump抓取并保存包：</div><div class="line">sudo tcpdump -i eth0 port 3306 -w plantegg.cap</div><div class="line"><span class="meta"></span></div><div class="line">#每隔3秒钟生成一个新文件，总共生成5个文件后（15秒后）终止抓包，然后包名也按时间规范好了</div><div class="line">sudo  tcpdump -t -s 0 tcp port 3306  -w 'dump_%Y-%m-%d_%H:%M:%S.pcap'   -G 3 -W 5 -Z root</div><div class="line"><span class="meta"></span></div><div class="line">#每隔30分钟生成一个包并压缩</div><div class="line">nohup sudo tcpdump -i eth0 -t -s 0 tcp and port 3306 -w 'dump_%Y-%m-%d_%H:%M:%S.pcap' -G 1800 -W 48 -Z root -z gzip &amp;</div><div class="line"><span class="meta"></span></div><div class="line">#file size 1000M </div><div class="line">nohup sudo tcpdump -i eth0 -t -s 0 tcp and port 3306 -w 'dump_' -C 1000 -W 300 -Z root -z gzip &amp;</div><div class="line"><span class="meta"></span></div><div class="line">#port range</div><div class="line">sudo  tcpdump -i enp44s0f0 -t -s 0 portrange 3000-3100  -w 'dump_%Y-%m-%d_%H:%M:%S.pcap'   -G 60 -W 100 -Z root</div><div class="line"><span class="meta"></span></div><div class="line">#subnet</div><div class="line">sudo  tcpdump -i enp44s0f0 -t -s 0 net 192.168.0.1/28 -w 'dump_%Y-%m-%d_%H:%M:%S.pcap'   -G 60 -W 100 -Z root</div><div class="line"><span class="meta"></span></div><div class="line">#抓取详细SQL语句, 快速确认client发过来的具体SQL内容：</div><div class="line">sudo tshark -i any -f 'port 8527' -s 0 -l -w - |strings</div><div class="line">sudo tshark -i eth0 -d tcp.port==3306,mysql -T fields -e mysql.query 'port 3306'</div><div class="line">sudo tshark -i eth0 -R "ip.addr==11.163.182.137" -d tcp.port==3306,mysql -T fields -e mysql.query 'port 3306'</div><div class="line">sudo tshark -i eth0 -R "tcp.srcport==62877" -d tcp.port==3001,mysql -T fields -e tcp.srcport -e mysql.query 'port 3001'</div><div class="line"><span class="meta"></span></div><div class="line">#query time</div><div class="line">sudo tshark -i eth0 -Y " ((tcp.port eq 3306 ) and tcp.len&gt;0 )" -o tcp.calculate_timestamps:true -T fields -e frame.number -e frame.time_epoch  -e frame.time_delta_displayed  -e ip.src -e tcp.srcport -e tcp.dstport -e ip.dst -e tcp.time_delta -e tcp.stream -e tcp.len -e mysql.query</div><div class="line"><span class="meta"></span></div><div class="line">#如果MySQL开启了SSL，那么抓包后的内容tshark/wireshark分析不到MySQL的具体内容，可以强制关闭：connectionProperties里加上useSSL=false</div><div class="line"></div><div class="line">tshark -r ./manager.cap -o tcp.calculate_timestamps:true -Y " tcp.analysis.retransmission "  -T fields -e tcp.stream -e frame.number -e frame.time -e ip.src -e tcp.srcport -e tcp.dstport -e ip.dst | sort</div><div class="line"><span class="meta"></span></div><div class="line">#MySQL响应时间直方图【第八列的含义-- Time since previous frame in this TCP stream: seconds】：</div><div class="line">tshark -r gege_plantegg.pcap -Y "mysql.query or (tcp.srcport3306 and tcp.len&gt;60)" -o tcp.calculate_timestamps:true -T fields -e frame.number -e frame.time_epoch  -e frame.time_delta_displayed  -e ip.src -e tcp.srcport -e tcp.dstport -e ip.dst -e tcp.time_delta -e tcp.stream -e tcp.len | awk 'BEGIN &#123;sum0=0;sum3=0;sum10=0;sum30=0;sum50=0;sum100=0;sum300=0;sum500=0;sum1000=0;sumo=0;count=0;sum=0&#125; &#123;rt=$8; if(rt&gt;=0.000) sum=sum+rt; count=count+1; if(rt&lt;=0.000) sum0=sum0+1; else if(rt&lt;0.003) sum3=sum3+1 ; else if(rt&lt;0.01) sum10=sum10+1; else if(rt&lt;0.03) sum30=sum30+1; else if(rt&lt;0.05) sum50=sum50+1; else if(rt &lt; 0.1) sum100=sum100+1; else if(rt &lt; 0.3) sum300=sum300+1; else if(rt &lt; 0.5) sum500=sum500+1; else if(rt &lt; 1) sum1000=sum1000+1; else sum=sum+1 ;&#125; END&#123;printf "-------------\n3ms:\t%s \n10ms:\t%s \n30ms:\t%s \n50ms:\t%s \n100ms:\t%s \n300ms:\t%s \n500ms:\t%s \n1000ms:\t%s \n&gt;1s:\t %s\n-------------\navg: %.6f \n" , sum3,sum10,sum30,sum50,sum100,sum300,sum500,sum1000,sumo,sum/count;&#125;'</div><div class="line"><span class="meta"></span></div><div class="line">#分析MySQL rt，倒数第四列基本就是rt</div><div class="line">tshark -r gege_plantegg.pcap -Y " ((tcp.srcport eq 3306 ) and tcp.len&gt;0 )" -o tcp.calculate_timestamps:true -T fields -e frame.number -e frame.time_epoch  -e frame.time_delta_displayed  -e ip.src -e tcp.srcport -e tcp.dstport -e ip.dst -e tcp.time_delta -e tcp.stream -e tcp.len -e tcp.analysis.ack_rtt   </div><div class="line"><span class="meta"></span></div><div class="line">#或者排序一下</div><div class="line">tshark -r 213_php.cap -Y "mysql.query or (  tcp.srcport==3306)" -o tcp.calculate_timestamps:true -T fields -e frame.number -e frame.time_epoch  -e frame.time_delta_displayed  -e ip.src -e tcp.srcport -e tcp.dstport -e ip.dst -e tcp.time_delta -e tcp.stream -e tcp.len -e mysql.query |sort -nk9 -nk1</div><div class="line"><span class="meta"></span></div><div class="line">#将 tls key和抓包文件合并</div><div class="line">editcap --inject-secrets tls,key.log in.pcap out.pcap</div><div class="line"><span class="meta">#</span>把包长截掉，只保留前面54，可以脱敏包内容</div><div class="line">editcap -s 54 old.pcap new.pcap</div></pre></td></tr></table></figure>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2022/01/01/Apple_M1_Pro和Intel_I9-12900K谁强/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/01/01/Apple_M1_Pro和Intel_I9-12900K谁强/" itemprop="url">Apple M1 Pro 和 Intel I9-12900K到底谁强</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-01-01T12:30:03+08:00">
                2022-01-01
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CPU/" itemprop="url" rel="index">
                    <span itemprop="name">CPU</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Apple-M1-Pro-和-Intel-I9-12900K到底谁强"><a href="#Apple-M1-Pro-和-Intel-I9-12900K到底谁强" class="headerlink" title="Apple M1 Pro 和 Intel I9-12900K到底谁强"></a>Apple M1 Pro 和 Intel I9-12900K到底谁强</h1><p>主要比较 M1 Pro和 I9-12900K，从芯片的参数来分析他们的差异。不和M1Max、M1Ultra比是因为从成本看没有可比性，M1Max、M1Ultra应该比I9贵多了，比起来意义不大，M1Max、M1Ultra的场景不一样。结论在最后</p>
<p>网上很多拿I9-12900K和M1 Max比实际没有意义，CPU core方面M1 Max和M1 Pro是一样的（跑分结果一样），干嘛不挑个便宜的去比较！</p>
<h2 id="The-M1-Pro"><a href="#The-M1-Pro" class="headerlink" title="The M1 Pro"></a><strong>The M1 Pro</strong></h2><p>The M1 Pro takes this higher, with:</p>
<ul>
<li>33.7 billion transistors on a 240mm squared die.</li>
<li>8 performance cores, 24MB L2 Cache，每个core 3MB，cache跟不要钱一样的堆</li>
<li>2 efficiency cores with 4MB L2 cache，每个core 2MB</li>
<li>16 GPU Cores.</li>
<li>32GB DDR5 memory at 200GB/s.</li>
</ul>
<p><img src="/images/951413iMgBlog/image-20220402101632476-8873839.png" alt="image-20220402101632476"></p>
<p><strong>从性能来看不推荐买M1</strong>，内存还是DDR4，M1Pro以上就都是DDR5了（文后有惊喜告诉你怎么用M1的价格买到M1 Pro） </p>
<p><img src="/images/951413iMgBlog/image-20220402104020407-8873873.png" alt="image-20220402104020407"></p>
<p>上图中PCPU就是高性能核，共8个，PCPU左边的是低频节能的2个ECPU，机器不忙的时候可以用ECPU，节能。一旦有复杂任务就可以用PCPU。至于M1 Max在狂堆 GPU, 然后M1 Ultra学习AMD把两块M1 Max封装在一起，有没有用就看你的应用场景了，比如搞程序编译、跑跑Idea用M1 Pro就够了，没必要多花几倍的钱用在GPU上，搞视频编辑、图片处理可以考虑Max、Ultra。</p>
<h3 id="The-M1-Max"><a href="#The-M1-Max" class="headerlink" title="The M1 Max"></a><strong>The M1 Max</strong></h3><p>The M1 Max provides:（相对M1 Pro主要是多堆了 16个GPU，CPU方面是一样的，大多数跑分是M1 Pro和Max几乎一样，多花钱买那16个GPU不一定值得）</p>
<ul>
<li>57 billion transistors on a 420mm squared die.</li>
<li>8 performance cores, 24MB L2 Cache.</li>
<li>2 efficiency cores with 4MB L2 cache.</li>
<li>32 GPU Cores.</li>
<li>64GB DDR5 memory at 400GB/s.</li>
</ul>
<h3 id="And-the-new-M1-Ultra"><a href="#And-the-new-M1-Ultra" class="headerlink" title="And the new M1 Ultra"></a><strong>And the new M1 Ultra</strong></h3><p>The M1 Ultra brings you:（下面的数据完全是M1 Max的2倍，实际就是封装两块M1 Max）</p>
<ul>
<li>114 billion transistors on a 840mm squared die.</li>
<li>16 performance cores, 48MB L2 Cache.</li>
<li>4 efficiency cores with 4MB L2 cache.</li>
<li>64 GPU Cores.</li>
<li>Up to 128GB DDR5 memory at 800GB/s.</li>
</ul>
<h3 id="M1-Pro主板拆解"><a href="#M1-Pro主板拆解" class="headerlink" title="M1 Pro主板拆解"></a>M1 Pro主板拆解</h3><p><img src="/images/951413iMgBlog/image-20220506142049220.png" alt="image-20220506142049220"></p>
<p>上图中，红框是 M1 Pro 芯片，黄框是三星 8GB 内存（共两块），绿框是铠侠的 128GB 闪存（共两块）。</p>
<h2 id="Inel-I9-12900K"><a href="#Inel-I9-12900K" class="headerlink" title="Inel I9-12900K"></a>Inel I9-12900K</h2><p>对比下 i9-12900K，i9也有GPU只是没有说多少个，它的GPU频率在0.3到1.55GHz之间</p>
<p><img src="/images/951413iMgBlog/400px-alder_lake_die_2.png" alt="alder lake die 2.png"></p>
<table>
<thead>
<tr>
<th>ISA</th>
<th>x86-64 (x86)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Microarchitecture</td>
<td><a href="https://en.wikichip.org/wiki/intel/microarchitectures/alder_lake" target="_blank" rel="external">Alder Lake</a>, <a href="https://en.wikichip.org/wiki/intel/microarchitectures/golden_cove" target="_blank" rel="external">Golden Cove</a>, <a href="https://en.wikichip.org/wiki/intel/microarchitectures/gracemont" target="_blank" rel="external">Gracemont</a></td>
</tr>
<tr>
<td>Process</td>
<td><a href="https://en.wikichip.org/w/index.php?title=Intel_7_process&amp;action=edit&amp;redlink=1" target="_blank" rel="external">Intel 7</a></td>
</tr>
<tr>
<td>Die</td>
<td>215.25 mm²” 20.5 mm × 10.5 mm</td>
</tr>
<tr>
<td>MCP</td>
<td>No (1 dies)</td>
</tr>
<tr>
<td>Cores</td>
<td>16</td>
</tr>
<tr>
<td>Threads</td>
<td>24</td>
</tr>
<tr>
<td><a href="https://en.wikichip.org/wiki/Property:l1$_size" target="_blank" rel="external">l1$ size</a></td>
<td>0.75 MiB (768 KiB, 786,432 B, 7.324219e-4 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l1-24-20size/0.75-20MiB" target="_blank" rel="external">+</a> and 0.625 MiB (640 KiB, 655,360 B, 6.103516e-4 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l1-24-20size/0.625-20MiB" target="_blank" rel="external">+</a></td>
</tr>
<tr>
<td><a href="https://en.wikichip.org/wiki/Property:l1d$_size" target="_blank" rel="external">l1d$ size</a></td>
<td>0.25 MiB (256 KiB, 262,144 B, 2.441406e-4 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l1d-24-20size/0.25-20MiB" target="_blank" rel="external">+</a> and 0.375 MiB (384 KiB, 393,216 B, 3.662109e-4 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l1d-24-20size/0.375-20MiB" target="_blank" rel="external">+</a></td>
</tr>
<tr>
<td><a href="https://en.wikichip.org/wiki/Property:l1i$_size" target="_blank" rel="external">l1i$ size</a></td>
<td>0.5 MiB (512 KiB, 524,288 B, 4.882812e-4 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l1i-24-20size/0.5-20MiB" target="_blank" rel="external">+</a> and 0.25 MiB (256 KiB, 262,144 B, 2.441406e-4 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l1i-24-20size/0.25-20MiB" target="_blank" rel="external">+</a></td>
</tr>
<tr>
<td><a href="https://en.wikichip.org/wiki/Property:l2$_size" target="_blank" rel="external">l2$ size</a></td>
<td>4 MiB (4,096 KiB, 4,194,304 B, 0.00391 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l2-24-20size/4-20MiB" target="_blank" rel="external">+</a> and 10 MiB (10,240 KiB, 10,485,760 B, 0.00977 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l2-24-20size/10-20MiB" target="_blank" rel="external">+</a> 共14Mb</td>
</tr>
<tr>
<td><a href="https://en.wikichip.org/wiki/Property:l3$_size" target="_blank" rel="external">l3$ size</a></td>
<td>6 MiB (6,144 KiB, 6,291,456 B, 0.00586 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l3-24-20size/6-20MiB" target="_blank" rel="external">+</a> and 24 MiB (24,576 KiB, 25,165,824 B, 0.0234 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l3-24-20size/24-20MiB" target="_blank" rel="external">+</a> 共30Mb</td>
</tr>
<tr>
<td>TDP</td>
<td>125 W</td>
</tr>
</tbody>
</table>
<p>从下面的芯片分布图来看，绿色部分是8个高性能物理core，每个2 thread，绿色其右边的蓝色E Cores是8个低频节能core，没开超线程，所以24个threads就是2*8PCPU+8ECPU。真正打起仗来从蓝色部分的面积占比来看基本可以忽略，重点得靠绿色的PCPU。</p>
<p><img src="/images/951413iMgBlog/arch2_small.jpg" alt="img"></p>
<h2 id="性能比较"><a href="#性能比较" class="headerlink" title="性能比较"></a>性能比较</h2><p>从上面分析来看 I9-12900K和M1 Pro的比较最终回到了各自8个PCPU的较量。Intel/X86的超线程在大部分场景下可以提升单核计算能力的1.5倍左右，所以这里就是Intel的12core打M1 Pro的，另外Intel主频也比M1 Pro要高，如果比较单core的计算能力Intel能睿频到5GHz以上，所以不考虑视频、图片、矩阵等简单计算场景，Intel的性能应该还是要强很多的。但是如果作为笔记本来说一定要考虑功耗，125W VS 45W，我的建议是买Apple（M1的软件兼容性也是个问题）。如果是当服务器工作站使用还是建议买I9. 价钱就不好比较了M1 Pro不单独卖没法估计价格。</p>
<p>I9弱在内存还是DDR4，而M1 Pro是DDR5了，另外就是M1 Pro的L2要大。当然I9也有DDR5的内存的。</p>
<p>笔记本领域M1整体来看应该优势明显，尤其是经过几年的生态发展能够把软件生态补上的话。</p>
<h2 id="购买建议"><a href="#购买建议" class="headerlink" title="购买建议"></a>购买建议</h2><p>如果想买苹果，推荐买这款：</p>
<p><img src="/images/951413iMgBlog/image-20220402103153047-8874337.png" alt="image-20220402103153047"></p>
<p>这种<a href="https://ata.alibaba-inc.com/articles/211563" target="_blank" rel="external">非标8核的M1（就是10核关闭了2核），便宜了2500，特别值</a>。苹果从来没有发布过8核的M1 Pro芯片，但是这款售卖的CPU号称是M1 Pro，比正常的M1 Pro少了两个CPU core和两个GPU。这点差异是不会重新设计一个新的芯片多搞一条生产线的，一般是正常的M1 Pro生产线下来检测发现坏了个别的core，扔了太浪费，于是关掉坏core当低配的M1 Pro在卖，价钱便宜了快一半了，实际性能其实差得不多。</p>
<p>如果是买Intel i9的话，从性价比上来看如果能买到i5-12600K也是非常不错的，实际就是i9关掉(坏掉)了2个PCPU和4个ECPU，价钱是i9的一半不到，PCPU少了但是Base主频反而高了，因为总核少了，发热就能控制，所以单核能跑到的频率更高一些。</p>
<p><img src="/images/951413iMgBlog/image_19.jpg" alt="image 19"></p>
<p>其实I9、I7、I5都是同一条生产线、同样的工艺下制造出来的，差别在于帮I9分摊成本，比如你看看<a href="https://en.wikichip.org/wiki/intel/core_i5/i5-12600k" target="_blank" rel="external">i5-12600k的参数</a>和i9-12900K基本是一样的，重点在215.25 mm² 的 Die Size：</p>
<table>
<thead>
<tr>
<th>ISA</th>
<th>x86-64 (x86)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Microarchitecture</td>
<td><a href="https://en.wikichip.org/wiki/intel/microarchitectures/alder_lake" target="_blank" rel="external">Alder Lake</a>, <a href="https://en.wikichip.org/wiki/intel/microarchitectures/golden_cove" target="_blank" rel="external">Golden Cove</a>, <a href="https://en.wikichip.org/wiki/intel/microarchitectures/gracemont" target="_blank" rel="external">Gracemont</a></td>
</tr>
<tr>
<td>Process</td>
<td><a href="https://en.wikichip.org/w/index.php?title=Intel_7_process&amp;action=edit&amp;redlink=1" target="_blank" rel="external">Intel 7</a></td>
</tr>
<tr>
<td>Die</td>
<td>215.25 mm² 20.5 mm × 10.5 mm</td>
</tr>
<tr>
<td>Cores</td>
<td>10</td>
</tr>
<tr>
<td>Threads</td>
<td>16</td>
</tr>
</tbody>
</table>
<p>即使把 <a href="https://www.techpowerup.com/review/intel-core-i5-12600k-alder-lake-12th-gen/2.html" target="_blank" rel="external">i5-12600k拆开</a>用放大镜看也是和i9-12900K 一样的：</p>
<p><img src="/images/951413iMgBlog/arch1_small.jpg" alt="img"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li>笔记本建议买M1 Pro</li>
<li>M1和M1 Pro如果看重性能的话肯定要买M1 Pro了</li>
<li>M1 Pro 建议买8 core的，买到就是赚到</li>
<li>集团内M1 Pro想要轻便就选14寸的，综合考虑我还是推荐14寸的</li>
<li>I9的笔记本建议买I7、I5，平时使用性能差得不多</li>
<li>性能还是I9强，做服务器更合适 </li>
</ul>
<p>最后我手里头既没有I9也没有M1，结论靠键盘 :)，买错了别找我。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://ata.alibaba-inc.com/articles/211563" target="_blank" rel="external">CPU的生产和概念</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/11/26/数据库计算向量化/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/11/26/数据库计算向量化/" itemprop="url">数据库计算向量化</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-11-26T17:30:03+08:00">
                2021-11-26
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MySQL/" itemprop="url" rel="index">
                    <span itemprop="name">MySQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="数据库计算向量化"><a href="#数据库计算向量化" class="headerlink" title="数据库计算向量化"></a>数据库计算向量化</h1><p>前面我们通过一系列的CPU原理来学习了CPU的结构，以及怎么样让CPU跑得更快，那么我们有没有很好的案例来实战让CPU跑得更快呢。接下来我们通过数据库领域的向量化计算是如何利用CPU这些特性来让CPU更快地帮我们处理数据(SQL)</p>
<p><a href="/2021/06/01/CPU的制造和概念/">CPU的制造和概念</a></p>
<p><a href="/2021/05/16/Perf IPC以及CPU利用率/">Perf IPC以及CPU性能</a></p>
<p><a href="https://plantegg.github.io/2021/07/19/CPU性能和CACHE/">CPU性能和CACHE</a></p>
<p><a href="/2021/05/16/CPU Cache Line 和性能/">CPU 性能和Cache Line</a></p>
<p><a href="/2021/05/14/十年后数据库还是不敢拥抱NUMA/">十年后数据库还是不敢拥抱NUMA？</a></p>
<p><a href="/2019/12/16/Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的/">Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的</a></p>
<p><a href="/2021/08/13/AMD_Zen_CPU架构/">AMD Zen CPU 架构 以及 AMD、海光、Intel、鲲鹏的性能对比</a></p>
<p><a href="/2021/06/18/几款CPU性能对比/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></p>
<p><a href="/2021/03/07/一次海光物理机资源竞争压测的记录/">一次海光物理机资源竞争压测的记录</a></p>
<p><a href="/2021/05/15/飞腾ARM芯片-FT2500的性能测试/">飞腾ARM芯片(FT2500)的性能测试</a></p>
<p>在做向量化之前数据库一直用的是volcano模型来处理SQL</p>
<h2 id="volcano火山模型"><a href="#volcano火山模型" class="headerlink" title="volcano火山模型"></a>volcano火山模型</h2><p>对于如下一条SQL, 数据库会将它解析成一颗树，这棵树每个节点就是一个operator(简单理解就是一个函数，进行一次计算处理)</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">SELECT</span> pv.siteId, user.nickame</div><div class="line"><span class="keyword">FROM</span> pv <span class="keyword">JOIN</span> <span class="keyword">user</span></div><div class="line"><span class="keyword">ON</span> pv.siteId = user.siteId <span class="keyword">AND</span> pv.userId = user.id</div><div class="line"><span class="keyword">WHERE</span> pv.siteId = <span class="number">123</span>;</div></pre></td></tr></table></figure>
<p><img src="/images/951413iMgBlog/relation-algebra.png" alt="Relation Algebra"></p>
<p>可以看到火山模型实现简单，只需要根据不同的计算提供一堆算子(operator)就可以了，然后根据不同的SQL只需要将operator进行组装（类似搭积木一样），就能得到一个递归调用结构（火山模型），每行数据按照这个调用逻辑经过每个operator进行嵌套处理就得到最终结果。</p>
<p>火山模型不但实现简单，框架结构性也非常好容易扩展。</p>
<p>但是火山模型效率不高: </p>
<ol>
<li>每个operator拆分必须到最小粒度，导致嵌套调用过多过深；</li>
<li>嵌套都是虚函数无法内联；</li>
<li>这个处理逻辑整体对CPU流水线不友好，CPU希望你不停地给我数据我按一个固定的逻辑(流程)来处理，而不是在不同的算子中间跳来跳去。</li>
</ol>
<h2 id="向量化加速的CPU原理"><a href="#向量化加速的CPU原理" class="headerlink" title="向量化加速的CPU原理"></a>向量化加速的CPU原理</h2><p>向量化加速的CPU原理:</p>
<ul>
<li><a href="https://topic.atatech.org/articles/210128" target="_blank" rel="external">内存访问比CPU计算慢两个数量级</a></li>
<li><a href="https://ata.alibaba-inc.com/articles/214221" target="_blank" rel="external">cpu按cache_line从内存取数据，取一个数据和取多个数据代价一样</a></li>
<li>以及数据局部性原理</li>
</ul>
<p>如下图，表示的是for循环每次跳K个int，在K小于16的时候虽然循环次数逐渐减少到原来的1/16, 但是总时间没变，因为一直是访问的同一个cache里面的数据。 到16个之后就会产生突变（跨了cache_line），再后面32、64、128的时间减少来源于循环次数的减少，因为如论如何每次循环都需要访问内存加载数据到cache_line中. </p>
<p>Cache_line大小是64，正好16个int，也就是存取1个或者16个int的代价基本是一样的。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">for (int i = 0; i &lt; arr.Length; i += K) arr[i] *= 3;</div></pre></td></tr></table></figure>
<p><img src="/images/951413iMgBlog/image6.png" alt="running times of this loop for different step values (/images/951413iMgBlog/image6.png)"></p>
<p>另外 一个大家耳熟能详的案例是对一个二维数组<strong>逐行遍历</strong>和<strong>逐列遍历</strong>的时间差异，循环次数一样，但是因为二维数组按行保存，所以逐行遍历对cache line 更友好，最终按行访问效率更高:</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">const</span> <span class="keyword">int</span> row = <span class="number">1024</span>;</div><div class="line"><span class="keyword">const</span> <span class="keyword">int</span> col = <span class="number">512</span></div><div class="line"><span class="keyword">int</span> matrix[row][col];</div><div class="line"><span class="comment">//逐行遍历耗时0.081ms</span></div><div class="line"><span class="keyword">int</span> sum_row=<span class="number">0</span>;</div><div class="line"><span class="keyword">for</span>(<span class="keyword">int</span> _r=<span class="number">0</span>; _r&lt;row; _r++) &#123;</div><div class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> _c=<span class="number">0</span>; _c&lt;col; _c++)&#123;</div><div class="line">        sum_row += matrix[_r][_c];</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">//逐列遍历耗时1.069ms</span></div><div class="line"><span class="keyword">int</span> sum_col=<span class="number">0</span>;</div><div class="line"><span class="keyword">for</span>(<span class="keyword">int</span> _c=<span class="number">0</span>; _c&lt;col; _c++) &#123;</div><div class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> _r=<span class="number">0</span>; _r&lt;row; _r++)&#123;</div><div class="line">        sum_col += matrix[_r][_c];</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>了解了以上CPU运算的原理我们再来看向量化就很简单了</p>
<h2 id="向量化"><a href="#向量化" class="headerlink" title="向量化"></a>向量化</h2><p>向量化执行的思想就是不再像火山模型一样调用一个算子一次处理一行数据，而是一次处理一批数据来均摊开销：这个开销很明显会因为一次处理一个数据没用利用好cache_line以及局部性原理，导致CPU在切换算子的时候要stall在取数据上，表现出来的结果就是IPC很低，cache miss、branch prediction失败都会增加。</p>
<p>举例来说，对于一个实现两个 int 相加的 expression，在向量化之前，其实现可能是这样的：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">ExpressionIntAdd</span> <span class="title">extends</span> <span class="title">Expression</span> &#123;</span></div><div class="line">        <span class="function">Datum <span class="title">eval</span><span class="params">(Row input)</span> </span>&#123;</div><div class="line">                <span class="keyword">int</span> left = input.getInt(leftIndex);</div><div class="line">                <span class="keyword">int</span> right = input.getInt(rightIndex);</div><div class="line">                <span class="keyword">return</span> <span class="keyword">new</span> Datum(left+right);</div><div class="line">        &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在向量化之后，其实现可能会变为这样：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">VectorExpressionIntAdd</span> <span class="title">extends</span> <span class="title">VectorExpression</span> &#123;</span></div><div class="line">        <span class="keyword">int</span>[] eval(<span class="keyword">int</span>[] left, <span class="keyword">int</span>[] right) &#123;</div><div class="line">                <span class="keyword">int</span>[] ret = <span class="keyword">new</span> <span class="keyword">int</span>[input.length];</div><div class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; input.length; i++) &#123;</div><div class="line">                  <span class="comment">//利用cache局部性原理一次取多个数据和取一个代价一样</span></div><div class="line">                  ret[i] = <span class="keyword">new</span> Datum(left[i] + right[i]);</div><div class="line">                &#125;</div><div class="line">                <span class="keyword">return</span> ret;</div><div class="line">        &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>很明显对比向量化之前的版本，向量化之后的版本不再是每次只处理一条数据，而是每次能处理一批数据，而且这种向量化的计算模式在计算过程中也具有更好的数据局部性。</p>
<p>向量化–Vector、批量化（一次处理一批数据）。向量化核心是利用数据局部性原理，一次取一个和取一批的时延基本是同样的。volcanno模型每次都是取一个处理一个，跳转到别的算子；而向量化是取一批处理一批后再跳转。整个过程中最耗时是取数据（访问内存比CPU计算慢两个数量级）</p>
<p><strong>如果把向量化计算改成批量化处理应该就好理解多了，但是low，向量化多玄乎啊</strong></p>
<p>为了支持这种批量处理数据的需求，CPU设计厂家又搞出了SIMD这种大杀器</p>
<h3 id="SIMD-Single-Instruction-Multiple-Data，单指令多数据"><a href="#SIMD-Single-Instruction-Multiple-Data，单指令多数据" class="headerlink" title="SIMD (Single Instruction Multiple Data，单指令多数据)"></a><a href="https://www.atatech.org/articles/211563" target="_blank" rel="external">SIMD (Single Instruction Multiple Data，单指令多数据)</a></h3><p>简单理解SIMD就是相对于之前一个指令(一般是一个时钟周期)操作一个数据，但现在有了SIMD就可以在一个时钟周期操作一批数据，这个批如果是64，那么性能就提升了64倍。</p>
<p>英特尔在1996年率先引入了MMX（Multi Media eXtensions）多媒体扩展指令集，也开创了<strong>SIMD</strong>（Single Instruction Multiple Data，单指令多数据）指令集之先河，即在一个周期内一个指令可以完成多个数据操作，MMX指令集的出现让当时的MMX Pentium处理器大出风头。</p>
<p><strong>SSE</strong>（Streaming SIMD Extensions，流式单指令多数据扩展）指令集是1999年英特尔在Pentium III处理器中率先推出的，并将矢量处理能力从64位扩展到了128位。</p>
<p>AVX 所代表的单指令多数据（Single Instruction Multi Data，SIMD）指令集，是近年来 CPU 提升 IPC（每时钟周期指令数）上为数不多的重要革新。随着每次数据宽度的提升，CPU 的性能都会大幅提升，但同时晶体管数量和能耗也会有相应的提升。因此在对功耗有较高要求的场景，如笔记本电脑或服务器中，CPU 运行 AVX 应用时需要降低频率从而降低功耗。</p>
<p>向量化当然也非常希望利用SIMD(跟GPU为什么挖矿比CPU快是一样的道理)</p>
<p>这里可以参考为什么这20年CPU主频基本都在2G-3G附近不再提升但是性能仍然遵循摩尔定律在提升。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="/2021/06/01/CPU的制造和概念/">CPU的制造和概念</a></p>
<p><a href="/2021/05/16/Perf IPC以及CPU利用率/">Perf IPC以及CPU性能</a></p>
<p><a href="https://plantegg.github.io/2021/07/19/CPU性能和CACHE/">CPU性能和CACHE</a></p>
<p><a href="/2021/05/16/CPU Cache Line 和性能/">CPU 性能和Cache Line</a></p>
<p><a href="/2021/05/14/十年后数据库还是不敢拥抱NUMA/">十年后数据库还是不敢拥抱NUMA？</a></p>
<p><a href="/2019/12/16/Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的/">Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的</a></p>
<p><a href="/2021/08/13/AMD_Zen_CPU架构/">AMD Zen CPU 架构 以及 AMD、海光、Intel、鲲鹏的性能对比</a></p>
<p><a href="/2021/06/18/几款CPU性能对比/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></p>
<p><a href="/2021/03/07/一次海光物理机资源竞争压测的记录/">一次海光物理机资源竞争压测的记录</a></p>
<p><a href="/2021/05/15/飞腾ARM芯片-FT2500的性能测试/">飞腾ARM芯片(FT2500)的性能测试</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/08/13/AMD_Zen_CPU架构/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/08/13/AMD_Zen_CPU架构/" itemprop="url">AMD Zen CPU 架构以及不同CPU性能大PK</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-08-13T17:30:03+08:00">
                2021-08-13
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CPU/" itemprop="url" rel="index">
                    <span itemprop="name">CPU</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="AMD-Zen-CPU-架构"><a href="#AMD-Zen-CPU-架构" class="headerlink" title="AMD Zen CPU 架构"></a>AMD Zen CPU 架构</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本文先介绍AMD Zen 架构，结合前一篇文章《<a href="https://www.atatech.org/articles/211563" target="_blank" rel="external">CPU的生产和概念</a>》一起来看效果会更好，在<a href="https://www.atatech.org/articles/211563" target="_blank" rel="external">CPU的生产和概念</a>中主要是以Intel方案来介绍，CPU的生产和概念中的 多核和多个CPU方案2 就是指的AMD Zen2架构。</p>
<p>Zen1 和 Intel 还比较像，只是一个CPU会封装多个小的Die来得到多核能力，导致NUMA node比较多。</p>
<p>AMD 从Zen2开始架构有了比较大的变化，Zen2架构改动比较大，将IO从Core Die中抽离出来，形成一个专门的IO Die，这个IO Die可以用上一代的工艺实现来提升成品率降低成本。剩下的core Die 专注在core和cache的实现上，同时可以通过最新一代的工艺来提升性能。并且在一个CPU上封装一个 IO Die + 8个 core Die这样一块CPU做到像Intel一样就是一个大NUMA，但是成本低了很多，也许在云计算时代这么搞比较合适。当然会被大家笑话为胶水核（用胶水把多个Die拼在一起），性能肯定是不如一个大Die好，但是挡不住便宜啊。这估计就是大家所说的 <strong>AMD YES！</strong>吧</p>
<p>比如Core Die用7nm工艺，IO Die用14nm工艺，一块CPU封装8个Core Die+1个IO Die的话既能得到一个多核的CPU成本有非常低，参考 《CPU的生产和概念》中的良品率和成品部分。</p>
<p>介绍完AMD架构后，会拿海光7280这块CPU（实际是OEM的AMD Zen1 架构，一块芯片封装4个die）和 Intel的CPU用MySQL 来对比一下实际性能。</p>
<p>网上Intel CPU架构、技术参数等各种资料还是很丰富的，但是AMD EPYC就比较少了，所以先来学习一下EPYC的架构特点。</p>
<p><img src="/images/951413iMgBlog/image-20220331120118117.png" alt="image-20220331120118117"></p>
<h2 id="AMD-EPYC-CPU演进路线"><a href="#AMD-EPYC-CPU演进路线" class="headerlink" title="AMD EPYC CPU演进路线"></a>AMD EPYC CPU演进路线</h2><p><img src="/images/951413iMgBlog/amd-rome-naples-chiplets.jpg" alt="img"></p>
<p>后面会针对 第二代的 EPYC来做一个对比测试。</p>
<p><img src="/images/951413iMgBlog/AMD-Packaging-to-X3D-FAD-2020.jpg" alt="AMD Accelerated Computing FAD 2020"></p>
<p> AMD EPYC CPU Families:</p>
<table>
<thead>
<tr>
<th style="text-align:left">Family Name</th>
<th style="text-align:left">AMD EPYC Naples</th>
<th style="text-align:left">AMD EPYC Rome</th>
<th style="text-align:left">AMD EPYC Milan</th>
<th style="text-align:left">AMD EPYC Genoa</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Family Branding</td>
<td style="text-align:left">EPYC 7001</td>
<td style="text-align:left">EPYC 7002</td>
<td style="text-align:left">EPYC 7003</td>
<td style="text-align:left">EPYC 7004?</td>
</tr>
<tr>
<td style="text-align:left">Family Launch</td>
<td style="text-align:left">2017</td>
<td style="text-align:left">2019</td>
<td style="text-align:left">2021</td>
<td style="text-align:left">2022</td>
</tr>
<tr>
<td style="text-align:left">CPU Architecture</td>
<td style="text-align:left">Zen 1</td>
<td style="text-align:left">Zen 2</td>
<td style="text-align:left">Zen 3</td>
<td style="text-align:left">Zen 4</td>
</tr>
<tr>
<td style="text-align:left">Process Node</td>
<td style="text-align:left">14nm GloFo</td>
<td style="text-align:left">7nm TSMC</td>
<td style="text-align:left">7nm TSMC</td>
<td style="text-align:left">5nm TSMC</td>
</tr>
<tr>
<td style="text-align:left">Platform Name</td>
<td style="text-align:left">SP3</td>
<td style="text-align:left">SP3</td>
<td style="text-align:left">SP3</td>
<td style="text-align:left">SP5</td>
</tr>
<tr>
<td style="text-align:left">Socket</td>
<td style="text-align:left">LGA 4094</td>
<td style="text-align:left">LGA 4094</td>
<td style="text-align:left">LGA 4094</td>
<td style="text-align:left">LGA 6096</td>
</tr>
<tr>
<td style="text-align:left">Max Core Count</td>
<td style="text-align:left">32</td>
<td style="text-align:left">64</td>
<td style="text-align:left">64</td>
<td style="text-align:left">96</td>
</tr>
<tr>
<td style="text-align:left">Max Thread Count</td>
<td style="text-align:left">64</td>
<td style="text-align:left">128</td>
<td style="text-align:left">128</td>
<td style="text-align:left">192</td>
</tr>
<tr>
<td style="text-align:left">Max L3 Cache</td>
<td style="text-align:left">64 MB</td>
<td style="text-align:left">256 MB</td>
<td style="text-align:left">256 MB</td>
<td style="text-align:left">384 MB?</td>
</tr>
<tr>
<td style="text-align:left">Chiplet Design</td>
<td style="text-align:left">4 CCD’s (2 CCX’s per CCD)，4 Die</td>
<td style="text-align:left">8 CCD’s (2 CCX’s per CCD) + 1 IOD ，9 Die</td>
<td style="text-align:left">8 CCD’s (1 CCX per CCD) + 1 IOD</td>
<td style="text-align:left">12 CCD’s (1 CCX per CCD) + 1 IOD</td>
</tr>
<tr>
<td style="text-align:left">Memory Support</td>
<td style="text-align:left">DDR4-2666</td>
<td style="text-align:left">DDR4-3200</td>
<td style="text-align:left">DDR4-3200</td>
<td style="text-align:left">DDR5-5200</td>
</tr>
<tr>
<td style="text-align:left">Memory Channels</td>
<td style="text-align:left">8 Channel</td>
<td style="text-align:left">8 Channel</td>
<td style="text-align:left">8 Channel</td>
<td style="text-align:left">12 Channel</td>
</tr>
<tr>
<td style="text-align:left">PCIe Gen Support</td>
<td style="text-align:left">64 Gen 3</td>
<td style="text-align:left">128 Gen 4</td>
<td style="text-align:left">128 Gen 4</td>
<td style="text-align:left">128 Gen 5</td>
</tr>
<tr>
<td style="text-align:left">TDP Range</td>
<td style="text-align:left">200W</td>
<td style="text-align:left">280W</td>
<td style="text-align:left">280W</td>
<td style="text-align:left">320W (cTDP 400W)</td>
</tr>
</tbody>
</table>
<h2 id="Zen1"><a href="#Zen1" class="headerlink" title="Zen1"></a>Zen1</h2><p>hygon 5280封装后类似下图(一块CPU封装了2个Die，还有封装4个Die的，core更多更贵而已)</p>
<p><img src="/images/951413iMgBlog/image-20210812204437220.png" alt="image-20210812204437220"></p>
<p>或者4个Die封装在一起</p>
<p><img src="/images/951413iMgBlog/image-20210813085044786.png" alt="image-20210813085044786"></p>
<h3 id="Zen1-Die"><a href="#Zen1-Die" class="headerlink" title="Zen1 Die"></a>Zen1 Die</h3><p>下面这块Die集成了两个CCX（每个CCX四个物理core), 同时还有IO接口</p>
<p><img src="/images/951413iMgBlog/zeppelin_face_down2.png" alt="Блоки CCX"></p>
<p><img src="/images/951413iMgBlog/515px-zen-1zep.svg.png" alt="img"></p>
<p>Quad-Zeppelin Configuration, as found in <a href="https://en.wikichip.org/wiki/amd/epyc" target="_blank" rel="external">EPYC</a>. </p>
<p><img src="/images/951413iMgBlog/512px-zen-4zep.svg.png" alt="img"></p>
<h3 id="Zen-CPU-Complex-CCX"><a href="#Zen-CPU-Complex-CCX" class="headerlink" title="Zen CPU Complex(CCX)"></a>Zen CPU Complex(CCX)</h3><p>hygon 5280使用这个结构， There are 4 cores per CCX and 2 CCXs per die for 8 cores.</p>
<ul>
<li>44 mm² area</li>
<li>L3 8 MiB; 16 mm²</li>
<li>1,400,000,000 transistors</li>
</ul>
<p><img src="/images/951413iMgBlog/450px-amd_zen_ccx.png" alt="amd zen ccx.png"></p>
<p><img src="/images/951413iMgBlog/700px-amd_zen_ccx_2_annotated.png" alt="amd zen ccx 2"></p>
<h3 id="封装后的Zen1（4Die）"><a href="#封装后的Zen1（4Die）" class="headerlink" title="封装后的Zen1（4Die）"></a>封装后的Zen1（4Die）</h3><p><img src="/images/951413iMgBlog/image-20210813085044786.png" alt="image-20210813085044786"></p>
<p>4个Die的内部关系</p>
<p><img src="/images/951413iMgBlog/800px-AMD_Naples_SoC.svg.png" alt="AMD Naples SoC.svg"></p>
<p>详实数据和结构</p>
<p><img src="/images/951413iMgBlog/AMD-EPYC-Infinity-Fabric-Topology-Mapping.webp" alt="Топология процессора"></p>
<h2 id="Zen2-Rome"><a href="#Zen2-Rome" class="headerlink" title="Zen2 Rome"></a><a href="https://en.wikichip.org/wiki/amd/microarchitectures/zen_2" target="_blank" rel="external">Zen2 Rome</a></h2><p>Zen2开始最大的变化就是将IO从Core Die中抽离出来，形成一个专门的IO Die。封装后如下图：</p>
<p><img src="/images/951413iMgBlog/image-20210602165525641.png" alt="AMD Rome package with card" style="zoom:50%;"></p>
<p>以上结构的CPU在2路服务器下的内部结构：</p>
<p><img src="/images/951413iMgBlog/1624282522149-35de1452-3e8d-4632-a53a-b99f1ed39a21.png" alt="img"></p>
<p>跨socket的内存访问的数据流跟互联有关，如上图标示，比如从左边的CCD0到右边的CCD0的内存，大概需要经过10跳。</p>
<table>
<thead>
<tr>
<th></th>
<th>node0</th>
<th>node1</th>
<th>node2</th>
<th>node3</th>
<th>node4</th>
<th>node5</th>
<th>node6</th>
<th>node7</th>
</tr>
</thead>
<tbody>
<tr>
<td>node0</td>
<td>89.67</td>
<td>99.357</td>
<td>108.11</td>
<td>110.54</td>
<td>181.85</td>
<td>187.71</td>
<td>179.507</td>
<td>179.463</td>
</tr>
<tr>
<td>node1</td>
<td></td>
<td>90.983</td>
<td>111.65</td>
<td>106.11</td>
<td>188.77</td>
<td>194.7</td>
<td>188.179</td>
<td>189.512</td>
</tr>
<tr>
<td>node2</td>
<td></td>
<td></td>
<td>91.2</td>
<td>98.272</td>
<td>180.95</td>
<td>190.53</td>
<td>184.865</td>
<td>186.088</td>
</tr>
<tr>
<td>node3</td>
<td></td>
<td></td>
<td></td>
<td>89.971</td>
<td>186.81</td>
<td>193.43</td>
<td>192.459</td>
<td>192.615</td>
</tr>
<tr>
<td>node4</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>89.566</td>
<td>97.943</td>
<td>108.19</td>
<td>109.942</td>
</tr>
<tr>
<td>node5</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>90.927</td>
<td>111.123</td>
<td>108.046</td>
</tr>
<tr>
<td>node6</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>91.212</td>
<td>103.719</td>
</tr>
<tr>
<td>node7</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>89.692</td>
</tr>
</tbody>
</table>
<p>上面表格是3 xGMI互联的情况下，测试出来的访存时延，可以看到在某些node间访存时延会有一些的突增，不够均匀，比如node1到node 5、node2到node5；上述latency跨socket如果用默认BIOS值在280左右</p>
<p>以下表格是厂商默认值和优化值对比（用优化值能将latency从280下降到180左右）：</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>可选项</th>
<th>默认值 （milan:V260 rome:V26.02）</th>
<th>优化值</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td>xGMI Link Width Control</td>
<td>Manual/Auto</td>
<td>Auto</td>
<td>Manual</td>
<td></td>
</tr>
<tr>
<td>xGMI Force Link Width Control</td>
<td>Unforce/Force</td>
<td>Unforce</td>
<td>Force</td>
<td></td>
</tr>
<tr>
<td>xGMI Force Link Width</td>
<td>0/1/2</td>
<td>2</td>
<td>2</td>
<td>2 = Force xGMI link width to x16</td>
</tr>
<tr>
<td>3-link xGMI max speed</td>
<td>[00]6.4Gbps     ……   [0A]16Gbps   ……[13]25Gbps     *[FF]Auto</td>
<td>Auto</td>
<td>16Gbps</td>
<td>IEC的rome和milan都是16Gbs，其他产品要与硬件确认</td>
</tr>
</tbody>
</table>
<p>另外发现启用透明大页后测试内存时延能降低20%（通过perf发现没开THP的tlb miss很高）</p>
<p><img src="/images/951413iMgBlog/AMD_Rome_layout-617x486.jpg" alt="AMD Rome layout"></p>
<p><img src="/images/951413iMgBlog/amd-rome-feature-chart.jpg" alt="img"></p>
<h3 id="Zen2-Core-Complex-Die"><a href="#Zen2-Core-Complex-Die" class="headerlink" title="Zen2 Core Complex Die"></a>Zen2 Core Complex Die</h3><ul>
<li>TSMC <a href="https://en.wikichip.org/wiki/N7" target="_blank" rel="external">7-nanometer process</a></li>
<li>13 metal layers[<a href="https://en.wikichip.org/wiki/amd/microarchitectures/zen_2#cite_note-isscc2020j-zen2-1" target="_blank" rel="external">1</a>]</li>
<li>3,800,000,000 transistors[<a href="https://en.wikichip.org/wiki/amd/microarchitectures/zen_2#cite_note-isscc2020p-chiplet-2" target="_blank" rel="external">2</a>]</li>
<li>Die size: 74 mm²</li>
<li>CCX size: 31.3 mm²， 4core per CCX // 16M L3 perf CCX</li>
<li>2 × 16 MiB L3 cache: 2 × 16.8 mm² (estimated) // 中间蓝色部分是L3 16M，一个Die封装两个CCX的情况下</li>
</ul>
<p><img src="/images/951413iMgBlog/500px-AMD_Zen_2_CCD.jpg" alt="AMD Zen 2 CCD.jpg"></p>
<p><img src="/images/951413iMgBlog/4f71c923-4601-4d98-a311-91da8996c526.png" alt="img"></p>
<p>在Zen2/Rome架构中，一个CCD由两个CCX构成，一个CCX包含4个物理核，共享16MB的L3 cache。</p>
<p>在Zen3/Milan架构中，抛弃了两个CCX组成一个CCD的概念，一个CCD直接由8个物理核构成，共享整个Die上的32MB L3 cache。</p>
<h2 id="Zen1-VS-Zen2"><a href="#Zen1-VS-Zen2" class="headerlink" title="Zen1 VS Zen2"></a>Zen1 VS Zen2</h2><p>Here is what the Naples and Rome packages look like from the outside:</p>
<p><img src="/images/951413iMgBlog/amd-rome-epyc-zen1-zen2.jpg" alt="img"></p>
<p>numa</p>
<p><img src="/images/951413iMgBlog/image-20210813091455662.png" alt="image-20210813091455662"></p>
<p>zen1 numa distance:</p>
<p><img src="/images/951413iMgBlog/OctalNUMA_575px.png" alt="img"></p>
<p>hygon numa distance:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"># numactl -H  //Zen1 hygon 7280  2 socket enable die interleaving</div><div class="line">available: 2 nodes (0-1)</div><div class="line">node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95</div><div class="line">node 0 size: 257578 MB</div><div class="line">node 0 free: 115387 MB</div><div class="line">node 1 cpus: 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127</div><div class="line">node 1 size: 257005 MB</div><div class="line">node 1 free: 221031 MB</div><div class="line">node distances:</div><div class="line">node   0   1</div><div class="line">  0:  10  22</div><div class="line">  1:  22  10</div><div class="line">  </div><div class="line">  #numactl -H //Zen1 hygon 5280  2 socket disable die interleaving</div><div class="line">available: 4 nodes (0-3)</div><div class="line">node 0 cpus: 0 1 2 3 4 5 6 7 32 33 34 35 36 37 38 39</div><div class="line">node 0 size: 128854 MB</div><div class="line">node 0 free: 89350 MB</div><div class="line">node 1 cpus: 8 9 10 11 12 13 14 15 40 41 42 43 44 45 46 47</div><div class="line">node 1 size: 129019 MB</div><div class="line">node 1 free: 89326 MB</div><div class="line">node 2 cpus: 16 17 18 19 20 21 22 23 48 49 50 51 52 53 54 55</div><div class="line">node 2 size: 128965 MB</div><div class="line">node 2 free: 86542 MB</div><div class="line">node 3 cpus: 24 25 26 27 28 29 30 31 56 57 58 59 60 61 62 63</div><div class="line">node 3 size: 129020 MB</div><div class="line">node 3 free: 98227 MB</div><div class="line">node distances:</div><div class="line">node   0   1   2   3</div><div class="line">  0:  10  16  28  22</div><div class="line">  1:  16  10  22  28</div><div class="line">  2:  28  22  10  16</div><div class="line">  3:  22  28  16  10</div></pre></td></tr></table></figure>
<p>看完这些结构上的原理，让我们实际来看看AMD的性能怎么样。</p>
<h2 id="hygon-7280-PCM数据"><a href="#hygon-7280-PCM数据" class="headerlink" title="hygon 7280 PCM数据"></a>hygon 7280 PCM数据</h2><p>hygon pcm(performance counter monitor) 工具由芯片公司提供</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div></pre></td><td class="code"><pre><div class="line">[root@hygon3 16:58 /root/PCM]</div><div class="line"><span class="meta">#</span>./pcm.x -r -topdown -i=1 -nc -ns -l2</div><div class="line"></div><div class="line"> Processor Counter Monitor  (2019-08-21 17:07:31 +0800 ID=378f2fc)</div><div class="line"></div><div class="line">Number of physical cores: 64</div><div class="line">Number of logical cores: 128</div><div class="line">Number of online logical cores: 128</div><div class="line">Threads (logical cores) per physical core: 2</div><div class="line">Num sockets: 2</div><div class="line">Physical cores per socket: 32</div><div class="line">Core PMU (perfmon) version: 3</div><div class="line">Number of core PMU generic (programmable) counters: 6</div><div class="line">Width of generic (programmable) counters: 64 bits</div><div class="line">Ccxs per Node: 8</div><div class="line">Logical cores per Ccx: 8</div><div class="line">Physical Cores per Ccx: 4</div><div class="line">Nodes per socket: 4</div><div class="line">Number of core PMU fixed counters: 0</div><div class="line">Width of fixed counters: 0 bits</div><div class="line">Nominal core frequency: 2000000000 Hz</div><div class="line">Package thermal spec power: -1 Watt; Package minimum power: -1 Watt; Package maximum power: -1 Watt;</div><div class="line"></div><div class="line"> Resetting PMU configuration</div><div class="line"> Zeroed PMU registers</div><div class="line"></div><div class="line">Detected Hygon C86 7280 32-core Processor  "Hygon(r) microarchitecture codename DHYANA" stepping 1</div><div class="line"></div><div class="line"> EXEC  : instructions per nominal CPU cycle</div><div class="line"> IPC   : instructions per CPU cycle</div><div class="line"> FREQ  : relation to nominal CPU frequency='unhalted clock ticks'/'invariant timer ticks' (includes Intel Turbo Boost)</div><div class="line"> AFREQ : relation to nominal CPU frequency while in active state (not in power-saving C state)='unhalted clock ticks'/'invariant timer ticks while in C0-state'  (includes Intel Turbo Boost)</div><div class="line"> L3MISS: L3 (read) cache misses</div><div class="line"> L3MPKI: L3 misses per kilo instructions</div><div class="line"> L3HIT : L3 (read) cache hit ratio (0.00-1.00)</div><div class="line"> L2DMISS:L2 data cache misses</div><div class="line"> L2DHIT :L2 data cache hit ratio (0.00-1.00)</div><div class="line"> L2DMPKI:number of L2 data cache misses per kilo instruction</div><div class="line"> L2IMISS:L2 instruction cache misses</div><div class="line"> L2IHIT :L2 instructoon cache hit ratio (0.00-1.00)</div><div class="line"> L2IMPKI:number of L2  instruction cache misses per kilo instruction</div><div class="line"> L2MPKI :number of both L2 instruction and data cache misses per kilo instruction</div><div class="line"></div><div class="line"> Core (SKT) |  EXEC  |   IPC  |  FREQ  |  AFREQ | L2DMISS| L2DHIT | L2DMPKI| L2IMISS| L2IHIT | L2IMPKI| L2MPKI | L3MISS | L3MPKI |  L3HIT | TEMP</div><div class="line"></div><div class="line">---------------------------------------------------------------------------------------------------------------</div><div class="line"> TOTAL  *     1.29     1.20     1.08     1.00     12 M     0.73     0.04     10 M     0.87     0.03     0.07     19 M     0.00     0.55     N/A</div><div class="line"></div><div class="line"> Instructions retired:  336 G ; Active cycles:  281 G ; Time (TSC): 2082 Mticks ; C0 (active,non-halted) core residency: 107.90 %</div><div class="line"></div><div class="line"></div><div class="line"> PHYSICAL CORE IPC                 : 2.39 =&gt; corresponds to 34.14 % utilization for cores in active state</div><div class="line"> Instructions per nominal CPU cycle: 2.58 =&gt; corresponds to 36.84 % core utilization over time interval</div><div class="line">---------------------------------------------------------------------------------------------------------------</div><div class="line"></div><div class="line">Cleaning up</div><div class="line"> Zeroed PMU registers</div></pre></td></tr></table></figure>
<p>在本地启动benchmarksql压力，并将进程绑定到0-8core，然后采集到数据：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span>./pcm.x -r -topdown -i=1 -l2</div><div class="line"></div><div class="line"> Processor Counter Monitor  (2019-08-21 17:07:31 +0800 ID=378f2fc)</div><div class="line"></div><div class="line">Number of physical cores: 64</div><div class="line">Number of logical cores: 128</div><div class="line">Number of online logical cores: 128</div><div class="line">Threads (logical cores) per physical core: 2</div><div class="line">Num sockets: 2</div><div class="line">Physical cores per socket: 32</div><div class="line">Core PMU (perfmon) version: 3</div><div class="line">Number of core PMU generic (programmable) counters: 6</div><div class="line">Width of generic (programmable) counters: 64 bits</div><div class="line">Ccxs per Node: 8</div><div class="line">Logical cores per Ccx: 8</div><div class="line">Physical Cores per Ccx: 4</div><div class="line">Nodes per socket: 4</div><div class="line">Number of core PMU fixed counters: 0</div><div class="line">Width of fixed counters: 0 bits</div><div class="line">Nominal core frequency: 2000000000 Hz</div><div class="line">Package thermal spec power: -1 Watt; Package minimum power: -1 Watt; Package maximum power: -1 Watt;</div><div class="line"></div><div class="line"> Resetting PMU configuration</div><div class="line"> Zeroed PMU registers</div><div class="line"></div><div class="line">Detected Hygon C86 7280 32-core Processor  "Hygon(r) microarchitecture codename DHYANA" stepping 1</div><div class="line"></div><div class="line"> EXEC  : instructions per nominal CPU cycle</div><div class="line"> IPC   : instructions per CPU cycle</div><div class="line"> FREQ  : relation to nominal CPU frequency='unhalted clock ticks'/'invariant timer ticks' (includes Intel Turbo Boost)</div><div class="line"> AFREQ : relation to nominal CPU frequency while in active state (not in power-saving C state)='unhalted clock ticks'/'invariant timer ticks while in C0-state'  (includes Intel Turbo Boost)</div><div class="line"> L3MISS: L3 (read) cache misses</div><div class="line"> L3MPKI: L3 misses per kilo instructions</div><div class="line"> L3HIT : L3 (read) cache hit ratio (0.00-1.00)</div><div class="line"> L2DMISS:L2 data cache misses</div><div class="line"> L2DHIT :L2 data cache hit ratio (0.00-1.00)</div><div class="line"> L2DMPKI:number of L2 data cache misses per kilo instruction</div><div class="line"> L2IMISS:L2 instruction cache misses</div><div class="line"> L2IHIT :L2 instructoon cache hit ratio (0.00-1.00)</div><div class="line"> L2IMPKI:number of L2  instruction cache misses per kilo instruction</div><div class="line"> L2MPKI :number of both L2 instruction and data cache misses per kilo instruction</div><div class="line"></div><div class="line"> Core (SKT) |  EXEC  |   IPC  |  FREQ  |  AFREQ | L2DMISS| L2DHIT | L2DMPKI| L2IMISS| L2IHIT | L2IMPKI| L2MPKI | L3MISS | L3MPKI |  L3HIT | TEMP</div><div class="line"></div><div class="line">   0    0     1.34     1.26     1.06     1.00   8901 K     0.72     3.15     15 M     0.68     5.43     8.58     71 M     4.00     0.60      N/A</div><div class="line">   1    0     1.42     1.33     1.06     1.00   8491 K     0.73     2.83     14 M     0.68     4.67     7.50     71 M     4.00     0.60      N/A</div><div class="line">   2    0     1.41     1.33     1.06     1.00   8206 K     0.74     2.75     12 M     0.72     4.25     7.00     71 M     4.00     0.60      N/A</div><div class="line">   3    0     1.46     1.38     1.06     1.00   7464 K     0.75     2.40     11 M     0.68     3.81     6.21     71 M     4.00     0.60      N/A</div><div class="line">   4    0     1.31     1.24     1.06     1.00   9118 K     0.71     3.28     15 M     0.69     5.61     8.88     70 M     4.00     0.61      N/A</div><div class="line">   5    0     1.41     1.33     1.06     1.00   8700 K     0.74     2.92     13 M     0.69     4.66     7.57     70 M     4.00     0.61      N/A</div><div class="line">   6    0     1.41     1.33     1.06     1.00   8094 K     0.74     2.79     12 M     0.70     4.40     7.18     70 M     4.00     0.61      N/A</div><div class="line">   7    0     1.43     1.35     1.06     1.00   7873 K     0.74     2.68     12 M     0.71     4.13     6.81     70 M     4.00     0.61      N/A</div><div class="line">   8    0     1.44     1.36     1.06     1.00   8544 K     0.73     2.79     14 M     0.67     4.87     7.66     20 M     1.00     0.61      N/A</div><div class="line">   9    0     1.24     1.16     1.06     1.00    524 K     0.51     0.21     86 K     0.94     0.03     0.24     20 M     1.00     0.61      N/A</div><div class="line">  10    0     1.26     1.18     1.07     1.00    379 K     0.50     0.15     60 K     0.95     0.02     0.17     20 M     1.00     0.61      N/A</div><div class="line">  11    0     1.24     1.16     1.07     1.00    533 K     0.50     0.20     96 K     0.94     0.04     0.24     20 M     1.00     0.61      N/A</div><div class="line">  12    0     1.22     1.14     1.07     1.00   1180 K     0.34     0.47     98 K     0.94     0.04     0.51   3872 K     0.12     0.46      N/A</div><div class="line">  13    0     1.24     1.16     1.07     1.00    409 K     0.49     0.16     64 K     0.94     0.03     0.19   3872 K     0.12     0.46      N/A</div><div class="line">  </div><div class="line">  ---------------------------------------------------------------------------------------------------------------</div><div class="line"> SKT    0     1.18     1.11     1.06     1.00    113 M     0.67     0.73    139 M     0.71     0.89     1.62    186 M     1.12     0.59      N/A</div><div class="line"> SKT    1     1.23     1.14     1.08     1.00     33 M     0.53     0.21     11 M     0.89     0.07     0.28     38 M     0.12     0.45      N/A</div><div class="line">---------------------------------------------------------------------------------------------------------------</div><div class="line"> TOTAL  *     1.21     1.13     1.07     1.00    147 M     0.65     0.46    150 M     0.74     0.47     0.93    224 M     0.62     0.57     N/A</div><div class="line"></div><div class="line"> Instructions retired:  319 G ; Active cycles:  283 G ; Time (TSC): 2108 Mticks ; C0 (active,non-halted) core residency: 107.12 %</div><div class="line"></div><div class="line"></div><div class="line"> PHYSICAL CORE IPC                 : 2.25 =&gt; corresponds to 32.18 % utilization for cores in active state</div><div class="line"> Instructions per nominal CPU cycle: 2.41 =&gt; corresponds to 34.48 % core utilization over time interval</div><div class="line">---------------------------------------------------------------------------------------------------------------</div><div class="line"></div><div class="line">Cleaning up</div><div class="line"> Zeroed PMU registers</div></pre></td></tr></table></figure>
<h2 id="Apple-M1"><a href="#Apple-M1" class="headerlink" title="Apple M1"></a>Apple M1</h2><p><img src="/images/951413iMgBlog/image-20220402101632476.png" alt="M1, M1 Pro, and M1 Max chips are shown next to each other." style="zoom:50%;"></p>
<h3 id="The-M1"><a href="#The-M1" class="headerlink" title="The M1"></a><strong>The M1</strong></h3><p>The critically-acclaimed M1 processor delivers:</p>
<ul>
<li>16 billion transistors and a 119mm squared-die size.</li>
<li>4 performance cores, 12MB L2 Cache.</li>
<li>4 efficiency cores ith 4MB L2 cache.</li>
<li>8 GPU Cores.</li>
<li>16GB DDR4x memory at 68GB/s.</li>
</ul>
<h3 id="The-M1-Pro"><a href="#The-M1-Pro" class="headerlink" title="The M1 Pro"></a><strong>The M1 Pro</strong></h3><p>The M1 Pro takes this higher, with:</p>
<ul>
<li>33.7 billion transistors on a 240mm squared die.</li>
<li>8 performance cores, 24MB L2 Cache.</li>
<li>2 efficiency cores with 4MB L2 cache.</li>
<li>16 GPU Cores.</li>
<li>32GB DDR5 memory at 200GB/s.</li>
</ul>
<p>对比下 i9-12000，i9也有GPU只是没有说多少个，它的GPU频率在0.3到1.55GHz之间</p>
<p><img src="/images/951413iMgBlog/400px-alder_lake_die_2.png" alt="alder lake die 2.png"></p>
<table>
<thead>
<tr>
<th>ISA</th>
<th>x86-64 (x86)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Microarchitecture</td>
<td><a href="https://en.wikichip.org/wiki/intel/microarchitectures/alder_lake" target="_blank" rel="external">Alder Lake</a>, <a href="https://en.wikichip.org/wiki/intel/microarchitectures/golden_cove" target="_blank" rel="external">Golden Cove</a>, <a href="https://en.wikichip.org/wiki/intel/microarchitectures/gracemont" target="_blank" rel="external">Gracemont</a></td>
</tr>
<tr>
<td>Process</td>
<td><a href="https://en.wikichip.org/w/index.php?title=Intel_7_process&amp;action=edit&amp;redlink=1" target="_blank" rel="external">Intel 7</a></td>
</tr>
<tr>
<td>Die</td>
<td>215.25 mm²” 20.5 mm × 10.5 mm</td>
</tr>
<tr>
<td>MCP</td>
<td>No (1 dies)</td>
</tr>
<tr>
<td>Cores</td>
<td>16</td>
</tr>
<tr>
<td>Threads</td>
<td>24</td>
</tr>
<tr>
<td><a href="https://en.wikichip.org/wiki/Property:l1$_size" target="_blank" rel="external">l1$ size</a></td>
<td>0.75 MiB (768 KiB, 786,432 B, 7.324219e-4 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l1-24-20size/0.75-20MiB" target="_blank" rel="external">+</a> and 0.625 MiB (640 KiB, 655,360 B, 6.103516e-4 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l1-24-20size/0.625-20MiB" target="_blank" rel="external">+</a></td>
</tr>
<tr>
<td><a href="https://en.wikichip.org/wiki/Property:l1d$_size" target="_blank" rel="external">l1d$ size</a></td>
<td>0.25 MiB (256 KiB, 262,144 B, 2.441406e-4 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l1d-24-20size/0.25-20MiB" target="_blank" rel="external">+</a> and 0.375 MiB (384 KiB, 393,216 B, 3.662109e-4 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l1d-24-20size/0.375-20MiB" target="_blank" rel="external">+</a></td>
</tr>
<tr>
<td><a href="https://en.wikichip.org/wiki/Property:l1i$_size" target="_blank" rel="external">l1i$ size</a></td>
<td>0.5 MiB (512 KiB, 524,288 B, 4.882812e-4 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l1i-24-20size/0.5-20MiB" target="_blank" rel="external">+</a> and 0.25 MiB (256 KiB, 262,144 B, 2.441406e-4 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l1i-24-20size/0.25-20MiB" target="_blank" rel="external">+</a></td>
</tr>
<tr>
<td><a href="https://en.wikichip.org/wiki/Property:l2$_size" target="_blank" rel="external">l2$ size</a></td>
<td>4 MiB (4,096 KiB, 4,194,304 B, 0.00391 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l2-24-20size/4-20MiB" target="_blank" rel="external">+</a> and 10 MiB (10,240 KiB, 10,485,760 B, 0.00977 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l2-24-20size/10-20MiB" target="_blank" rel="external">+</a></td>
</tr>
<tr>
<td><a href="https://en.wikichip.org/wiki/Property:l3$_size" target="_blank" rel="external">l3$ size</a></td>
<td>6 MiB (6,144 KiB, 6,291,456 B, 0.00586 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l3-24-20size/6-20MiB" target="_blank" rel="external">+</a> and 24 MiB (24,576 KiB, 25,165,824 B, 0.0234 GiB) <a href="https://en.wikichip.org/wiki/Special:SearchByProperty/:l3-24-20size/24-20MiB" target="_blank" rel="external">+</a></td>
</tr>
</tbody>
</table>
<h3 id="The-M1-Max"><a href="#The-M1-Max" class="headerlink" title="The M1 Max"></a><strong>The M1 Max</strong></h3><p>The M1 Max provides:</p>
<ul>
<li>57 billion transistors on a 420mm squared die.</li>
<li>8 performance cores, 24MB L2 Cache.</li>
<li>2 efficiency cores with 4MB L2 cache.</li>
<li>32 GPU Cores.</li>
<li>64GB DDR5 memory at 400GB/s.</li>
</ul>
<h3 id="And-the-new-M1-Ultra"><a href="#And-the-new-M1-Ultra" class="headerlink" title="And the new M1 Ultra"></a><strong>And the new M1 Ultra</strong></h3><p>The M1 Ultra brings you:</p>
<ul>
<li>114 billion transistors on a 840mm squared die.</li>
<li>16 performance cores, 48MB L2 Cache.</li>
<li>4 efficiency cores with 4MB L2 cache.</li>
<li>64 GPU Cores.</li>
<li>Up to 128GB DDR5 memory at 800GB/s.</li>
</ul>
<h2 id="倚天710"><a href="#倚天710" class="headerlink" title="倚天710"></a>倚天710</h2><p>一个die有64core，每两个core是一个cluster，一块cpu封装两个die</p>
<p>一个die大小是314平方毫米，600亿晶体管</p>
<p><img src="/images/951413iMgBlog/image-20211205130348832.png" alt="image-20211205130348832"></p>
<p>平头哥的几款芯片：</p>
<p><img src="/images/951413iMgBlog/v2-4a587237e30986b36c5657761c31ae21_r.jpg" alt="preview"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>AMD和Intel在服务器领域CPU设计上走了两个不同的方向，Intel通过RingBus、Mesh等方案在一块Die上集成多个core，成本高，在多核场景下性能好。</p>
<p>AMD则是通过设计小的Die来降低成本，然后将多个Die封装到一块CPU上来售卖，Zen1架构的多个Die之间延迟高，于是Zen2将IO抽离出来用一块单独的IO Die来负责IO，这样多核之间的时延比Zen1好了很多。</p>
<p>而在云计算场景下AMD的设计非常有竞争优势，因为云计算大部分时候是要把一块大的CPU分拆售卖，从架构上AMD对分拆售卖非常友好。</p>
<p>整体来说AMD用领先了一代的工艺（7nm VS 14nm)，在MySQL查询场景中终于可以接近Intel了，但是海光、鲲鹏、飞腾还是不给力。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="/2021/06/01/CPU的制造和概念/">CPU的制造和概念</a></p>
<p><a href="/2021/05/16/CPU Cache Line 和性能/">CPU 性能和Cache Line</a></p>
<p><a href="/2021/05/16/Perf IPC以及CPU利用率/">Perf IPC以及CPU性能</a></p>
<p><a href="/2021/06/18/几款CPU性能对比/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></p>
<p><a href="/2021/05/15/飞腾ARM芯片(FT2500">飞腾ARM芯片(FT2500)的性能测试</a>的性能测试/)</p>
<p><a href="/2021/05/14/十年后数据库还是不敢拥抱NUMA/">十年后数据库还是不敢拥抱NUMA？</a></p>
<p><a href="/2021/03/07/一次海光物理机资源竞争压测的记录/">一次海光物理机资源竞争压测的记录</a></p>
<p><a href="/2019/12/16/Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的/">Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的</a></p>
<p><a href="https://blog.csdn.net/xuanjian_bjtu/article/details/107178226" target="_blank" rel="external">lmbench测试要考虑cache等</a> </p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/07/19/CPU性能和CACHE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/07/19/CPU性能和CACHE/" itemprop="url">CPU性能和CACHE</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-07-19T12:30:03+08:00">
                2021-07-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CPU/" itemprop="url" rel="index">
                    <span itemprop="name">CPU</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="CPU性能和CACHE"><a href="#CPU性能和CACHE" class="headerlink" title="CPU性能和CACHE"></a>CPU性能和CACHE</h1><p>为了让程序能快点，特意了解了CPU的各种原理，比如多核、超线程、NUMA、睿频、功耗、GPU、大小核再到分支预测、cache_line失效、加锁代价、IPC等各种指标（都有对应的代码和测试数据）都会在这系列文章中得到答案。当然一定会有程序员最关心的分支预测案例、Disruptor无锁案例、cache_line伪共享案例等等。</p>
<p>这次让我们从最底层的沙子开始用8篇文章来回答各种疑问以及大量的实验对比案例和测试数据。</p>
<p>大的方面主要是从这几个疑问来写这些文章：</p>
<ul>
<li>同样程序为什么CPU跑到800%还不如CPU跑到200%快？</li>
<li>IPC背后的原理和和程序效率的关系？</li>
<li>为什么数据库领域都爱把NUMA关了，这对吗？</li>
<li>几个国产芯片的性能到底怎么样？</li>
</ul>
<h2 id="系列文章"><a href="#系列文章" class="headerlink" title="系列文章"></a>系列文章</h2><p><a href="/2021/06/01/CPU的制造和概念/">CPU的制造和概念</a></p>
<p><a href="/2021/05/16/Perf IPC以及CPU利用率/">Perf IPC以及CPU性能</a></p>
<p><a href="/2021/05/16/CPU Cache Line 和性能/">CPU 性能和Cache Line</a></p>
<p><a href="/2021/05/14/十年后数据库还是不敢拥抱NUMA/">十年后数据库还是不敢拥抱NUMA？</a></p>
<p><a href="/2019/12/16/Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的/">Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的</a></p>
<p><a href="/2021/06/18/几款CPU性能对比/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></p>
<p><a href="/2021/03/07/一次海光物理机资源竞争压测的记录/">一次海光物理机资源竞争压测的记录</a></p>
<p><a href="/2021/05/15/飞腾ARM芯片-FT2500的性能测试/">飞腾ARM芯片(FT2500)的性能测试</a></p>
<p><img src="/images/951413iMgBlog/image-20210802161558248.png" alt="image-20210802161558248"></p>
<h2 id="CPU中为什么要L1-L2等各级cache"><a href="#CPU中为什么要L1-L2等各级cache" class="headerlink" title="CPU中为什么要L1/L2等各级cache"></a>CPU中为什么要L1/L2等各级cache</h2><p>因为CPU的速度和访问内存速度差异太大，导致CPU在计算的时候90%以上的时间花在等待从内存中取数据、写数据而此时CPU处于闲置状态，也就导致了所谓的 <strong>内存墙</strong></p>
<p>cpu的速度大概50-60%每年的增长率，内存只有7%每年增长率：</p>
<p><img src="/images/951413iMgBlog/476909_1_En_15_Fig3_HTML.png" alt="A 1000× Improvement of the Processor-Memory Gap | SpringerLink"></p>
<p>CPU访问内存慢的案例参考：<a href="http://igoro.com/archive/gallery-of-processor-cache-effects/" target="_blank" rel="external">Gallery of Processor Cache Effects</a></p>
<p>在数据使用前加载到CPU内更快的缓存中，最快的一级缓存等待时间是1~3个时钟周期。限制在于对于不在缓存中的数据，还是要等待数十上百个周期——按50周期算的话，不考虑并发和指令执行时间，缓存命中率达到98%，才能发挥一半的理论性能。然而实际情况中，大部分应用都无法达到这个命中率。</p>
<p><img src="/images/951413iMgBlog/image-20211110174606037.png" alt="image-20211110174606037"></p>
<h2 id="CPU中的cache变迁历史"><a href="#CPU中的cache变迁历史" class="headerlink" title="CPU中的cache变迁历史"></a>CPU中的cache变迁历史</h2><p>80486(1989), 8K的L1 cache第一次被集成在CPU中:</p>
<p><img src="/images/951413iMgBlog/42gg2.png" alt="486 motherboard with CPU location and 2nd level cache marked"></p>
<p><strong>80686</strong>(1995) ，<a href="https://superuser.com/questions/196143/where-exactly-l1-l2-and-l3-caches-located-in-computer" target="_blank" rel="external">L2被放入到CPU的Package</a>上，但是是一个独立的Die，可以看到L2大小和一个Die差不多:</p>
<p><img src="/images/951413iMgBlog/eAvLK.png" alt="Picture of a pentium Pro CPU, 256KB cache model"></p>
<p>以酷睿为例，现在的CPU集成了L1/L2/L3等各级CACHE，<strong>CACHE面积能占到CPU的一半</strong>:</p>
<p><img src="/images/951413iMgBlog/4Z1nU.png" alt="modernCPUwithL3.png"></p>
<p>从上图可以看到L3的大小快到die的一半，L1/L2由每个core独享，L3是所有core共享，3级CACHE总面积跟所有core差不多大了。</p>
<p><img src="/images/951413iMgBlog/image-20211110174810752.png" alt="image-20211110174810752"></p>
<p>下图是目前一个主流的Die中CACHE的构成：</p>
<p><img src="/images/951413iMgBlog/cache.architecture.png" alt="img"></p>
<p>cache对速度的影响：</p>
<ul>
<li>一个方面是物理速度，如果要更大的容量就需要更多的晶体管，除了芯片的体积会变大，更重要的是大量的晶体管会导致速度下降，因为访问速度和要访问的晶体管所在的位置成反比，也就是当信号路径变长时，通信速度会变慢。这部分是物理问题。</li>
<li>另外一个问题是，多核技术中，数据的状态需要在多个CPU中进行同步，并且，我们可以看到，cache和RAM的速度差距太大，所以，多级不同尺寸的缓存有利于提高整体的性能。</li>
</ul>
<h2 id="不同型号CPU的cache、内存时延"><a href="#不同型号CPU的cache、内存时延" class="headerlink" title="不同型号CPU的cache、内存时延"></a>不同型号CPU的cache、内存时延</h2><p>测试命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">numactl --membind=0 --cpunodebind=0 ./bin/lat_mem_rd 2000 64 //从结果看L3/memory latency不符合常识</div></pre></td></tr></table></figure>
<p><img src="/images/951413iMgBlog/image-20220304104859770.png" alt="image-20220304104859770"></p>
<p>调整测试参数，增加 -t 参数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">numactl -C 0 -m 0 ./bin/lat_mem_rd -W 5 -N 5 -t 2000M</div></pre></td></tr></table></figure>
<blockquote>
<p>内存基准测试命令 lat_mem_rd 的 -t 参数指定测试集以制造 TLB miss, Cache miss的压力场景，以测试 TLB miss,Cache miss对内存访问延迟的影响</p>
</blockquote>
<p><img src="/images/951413iMgBlog/image-20220304152056740.png" alt="image-20220304152056740"></p>
<p>从上图可以看到的一些测试结论</p>
<ul>
<li>添加 -t 后(第二组测试)，L2和L3的延时比较正常了</li>
<li>倒数第三图hygon 7280 2node VS 8node(橙色) , 可以看到8node 内存延时降低了25%</li>
<li>飞腾没开numa内存延时抖动非常大（倒数图二，灰色线），基本不可用，整体延时也比其它CPU高很多</li>
<li>hygon L3大小比较特殊，一个socket下多个Die之间没有共享</li>
<li>intel E5时延表现很优秀，intel E5 CPU开启numa后内存延时有30%以上的减少（图三）</li>
<li>鲲鹏数据比较中规中矩，接近intel</li>
<li>stride参数、-t参数对整体数据影响比较大，x86、arm不同参数下也不一样</li>
</ul>
<p>E5机器内存速度为2133 MT/S, 8163和8269则是2666 MT/S, 所以说E5的时延表现很优秀</p>
<h2 id="cache对CPU性能的影响"><a href="#cache对CPU性能的影响" class="headerlink" title="cache对CPU性能的影响"></a>cache对CPU性能的影响</h2><p>CPU访问内存是非常慢的，所以我们在CPU中增加了多级缓存来<strong>匹配</strong>CPU和内存的速度。主频这20年基本都没怎么做高了，但是工艺提升了两个数量级，也就是集成的晶体管数量提升了2个数量级，工艺提升的能力主要给了cache，从而整体CPU性能提升了很多。</p>
<h3 id="缓存对Oceanbase-，MySQL-ODPS的性能影响"><a href="#缓存对Oceanbase-，MySQL-ODPS的性能影响" class="headerlink" title="缓存对Oceanbase ，MySQL, ODPS的性能影响"></a>缓存对Oceanbase ，MySQL, ODPS的性能影响</h3><p>以下测试数据主要来源于真实的业务场景：OB/MySQL/ODPS</p>
<p><img src="/images/951413iMgBlog/bb29ac99-3645-4482-8473-c55b190af777.png" alt="img"></p>
<p>x86 Skylake之前，L1 I/D 32KB, L2 256KB, L3 2.5MB/core， 2.5MB/core的L3（LLC）芯片面积相当于1/2 CPU core 的尺寸</p>
<ol>
<li>关闭L3（2.5MB），关闭L2（256KB），此时性能CPI（越小越好）是4.25</li>
<li>关闭L3，打开L2（256KB），此时性能CPI为2.23</li>
<li>关闭L3，打开L2同时增加256KB，L2尺寸到512KB，性能CPI为1.38</li>
<li>打开L3（2.5MB），打开L2（256KB），性能为1.28 ，该状态就是intel CPU出厂的状态</li>
<li>打开L3，增加到16MB，打开L2（256KB），性能为1.25 </li>
</ol>
<p>上面的数据显示当L3关闭之后，从case 3 开始，L2仅仅增加256KB，L2芯片面积相对于CPU core 增加 5%(0.5 /2.5M <em> 025M)，性能相对于case 2 提升1.61倍（2.23/1.38），而使用case 4 ,L3 2.5MB打开，相对于case 3，增加2.3MB（2.5MB - 256KB）,芯片面积相对于CPU core 增加 46%（0.5/2.5M </em> 2.3M）， 而性能仅仅提升 1.07倍（1.38/1.28），所以14年给Intel提议需要增加L2尺寸降低L3尺寸，这些数据促使Intel开始重新考虑对于数据中心缓存新的设计。</p>
<p>2014年的 Broadwell 的第五代智能酷睿处理器，是 Haswell 的 14nm 升级版（$1745.00 - $1749.00）：</p>
<p><img src="/images/951413iMgBlog/image-20210719102039296.png" alt="image-20210719102039296"></p>
<p>E5一个Die有16个物理core（上面截图是两个Socket, 每个Socket一个Die，每个物理core两个超线程），所以每core的L3大小：40M/16=2.5M/core</p>
<p>2015年则推出 SkyLake 架构的Platinum 8269CY（$4702.00）, 每core的L3大小：36M/26=1.38M/core：</p>
<p><img src="/images/951413iMgBlog/image-20210719102112331.png" alt="image-20210719102112331"></p>
<p>Intel 2015年 发表论文<a href="https://people.csail.mit.edu/emer/papers/2015.02.hpca.cache_hierarchy.pdf" target="_blank" rel="external">《High Performing Cache Hierarchies for Server Workloads》</a>证明了阿里提出的建议的正确性，从Skylake架构开始将L2 cache 由 256KB 升级到 1MB， L3由2.5MB /core 压缩到 1.375MB / core， Intel之所以没有完全去掉L3的原因是希望这样设计的CPU对于 使用 CPU2006的workload性能仍然能够做到不受影响。</p>
<p><img src="/images/951413iMgBlog/image-20210716102624566.png" alt="image-20210716102624566"></p>
<p>上图是不同业务场景下，CPI 随cache大小的变化，可以看到随着cache增加性能基本不增加了。</p>
<h3 id="CPU-L2-Last-Level-Cache-LLC-缓存的演变"><a href="#CPU-L2-Last-Level-Cache-LLC-缓存的演变" class="headerlink" title="CPU L2, Last Level Cache (LLC) 缓存的演变"></a>CPU L2, Last Level Cache (LLC) 缓存的演变</h3><p>Last Level Cache(L3) 在2016年之前都是2MB/core 或者 2.5MB/core, 这个原因取决于在此之前行业都是使用CPU2006作为设计CPU的benchmark，如下图所示：</p>
<p><img src="/images/951413iMgBlog/141f4ccd-37ce-41e5-b404-101e6b9acf5d.png" alt="img"></p>
<p>根据上图中CPU2006的MPKI数据显示如果LLC在4MB的时候非常好，LLC在2.5MB之后MKPI提升10%性能只有1～3%的提升，2.5MB LLC cache是 CPU core 1/2 的芯片面积，因此若将LLC 由2.5MB升级到4MB，换算成CPU core的芯片面积是增长30%（1/2 * 1.5M/2.5M），但性能仅仅提升最多3%，这就是为什么基于CPU2006的benchmark条件下，intel将LLC设定为2~2.5MB的原因。</p>
<h2 id="Cache的缺点"><a href="#Cache的缺点" class="headerlink" title="Cache的缺点"></a>Cache的缺点</h2><p>缓存有两大缺点：</p>
<ul>
<li>当数据集非常大的时候，时间空间局部性较低时缓存的工作效率很低；</li>
<li>当缓存工作效率高的时候，局部性非常高，这意味着，根据定义，大多数缓存在大多数时间都处于空闲状态。</li>
</ul>
<h2 id="Hardware-Memory-Models-顺序一致性"><a href="#Hardware-Memory-Models-顺序一致性" class="headerlink" title="Hardware Memory Models 顺序一致性"></a><a href="https://colobu.com/2021/06/30/hwmm/" target="_blank" rel="external">Hardware Memory Models 顺序一致性</a></h2><blockquote>
<p>对存储在内存中数据更改的可见性和一致性，所以这个契约被称为内存一致性模型（<code>memory consistency model</code>）或仅仅是内存模型(<code>memory model</code>)</p>
</blockquote>
<p>r1/r2是线程本地变量，如下代码的可能结果是哪些？</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">Litmus Test: Message Passing</div><div class="line">Can this program see r1 = 1, r2 = 0?</div><div class="line"></div><div class="line">// Thread 1           // Thread 2</div><div class="line">x = 1                 r1 = y</div><div class="line">y = 1                 r2 = x</div></pre></td></tr></table></figure>
<p>如果该<code>litmus test</code>的执行顺序一致，则只有六种可能的交替:</p>
<p><a href="https://colobu.com/2021/06/30/hwmm/mem-litmus.png" target="_blank" rel="external"><img src="/images/951413iMgBlog/mem-litmus.png" alt="img"></a></p>
<p>因为没有交替执行的结果会产生<code>r1 = 1, r2 = 0</code>,所以这个结果是不允许的。也就是说，在顺序执行的硬件上，litmus test执行结果出现<code>r1 = 1, r2 = 0</code>是不可能的。</p>
<p>顺序一致性的一个很好的思维模型是想象所有处理器直接连接到同一个共享内存，它可以一次处理一个线程的读或写请求。 不涉及缓存，因此每次处理器需要读取或写入内存时，该请求都会转到共享内存。 一次使用一次的共享内存对所有内存访问的执行施加了顺序顺序：顺序一致性。</p>
<p><a href="https://colobu.com/2021/06/30/hwmm/mem-sc.png" target="_blank" rel="external"><img src="/images/951413iMgBlog/mem-sc.png" alt="img"></a></p>
<h3 id="x86-Total-Store-Order-x86-TSO-总存储有序"><a href="#x86-Total-Store-Order-x86-TSO-总存储有序" class="headerlink" title="x86 Total Store Order (x86-TSO) 总存储有序"></a><a href="https://research.swtch.com/hwmm#x86" target="_blank" rel="external">x86 Total Store Order (x86-TSO) 总存储有序</a></h3><p>所有处理器仍然连接到一个共享内存，但是每个处理器都将对该内存的写入(<code>write</code>)放入到本地写入队列中。处理器继续执行新指令，同时写操作(<code>write</code>)会更新到这个共享内存。一个处理器上的内存读取在查询主内存之前会查询本地写队列，但它看不到其他处理器上的写队列。其效果就是当前处理器比其他处理器会先看到自己的写操作。但是——这一点非常重要——==所有处理器都保证写入(存储<code>store</code>)到共享内存的(总)顺序，所以给这个模型起了个名字:总存储有序，或<code>TSO</code>==。当一个写操作到达共享内存时，任何处理器上的任何未来读操作都将看到它并使用该值(直到它被以后的写操作覆盖，或者可能被另一个处理器的缓冲写操作覆盖)。</p>
<p><img src="/images/951413iMgBlog/mem-tso.png" alt="img"></p>
<p>针对前文的litmus test案例，写队列保证线程1在y之前将x写入内存，关于内存写入顺序(总存储有序)的系统级协议保证线程2在读y的新值之前读x的新值。因此，<code>r1 = y</code>在<code>r2 = x</code>看不到新的x之前不可能看到新的y。存储顺序至关重要:线程1在写入y之前先写入x，因此线程2在看到x的写入之前不可能看到y的写入。</p>
<p>但是对于TSO系统下，以下case能看到r1 = 0, r2 = 0, 如果在顺序一致性的协议下这是不可能发生的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">Litmus Test: Write Queue (also called Store Buffer)</div><div class="line">Can this program see r1 = 0, r2 = 0?</div><div class="line"></div><div class="line">// Thread 1           // Thread 2</div><div class="line">x = 1                 y = 1</div><div class="line">r1 = y                r2 = x</div><div class="line">On sequentially consistent hardware: no.</div><div class="line">On x86 (or other TSO): yes!</div></pre></td></tr></table></figure>
<p>为了让TSO和顺序一致性协议保持一致，我们需要依赖于更强的内存排序，非顺序一致的硬件提供了称为内存屏障(或栅栏)的显式指令，可用于控制排序。我们可以添加一个内存屏障，以确保每个线程在开始读取之前都会刷新其先前对内存的写入:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">// Thread 1           // Thread 2</div><div class="line">x = 1                 y = 1</div><div class="line">barrier               barrier</div><div class="line">r1 = y                r2 = x</div></pre></td></tr></table></figure>
<p>加上正确的障碍，<code>r1 = 0，r2 = 0</code>也是不可能的了。内存屏障有很多种，它的存在给了程序员或语言实现者一种在程序的关键时刻强制顺序一致行为的方法。</p>
<h3 id="ARM-POWER-Relaxed-Memory-Model"><a href="#ARM-POWER-Relaxed-Memory-Model" class="headerlink" title="ARM/POWER Relaxed Memory Model"></a><a href="https://research.swtch.com/hwmm#relaxed" target="_blank" rel="external">ARM/POWER Relaxed Memory Model</a></h3><p>ARM和POWER系统的概念模型是，每个处理器从其自己的完整内存副本中读取和向其写入，每个写入独立地传播到其他处理器，随着写入的传播，允许重新排序。</p>
<p><img src="/images/951413iMgBlog/mem-weak.png" alt="img"></p>
<p>这里没有总存储顺序。虽然没有描述，但是每个处理器都被允许推迟读取(<code>read</code>)，直到它等到它需要结果:读取(<code>read</code>)可以被延迟到稍后的写入(<code>write</code>)之后。在这个宽松的(<code>relaxed</code>)模型中，我们迄今为止所看到的每一个litmus test的答案都是“yes，这真的可能发生。”</p>
<p>在这个内存模型下，对于前文中的 Litmus Test: Message Passing case是可以看到r1=1,r2=0的（TSO保证不会），但是可以保证 Litmus Test: Store Buffering case 和TSO一致。</p>
<p>最后再附加几个Latency数据，让大家比较起来更有体感一些</p>
<h2 id="各级IO延迟数字"><a href="#各级IO延迟数字" class="headerlink" title="各级IO延迟数字"></a>各级IO延迟数字</h2><h3 id="Cache、内存、磁盘、网络的延迟比较"><a href="#Cache、内存、磁盘、网络的延迟比较" class="headerlink" title="Cache、内存、磁盘、网络的延迟比较"></a>Cache、内存、磁盘、网络的延迟比较</h3><p><a href="http://cizixs.com/2017/01/03/how-slow-is-disk-and-network" target="_blank" rel="external">假设主频2.6G的CPU，每个指令只需要 0.38ns</a> </p>
<p>每次内存寻址需要 100ns </p>
<p>一次 CPU 上下文切换（系统调用）需要大约 1500ns，也就是 1.5us（这个数字参考了<a href="http://blog.tsunanet.net/2010/11/how-long-does-it-take-to-make-context.html" target="_blank" rel="external">这篇文章</a>，采用的是单核 CPU 线程平均时间）</p>
<p>SSD 随机读取耗时为 150us</p>
<p>从内存中读取 1MB 的连续数据，耗时大约为 250us</p>
<p>同一个数据中心网络上跑一个来回需要 0.5ms</p>
<p>从 SSD 读取 1MB 的顺序数据，大约需要 1ms （是内存速度的四分之一）</p>
<p>磁盘寻址时间为 10ms</p>
<p>从磁盘读取 1MB 连续数据需要 20ms</p>
<p>如果 CPU 访问 L1 缓存需要 1 秒，那么访问主存需要 3 分钟、从 SSD 中随机读取数据需要 3.4 天、磁盘寻道需要 2 个月，网络传输可能需要 1 年多的时间。</p>
<h2 id="内存和cache的latency对比"><a href="#内存和cache的latency对比" class="headerlink" title="内存和cache的latency对比"></a>内存和cache的latency对比</h2><p><img src="/images/951413iMgBlog/latency.png" alt="latency"></p>
<p><a href="http://www.webstersystems.co.uk/threads.htm" target="_blank" rel="external">各级cache的Latency</a>：</p>
<p><img src="/images/951413iMgBlog/cycle_times.jpg" alt="Cycle times"></p>
<p><strong>2012 年延迟数字对比表：</strong></p>
<table>
<thead>
<tr>
<th>Work</th>
<th>Latency</th>
</tr>
</thead>
<tbody>
<tr>
<td>L1 cache reference</td>
<td>0.5 ns</td>
</tr>
<tr>
<td>Branch mispredict</td>
<td>5 ns</td>
</tr>
<tr>
<td>L2 cache reference</td>
<td>7 ns</td>
</tr>
<tr>
<td>Mutex lock/unlock</td>
<td>25 ns</td>
</tr>
<tr>
<td>Main memory reference</td>
<td>100 ns</td>
</tr>
<tr>
<td>Compress 1K bytes with Zippy</td>
<td>3,000 ns</td>
</tr>
<tr>
<td>Send 1K bytes over 1 Gbps network</td>
<td>10,000 ns</td>
</tr>
<tr>
<td>Read 4K randomly from SSD*</td>
<td>150,000 ns</td>
</tr>
<tr>
<td>Read 1 MB sequentially from memory</td>
<td>250,000 ns</td>
</tr>
<tr>
<td>Round trip within same datacenter</td>
<td>500,000 ns</td>
</tr>
<tr>
<td>Read 1 MB sequentially from SSD*</td>
<td>1,000,000 ns</td>
</tr>
<tr>
<td>Disk seek</td>
<td>10,000,000 ns</td>
</tr>
<tr>
<td>Read 1 MB sequentially from disk</td>
<td>20,000,000 ns</td>
</tr>
<tr>
<td>Send packet CA-&gt;Netherlands-&gt;CA</td>
<td>150,000,000 ns</td>
</tr>
</tbody>
</table>
<p>一个比较有体感的比较：如果 CPU 访问 寄存器需要 1 秒，那么访问主存需要 3 分钟、从 SSD 中随机读取数据需要 3.4 天、磁盘寻道需要 2 个月，网络传输可能需要 1 年多的时间。</p>
<p><img src="/images/951413iMgBlog/1460000039103606.png" alt="img"></p>
<p>当然更古老一点的年代给出来的数据可能又不一样一点，但是基本比例差异还是差不多的：</p>
<p><img src="/images/951413iMgBlog/cache-hierarchy-1.jpg" alt="Memory Hierarchy"></p>
<p>测试Inte E5 L1 、L2、L3的cache延时图来加深印象，可以看到在每级cache大小附近时延有个跳跃(纵坐标是纳秒，横坐标是大小 M)：</p>
<p><img src="/images/951413iMgBlog/image-20220321172431647.png" alt="image-20220321172431647"></p>
<p><a href="https://colin-scott.github.io/personal_website/research/interactive_latency.html" target="_blank" rel="external">推荐从这里看延时，拖动时间轴可以看到随着技术、工艺的改变Latency每一年的变化</a></p>
<p><img src="/images/951413iMgBlog/image-20210613123006681.png" alt="image-20210613123006681"></p>
<p>查看cpu cache数据</p>
<pre><code>cat /proc/cpuinfo |grep -i cache
</code></pre><p><img src="/images/951413iMgBlog/ad19b92ccc97763aa7f78d8d1d514c84.jpg" alt="image.png" style="zoom:50%;"></p>
<h3 id="L1C、L2C、L3C、DDR-的Latency测试数据"><a href="#L1C、L2C、L3C、DDR-的Latency测试数据" class="headerlink" title="L1C、L2C、L3C、DDR 的Latency测试数据"></a>L1C、L2C、L3C、DDR 的Latency测试数据</h3><p><a href="https://topic.atatech.org/articles/100065" target="_blank" rel="external">下图从左至右响应时间分别是L1C、L2C、L3C、DDR</a>，可以看出这四个Latency变化还是非常明显的，泾渭分明。</p>
<p><img src="/images/951413iMgBlog/58286da947132f269cb26ff3eda25c68.png" alt="img"></p>
<p><img src="/images/951413iMgBlog/image-20210511160107225.png" alt="image-20210511160107225"></p>
<p><img src="/images/951413iMgBlog/f5728a2afb29c653a3e1bf21f4d56056.png" alt="image.png"></p>
<h2 id="测试memory-latency"><a href="#测试memory-latency" class="headerlink" title="测试memory latency"></a>测试memory latency</h2><p><a href="https://mp.weixin.qq.com/s/QNgMS0gOXhZml8l_towAbw" target="_blank" rel="external">memory latency逻辑</a>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div></pre></td><td class="code"><pre><div class="line">#include &lt;sys/types.h&gt;</div><div class="line">#include &lt;stdlib.h&gt;</div><div class="line">#include &lt;stdio.h&gt;</div><div class="line">#include &lt;sys/mman.h&gt;</div><div class="line">#include &lt;sys/time.h&gt;</div><div class="line">#include &lt;unistd.h&gt;</div><div class="line"></div><div class="line">#define ONE p = (char **)*p;</div><div class="line">#define FIVE    ONE ONE ONE ONE ONE</div><div class="line">#define TEN FIVE FIVE</div><div class="line">#define FIFTY   TEN TEN TEN TEN TEN</div><div class="line">#define HUNDRED FIFTY FIFTY</div><div class="line"></div><div class="line">static void usage()</div><div class="line">&#123;</div><div class="line">    printf(&quot;Usage: ./mem-lat -b xxx -n xxx -s xxx\n&quot;);</div><div class="line">    printf(&quot;   -b buffer size in KB\n&quot;);</div><div class="line">    printf(&quot;   -n number of read\n\n&quot;);</div><div class="line">    printf(&quot;   -s stride skipped before the next access\n\n&quot;);</div><div class="line">    printf(&quot;Please don&apos;t use non-decimal based number\n&quot;);</div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line">int main(int argc, char* argv[])</div><div class="line">&#123;</div><div class="line">  unsigned long i, j, size, tmp;</div><div class="line">    unsigned long memsize = 0x800000; /* 1/4 LLC size of skylake, 1/5 of broadwell */</div><div class="line">    unsigned long count = 1048576; /* memsize / 64 * 8 */</div><div class="line">    unsigned int stride = 64; /* skipped amount of memory before the next access */</div><div class="line">    unsigned long sec, usec;</div><div class="line">    struct timeval tv1, tv2;</div><div class="line">    struct timezone tz;</div><div class="line">    unsigned int *indices;</div><div class="line"></div><div class="line">    while (argc-- &gt; 0) &#123;</div><div class="line">        if ((*argv)[0] == &apos;-&apos;) &#123;  /* look at first char of next */</div><div class="line">            switch ((*argv)[1]) &#123;   /* look at second */</div><div class="line">                case &apos;b&apos;:</div><div class="line">                    argv++;</div><div class="line">                    argc--;</div><div class="line">                    memsize = atoi(*argv) * 1024;</div><div class="line">                    break;</div><div class="line"></div><div class="line">                case &apos;n&apos;:</div><div class="line">                    argv++;</div><div class="line">                    argc--;</div><div class="line">                    count = atoi(*argv);</div><div class="line">                    break;</div><div class="line"></div><div class="line">                case &apos;s&apos;:</div><div class="line">                    argv++;</div><div class="line">                    argc--;</div><div class="line">                    stride = atoi(*argv);</div><div class="line">                    break;</div><div class="line"></div><div class="line">                default:</div><div class="line">                    usage();</div><div class="line">                    exit(1);</div><div class="line">                    break;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        argv++;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">  char* mem = mmap(NULL, memsize, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANON, -1, 0);</div><div class="line">    // trick3: init pointer chasing, per stride=8 byte</div><div class="line">    size = memsize / stride;</div><div class="line">    indices = malloc(size * sizeof(int));</div><div class="line"></div><div class="line">    for (i = 0; i &lt; size; i++)</div><div class="line">        indices[i] = i;</div><div class="line"></div><div class="line">    // trick 2: fill mem with pointer references</div><div class="line">    for (i = 0; i &lt; size - 1; i++)</div><div class="line">        *(char **)&amp;mem[indices[i]*stride]= (char*)&amp;mem[indices[i+1]*stride];</div><div class="line">    *(char **)&amp;mem[indices[size-1]*stride]= (char*)&amp;mem[indices[0]*stride];</div><div class="line"></div><div class="line">    register char **p = (char **) mem;</div><div class="line">    //char **p = (char **) mem;</div><div class="line">    tmp = count / 100;</div><div class="line"></div><div class="line">    gettimeofday (&amp;tv1, &amp;tz);</div><div class="line">    for (i = 0; i &lt; tmp; ++i) &#123;</div><div class="line">        HUNDRED;  //trick 1</div><div class="line">    &#125;</div><div class="line">    gettimeofday (&amp;tv2, &amp;tz);</div><div class="line">    char **touch = p;</div><div class="line">    if (tv2.tv_usec &lt; tv1.tv_usec) &#123;</div><div class="line">        usec = 1000000 + tv2.tv_usec - tv1.tv_usec;</div><div class="line">        sec = tv2.tv_sec - tv1.tv_sec - 1;</div><div class="line">    &#125; else &#123;</div><div class="line">        usec = tv2.tv_usec - tv1.tv_usec;</div><div class="line">        sec = tv2.tv_sec - tv1.tv_sec;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    printf(&quot;Buffer size: %ld KB, stride %d, time %d.%06d s, latency %.2f ns\n&quot;,</div><div class="line">            memsize/1024, stride, sec, usec, (sec * 1000000  + usec) * 1000.0 / (tmp *100));</div><div class="line">    munmap(mem, memsize);</div><div class="line">    free(indices);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>分别在intel 8163和arm 鲲鹏920上执行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div></pre></td><td class="code"><pre><div class="line">$cat run_mem_lat.sh</div><div class="line">#!/bin/sh</div><div class="line">#set -x</div><div class="line"></div><div class="line">work=./mem-lat</div><div class="line">buffer_size=1</div><div class="line">node=$1</div><div class="line">mem=$2</div><div class="line"></div><div class="line">for i in `seq 1 15`; do</div><div class="line">    #echo $i</div><div class="line">        #echo $buffer_size</div><div class="line">    taskset -ac 1 $work -b $buffer_size -s 64</div><div class="line">    buffer_size=$(($buffer_size*2))</div><div class="line">done</div><div class="line"></div><div class="line">#sh run_mem_lat.sh</div><div class="line">Buffer size: 1 KB, stride 64, time 0.001682 s, latency 1.60 ns</div><div class="line">Buffer size: 2 KB, stride 64, time 0.001685 s, latency 1.61 ns</div><div class="line">Buffer size: 4 KB, stride 64, time 0.001687 s, latency 1.61 ns</div><div class="line">Buffer size: 8 KB, stride 64, time 0.001682 s, latency 1.60 ns</div><div class="line">Buffer size: 16 KB, stride 64, time 0.001688 s, latency 1.61 ns</div><div class="line">Buffer size: 32 KB, stride 64, time 0.001817 s, latency 1.73 ns</div><div class="line">Buffer size: 64 KB, stride 64, time 0.005842 s, latency 5.57 ns</div><div class="line">Buffer size: 128 KB, stride 64, time 0.005838 s, latency 5.57 ns</div><div class="line">Buffer size: 256 KB, stride 64, time 0.005838 s, latency 5.57 ns</div><div class="line">Buffer size: 512 KB, stride 64, time 0.005841 s, latency 5.57 ns</div><div class="line">Buffer size: 1024 KB, stride 64, time 0.006056 s, latency 5.78 ns</div><div class="line">Buffer size: 2048 KB, stride 64, time 0.006175 s, latency 5.89 ns</div><div class="line">Buffer size: 4096 KB, stride 64, time 0.006203 s, latency 5.92 ns</div><div class="line">Buffer size: 8192 KB, stride 64, time 0.006383 s, latency 6.09 ns</div><div class="line">Buffer size: 16384 KB, stride 64, time 0.007345 s, latency 7.01 ns</div><div class="line"></div><div class="line">[root@x86.170 /root]</div><div class="line">#lscpu</div><div class="line">Architecture:          x86_64</div><div class="line">CPU op-mode(s):        32-bit, 64-bit</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                96</div><div class="line">On-line CPU(s) list:   0-95</div><div class="line">Thread(s) per core:    2</div><div class="line">Core(s) per socket:    24</div><div class="line">Socket(s):             2</div><div class="line">NUMA node(s):          1</div><div class="line">Vendor ID:             GenuineIntel</div><div class="line">CPU family:            6</div><div class="line">Model:                 85</div><div class="line">Model name:            Intel(R) Xeon(R) Platinum 8163 CPU @ 2.50GHz</div><div class="line">Stepping:              4</div><div class="line">CPU MHz:               2500.390</div><div class="line">CPU max MHz:           3100.0000</div><div class="line">CPU min MHz:           1000.0000</div><div class="line">BogoMIPS:              4998.87</div><div class="line">Virtualization:        VT-x</div><div class="line">L1d cache:             32K</div><div class="line">L1i cache:             32K</div><div class="line">L2 cache:              1024K</div><div class="line">L3 cache:              33792K</div><div class="line">NUMA node0 CPU(s):     0-95</div><div class="line"></div><div class="line">//鲲鹏920</div><div class="line">#sh run_mem_lat.sh</div><div class="line">Buffer size: 1 KB, stride 64, time 0.001628 s, latency 1.55 ns</div><div class="line">Buffer size: 2 KB, stride 64, time 0.001623 s, latency 1.55 ns</div><div class="line">Buffer size: 4 KB, stride 64, time 0.001613 s, latency 1.54 ns</div><div class="line">Buffer size: 8 KB, stride 64, time 0.001613 s, latency 1.54 ns</div><div class="line">Buffer size: 16 KB, stride 64, time 0.001622 s, latency 1.55 ns</div><div class="line">Buffer size: 32 KB, stride 64, time 0.001613 s, latency 1.54 ns</div><div class="line">Buffer size: 64 KB, stride 64, time 0.001637 s, latency 1.56 ns</div><div class="line">Buffer size: 128 KB, stride 64, time 0.003749 s, latency 3.58 ns</div><div class="line">Buffer size: 256 KB, stride 64, time 0.003320 s, latency 3.17 ns</div><div class="line">Buffer size: 512 KB, stride 64, time 0.003779 s, latency 3.60 ns</div><div class="line">Buffer size: 1024 KB, stride 64, time 0.004310 s, latency 4.11 ns</div><div class="line">Buffer size: 2048 KB, stride 64, time 0.004655 s, latency 4.44 ns</div><div class="line">Buffer size: 4096 KB, stride 64, time 0.005032 s, latency 4.80 ns</div><div class="line">Buffer size: 8192 KB, stride 64, time 0.005721 s, latency 5.46 ns</div><div class="line">Buffer size: 16384 KB, stride 64, time 0.006470 s, latency 6.17 ns</div><div class="line"></div><div class="line">[root@ARM 15:58 /root]</div><div class="line">#lscpu</div><div class="line">Architecture:          aarch64</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                96</div><div class="line">On-line CPU(s) list:   0-95</div><div class="line">Thread(s) per core:    1</div><div class="line">Core(s) per socket:    48</div><div class="line">Socket(s):             2</div><div class="line">NUMA node(s):          4</div><div class="line">Model:                 0</div><div class="line">CPU max MHz:           2600.0000</div><div class="line">CPU min MHz:           200.0000</div><div class="line">BogoMIPS:              200.00</div><div class="line">L1d cache:             64K</div><div class="line">L1i cache:             64K</div><div class="line">L2 cache:              512K</div><div class="line">L3 cache:              24576K</div><div class="line">NUMA node0 CPU(s):     0-23</div><div class="line">NUMA node1 CPU(s):     24-47</div><div class="line">NUMA node2 CPU(s):     48-71</div><div class="line">NUMA node3 CPU(s):     72-95</div></pre></td></tr></table></figure>
<h2 id="为什么CACHE比内存快？"><a href="#为什么CACHE比内存快？" class="headerlink" title="为什么CACHE比内存快？"></a>为什么CACHE比内存快？</h2><p>首先肯定是距离的原因，另外这两种存储结构的制造工艺不同导致的速度差异也很大，从上面可以看到一块4000刀的CPU有一半的面积是cache，也就是40M CACHE花了2000刀，如果用来买内存条能卖一大堆吧。</p>
<p>接下来说下CACHE（SRAM) 和内存（DRAM）制造的工艺差异</p>
<h3 id="SRAM（Static-Random-Access-Memory，静态随机存取存储器）的芯片"><a href="#SRAM（Static-Random-Access-Memory，静态随机存取存储器）的芯片" class="headerlink" title="SRAM（Static Random-Access Memory，静态随机存取存储器）的芯片"></a>SRAM（Static Random-Access Memory，静态随机存取存储器）的芯片</h3><p>CPU Cache 用的是一种叫作 SRAM（Static Random-Access Memory，静态随机存取存储器）的芯片。</p>
<p>SRAM 之所以被称为”静态”存储器，是因为只要处在通电状态，里面的数据就可以保持存在。而一旦断电，里面的数据就会丢失了。在 SRAM 里面，一个比特的数据，需要 6～8 个晶体管。所以 SRAM 的存储密度不高。同样的物理空间下，能够存储的数据有限。不过，因为 SRAM 的电路简单，所以访问速度非常快。</p>
<p>L1和L2一般是SRAM， L1的容量通常比L2小，容量大的SRAM访问时间就越长，同样制程和设计的情况下，<strong>访问延时与容量的开方大致是成正比</strong>的。</p>
<p>另外工作原理不同速度差异也不一样，L1就是讲究快，比如L1是N路组相联，N路阻相联的意思就是N个Cache单元同时读取数据（有点类似RAID0）。</p>
<p>L3用的还是SRAM，但是在考虑换成STT-MRAM，这样容量更大。</p>
<h3 id="DRAM（Dynamic-Random-Access-Memory，动态随机存取存储器）的芯片"><a href="#DRAM（Dynamic-Random-Access-Memory，动态随机存取存储器）的芯片" class="headerlink" title="DRAM（Dynamic Random Access Memory，动态随机存取存储器）的芯片"></a>DRAM（Dynamic Random Access Memory，动态随机存取存储器）的芯片</h3><p>为磁芯存储器画上句号的是集成电路随机存储器件。1966年，IBM Thomas J. Watson研究中心的Dr. Robert H. Dennard开发出了单个单元的动态随机存储器DRAM，DRAM每个单元包含一个开关晶体管和一个电容，利用电容中的电荷存储数据。因为电容中的电荷会泄露，需要每个周期都进行刷新重新补充电量，所以称其为动态随机存储器。</p>
<p>内存用的芯片和 Cache 有所不同，它用的是一种叫作 DRAM（Dynamic Random Access Memory，动态随机存取存储器）的芯片，比起 SRAM 来说，它的密度更高，有更大的容量，而且它也比 SRAM 芯片便宜不少。</p>
<p>动态随机存取存储器（DRAM）是一种半导体存储器，主要的作用原理是利用电容内存储电荷的多寡来代表一个二进制比特（bit）是1还是0。由于<strong>在现实中晶体管会有漏电电流的现象</strong>，导致电容上所存储的电荷数量并不足以正确的判别数据，而导致数据毁损。因此对于DRAM来说，周期性地充电是一个无可避免的要件。由于这种需要定时刷新的特性，因此被称为“动态”存储器。相对来说，静态存储器（SRAM）只要存入数据后，纵使不刷新也不会丢失记忆。</p>
<p>DRAM 的一个比特，只需要一个晶体管和一个电容就能存储。所以，DRAM 在同样的物理空间下，能够存储的数据也就更多，也就是存储的”密度”更大。DRAM 的数据访问电路和刷新电路都比 SRAM 更复杂，所以访问延时也就更长。</p>
<p><img src="/images/951413iMgBlog/d39b0f2b3962d646133d450541fb75a6.png" alt="img"></p>
<p>SRAM是比<strong>DRAM</strong>更为昂贵，但更为快速、非常低功耗（特别是在空闲状态）。 因此<strong>SRAM</strong>首选用于带宽要求高，或者功耗要求低，或者二者兼而有之。 <strong>SRAM</strong>比起<strong>DRAM</strong>更为容易控制，也更是随机访问。 由于复杂的内部结构，<strong>SRAM</strong>比<strong>DRAM</strong>的占用面积更大，因而不适合用于更高储存密度低成本的应用，如PC内存。</p>
<h3 id="SRAM和DRAM原理比较"><a href="#SRAM和DRAM原理比较" class="headerlink" title="SRAM和DRAM原理比较"></a>SRAM和DRAM原理比较</h3><p><a href="https://mp.weixin.qq.com/s?__biz=MzI2NDYwMDAxOQ==&amp;mid=2247483772&amp;idx=1&amp;sn=d7c188247b9851f7985676e2f9dd9a0e&amp;chksm=eaab61c0dddce8d62bdb521de1ada13142264882feae1ff06d6dcd81430a0063377e4b34cedb&amp;scene=178&amp;cur_album_id=1368835510680272898#rd" target="_blank" rel="external">简单说DRAM只有一个晶体管和一个电容，SRAM就复杂多了，需要6个晶体管</a></p>
<p><img src="/images/951413iMgBlog/image-20210603114550646.png" alt="What is the difference between SRAM and DRAM"></p>
<p>详细比较：</p>
<p><img src="/images/951413iMgBlog/maxresdefault.jpg" alt="Difference Between SRAM and DRAM - YouTube"></p>
<h2 id="系列文章-1"><a href="#系列文章-1" class="headerlink" title="系列文章"></a>系列文章</h2><p><a href="/2021/06/01/CPU的制造和概念/">CPU的制造和概念</a></p>
<p><a href="/2021/05/16/CPU Cache Line 和性能/">CPU 性能和Cache Line</a></p>
<p><a href="/2021/05/16/Perf IPC以及CPU利用率/">Perf IPC以及CPU性能</a></p>
<p><a href="/2021/06/18/几款CPU性能对比/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></p>
<p><a href="/2021/05/15/飞腾ARM芯片(FT2500">飞腾ARM芯片(FT2500)的性能测试</a>的性能测试/)</p>
<p><a href="/2021/05/14/十年后数据库还是不敢拥抱NUMA/">十年后数据库还是不敢拥抱NUMA？</a></p>
<p><a href="/2021/03/07/一次海光物理机资源竞争压测的记录/">一次海光物理机资源竞争压测的记录</a></p>
<p><a href="/2019/12/16/Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的/">Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的</a></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="http://igoro.com/archive/gallery-of-processor-cache-effects/" target="_blank" rel="external">Gallery of Processor Cache Effects</a></p>
<p><a href="https://coolshell.cn/articles/10249.html" target="_blank" rel="external">7个示例科普CPU CACHE</a></p>
<p><a href="https://coolshell.cn/articles/20793.html" target="_blank" rel="external">与程序员相关的CPU缓存知识</a></p>
<p><a href="https://arxiv.org/ftp/arxiv/papers/1803/1803.00254.pdf" target="_blank" rel="external">45-year CPU evolution: one law and two equations</a></p>
<p><a href="https://mp.weixin.qq.com/s/QNgMS0gOXhZml8l_towAbw" target="_blank" rel="external">揭秘 cache 访问延迟背后的计算机原理</a></p>
<p><a href="https://mp.weixin.qq.com/s/FC-bPwHUT7EpTydxDk5btQ" target="_blank" rel="external">业务与芯片垂直整合的一点思考</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/06/23/做了一道数学几何题/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/06/23/做了一道数学几何题/" itemprop="url">做了一道数学几何题</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-06-23T12:30:03+08:00">
                2021-06-23
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/技巧/" itemprop="url" rel="index">
                    <span itemprop="name">技巧</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="做了一道数学几何题"><a href="#做了一道数学几何题" class="headerlink" title="做了一道数学几何题"></a>做了一道数学几何题</h1><p>John Hattie的visible learning，这本书集成了两亿多学生的数据，然后得到了哪些品质能够决定一个人学习好坏，想通过一道几何题目来验证下。先看下John Hattie的结论</p>
<h2 id="哪些品质能够决定一个人学习好坏"><a href="#哪些品质能够决定一个人学习好坏" class="headerlink" title="哪些品质能够决定一个人学习好坏"></a>哪些品质能够决定一个人学习好坏</h2><h3 id="排在第一名的品质是复盘、总结能力"><a href="#排在第一名的品质是复盘、总结能力" class="headerlink" title="排在第一名的品质是复盘、总结能力"></a>排在第一名的品质是复盘、总结能力</h3><p>简单的说，这个能力就是这个孩子心里是否有个“小教练”，能够每次跳脱出当前任务，帮助自己分析，失败在哪里，成功在哪里，如何进阶，如何训练等等。</p>
<p>举几个例子：</p>
<ol>
<li><p>如果写不出作文，这个“小教练”能告诉孩子，是没有素材，还是文字能力不强。</p>
<p>如果是文字能力不强，应该如何训练（是造句，还是拆段落）</p>
</li>
<li><p>如果数学题做不出来，这个“小教练”能告诉孩子，我的弱点在哪里，哪个类型题我有重大问题，是因为哪里没有理解和打通。</p>
</li>
</ol>
<p>有内化的“自我教练”，这个能力系数是1.67。也就是其他能力相当，学习效果可以翻1.67倍。</p>
<h3 id="排在第二名的是建构能力。简单的说是逻辑推理，做事顺序等等"><a href="#排在第二名的是建构能力。简单的说是逻辑推理，做事顺序等等" class="headerlink" title="排在第二名的是建构能力。简单的说是逻辑推理，做事顺序等等"></a>排在第二名的是建构能力。简单的说是逻辑推理，做事顺序等等</h3><p>在内心“小教练”能把问题进行拆解之后，建构能力能把这些问题进行排序，应该怎么做更合理。</p>
<p>最终怎么把训练步骤整合。遇见一个问题，先干什么，再干什么等等。</p>
<p>有很强的顺序能力，系数为1.44。也就是其他能力相当，学习效果可以翻1.44倍。</p>
<h3 id="排在第三名的能力是智商和过去成绩"><a href="#排在第三名的能力是智商和过去成绩" class="headerlink" title="排在第三名的能力是智商和过去成绩"></a>排在第三名的能力是智商和过去成绩</h3><p>这个毋庸置疑，聪明做事就会简单一些。平均效应系数为0.67。</p>
<p>也就是说，其他能力相当，智商高和过去成绩好，学习效果提升67%</p>
<p>智商重要程度应该比这里更高，但是实际高智商的太少，<strong>大多都是因为基础知识好给人产生了智商高的误解！</strong></p>
<h3 id="排在第四名的能力是自我驱动力"><a href="#排在第四名的能力是自我驱动力" class="headerlink" title="排在第四名的能力是自我驱动力"></a>排在第四名的能力是自我驱动力</h3><p>简单的说，知道自己为什么学习，能够自我鼓励，遇见失败能抗挫，有很强的心理驱动力。</p>
<p>平均效应系数为0.48。也就是说，其他能力相当，有自我驱动力的人，学习效果提升48%。</p>
<h3 id="排在第五名的才是集中注意力"><a href="#排在第五名的才是集中注意力" class="headerlink" title="排在第五名的才是集中注意力"></a>排在第五名的才是集中注意力</h3><p>也就是说，注意力强。注意力对学习影响，并没有很多家长想象的那么大。</p>
<p>注意力的平均效应系数为0.44</p>
<p>也就是说，其他能力相当，注意力好的孩子，效果能提升44%</p>
<p>———总结一下——-</p>
<p>学习提升的个人因素：</p>
<p>自我分析，自我教练的元认知能力 》 逻辑排序与制定计划的建构能力》 智商和过去成绩 》自我驱动力》 集中注意力。</p>
<p>很多家长痴迷于“专注力”。当然专注力是一个效应量很强的学习力，但是从整体数据看，对学习的提升效果，仅仅排到第五名。</p>
<p>帮助孩子建立元认知能力和建构能力的培训，才能给他们对终身学习有帮助的技能包</p>
<p>以上缺少了对方法的落地执行能力的评估，实际这是影响最大的</p>
<h2 id="案例数学几何题"><a href="#案例数学几何题" class="headerlink" title="案例数学几何题"></a>案例数学几何题</h2><p>题目如下（图中红色、绿色线是我绘上去的辅助线）</p>
<p><img src="/images/951413iMgBlog/image-20210623121704887.png" alt="image-20210623121704887"></p>
<h3 id="目标分解"><a href="#目标分解" class="headerlink" title="目标分解"></a><strong>目标分解</strong></h3><p>求得四个阴影部分的面积相加；</p>
<p>求得白色部分面积即可以得到三角形内部两块阴影部分面积；</p>
<p>求得红色三角形面积记得通过圆面积减得三角形面积得到三角形外部阴影面积。红色辅助线、绿色辅助线</p>
<h3 id="题目给出的条件"><a href="#题目给出的条件" class="headerlink" title="题目给出的条件"></a><strong>题目给出的条件</strong></h3><p>大三角形是等腰直角三角形（两个角都是45度，直角90度）；</p>
<p>两圆相切：圆心连线经过切点，连线长度为两圆半径相加。大圆半径为2</p>
<p>这里关于两圆相切我完全不记得有啥特性了，所以去Google了一把得到如下两圆相切的特性：</p>
<p><img src="/images/951413iMgBlog/image-20210623130815151.png" alt="image-20210623130815151"></p>
<blockquote>
<p>想了一下在我丢开课本几十年后我看到等要直接三角形我能得到：45度、两条边相等这两个结论；但是看到两圆相切我完全想不起来这是什么东西了。相信这两个知识点在我中学的时候肯定无比熟练。</p>
<p>但是两圆相切完全不会出现在我的生活和应用中，但是等要直接三角形太常见了，它反复出现在我的生活中，所以我只要没得老年痴呆应该会一直记得。</p>
</blockquote>
<h3 id="解题关键"><a href="#解题关键" class="headerlink" title="解题关键"></a><strong>解题关键</strong></h3><ol>
<li>如何求得小圆半径；</li>
<li>如何求红色辅助线构成的右下角三角形的面积（是否是个等腰直角三角形？），求得这个三角形的面积就能算出右下角阴影面积</li>
<li>从1的小圆半径和2的方法同理可得左上角的外部阴影面积</li>
<li>从2、3的阴影面积可以求得大三角形内部两块白色区域面积</li>
<li>这样的到了全部阴影的面积</li>
</ol>
<h3 id="详细步骤"><a href="#详细步骤" class="headerlink" title="详细步骤"></a><strong>详细步骤</strong></h3><ol>
<li>求解小圆半径：相切是切入点，两圆圆心连线经过想切点（连线长=大圆半径+小圆半径）（绿线）</li>
<li>利用等腰直接三角形得到左下角绿色新直角三角形由勾股定理算出小圆半径（绿线）</li>
<li>大圆交点到圆心作辅助线得到右下角等腰三角形，由一个角是45度，和等腰三角形的特点退出另外一个角也为45度，从而得到右下角红色三角形是等腰直角三角形（红线）</li>
<li>通过大圆四分之一面积减掉右下角红线等腰三角形面积得到右下阴影部分面积，同理可得右上阴影面积。</li>
<li>通过半圆面积减掉阴影面积可分别得到两个半圆内部的白色部分面积</li>
<li>大三角形面积减掉6中的两个白色面积得到两个小阴影面积</li>
<li>到此分别得到了四个阴影部分面积</li>
</ol>
<h3 id="复盘求解过程"><a href="#复盘求解过程" class="headerlink" title="复盘求解过程"></a><strong>复盘求解过程</strong></h3><h4 id="教练在哪里"><a href="#教练在哪里" class="headerlink" title="教练在哪里?"></a>教练在哪里?</h4><p>教练就是日益自我训练的过程，教练在事后复盘上述过程，解题过程中没有教练参与</p>
<p>如果做不出来，那么教练就来问：</p>
<p>是题目没读懂得到的信息不够（仔细多读题，提高阅读能力）；</p>
<p>还是由题目中的已知条件得不到相关的直接推理（比如两圆相切因为不了解特性，所以得不到连线就是两个圆半径之和—-这种只能多看书）；</p>
<p>或者推不出来右下角的直角等腰三角形（对等腰三角形理解不够）……</p>
<p>如果做得过于绕，那么教练就来问：</p>
<p>还能简化（这个简化不是要奇技淫巧的快解），而是要既解决问题又不啰嗦，同时又是自己掌握知识的恰切运用！</p>
<p>教练就是复盘上述过程，得到方法进步或者知识缺陷或者理解缺陷，而不是得到答案。</p>
<h4 id="逻辑推理，做事顺序"><a href="#逻辑推理，做事顺序" class="headerlink" title="逻辑推理，做事顺序"></a>逻辑推理，做事顺序</h4><p>先求什么再求什么，怎么样从已知条件得到简单结论，然后再分步得到阶段性小结论（各个小块面积）到最终目标，这就是John Hattie提到的逻辑推理做事顺序能力</p>
<h4 id="基础知识的运用"><a href="#基础知识的运用" class="headerlink" title="基础知识的运用"></a><strong>基础知识的运用</strong></h4><p>勾股定理、等腰三角形、三角形三角之和、相切特性、圆面积、等腰三角形面积计算</p>
<p>没有任何一个复杂的基础知识，也没有任何需要几次的推导，全是定理带来的直接特性，对智力要求极低</p>
<p>自我驱动和集中注意力是个长期过程，自我驱动决定了之前的学习欲望和基本知识点的掌握</p>
<h2 id="其他总结"><a href="#其他总结" class="headerlink" title="其他总结"></a>其他总结</h2><p>你有更巧妙的解法？对不起，我不需要，我要的就是这种学渣也完全能掌握，只需要简单地1+1+1+1就得到4的方法，我不需要2*2得到4，因为1+1+1+1对不会乘法的学渣也能掌握，我要的就是这种普适的方法。</p>
<p>学渣也能掌握这个方法，然后用这个方法训练自己解决其他类似题目。对学渣来说考80分就很开心了，等他们有了考80分的能力就有野心向90进发。</p>
<p>学渣更重要的是追求容易的全部解决，复杂的直接战略性放弃，只有在容易的全部掌握后才能慢慢挑战复杂题目。容易的基础题都解决不好只是追求奇技淫巧的解法或者复杂题目容易迷失自己和快速遗忘。</p>
<h2 id="受过训练的中学生如何解这题"><a href="#受过训练的中学生如何解这题" class="headerlink" title="受过训练的中学生如何解这题"></a>受过训练的中学生如何解这题</h2><p>做如下BD和HE两条辅助线，梯形BDEH的面积就是要求的面积。</p>
<p>也就是ABC三角形的面积减掉AEH和BCD两个三角形的面积。</p>
<p>那么需要证明 BD=CD，因为DF=CF，角FCD为45度，所以CDF为等腰三角形，接下来证明过程和上面一样。同时同理可证AEH也是等腰直角三角形。</p>
<p>可以看到受过训练的中学生的解题方法更为犀利一些，但是前面文章的方法最为朴素和直接。训练过的方法效率更高，当然两个方法基本知识的运用没有差别。</p>
<p>比如受过训练的方法还是需要下图红色、绿色两条辅助线。这就是职业和业余的差距。</p>
<p><img src="/images/951413iMgBlog/image-20210625175006683.png" alt="image-20210625175006683"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/06/18/几款CPU性能对比/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/06/18/几款CPU性能对比/" itemprop="url">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-06-18T17:30:03+08:00">
                2021-06-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CPU/" itemprop="url" rel="index">
                    <span itemprop="name">CPU</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Intel-海光-鲲鹏920-飞腾2500-CPU性能对比"><a href="#Intel-海光-鲲鹏920-飞腾2500-CPU性能对比" class="headerlink" title="Intel 海光 鲲鹏920 飞腾2500 CPU性能对比"></a>Intel 海光 鲲鹏920 飞腾2500 CPU性能对比</h1><p>为了让程序能快点，特意了解了CPU的各种原理，比如多核、超线程、NUMA、睿频、功耗、GPU、大小核再到分支预测、cache_line失效、加锁代价、IPC等各种指标（都有对应的代码和测试数据）都会在这系列文章中得到答案。当然一定会有程序员最关心的分支预测案例、Disruptor无锁案例、cache_line伪共享案例等等。</p>
<p>这次让我们从最底层的沙子开始用8篇文章来回答各种疑问以及大量的实验对比案例和测试数据。</p>
<p>大的方面主要是从这几个疑问来写这些文章：</p>
<ul>
<li>同样程序为什么CPU跑到800%还不如CPU跑到200%快？</li>
<li>IPC背后的原理和和程序效率的关系？</li>
<li>为什么数据库领域都爱把NUMA关了，这对吗？</li>
<li>几个国产芯片的性能到底怎么样？</li>
</ul>
<h2 id="系列文章"><a href="#系列文章" class="headerlink" title="系列文章"></a>系列文章</h2><p><a href="/2021/06/01/CPU的制造和概念/">CPU的制造和概念</a></p>
<p><a href="/2021/05/16/Perf IPC以及CPU利用率/">Perf IPC以及CPU性能</a></p>
<p><a href="https://plantegg.github.io/2021/07/19/CPU性能和CACHE/">CPU性能和CACHE</a></p>
<p><a href="/2021/05/16/CPU Cache Line 和性能/">CPU 性能和Cache Line</a></p>
<p><a href="/2021/05/14/十年后数据库还是不敢拥抱NUMA/">十年后数据库还是不敢拥抱NUMA？</a></p>
<p><a href="/2019/12/16/Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的/">Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的</a></p>
<p><a href="/2021/06/18/几款CPU性能对比/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></p>
<p><a href="/2021/03/07/一次海光物理机资源竞争压测的记录/">一次海光物理机资源竞争压测的记录</a></p>
<p><a href="/2021/05/15/飞腾ARM芯片-FT2500的性能测试/">飞腾ARM芯片(FT2500)的性能测试</a></p>
<p>本篇是收尾篇，横向对比一下x86和ARM芯片，以及不同方案权衡下的性能比较</p>
<h2 id="CPU基本信息"><a href="#CPU基本信息" class="headerlink" title="CPU基本信息"></a>CPU基本信息</h2><p><img src="/images/951413iMgBlog/image-20210723161314138.png" alt="image-20210723161314138"></p>
<h3 id="海光"><a href="#海光" class="headerlink" title="海光"></a>海光</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line">#lscpu</div><div class="line">Architecture:          x86_64</div><div class="line">CPU op-mode(s):        32-bit, 64-bit</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                64</div><div class="line">On-line CPU(s) list:   0-63</div><div class="line">Thread(s) per core:    2      //每个物理core有两个超线程</div><div class="line">Core(s) per socket:    16     //每路16个物理core</div><div class="line">Socket(s):             2      //2路</div><div class="line">NUMA node(s):          4</div><div class="line">Vendor ID:             HygonGenuine</div><div class="line">CPU family:            24</div><div class="line">Model:                 1</div><div class="line">Model name:            Hygon C86 5280 16-core Processor</div><div class="line">Stepping:              1</div><div class="line">CPU MHz:               2455.552</div><div class="line">CPU max MHz:           2500.0000</div><div class="line">CPU min MHz:           1600.0000</div><div class="line">BogoMIPS:              4999.26</div><div class="line">Virtualization:        AMD-V</div><div class="line">L1d cache:             32K</div><div class="line">L1i cache:             64K</div><div class="line">L2 cache:              512K</div><div class="line">L3 cache:              8192K</div><div class="line">NUMA node0 CPU(s):     0-7,32-39</div><div class="line">NUMA node1 CPU(s):     8-15,40-47</div><div class="line">NUMA node2 CPU(s):     16-23,48-55</div><div class="line">NUMA node3 CPU(s):     24-31,56-63</div><div class="line">Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid amd_dcm aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb hw_pstate sme ssbd sev ibpb vmmcall fsgsbase bmi1 avx2 smep bmi2 MySQLeed adx smap clflushopt sha_ni xsaveopt xsavec xgetbv1 xsaves clzero irperf xsaveerptr arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif overflow_recov succor smca</div><div class="line"></div><div class="line">#numactl -H</div><div class="line">available: 4 nodes (0-3)</div><div class="line">node 0 cpus: 0 1 2 3 4 5 6 7 32 33 34 35 36 37 38 39</div><div class="line">node 0 size: 128854 MB</div><div class="line">node 0 free: 89350 MB</div><div class="line">node 1 cpus: 8 9 10 11 12 13 14 15 40 41 42 43 44 45 46 47</div><div class="line">node 1 size: 129019 MB</div><div class="line">node 1 free: 89326 MB</div><div class="line">node 2 cpus: 16 17 18 19 20 21 22 23 48 49 50 51 52 53 54 55</div><div class="line">node 2 size: 128965 MB</div><div class="line">node 2 free: 86542 MB</div><div class="line">node 3 cpus: 24 25 26 27 28 29 30 31 56 57 58 59 60 61 62 63</div><div class="line">node 3 size: 129020 MB</div><div class="line">node 3 free: 98227 MB</div><div class="line">node distances:</div><div class="line">node   0   1   2   3</div><div class="line">  0:  10  16  28  22</div><div class="line">  1:  16  10  22  28</div><div class="line">  2:  28  22  10  16</div><div class="line">  3:  22  28  16  10</div></pre></td></tr></table></figure>
<p>这CPU据说是胶水核，也就是把两个die拼一块封装成一块CPU，所以一块CPU内跨die之间延迟还是很高的。</p>
<h4 id="64-个-core-的分配策略"><a href="#64-个-core-的分配策略" class="headerlink" title="64 个 core 的分配策略"></a>64 个 core 的分配策略</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">physical         core      processor</div><div class="line">0                0~15         0~15</div><div class="line">1                0~15         16~31</div><div class="line">0                0~15         32~47</div><div class="line">1                0~15         48~63</div></pre></td></tr></table></figure>
<p><img src="/images/951413iMgBlog/image-20210805085715353.png" alt="image-20210805085715353"></p>
<h3 id="Intel-CPU"><a href="#Intel-CPU" class="headerlink" title="Intel CPU"></a>Intel CPU</h3><p><img src="/images/951413iMgBlog/750px-cascade_lake_naming_scheme.svg.png" alt="cascade lake naming scheme.svg"></p>
<p>Cascade Lake架构相对Broadwell L1没变，L2从256K增加到1M增加了4倍，L3从2.5下降到1.38M每core</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div></pre></td><td class="code"><pre><div class="line">#lscpu</div><div class="line">Architecture:          x86_64</div><div class="line">CPU op-mode(s):        32-bit, 64-bit</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                104</div><div class="line">On-line CPU(s) list:   0-103</div><div class="line">Thread(s) per core:    2</div><div class="line">Core(s) per socket:    26</div><div class="line">座：                 2</div><div class="line">NUMA 节点：         1</div><div class="line">厂商 ID：           GenuineIntel</div><div class="line">CPU 系列：          6</div><div class="line">型号：              85</div><div class="line">型号名称：        Intel(R) Xeon(R) Platinum 8269CY CPU @ 2.50GHz</div><div class="line">步进：              7</div><div class="line">CPU MHz：             1200.000</div><div class="line">CPU max MHz:           2501.0000</div><div class="line">CPU min MHz:           1200.0000</div><div class="line">BogoMIPS：            5000.00</div><div class="line">虚拟化：           VT-x</div><div class="line">L1d 缓存：          32K</div><div class="line">L1i 缓存：          32K</div><div class="line">L2 缓存：           1024K</div><div class="line">L3 缓存：           36608K</div><div class="line">NUMA 节点0 CPU：    0-103</div><div class="line">Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb cat_l3 cdp_l3 intel_ppin intel_pt ssbd mba ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm mpx rdt_a avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts pku ospke avx512_vnni spec_ctrl intel_stibp flush_l1d arch_capabilities</div><div class="line"></div><div class="line"># numactl -H</div><div class="line">available: 1 nodes (0)</div><div class="line">node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103</div><div class="line">node 0 size: 785826 MB</div><div class="line">node 0 free: 108373 MB</div><div class="line">node distances:</div><div class="line">node   0</div><div class="line">  0:  10  </div><div class="line"></div><div class="line">//志强E5</div><div class="line">  #lscpu</div><div class="line">Architecture:          x86_64</div><div class="line">CPU op-mode(s):        32-bit, 64-bit</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                64</div><div class="line">On-line CPU(s) list:   0-63</div><div class="line">Thread(s) per core:    2</div><div class="line">Core(s) per socket:    16</div><div class="line">Socket(s):             2</div><div class="line">NUMA node(s):          2</div><div class="line">Vendor ID:             GenuineIntel</div><div class="line">CPU family:            6</div><div class="line">Model:                 79</div><div class="line">Model name:            Intel(R) Xeon(R) CPU E5-2682 v4 @ 2.50GHz</div><div class="line">Stepping:              1</div><div class="line">CPU MHz:               2500.000</div><div class="line">CPU max MHz:           3000.0000</div><div class="line">CPU min MHz:           1200.0000</div><div class="line">BogoMIPS:              5000.06</div><div class="line">Virtualization:        VT-x</div><div class="line">L1d cache:             32K</div><div class="line">L1i cache:             32K</div><div class="line">L2 cache:              256K</div><div class="line">L3 cache:              40960K</div><div class="line">NUMA node0 CPU(s):     0-15,32-47</div><div class="line">NUMA node1 CPU(s):     16-31,48-63</div><div class="line">Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 ds_cpl vmx smx est tm2 ssse3 fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch ida arat epb invpcid_single pln pts dtherm spec_ctrl ibpb_support tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local cat_l3</div><div class="line"></div><div class="line">#numactl -H</div><div class="line">available: 2 nodes (0-1)</div><div class="line">node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47</div><div class="line">node 0 size: 262008 MB</div><div class="line">node 0 free: 240846 MB</div><div class="line">node 1 cpus: 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63</div><div class="line">node 1 size: 262144 MB</div><div class="line">node 1 free: 242774 MB</div><div class="line">node distances:</div><div class="line">node   0   1</div><div class="line">  0:  10  21</div><div class="line">  1:  21  10</div></pre></td></tr></table></figure>
<h3 id="鲲鹏920"><a href="#鲲鹏920" class="headerlink" title="鲲鹏920"></a>鲲鹏920</h3><p>鲲鹏920-4826的L1比8269C 大一倍，但是L2小一倍。L3鲲鹏为1M/core  8269为1.38M/core(物理core）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line">#lscpu</div><div class="line">Architecture:          aarch64</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                96</div><div class="line">On-line CPU(s) list:   0-95</div><div class="line">Thread(s) per core:    1</div><div class="line">Core(s) per socket:    48</div><div class="line">Socket(s):             2</div><div class="line">NUMA node(s):          1</div><div class="line">Model:                 0</div><div class="line">CPU max MHz:           2600.0000</div><div class="line">CPU min MHz:           200.0000</div><div class="line">BogoMIPS:              200.00</div><div class="line">L1d cache:             64K</div><div class="line">L1i cache:             64K</div><div class="line">L2 cache:              512K</div><div class="line">L3 cache:              49152K</div><div class="line">NUMA node0 CPU(s):     0-95</div><div class="line">Flags:                 fp asimd evtstrm aes pmull sha1 sha2 crc32 atomics fphp asimdhp cpuid asimdrdm jscvt fcma dcpop asimddp asimdfhm</div><div class="line"></div><div class="line">#numactl -H</div><div class="line">available: 4 nodes (0-3)</div><div class="line">node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23</div><div class="line">node 0 size: 192832 MB</div><div class="line">node 0 free: 187693 MB</div><div class="line">node 1 cpus: 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47</div><div class="line">node 1 size: 193533 MB</div><div class="line">node 1 free: 191827 MB</div><div class="line">node 2 cpus: 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71</div><div class="line">node 2 size: 193533 MB</div><div class="line">node 2 free: 192422 MB</div><div class="line">node 3 cpus: 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95</div><div class="line">node 3 size: 193532 MB</div><div class="line">node 3 free: 193139 MB</div><div class="line">node distances:</div><div class="line">node   0   1   2   3</div><div class="line">  0:  10  12  20  22</div><div class="line">  1:  12  10  22  24</div><div class="line">  2:  20  22  10  12</div><div class="line">  3:  22  24  12  10</div><div class="line"></div><div class="line">#dmidecode -t processor | grep Version</div><div class="line">    Version: Kunpeng 920-4826</div><div class="line">    Version: Kunpeng 920-4826  </div><div class="line"></div><div class="line">以上四个鲲鹏920的四个NUMA node之间的距离描述如下：</div><div class="line">node 0 &lt;------------ socket distance ------------&gt; node 2</div><div class="line">    | (die distance)                                  | (die distance)</div><div class="line">node 1                                             node 3    </div><div class="line">要注意node1到node3比node0到node3要大，猜测Socket之间的UPI只接上了node1和node2</div></pre></td></tr></table></figure>
<p><a href="https://fuse.wikichip.org/news/2274/huawei-expands-kunpeng-server-cpus-plans-smt-sve-for-next-gen/" target="_blank" rel="external">鲲鹏920架构参考这里</a></p>
<p><img src="/images/951413iMgBlog/taishan-v110-soc-block-diagram.png" alt="img"></p>
<p>Though Huawei has been keeping a tight lip on the chip design itself, the Hi1620 is actually a multi-chip design. Actually, we believe are three dies. The chip itself comprise two compute dies called the <strong>Super CPU cluster</strong> (SCCL), each one packing 32 cores. It’s also possible the SCCL only have 24 cores, in which case there are three such dies with a theoretical maximum core count of 72 cores possible but are not offered for yield reasons. Regardless of this, there are at least two SCCL dies for sure. Additionally, there is also an I/O die called the <strong>Super IO Cluster</strong> (SICL) which contains all the high-speed SerDes and low-speed I/Os.</p>
<p>下图是6426型号，我测试用的是4826型号，也就是一个CPU内是48core，一个CPU封装3个Die，两个Die是 core，还有一个是Super IO Cluster</p>
<p><img src="/images/951413iMgBlog/700px-taishan_v110_soc_details.svg.png" alt="taishan v110 soc details.svg"></p>
<p>鲲鹏命令规范：</p>
<p><img src="/images/951413iMgBlog/kunpeng-naming-scheme.png" alt="img"></p>
<p>鲲鹏 RoadMap</p>
<p><img src="/images/951413iMgBlog/kunpeng-future-roadmap-1024x512.png" alt="img"></p>
<h4 id="鲲鹏-Kunpeng-920-4826-跨numa性能比较"><a href="#鲲鹏-Kunpeng-920-4826-跨numa性能比较" class="headerlink" title="鲲鹏 Kunpeng 920-4826 跨numa性能比较"></a>鲲鹏 Kunpeng 920-4826 跨numa性能比较</h4><p>绑24core，跨numa0、numa3，是numactl -H看到的比较远距离。两分钟的 Current tpmC: 69660</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">#taskset -a -cp  12-23,72-83 20799</div><div class="line"></div><div class="line">#perf stat -e branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,stalled-cycles-backend,stalled-cycles-frontend,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-store-misses,L1-dcache-stores,L1-icache-load-misses,L1-icache-loads,branch-load-misses,branch-loads,dTLB-load-misses,dTLB-loads,iTLB-load-misses,iTLB-loads,cpu-migrations -p 20799</div><div class="line">^C</div><div class="line"> Performance counter stats for process id &apos;20799&apos;:</div><div class="line"></div><div class="line">     2,866,418,154      branch-misses                                                 (59.84%)</div><div class="line">   549,673,215,827      bus-cycles                                                    (59.89%)</div><div class="line">     2,179,816,578      cache-misses              #    2.360 % of all cache refs      (59.93%)</div><div class="line">    92,377,674,343      cache-references                                              (60.04%)</div><div class="line">   549,605,057,475      cpu-cycles                                                    (65.05%)</div><div class="line">   229,958,980,614      instructions              #    0.42  insn per cycle</div><div class="line">                                                  #    1.31  stalled cycles per insn  (65.05%)</div><div class="line">   146,201,062,116      stalled-cycles-backend    #   26.60% backend cycles idle      (65.08%)</div><div class="line">   301,814,831,043      stalled-cycles-frontend   #   54.91% frontend cycles idle     (65.08%)</div><div class="line">     2,177,062,319      L1-dcache-load-misses     #    2.35% of all L1-dcache hits    (65.04%)</div><div class="line">    92,481,797,426      L1-dcache-loads                                               (65.11%)</div><div class="line">     2,175,030,428      L1-dcache-store-misses                                        (65.15%)</div><div class="line">    92,507,474,710      L1-dcache-stores                                              (65.14%)</div><div class="line">     9,299,812,249      L1-icache-load-misses     #   12.47% of all L1-icache hits    (65.20%)</div><div class="line">    74,579,909,037      L1-icache-loads                                               (65.16%)</div><div class="line">     2,862,664,443      branch-load-misses                                            (65.08%)</div><div class="line">    52,826,930,842      branch-loads                                                  (65.04%)</div><div class="line">     3,729,265,130      dTLB-load-misses          #    3.11% of all dTLB cache hits   (64.95%)</div><div class="line">   119,896,014,498      dTLB-loads                                                    (59.90%)</div><div class="line">     1,350,782,047      iTLB-load-misses          #    1.83% of all iTLB cache hits   (59.84%)</div><div class="line">    74,005,620,378      iTLB-loads                                                    (59.82%)</div><div class="line">               510      cpu-migrations</div><div class="line"></div><div class="line">       9.483137760 seconds time elapsed</div></pre></td></tr></table></figure>
<p>绑72-95core，在同一个numa下，但是没有重启进程，导致有一半内存仍然在numa0上，2分钟的Current tpmC: 75900</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line">#taskset -a -cp  72-95 20799</div><div class="line"></div><div class="line">#perf stat -e branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,stalled-cycles-backend,stalled-cycles-frontend,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-store-misses,L1-dcache-stores,L1-icache-load-misses,L1-icache-loads,branch-load-misses,branch-loads,dTLB-load-misses,dTLB-loads,iTLB-load-misses,iTLB-loads,cpu-migrations -p 20799</div><div class="line">^C</div><div class="line"> Performance counter stats for process id &apos;20799&apos;:</div><div class="line"></div><div class="line">     2,665,583,722      branch-misses                                                 (59.90%)</div><div class="line">   500,184,789,050      bus-cycles                                                    (59.95%)</div><div class="line">     1,997,726,097      cache-misses              #    2.254 % of all cache refs      (59.94%)</div><div class="line">    88,628,013,529      cache-references                                              (59.93%)</div><div class="line">   500,111,712,450      cpu-cycles                                                    (64.98%)</div><div class="line">   221,098,464,920      instructions              #    0.44  insn per cycle</div><div class="line">                                                  #    1.35  stalled cycles per insn  (65.02%)</div><div class="line">   105,957,124,479      stalled-cycles-backend    #   21.19% backend cycles idle      (65.02%)</div><div class="line">   298,186,439,955      stalled-cycles-frontend   #   59.62% frontend cycles idle     (65.02%)</div><div class="line">     1,996,313,908      L1-dcache-load-misses     #    2.25% of all L1-dcache hits    (65.04%)</div><div class="line">    88,701,699,646      L1-dcache-loads                                               (65.09%)</div><div class="line">     1,997,851,364      L1-dcache-store-misses                                        (65.10%)</div><div class="line">    88,614,658,960      L1-dcache-stores                                              (65.10%)</div><div class="line">     8,635,807,737      L1-icache-load-misses     #   12.30% of all L1-icache hits    (65.13%)</div><div class="line">    70,233,323,630      L1-icache-loads                                               (65.16%)</div><div class="line">     2,665,567,783      branch-load-misses                                            (65.10%)</div><div class="line">    50,482,936,168      branch-loads                                                  (65.09%)</div><div class="line">     3,614,564,473      dTLB-load-misses          #    3.15% of all dTLB cache hits   (65.04%)</div><div class="line">   114,619,822,486      dTLB-loads                                                    (59.96%)</div><div class="line">     1,270,926,362      iTLB-load-misses          #    1.81% of all iTLB cache hits   (59.97%)</div><div class="line">    70,248,645,721      iTLB-loads                                                    (59.94%)</div><div class="line">               128      cpu-migrations</div><div class="line"></div><div class="line">       8.610934700 seconds time elapsed</div><div class="line"></div><div class="line">#/root/numa-maps-summary.pl &lt;/proc/20799/numa_maps</div><div class="line">N0        :      8220658 ( 31.36 GB)</div><div class="line">N1        :        38620 (  0.15 GB)</div><div class="line">N2        :       480619 (  1.83 GB)</div><div class="line">N3        :      8281759 ( 31.59 GB)</div><div class="line">active    :        28797 (  0.11 GB)</div><div class="line">anon      :     17015902 ( 64.91 GB)</div><div class="line">dirty     :     16990615 ( 64.81 GB)</div><div class="line">kernelpagesize_kB:         9076 (  0.03 GB)</div><div class="line">mapmax    :          760 (  0.00 GB)</div><div class="line">mapped    :         5754 (  0.02 GB)</div></pre></td></tr></table></figure>
<p>重启进程后继续绑72-95core，在同一个numa下，先进成充分热身，然后2分钟的 Current tpmC: 77880</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line">#perf stat -e branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,stalled-cycles-backend,stalled-cycles-frontend,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-store-misses,L1-dcache-stores,L1-icache-load-misses,L1-icache-loads,branch-load-misses,branch-loads,dTLB-load-misses,dTLB-loads,iTLB-load-misses,iTLB-loads,cpu-migrations -p 49512</div><div class="line">^C</div><div class="line"> Performance counter stats for process id &apos;49512&apos;:</div><div class="line"></div><div class="line">     1,849,313,199      branch-misses                                                 (59.99%)</div><div class="line">   319,122,053,367      bus-cycles                                                    (60.02%)</div><div class="line">     1,319,212,546      cache-misses              #    2.238 % of all cache refs      (59.95%)</div><div class="line">    58,950,581,370      cache-references                                              (60.02%)</div><div class="line">   319,088,767,311      cpu-cycles                                                    (65.01%)</div><div class="line">   146,580,891,374      instructions              #    0.46  insn per cycle</div><div class="line">                                                  #    1.32  stalled cycles per insn  (65.01%)</div><div class="line">    61,109,919,226      stalled-cycles-backend    #   19.15% backend cycles idle      (65.04%)</div><div class="line">   193,963,590,196      stalled-cycles-frontend   #   60.79% frontend cycles idle     (65.06%)</div><div class="line">     1,319,593,051      L1-dcache-load-misses     #    2.24% of all L1-dcache hits    (65.03%)</div><div class="line">    58,967,303,454      L1-dcache-loads                                               (65.04%)</div><div class="line">     1,318,842,690      L1-dcache-store-misses                                        (65.13%)</div><div class="line">    58,988,059,583      L1-dcache-stores                                              (65.07%)</div><div class="line">     5,769,871,870      L1-icache-load-misses     #   12.25% of all L1-icache hits    (65.12%)</div><div class="line">    47,085,299,316      L1-icache-loads                                               (65.10%)</div><div class="line">     1,850,419,802      branch-load-misses                                            (65.03%)</div><div class="line">    33,687,548,636      branch-loads                                                  (65.08%)</div><div class="line">     2,375,028,039      dTLB-load-misses          #    3.12% of all dTLB cache hits   (65.08%)</div><div class="line">    76,113,084,244      dTLB-loads                                                    (60.01%)</div><div class="line">       825,388,210      iTLB-load-misses          #    1.75% of all iTLB cache hits   (59.99%)</div><div class="line">    47,092,738,092      iTLB-loads                                                    (59.95%)</div><div class="line">                49      cpu-migrations</div><div class="line"></div><div class="line">#/root/numa-maps-summary.pl &lt;/proc/49512/numa_maps</div><div class="line">N0        :         5765 (  0.02 GB)</div><div class="line">N1        :        41599 (  0.16 GB)</div><div class="line">N2        :          566 (  0.00 GB)</div><div class="line">N3        :     16955491 ( 64.68 GB)</div><div class="line">active    :        30430 (  0.12 GB)</div><div class="line">anon      :     16997663 ( 64.84 GB)</div><div class="line">dirty     :     16989252 ( 64.81 GB)</div><div class="line">kernelpagesize_kB:         9020 (  0.03 GB)</div><div class="line">mapmax    :          745 (  0.00 GB)</div><div class="line">mapped    :         5758 (  0.02 GB)</div></pre></td></tr></table></figure>
<p>IPC从0.42到0.44再到0.46，tpmC也不断增加，整体压力都不大只压了25%的CPU，所以跨NUMA大概有10%的性能差异. IPC也是0.42 VS 0.46 。测试场景是DRDS Server服务。</p>
<p>如果跨4core绑定core的话最好和最差绑法性能会下降25-30%，四个core绑不同numa的性能比较</p>
<table>
<thead>
<tr>
<th>被压进程绑定的core id</th>
<th>tpmC</th>
</tr>
</thead>
<tbody>
<tr>
<td>72,73,74,75</td>
<td>14460</td>
</tr>
<tr>
<td>48,49,72,73</td>
<td>13800</td>
</tr>
<tr>
<td>24,25,72,73</td>
<td>11760</td>
</tr>
<tr>
<td>0,1,72,73</td>
<td>11940</td>
</tr>
<tr>
<td>0,24,48,72</td>
<td>10800</td>
</tr>
</tbody>
</table>
<h3 id="飞腾2500"><a href="#飞腾2500" class="headerlink" title="飞腾2500"></a>飞腾2500</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div></pre></td><td class="code"><pre><div class="line">#lscpu</div><div class="line">Architecture:          aarch64</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                128</div><div class="line">On-line CPU(s) list:   0-127</div><div class="line">Thread(s) per core:    1</div><div class="line">Core(s) per socket:    64</div><div class="line">Socket(s):             2</div><div class="line">NUMA node(s):          16</div><div class="line">Model:                 3</div><div class="line">BogoMIPS:              100.00</div><div class="line">L1d cache:             32K</div><div class="line">L1i cache:             32K</div><div class="line">L2 cache:              2048K</div><div class="line">L3 cache:              65536K</div><div class="line">NUMA node0 CPU(s):     0-7</div><div class="line">NUMA node1 CPU(s):     8-15</div><div class="line">NUMA node2 CPU(s):     16-23</div><div class="line">NUMA node3 CPU(s):     24-31</div><div class="line">NUMA node4 CPU(s):     32-39</div><div class="line">NUMA node5 CPU(s):     40-47</div><div class="line">NUMA node6 CPU(s):     48-55</div><div class="line">NUMA node7 CPU(s):     56-63</div><div class="line">NUMA node8 CPU(s):     64-71</div><div class="line">NUMA node9 CPU(s):     72-79</div><div class="line">NUMA node10 CPU(s):    80-87</div><div class="line">NUMA node11 CPU(s):    88-95</div><div class="line">NUMA node12 CPU(s):    96-103</div><div class="line">NUMA node13 CPU(s):    104-111</div><div class="line">NUMA node14 CPU(s):    112-119</div><div class="line">NUMA node15 CPU(s):    120-127</div><div class="line">Flags:                 fp asimd evtstrm aes pmull sha1 sha2 crc32 cpuid</div><div class="line"></div><div class="line">node distances:</div><div class="line">node   0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15</div><div class="line">  0:  10  20  40  30  20  30  50  40  100  100  100  100  100  100  100  100</div><div class="line">  1:  20  10  30  40  50  20  40  50  100  100  100  100  100  100  100  100</div><div class="line">  2:  40  30  10  20  40  50  20  30  100  100  100  100  100  100  100  100</div><div class="line">  3:  30  40  20  10  30  20  40  50  100  100  100  100  100  100  100  100</div><div class="line">  4:  20  50  40  30  10  50  30  20  100  100  100  100  100  100  100  100</div><div class="line">  5:  30  20  50  20  50  10  50  40  100  100  100  100  100  100  100  100</div><div class="line">  6:  50  40  20  40  30  50  10  30  100  100  100  100  100  100  100  100</div><div class="line">  7:  40  50  30  50  20  40  30  10  100  100  100  100  100  100  100  100</div><div class="line">  8:  100  100  100  100  100  100  100  100  10  20  40  30  20  30  50  40</div><div class="line">  9:  100  100  100  100  100  100  100  100  20  10  30  40  50  20  40  50</div><div class="line"> 10:  100  100  100  100  100  100  100  100  40  30  10  20  40  50  20  30</div><div class="line"> 11:  100  100  100  100  100  100  100  100  30  40  20  10  30  20  40  50</div><div class="line"> 12:  100  100  100  100  100  100  100  100  20  50  40  30  10  50  30  20</div><div class="line"> 13:  100  100  100  100  100  100  100  100  30  20  50  20  50  10  50  40</div><div class="line"> 14:  100  100  100  100  100  100  100  100  50  40  20  40  30  50  10  30</div><div class="line"> 15:  100  100  100  100  100  100  100  100  40  50  30  50  20  40  30  10</div><div class="line"></div><div class="line">#dmidecode -t processor</div><div class="line"># dmidecode 3.0</div><div class="line">Getting SMBIOS data from sysfs.</div><div class="line">SMBIOS 3.2.0 present.</div><div class="line"># SMBIOS implementations newer than version 3.0 are not</div><div class="line"># fully supported by this version of dmidecode.</div><div class="line"></div><div class="line">Handle 0x0004, DMI type 4, 48 bytes</div><div class="line">Processor Information</div><div class="line">    Socket Designation: BGA3576</div><div class="line">    Type: Central Processor</div><div class="line">    Family: &lt;OUT OF SPEC&gt;</div><div class="line">    Manufacturer: PHYTIUM</div><div class="line">    ID: 00 00 00 00 70 1F 66 22</div><div class="line">    Version: FT2500</div><div class="line">    Voltage: 0.8 V</div><div class="line">    External Clock: 50 MHz</div><div class="line">    Max Speed: 2100 MHz</div><div class="line">    Current Speed: 2100 MHz</div><div class="line">    Status: Populated, Enabled</div><div class="line">    Upgrade: Other</div><div class="line">    L1 Cache Handle: 0x0005</div><div class="line">    L2 Cache Handle: 0x0007</div><div class="line">    L3 Cache Handle: 0x0008</div><div class="line">    Serial Number: 1234567</div><div class="line">    Asset Tag: No Asset Tag</div><div class="line">    Part Number: NULL</div><div class="line">    Core Count: 64</div><div class="line">    Core Enabled: 64</div><div class="line">    Thread Count: 64</div><div class="line">    Characteristics:</div><div class="line">        64-bit capable</div><div class="line">        Multi-Core</div><div class="line">        Hardware Thread</div><div class="line">        Execute Protection</div><div class="line">        Enhanced Virtualization</div><div class="line">        Power/Performance Control</div></pre></td></tr></table></figure>
<h3 id="申威3231"><a href="#申威3231" class="headerlink" title="申威3231"></a>申威3231</h3><p>申威系列微处理器的开发主要是被<a href="https://zh.wikipedia.org/wiki/中华人民共和国" target="_blank" rel="external">中华人民共和国</a>用于军事方面<a href="https://zh.wikipedia.org/wiki/Wikipedia:列明来源" target="_blank" rel="external">[来源请求]</a>。根据部分公开信息表明，此系列的微体系架构基于<a href="https://zh.wikipedia.org/wiki/DEC_Alpha" target="_blank" rel="external">DEC Alpha</a>派生而来。<a href="https://zh.wikipedia.org/wiki/申威处理器#cite_note-gen123-1" target="_blank" rel="external">[1]</a><a href="https://zh.wikipedia.org/wiki/申威处理器#cite_note-linkedin-chengang-2" target="_blank" rel="external">[2]</a>而SW-3/SW1600处理器则是基于Alpha 21164。<a href="https://zh.wikipedia.org/wiki/申威处理器#cite_note-3" target="_blank" rel="external">[3]</a></p>
<p>不过申威系列最新的SW26010处理器，目前没有详细的信息表明它是基于DEC Alpha微架构的派生品。<a href="https://zh.wikipedia.org/wiki/申威处理器#cite_note-dongarra2016-4" target="_blank" rel="external">[4]</a><a href="https://zh.wikipedia.org/wiki/申威处理器#cite_note-next-platform-5" target="_blank" rel="external">[5]</a>不过处理器的处理器核心结构布局，则是类似于基于POWER指令集架构的<a href="https://zh.wikipedia.org/wiki/Cell_(微處理器" target="_blank" rel="external">Cell微架构</a>)。</p>
<p>申威 3231处理器是基于第三代“申威 64” 二次优化版核心（C3B）的国产高性能多核处理器。3231的内核与1621属于同一代，采用新一代工艺，最高主频2.5Ghz，32核心，3231基本上可以视为1621换工艺后的32核版本，主要面向高性能计算和高端服务器应用。</p>
<p>申威 3231采用“申威64”自主指令系统；</p>
<p>基于第三代“申威 64”二次优化版核心（C3B）的32核64位通用处理器;</p>
<p>采用CC-NUMA多核结构和SoC技术，片内包含8路DDR4存储控制器接口以及40lane的PCI-E 4.0标准I/O接口；</p>
<p>集成3路直连接口，可构建2路或4路服务器系统；</p>
<p>计算性能：双精度浮点性能可达1280GFlops，整数性能可达880Gops；</p>
<p>访存性能：最大传输率为3200Mbps，最大总存储器容量2TB；</p>
<p>I/O性能：双向聚合有效带宽可达到160GB/s，支持I/O虚拟化。</p>
<p><img src="/images/951413iMgBlog/641.png" alt="img"></p>
<p>3232推出的时间会比3231迟一些，采用新一代CPU核，IPC会非常惊人，保底10/G，争取12/G，考虑倒申威团队一向严谨，以及过去基本没有让大家失望过，因而对3232的IPC，可以采用就高原则。</p>
<p>申威 3231架构</p>
<p><img src="/images/951413iMgBlog/1604285554727-f6a30266-c4be-42b4-ad77-2fabbf066070.png" alt="image.png"></p>
<p>申威 6B 芯片结构的主要特点如下：</p>
<ul>
<li>全芯片集成 32 个物理核心，每个物理核心支持 1 个线程，软件可见 32 个逻辑核心；</li>
<li><p>每个物理核心集成 32KB L1 指令 Cache（ICache）、32KB L1 数据 Cache（DCache）和 512KB 的 L2 Cache（SCache），核心内的所有 Cache 为核心私有 Cache；</p>
</li>
<li><p>全芯片集成 64MB 的 L3 Cache（TCache），本芯片内所有核心分布共享，TCache 由16 个体组成，每个体跟2 个物理核心及其对应的管理部件（LCPM）一起组成一个核组，连接在环网节点上，核心访问不同 TCache 体中的副本延迟略有不同；</p>
</li>
<li><p>存储器接口：全芯片集成 8 个 DDR4 存储器通道，每个通道数据宽度为 72bit（含 8 位 ECC），支持 UDIMM、RDIMM 和 LRDIMM，单通道内存容量最大支持 256GB 容量，单通道带宽可达 25.6GB/s（DDR4-3200）；每4 个存储器通道对应一个主存代理部件（GCPM），所有核心和 IO 设备都可访问；</p>
</li>
<li><p>PCIe 接口：全芯片集成 40 Lane 的 PCIe 4.0 链路，支持 x4、x8 和 x16 灵活配置，最大支持 6 个 RC；</p>
</li>
<li><p>直连接口：全芯片集成 3 路直连接口，可构建 2 路或 4 路服务器系统，每路直连接口为9 个lane的serdes 接口，接口速率为28Gbps；</p>
</li>
<li><p>维护调试测试接口：维护控制部件实现芯片配置、初始引导以及提供各种维护和调试支持。维护控制部件支持芯片的上电初始化、配置加载、存储器读写或 IO 读写、维护中断以及内部状态的扫描观测等。支持外部维护通过 Jtag 接口进行初始引导；支持通过 SPI Master 接口从 SPI Flash中进行自举引导；</p>
</li>
<li>集成三套 I2C 接口、一套 Uart、GPIO 和 LPC 低速接口。</li>
</ul>
<p> 申威1621处理器是基于第三代“申威64”核心（增强版）的国产高性能多核处理器，主要面向高性能计算和中高端服务器应用。目前，该处理器已经实现量产。</p>
<p><img src="/images/951413iMgBlog/20170829092439580.png" alt="img">    申威1621采用对称多核结构和SoC技术，单芯片集成了16个64位RISC结构的申威处理器核心，目标设计主频为2GHz。芯片还集成八路DDR3存储控制器和双路PCI-E3.0标准I/O接口。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div></pre></td><td class="code"><pre><div class="line">#dmidecode -t processor</div><div class="line"># dmidecode 3.0</div><div class="line">Getting SMBIOS data from sysfs.</div><div class="line">SMBIOS 3.2.0 present.</div><div class="line"># SMBIOS implementations newer than version 3.0 are not</div><div class="line"># fully supported by this version of dmidecode.</div><div class="line"></div><div class="line">Handle 0x0022, DMI type 4, 48 bytes</div><div class="line">Processor Information</div><div class="line">        Socket Designation: CPU 0</div><div class="line">        Type: Central Processor</div><div class="line">        Family: Other</div><div class="line">        Manufacturer: SW3231</div><div class="line">        ID: 28 00 C8 80 01 00 00 00</div><div class="line">        Version: Product</div><div class="line">        Voltage: 3.3 V</div><div class="line">        External Clock: 200 MHz</div><div class="line">        Max Speed: 2400 MHz</div><div class="line">        Current Speed: 2400 MHz</div><div class="line">        Status: Unpopulated</div><div class="line">        Upgrade: Other</div><div class="line">        L1 Cache Handle: 0x2000</div><div class="line">        L2 Cache Handle: 0x2002</div><div class="line">        L3 Cache Handle: 0x2003</div><div class="line">        Serial Number: .......</div><div class="line">        Asset Tag: Asset Tag#To Be Filled By O.E.M.</div><div class="line">        Part Number: Part Number#To Be Filled By O.E.M.</div><div class="line">        Core Count: 32</div><div class="line">        Core Enabled: 32</div><div class="line">        Thread Count: 0</div><div class="line">        Characteristics:</div><div class="line">                64-bit capable</div><div class="line"></div><div class="line">Handle 0x0023, DMI type 4, 48 bytes</div><div class="line">Processor Information</div><div class="line">        Socket Designation: CPU 1</div><div class="line">        Type: Central Processor</div><div class="line">        Family: Other</div><div class="line">        Manufacturer: SW3231</div><div class="line">        ID: 28 00 C8 80 01 00 00 00</div><div class="line">        Version: Product</div><div class="line">        Voltage: 3.3 V</div><div class="line">        External Clock: 200 MHz</div><div class="line">        Max Speed: 2400 MHz</div><div class="line">        Current Speed: 2400 MHz</div><div class="line">        Status: Unpopulated</div><div class="line">        Upgrade: Other</div><div class="line">        L1 Cache Handle: 0x2000</div><div class="line">        L2 Cache Handle: 0x2002</div><div class="line">        L3 Cache Handle: 0x2003</div><div class="line">        Serial Number: .......</div><div class="line">        Asset Tag: Asset Tag#To Be Filled By O.E.M.</div><div class="line">        Part Number: Part Number#To Be Filled By O.E.M.</div><div class="line">        Core Count: 32</div><div class="line">        Core Enabled: 32</div><div class="line">        Thread Count: 0</div><div class="line">        Characteristics:</div><div class="line">                64-bit capable</div><div class="line"></div><div class="line"></div><div class="line">[root@d22b04001.cloud.b04.amtest11 /root] 193E_OPS1</div><div class="line">#numactl -H</div><div class="line">available: 2 nodes (0-1)</div><div class="line">node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31</div><div class="line">node 0 size: 259482 MB</div><div class="line">node 0 free: 121171 MB</div><div class="line">node 1 cpus: 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63</div><div class="line">node 1 size: 260091 MB</div><div class="line">node 1 free: 88564 MB</div><div class="line">node distances:</div><div class="line">node   0   1</div><div class="line">  0:  10  20</div><div class="line">  1:  20  10</div><div class="line"></div><div class="line">#lscpu</div><div class="line">Architecture:          sw_64</div><div class="line">CPU op-mode(s):        64-bit</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                64</div><div class="line">On-line CPU(s) list:   0-63</div><div class="line">Thread(s) per core:    1</div><div class="line">Core(s) per socket:    32</div><div class="line">Socket(s):             2</div><div class="line">NUMA node(s):          2</div><div class="line">Vendor ID:             sw</div><div class="line">CPU family:            6</div><div class="line">Model:                 6</div><div class="line">Model name:            sw</div><div class="line">CPU MHz:               2400.00</div><div class="line">BogoMIPS:              4800.00</div><div class="line">NUMA node0 CPU(s):     0-31</div><div class="line">NUMA node1 CPU(s):     32-63</div></pre></td></tr></table></figure>
<h2 id="openssl-speed-aes-256-ige性能比较"><a href="#openssl-speed-aes-256-ige性能比较" class="headerlink" title="openssl speed aes-256-ige性能比较"></a>openssl speed aes-256-ige性能比较</h2><p>测试脚本</p>
<blockquote>
<p>openssl speed aes-256-ige -multi 1</p>
</blockquote>
<p>单核能力</p>
<table>
<thead>
<tr>
<th>Intel (52物理core)</th>
<th>aes-256 ige      89602.86k    97498.37k    98271.49k    98399.91k    89101.65k</th>
</tr>
</thead>
<tbody>
<tr>
<td>海光（32物理core）</td>
<td>aes-256 ige      76919.66k    77935.81k    79201.88k    79529.30k    79555.24k</td>
</tr>
<tr>
<td>鲲鹏920（96物理core)</td>
<td>aes-256 ige     133174.89k   140578.99k   142156.46k   142663.34k   143196.16k</td>
</tr>
</tbody>
</table>
<p>测试32个线程并行</p>
<table>
<thead>
<tr>
<th>Intel (52物理core)</th>
<th>aes-256 ige    2642742.25k  2690638.98k  2703860.74k  2734114.82k  2680422.40</th>
</tr>
</thead>
<tbody>
<tr>
<td>海光（32物理core）</td>
<td>aes-256 ige    2464568.75k  2499381.80k  2528665.34k  2544845.14k  2550723.93k</td>
</tr>
<tr>
<td>鲲鹏920（96物理core)</td>
<td>aes-256 ige    4261589.92k  4501245.55k  4552731.56k  4570456.75k  4584330.58k</td>
</tr>
</tbody>
</table>
<p>将所有核跑满包括HT</p>
<table>
<thead>
<tr>
<th>Intel (52物理core)</th>
<th>aes-256 ige    4869950.82k  5179884.71k  5135412.14k  5211367.08k  5247858.60k</th>
</tr>
</thead>
<tbody>
<tr>
<td>海光（32物理core）</td>
<td>aes-256 ige    2730195.74k  2836759.53k  2865252.35k  2857900.71k  2884302.17k</td>
</tr>
<tr>
<td>鲲鹏920（96物理core)</td>
<td>aes-256 ige   12788358.79k 13502288.53k 13657385.98k 13710908.76k 13751432.53k</td>
</tr>
</tbody>
</table>
<h2 id="单核计算-7-999999”-的性能对比"><a href="#单核计算-7-999999”-的性能对比" class="headerlink" title="单核计算 7^999999” 的性能对比"></a>单核计算 7^999999” 的性能对比</h2><p>测试命令：bash -c ‘echo “7^999999” | bc &gt; /dev/null’</p>
<table>
<thead>
<tr>
<th></th>
<th>执行时间(秒)</th>
<th>IPC</th>
<th>主频</th>
</tr>
</thead>
<tbody>
<tr>
<td>海光</td>
<td>26.729972414</td>
<td>0.92</td>
<td>2.5G</td>
</tr>
<tr>
<td>鲲鹏920</td>
<td>24.604603640</td>
<td>1.84</td>
<td>2.6G</td>
</tr>
<tr>
<td>飞腾2500</td>
<td>39.654819568</td>
<td>0.43</td>
<td>2.1G</td>
</tr>
<tr>
<td>Intel</td>
<td>18.603323495</td>
<td>2.19</td>
<td>2.5G</td>
</tr>
</tbody>
</table>
<p>当然也可以通过计算pi值来测试</p>
<blockquote>
<p>bash -c ‘ echo “scale=5000; 4*a(1)” | bc -l -q &gt;/dev/null ‘</p>
</blockquote>
<p>多核一起跑的话可以这样:</p>
<blockquote>
<p>for i in {0..95}; do time echo “scale=5000; 4*a(1)” | bc -l -q &gt;/dev/null &amp; done</p>
<p>perf stat -e branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,stalled-cycles-backend,stalled-cycles-frontend,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-store-misses,L1-dcache-stores,L1-icache-load-misses,L1-icache-loads,branch-load-misses,branch-loads,dTLB-load-misses,dTLB-loads,iTLB-load-misses,iTLB-loads – </p>
</blockquote>
<h3 id="intel"><a href="#intel" class="headerlink" title="intel"></a>intel</h3><p>耗时18.60秒，ipc 2.19</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"># sudo perf stat -e branch-instructions,branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,ref-cycles,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-stores,L1-icache-load-misses,LLC-load-misses,LLC-loads,LLC-store-misses,LLC-stores,branch-load-misses,branch-loads,dTLB-load-misses,dTLB-loads,dTLB-store-misses,dTLB-stores,iTLB-load-misses,iTLB-loads,node-load-misses,node-loads,node-store-misses,node-stores -- bash -c &apos;echo &quot;7^999999&quot; | bc &gt; /dev/null&apos;</div><div class="line"></div><div class="line"> Performance counter stats for &apos;bash -c echo &quot;7^999999&quot; | bc &gt; /dev/null&apos;:</div><div class="line"></div><div class="line">    25,130,886,211      branch-instructions                                           (10.72%)</div><div class="line">     1,200,086,175      branch-misses             #    4.78% of all branches          (14.29%)</div><div class="line">       460,824,074      bus-cycles                                                    (14.29%)</div><div class="line">         1,983,459      cache-misses              #   46.066 % of all cache refs      (14.30%)</div><div class="line">         4,305,730      cache-references                                              (14.30%)</div><div class="line">    58,626,314,801      cpu-cycles                                                    (17.87%)</div><div class="line">   128,284,870,917      instructions              #    2.19  insn per cycle           (21.45%)</div><div class="line">    46,040,656,499      ref-cycles                                                    (25.02%)</div><div class="line">        22,821,794      L1-dcache-load-misses     #    0.10% of all L1-dcache hits    (25.02%)</div><div class="line">    23,041,732,649      L1-dcache-loads                                               (25.01%)</div><div class="line">     5,386,243,625      L1-dcache-stores                                              (25.00%)</div><div class="line">        12,443,154      L1-icache-load-misses                                         (25.00%)</div><div class="line">           178,790      LLC-load-misses           #   30.52% of all LL-cache hits     (14.28%)</div><div class="line">           585,724      LLC-loads                                                     (14.28%)</div><div class="line">           469,381      LLC-store-misses                                              (7.14%)</div><div class="line">           664,865      LLC-stores                                                    (7.14%)</div><div class="line">     1,201,547,113      branch-load-misses                                            (10.71%)</div><div class="line">    25,139,625,428      branch-loads                                                  (14.28%)</div><div class="line">            63,334      dTLB-load-misses          #    0.00% of all dTLB cache hits   (14.28%)</div><div class="line">    23,023,969,089      dTLB-loads                                                    (14.28%)</div><div class="line">            17,355      dTLB-store-misses                                             (14.28%)</div><div class="line">     5,378,496,562      dTLB-stores                                                   (14.28%)</div><div class="line">           341,119      iTLB-load-misses          #  119.92% of all iTLB cache hits   (14.28%)</div><div class="line">           284,445      iTLB-loads                                                    (14.28%)</div><div class="line">           151,608      node-load-misses                                              (14.28%)</div><div class="line">            37,553      node-loads                                                    (14.29%)</div><div class="line">           434,537      node-store-misses                                             (7.14%)</div><div class="line">            65,709      node-stores                                                   (7.14%)</div><div class="line"></div><div class="line">      18.603323495 seconds time elapsed</div><div class="line"></div><div class="line">      18.525904000 seconds user</div><div class="line">       0.015197000 seconds sys</div></pre></td></tr></table></figure>
<h3 id="鲲鹏920-1"><a href="#鲲鹏920-1" class="headerlink" title="鲲鹏920"></a>鲲鹏920</h3><p>耗时24.6秒, IPC 1.84</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">#perf stat -e branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,stalled-cycles-backend,stalled-cycles-frontend,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-store-misses,L1-dcache-stores,L1-icache-load-misses,L1-icache-loads,branch-load-misses,branch-loads,dTLB-load-misses,dTLB-loads,iTLB-load-misses,iTLB-loads -- bash -c &apos;echo &quot;7^999999&quot; | bc &gt; /dev/null&apos;</div><div class="line"></div><div class="line"> Performance counter stats for &apos;bash -c echo &quot;7^999999&quot; | bc &gt; /dev/null&apos;:</div><div class="line"></div><div class="line">     1,467,769,425      branch-misses                                                 (59.94%)</div><div class="line">    63,866,536,853      bus-cycles                                                    (59.94%)</div><div class="line">         6,571,273      cache-misses              #    0.021 % of all cache refs      (59.94%)</div><div class="line">    30,768,754,927      cache-references                                              (59.96%)</div><div class="line">    63,865,354,560      cpu-cycles                                                    (64.97%)</div><div class="line">   117,790,453,518      instructions              #    1.84  insns per cycle</div><div class="line">                                                  #    0.07  stalled cycles per insn  (64.98%)</div><div class="line">       833,090,930      stalled-cycles-backend    #    1.30% backend  cycles idle     (65.00%)</div><div class="line">     7,918,227,782      stalled-cycles-frontend   #   12.40% frontend cycles idle     (65.01%)</div><div class="line">         6,962,902      L1-dcache-load-misses     #    0.02% of all L1-dcache hits    (65.03%)</div><div class="line">    30,804,266,645      L1-dcache-loads                                               (65.05%)</div><div class="line">         6,960,157      L1-dcache-store-misses                                        (65.06%)</div><div class="line">    30,807,954,068      L1-dcache-stores                                              (65.06%)</div><div class="line">         1,012,171      L1-icache-load-misses                                         (65.06%)</div><div class="line">    45,256,066,296      L1-icache-loads                                               (65.04%)</div><div class="line">     1,470,467,198      branch-load-misses                                            (65.03%)</div><div class="line">    27,108,794,972      branch-loads                                                  (65.01%)</div><div class="line">           475,707      dTLB-load-misses          #    0.00% of all dTLB cache hits   (65.00%)</div><div class="line">    35,159,826,836      dTLB-loads                                                    (59.97%)</div><div class="line">               912      iTLB-load-misses          #    0.00% of all iTLB cache hits   (59.96%)</div><div class="line">    45,325,885,822      iTLB-loads                                                    (59.94%)</div><div class="line"></div><div class="line">      24.604603640 seconds time elapsed</div></pre></td></tr></table></figure>
<h3 id="海光-1"><a href="#海光-1" class="headerlink" title="海光"></a>海光</h3><p>耗时 26.73秒, IPC 0.92</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">sudo perf stat -e branch-instructions,branch-misses,cache-references,cpu-cycles,instructions,stalled-cycles-backend,stalled-cycles-frontend,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-prefetches,L1-icache-load-misses,L1-icache-loads,branch-load-misses,branch-loads,dTLB-load-misses,dTLB-loads,iTLB-load-misses,iTLB-loads -a -- bash -c &apos;echo &quot;7^999999&quot; | bc &gt; /dev/null&apos;</div><div class="line"></div><div class="line"> Performance counter stats for &apos;system wide&apos;:</div><div class="line"></div><div class="line">    57,795,675,025      branch-instructions                                           (27.78%)</div><div class="line">     2,459,509,459      branch-misses             #    4.26% of all branches          (27.78%)</div><div class="line">    12,171,133,272      cache-references                                              (27.79%)</div><div class="line">   317,353,262,523      cpu-cycles                                                    (27.79%)</div><div class="line">   293,162,940,548      instructions              #    0.92  insn per cycle</div><div class="line">                                                  #    0.19  stalled cycles per insn  (27.79%)</div><div class="line">    55,152,807,029      stalled-cycles-backend    #   17.38% backend cycles idle      (27.79%)</div><div class="line">    44,410,732,991      stalled-cycles-frontend   #   13.99% frontend cycles idle     (27.79%)</div><div class="line">     4,065,273,083      L1-dcache-load-misses     #    3.58% of all L1-dcache hits    (27.79%)</div><div class="line">   113,699,208,151      L1-dcache-loads                                               (27.79%)</div><div class="line">     1,351,513,191      L1-dcache-prefetches                                          (27.79%)</div><div class="line">     2,091,035,340      L1-icache-load-misses     #    4.43% of all L1-icache hits    (27.79%)</div><div class="line">    47,240,289,316      L1-icache-loads                                               (27.79%)</div><div class="line">     2,459,838,728      branch-load-misses                                            (27.79%)</div><div class="line">    57,855,156,991      branch-loads                                                  (27.78%)</div><div class="line">        69,731,473      dTLB-load-misses          #   20.40% of all dTLB cache hits   (27.78%)</div><div class="line">       341,773,319      dTLB-loads                                                    (27.78%)</div><div class="line">        26,351,132      iTLB-load-misses          #   15.91% of all iTLB cache hits   (27.78%)</div><div class="line">       165,656,863      iTLB-loads                                                    (27.78%)</div><div class="line"></div><div class="line">      26.729972414 seconds time elapsed</div></pre></td></tr></table></figure>
<h3 id="飞腾"><a href="#飞腾" class="headerlink" title="飞腾"></a>飞腾</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">time perf stat -e branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-store-misses,L1-dcache-stores,L1-icache-load-misses,L1-icache-loads,branch-load-misses,branch-loads,dTLB-load-misses,iTLB-load-misses -a -- bash -c &apos;echo &quot;7^999999&quot; | bc &gt; /dev/null&apos;</div><div class="line"></div><div class="line"> Performance counter stats for &apos;system wide&apos;:</div><div class="line"></div><div class="line">        2552812813      branch-misses                                                 (38.08%)</div><div class="line">      602038279874      bus-cycles                                                    (37.54%)</div><div class="line">        1742826523      cache-misses              #    2.017 % of all cache refs      (37.54%)</div><div class="line">       86400294181      cache-references                                              (37.55%)</div><div class="line">      612467194375      cpu-cycles                                                    (43.79%)</div><div class="line">      263691445872      instructions              #    0.43  insns per cycle          (43.79%)</div><div class="line">        1706247569      L1-dcache-load-misses     #    2.00% of all L1-dcache hits    (43.78%)</div><div class="line">       85122454139      L1-dcache-loads                                               (43.77%)</div><div class="line">        1711243358      L1-dcache-store-misses                                        (39.38%)</div><div class="line">       86288158984      L1-dcache-stores                                              (37.52%)</div><div class="line">        2006641212      L1-icache-load-misses                                         (37.51%)</div><div class="line">      146380907111      L1-icache-loads                                               (37.51%)</div><div class="line">        2560208048      branch-load-misses                                            (37.52%)</div><div class="line">       63127187342      branch-loads                                                  (41.38%)</div><div class="line">         768494735      dTLB-load-misses                                              (43.77%)</div><div class="line">         124424415      iTLB-load-misses                                              (43.77%)</div><div class="line"></div><div class="line">      39.654819568 seconds time elapsed</div><div class="line"></div><div class="line">real    0m39.763s</div><div class="line">user    0m39.635s</div><div class="line">sys    0m0.127s</div></pre></td></tr></table></figure>
<h2 id="perf-数据对比"><a href="#perf-数据对比" class="headerlink" title="perf 数据对比"></a>perf 数据对比</h2><h3 id="Intel"><a href="#Intel" class="headerlink" title="Intel"></a>Intel</h3><p>intel的cpu随着线程的增加，ipc稳定减少，但不是线性的</p>
<p><img src="/images/oss/dcb68dff74ace2cf6f9c30378acdb377.png" alt="image.png"></p>
<p><img src="/images/oss/d0151c855011b24590efd672398bd9eb.png" alt="image.png"></p>
<p><img src="/images/oss/175a1df9274a830d4a7157dfda96c180.png" alt="image.png"></p>
<p><img src="/images/oss/e63a992fcd1df547568eb93f515a5c99.png" alt="image.png"></p>
<h3 id="海光-2"><a href="#海光-2" class="headerlink" title="海光"></a>海光</h3><p>如下数据可以看到在用满32个物理core之前，ipc保持稳定，超过32core后随着并发增加ipc相应减少，性能再也上不去了。</p>
<p><img src="/images/oss/ded1ee0ed8d5d2fa3822e6fdfa4335f1.png" alt="image.png"></p>
<p><img src="/images/oss/0f2410165932835a36d8c0611877ae77.png" alt="image.png"></p>
<p><img src="/images/oss/67df9ff04209a00bd864ba21b7593477.png" alt="image.png"></p>
<p><img src="/images/oss/1bc01f6e880c7e49672170f940ff40a0.png" alt="image.png"></p>
<p><img src="/images/oss/307d30c2b3507d5561d774f96b13e67a.png" alt="image.png"></p>
<h3 id="鲲鹏920-2"><a href="#鲲鹏920-2" class="headerlink" title="鲲鹏920"></a>鲲鹏920</h3><p>可以看到<strong>鲲鹏920多核跑openssl是没有什么争抢的，所以还能保证完全线性</strong></p>
<p><img src="/images/oss/39720b5eb41937b462e1772854e2d832.png" alt="image.png"></p>
<p><img src="/images/oss/a98a482a10f09bccd4a6ac49fd2850b9.png" alt="image.png"></p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>intel的流水线适合跑高带宽应用，不适合跑密集计算应用，也就是intel的pipeline数量少，但是内存读写上面优化好，乱序优化好。跑纯计算，不是intel的强项。</p>
<p>数据库场景下鲲鹏920大概相当于X86的70%的能力</p>
<p>prime计算一般走的fpu，不走cpu</p>
<h2 id="intel-x86-cpu-bound和memory-bond数据"><a href="#intel-x86-cpu-bound和memory-bond数据" class="headerlink" title="intel x86 cpu bound和memory bond数据"></a>intel x86 cpu bound和memory bond数据</h2><p>测试代码</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;emmintrin.h&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;signal.h&gt;</span></span></div><div class="line"></div><div class="line"><span class="keyword">char</span> a = <span class="number">1</span>;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">memory_bound</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">register</span> <span class="keyword">unsigned</span> i=<span class="number">0</span>;</div><div class="line">        <span class="keyword">register</span> <span class="keyword">char</span> b;</div><div class="line"></div><div class="line">        <span class="keyword">for</span> (i=<span class="number">0</span>;i&lt;(<span class="number">1u</span>&lt;&lt;<span class="number">24</span>);i++) &#123;</div><div class="line">                <span class="comment">// evict cacheline containing a</span></div><div class="line">                 _mm_clflush(&amp;a);</div><div class="line">                 b = a;</div><div class="line">        &#125;</div><div class="line">&#125;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">cpu_bound</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">register</span> <span class="keyword">unsigned</span> i=<span class="number">0</span>;</div><div class="line">        <span class="keyword">for</span> (i=<span class="number">0</span>;i&lt;(<span class="number">1u</span>&lt;&lt;<span class="number">31</span>);i++) &#123;</div><div class="line">                __asm__ (<span class="string">"nop\nnop\nnop"</span>);</div><div class="line">        &#125;</div><div class="line">&#125;</div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> i=<span class="number">0</span>;</div><div class="line">          <span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;<span class="number">10</span>; ++i)&#123;</div><div class="line">                 <span class="comment">//cpu_bound();</span></div><div class="line">                 memory_bound();</div><div class="line">          &#125;</div><div class="line">        <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a><strong>测试结果</strong></h3><p><strong>cpu_bound部分飞腾只有intel性能的30%</strong></p>
<p>如下测试perf数据可以看到IPC的明显差异</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash"> sudo perf <span class="built_in">stat</span> -e branch-instructions,branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,ref-cycles,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-stores,L1-icache-load-misses,LLC-load-misses,LLC-loads,LLC-store-misses,LLC-stores,branch-load-misses,branch-loads,dTLB-load-misses,dTLB-loads,dTLB-store-misses,dTLB-stores,iTLB-load-misses,iTLB-loads,node-load-misses,node-loads,node-store-misses,node-stores -a ./memory_bound</span></div><div class="line"></div><div class="line"> Performance counter stats for 'system wide':</div><div class="line"></div><div class="line">    36,162,872,212      branch-instructions                                           (14.21%)</div><div class="line">       586,644,153      branch-misses             #    1.62% of all branches          (12.95%)</div><div class="line">     4,632,787,085      bus-cycles                                                    (14.40%)</div><div class="line">       476,189,785      cache-misses              #   17.714 % of all cache refs      (14.38%)</div><div class="line">     2,688,284,129      cache-references                                              (14.35%)</div><div class="line">   258,946,713,506      cpu-cycles                                                    (17.93%)</div><div class="line">   181,069,328,200      instructions              #    0.70  insn per cycle           (21.51%)</div><div class="line">   456,889,428,341      ref-cycles                                                    (22.31%)</div><div class="line">     3,928,434,098      L1-dcache-load-misses     #    7.46% of all L1-dcache hits    (14.21%)</div><div class="line">    52,656,559,902      L1-dcache-loads                                               (14.31%)</div><div class="line">    26,711,751,387      L1-dcache-stores                                              (14.30%)</div><div class="line">     2,618,739,340      L1-icache-load-misses                                         (18.05%)</div><div class="line">       154,326,888      LLC-load-misses           #    8.60% of all LL-cache hits     (19.84%)</div><div class="line">     1,795,112,198      LLC-loads                                                     (9.81%)</div><div class="line">        66,802,375      LLC-store-misses                                              (10.19%)</div><div class="line">       206,810,811      LLC-stores                                                    (11.16%)</div><div class="line">       586,120,789      branch-load-misses                                            (14.28%)</div><div class="line">    36,121,237,395      branch-loads                                                  (14.29%)</div><div class="line">       114,927,298      dTLB-load-misses          #    0.22% of all dTLB cache hits   (14.29%)</div><div class="line">    52,902,163,128      dTLB-loads                                                    (14.29%)</div><div class="line">         7,010,297      dTLB-store-misses                                             (14.29%)</div><div class="line">    26,587,353,417      dTLB-stores                                                   (18.00%)</div><div class="line">       106,209,281      iTLB-load-misses          #  174.17% of all iTLB cache hits   (19.33%)</div><div class="line">        60,978,626      iTLB-loads                                                    (21.53%)</div><div class="line">       117,197,042      node-load-misses                                              (19.71%)</div><div class="line">        35,764,508      node-loads                                                    (11.65%)</div><div class="line">        57,655,994      node-store-misses                                             (7.80%)</div><div class="line">        11,563,328      node-stores                                                   (9.45%)</div><div class="line"></div><div class="line">      16.700731355 seconds time elapsed</div><div class="line"><span class="meta"></span></div><div class="line">#<span class="bash"> sudo perf <span class="built_in">stat</span> -e branch-instructions,branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,ref-cycles,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-stores,L1-icache-load-misses,LLC-load-misses,LLC-loads,LLC-store-misses,LLC-stores,branch-load-misses,branch-loads,dTLB-load-misses,dTLB-loads,dTLB-store-misses,dTLB-stores,iTLB-load-misses,iTLB-loads,node-load-misses,node-loads,node-store-misses,node-stores -a ./cpu_bound</span></div><div class="line"></div><div class="line"> Performance counter stats for 'system wide':</div><div class="line"></div><div class="line">    43,013,055,562      branch-instructions                                           (14.33%)</div><div class="line">       436,722,063      branch-misses             #    1.02% of all branches          (11.58%)</div><div class="line">     3,154,327,457      bus-cycles                                                    (14.31%)</div><div class="line">       306,977,772      cache-misses              #   17.837 % of all cache refs      (14.42%)</div><div class="line">     1,721,062,233      cache-references                                              (14.39%)</div><div class="line">   176,119,834,487      cpu-cycles                                                    (17.98%)</div><div class="line">   276,038,539,571      instructions              #    1.57  insn per cycle           (21.55%)</div><div class="line">   309,334,354,268      ref-cycles                                                    (22.31%)</div><div class="line">     2,551,915,790      L1-dcache-load-misses     #    6.78% of all L1-dcache hits    (13.12%)</div><div class="line">    37,638,319,334      L1-dcache-loads                                               (14.32%)</div><div class="line">    19,132,537,445      L1-dcache-stores                                              (15.73%)</div><div class="line">     1,834,976,400      L1-icache-load-misses                                         (18.90%)</div><div class="line">       131,307,343      LLC-load-misses           #   11.46% of all LL-cache hits     (19.94%)</div><div class="line">     1,145,964,874      LLC-loads                                                     (16.60%)</div><div class="line">        45,561,247      LLC-store-misses                                              (8.11%)</div><div class="line">       140,236,535      LLC-stores                                                    (9.60%)</div><div class="line">       423,294,349      branch-load-misses                                            (14.27%)</div><div class="line">    46,645,623,485      branch-loads                                                  (14.28%)</div><div class="line">        73,377,533      dTLB-load-misses          #    0.19% of all dTLB cache hits   (14.28%)</div><div class="line">    37,905,428,246      dTLB-loads                                                    (15.69%)</div><div class="line">         4,969,973      dTLB-store-misses                                             (17.21%)</div><div class="line">    18,729,947,580      dTLB-stores                                                   (19.71%)</div><div class="line">        72,073,313      iTLB-load-misses          #  167.86% of all iTLB cache hits   (20.60%)</div><div class="line">        42,935,532      iTLB-loads                                                    (19.16%)</div><div class="line">       112,306,453      node-load-misses                                              (15.35%)</div><div class="line">        37,239,267      node-loads                                                    (7.44%)</div><div class="line">        37,455,335      node-store-misses                                             (10.00%)</div><div class="line">         8,134,155      node-stores                                                   (8.87%)</div><div class="line"></div><div class="line">      10.838808208 seconds time elapsed</div></pre></td></tr></table></figure>
<h3 id="飞腾-1"><a href="#飞腾-1" class="headerlink" title="飞腾"></a>飞腾</h3><p>ipc 大概是intel的30%，加上主频也要差一些，</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash">time perf <span class="built_in">stat</span> -e branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-store-misses,L1-dcache-stores,L1-icache-load-misses,L1-icache-loads,branch-load-misses,branch-loads,dTLB-load-misses,iTLB-load-misses -a ./cpu_bound</span></div><div class="line"></div><div class="line"> Performance counter stats for 'system wide':</div><div class="line"></div><div class="line">       10496356859      branch-misses                                                 (37.60%)</div><div class="line">     2813170983911      bus-cycles                                                    (37.58%)</div><div class="line">       17604745519      cache-misses              #    3.638 % of all cache refs      (37.55%)</div><div class="line">      483878256161      cache-references                                              (37.54%)</div><div class="line">     2818545529083      cpu-cycles                                                    (43.78%)</div><div class="line">     1280497827941      instructions              #    0.45  insns per cycle          (43.78%)</div><div class="line">       17623592806      L1-dcache-load-misses     #    3.65% of all L1-dcache hits    (43.78%)</div><div class="line">      482429613337      L1-dcache-loads                                               (41.83%)</div><div class="line">       17604561232      L1-dcache-store-misses                                        (37.53%)</div><div class="line">      484126081882      L1-dcache-stores                                              (37.52%)</div><div class="line">       17774514325      L1-icache-load-misses                                         (37.50%)</div><div class="line">      641046300400      L1-icache-loads                                               (37.50%)</div><div class="line">       10574973722      branch-load-misses                                            (39.45%)</div><div class="line">      273851009656      branch-loads                                                  (43.76%)</div><div class="line">        9457594390      dTLB-load-misses                                              (43.77%)</div><div class="line">        1813954093      iTLB-load-misses                                              (43.77%)</div><div class="line"></div><div class="line">      31.172754504 seconds time elapsed</div><div class="line"></div><div class="line">real    0m31.284s</div><div class="line">user    0m31.096s</div><div class="line">sys    0m0.165s</div></pre></td></tr></table></figure>
<h2 id="unixBench-5-1-3-性能对比"><a href="#unixBench-5-1-3-性能对比" class="headerlink" title="unixBench 5.1.3 性能对比"></a>unixBench 5.1.3 性能对比</h2><p>测试命令： ./Run -c 1 -c 4</p>
<table>
<thead>
<tr>
<th>芯片</th>
<th>架构</th>
<th>逻辑核数</th>
<th>单核能力</th>
<th>4核能力</th>
<th>单核比值</th>
<th>4核比值</th>
<th>整机对比</th>
</tr>
</thead>
<tbody>
<tr>
<td>Intel 4114</td>
<td>x86</td>
<td>40</td>
<td>1150</td>
<td>3095</td>
<td>100%</td>
<td>100%</td>
<td>100%</td>
</tr>
<tr>
<td>海光 7165</td>
<td>x86</td>
<td>48</td>
<td>1586</td>
<td>2533</td>
<td>138%</td>
<td>82%</td>
<td>98%</td>
</tr>
<tr>
<td>华为鲲鹏920</td>
<td>arm</td>
<td>96</td>
<td>1168</td>
<td>2066</td>
<td>102%</td>
<td>67%</td>
<td>160%</td>
</tr>
<tr>
<td>飞腾2000</td>
<td>arm</td>
<td>64</td>
<td>731</td>
<td>1902</td>
<td>64%</td>
<td>61%</td>
<td>98%</td>
</tr>
<tr>
<td>申威1621</td>
<td>alpha</td>
<td>16</td>
<td>445</td>
<td>1065</td>
<td>39%</td>
<td>34%</td>
<td>14%</td>
</tr>
</tbody>
</table>
<p>以上CPU除了Intel，其它都没有HT，也就是Intel 4114实际是20个物理核。以上数据来自ata，仅供参考</p>
<h2 id="ARM-和-X86的总结"><a href="#ARM-和-X86的总结" class="headerlink" title="ARM 和 X86的总结"></a>ARM 和 X86的总结</h2><p>对比硬件：</p>
<p>ARM：泰山ARM 双路 128核心64核心/路），2.5G，4指令/周期，8个内存通道/路，mips体系架构。<br>X86: intel 8163服务器 双路 48核心（24核心/路），2.5GHZ， 6指令/周期，96smt， 6个内存通道</p>
<p>用 Geabase(C++)  测试所得 ARM是X86 性能的1.36倍，接近理论值的1.4倍</p>
<p>理论值的计算公式：</p>
<blockquote>
<p>CPU性能验证公式：频率 x 核数 x 发射数/周期 x 1.3/1.5(smt2/smt4) (smt是指超线程数量)</p>
</blockquote>
<p>ARM 优势的来源主要是工艺领先一代(7nm VS 14nm)</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li>对纯CPU 运算场景，并发不超过物理core时，比如Prime运算，比如DRDS(CPU bound，IO在网络，可以加并发弥补)<ul>
<li>海光的IPC能保持稳定；</li>
<li>intel的IPC有所下降，但是QPS在IPC下降后还能完美线性</li>
</ul>
</li>
<li>在openssl和MySQL oltp_read_only场景下<ul>
<li>如果并发没超过物理core数时，海光和Intel都能随着并发的翻倍性能能增加80%</li>
<li>如果并发超过物理core数后，Intel还能随着并发的翻倍性能增加50%，海光增加就只有20%了</li>
<li>简单理解在这两个场景下Intel的HT能发挥半个物理core的作用，海光的HT就只能发挥0.2个物理core的作用了</li>
</ul>
</li>
<li>海光zen1的AMD 架构，每个core只有一个fpu，综上在多个场景下HT基本上都可以忽略</li>
<li>飞腾2500性能比较差</li>
<li>国产CPU：飞腾、鲲鹏、龙芯、申威、海光(AMD授权)、兆芯(威盛via 授权x86)</li>
<li>CPU性能验证公式：频率 x 核数 x 发射数/周期 x 1.3/1.5(smt2/smt4) (smt是指超线程数量)</li>
<li>大吞吐量计算由多核CPU数量决定，多核CPU数量由制程工艺决定，制程工艺由资本决定，制程工艺资本由主流消费电子决定, 摩尔定律仍在持续</li>
</ul>
<h2 id="系列文章-1"><a href="#系列文章-1" class="headerlink" title="系列文章"></a>系列文章</h2><p><a href="/2021/06/01/CPU的制造和概念/">CPU的制造和概念</a></p>
<p><a href="/2021/05/16/CPU Cache Line 和性能/">CPU 性能和Cache Line</a></p>
<p><a href="/2021/05/16/Perf IPC以及CPU利用率/">Perf IPC以及CPU性能</a></p>
<p><a href="/2021/06/18/几款CPU性能对比/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></p>
<p><a href="/2021/05/15/飞腾ARM芯片(FT2500">飞腾ARM芯片(FT2500)的性能测试</a>的性能测试/)</p>
<p><a href="/2021/05/14/十年后数据库还是不敢拥抱NUMA/">十年后数据库还是不敢拥抱NUMA？</a></p>
<p><a href="/2021/03/07/一次海光物理机资源竞争压测的记录/">一次海光物理机资源竞争压测的记录</a></p>
<p><a href="/2019/12/16/Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的/">Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的</a></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://www.atatech.org/articles/157681" target="_blank" rel="external">Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的</a></p>
<p><a href="https://bbs.huaweicloud.com/blogs/146367" target="_blank" rel="external">华为TaiShan服务器ARMNginx应用调优案例 大量绑核、中断、Numa等相关调优信息</a></p>
<p><a href="https://topic.atatech.org/articles/178985" target="_blank" rel="external">主流处理器内部单核微架构细节1——AMD ZEN(即海光)微架构</a></p>
<p><a href="https://topic.atatech.org/articles/178986" target="_blank" rel="external">主流处理器内部单核微架构细节2——Skylake微架构</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/06/01/CPU的制造和概念/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/06/01/CPU的制造和概念/" itemprop="url">CPU的制造和概念</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-06-01T17:30:03+08:00">
                2021-06-01
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CPU/" itemprop="url" rel="index">
                    <span itemprop="name">CPU</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="CPU的制造和概念"><a href="#CPU的制造和概念" class="headerlink" title="CPU的制造和概念"></a>CPU的制造和概念</h1><p>为了让程序能快点，特意了解了CPU的各种原理，比如多核、超线程、NUMA、睿频、功耗、GPU、大小核再到分支预测、cache_line失效、加锁代价、IPC等各种指标（都有对应的代码和测试数据）都会在这系列文章中得到答案。当然一定会有程序员最关心的分支预测案例、Disruptor无锁案例、cache_line伪共享案例等等。</p>
<p>这次让我们从最底层的沙子开始用8篇文章来回答各种疑问以及大量的实验对比案例和测试数据。</p>
<p>大的方面主要是从这几个疑问来写这些文章：</p>
<ul>
<li>同样程序为什么CPU跑到800%还不如CPU跑到200%快？</li>
<li>IPC背后的原理和和程序效率的关系？</li>
<li>为什么数据库领域都爱把NUMA关了，这对吗？</li>
<li>几个国产芯片的性能到底怎么样？</li>
</ul>
<h2 id="系列文章"><a href="#系列文章" class="headerlink" title="系列文章"></a>系列文章</h2><p><a href="/2021/06/01/CPU的制造和概念/">CPU的制造和概念</a></p>
<p><a href="/2021/05/16/Perf IPC以及CPU利用率/">Perf IPC以及CPU性能</a></p>
<p><a href="https://plantegg.github.io/2021/07/19/CPU性能和CACHE/">CPU性能和CACHE</a></p>
<p><a href="/2021/05/16/CPU Cache Line 和性能/">CPU 性能和Cache Line</a></p>
<p><a href="/2021/05/14/十年后数据库还是不敢拥抱NUMA/">十年后数据库还是不敢拥抱NUMA？</a></p>
<p><a href="/2019/12/16/Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的/">Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的</a></p>
<p><a href="/2021/08/13/AMD_Zen_CPU架构/">AMD Zen CPU 架构 以及 AMD、海光、Intel、鲲鹏的性能对比</a></p>
<p><a href="/2021/06/18/几款CPU性能对比/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></p>
<p><a href="/2021/03/07/一次海光物理机资源竞争压测的记录/">一次海光物理机资源竞争压测的记录</a></p>
<p><a href="/2021/05/15/飞腾ARM芯片-FT2500的性能测试/">飞腾ARM芯片(FT2500)的性能测试</a></p>
<p><img src="/images/951413iMgBlog/image-20210802161410524-1011377.png" alt="image-20210802161410524"></p>
<h2 id="几个重要概念"><a href="#几个重要概念" class="headerlink" title="几个重要概念"></a>几个重要概念</h2><p>为了增加对文章的理解先解释下几个高频概念</p>
<p>Wafer：晶圆，一片大的纯硅圆盘，新闻里常说的12寸、30寸晶圆厂说的就是它，光刻机在晶圆上蚀刻出电路</p>
<p>Die：从晶圆上切割下来的CPU(通常一个Die中包含多个core、L3cache、内存接口、GPU等，core里面又包含了L1、L2cache），Die的大小可以自由决定，得考虑成本和性能, Die做成方形便于切割和测试，服务器所用的Intel CPU的Die大小一般是大拇指指甲大小。</p>
<p>封装：将一个或多个Die封装成一个物理上可以售卖的CPU</p>
<p>路：就是socket、也就是封装后的物理CPU</p>
<p>node：同一个Die下的多个core以及他们对应的内存，对应着NUMA</p>
<h2 id="售卖的CPU实物"><a href="#售卖的CPU实物" class="headerlink" title="售卖的CPU实物"></a>售卖的CPU实物</h2><p>购买到的CPU实体外观和大小，一般是40mm X 50mm大小，可以看出一个CPU比一个Die大多了。</p>
<p><img src="/images/951413iMgBlog/AFCCC93B-D8A7-400A-9E80-978F8B05CD7E.jpeg" alt="How to Perform a CPU Stress Test and Push It to the Limit | AVG"></p>
<p><img src="/images/951413iMgBlog/images.jpeg" alt="Coffee Lake-Refresh Desktop CPU List Surfaces: 35W Core i9-9900T &amp; 8-Core  Xeon E-2200 Confirmed"></p>
<p><img src="/images/951413iMgBlog/yp6cf.jpg" alt="enter image description here"></p>
<h2 id="裸片Die-制作"><a href="#裸片Die-制作" class="headerlink" title="裸片Die 制作"></a>裸片Die 制作</h2><p>晶圆为什么总是圆的呢？生产过程就是从沙子中提纯硅，硅晶柱生长得到晶圆，生长是以圆柱形式的，所以切割下来的晶圆就是圆的了：</p>
<p><img src="/images/951413iMgBlog/weixin15664418828781.gif" alt="img"></p>
<p>硅晶柱切片：</p>
<p><img src="/images/951413iMgBlog/e510d61ed3e648a3ae64be7ac1da26e7.png" alt="img"></p>
<p>直径为 300 毫米的纯硅晶圆（从硅柱上切割下来的圆片），俗称 12 寸晶圆，大约是 400 美金。但尺寸并不是衡量硅晶圆的最重要指标，纯度才是。日本的信越公司可以生产 13 个 9 纯度的晶圆。</p>
<p>高纯硅的传统霸主依然是德国Wacker和美国Hemlock(美日合资)，中国任重而道远。太阳能级高纯硅要求是99.9999%，低纯度的硅全世界超过一半是中国产的，但是不值钱。而芯片用的电子级高纯硅要求99.999999999%，几乎全赖进口，直到2018年江苏鑫华公司才实现量产，目前年产0.5万吨，而中国一年进口15万吨。核心材料技术这块毫无疑问“外国仍然把中国摁在地上摩擦”。</p>
<h3 id="芯片设计"><a href="#芯片设计" class="headerlink" title="芯片设计"></a>芯片设计</h3><p>主要依赖EDA， EDA工具是电子设计自动化（Electronic Design Automation）的简称，从计算机辅助设计（CAD）、计算机辅助制造（CAM）、计算机辅助测试（CAT）和计算机辅助工程（CAE）的概念发展而来的，是IC基础设计能力。利用EDA工具，工程师将芯片的电路设计、性能分析、设计出IC版图的整个过程交由计算机自动处理完成。</p>
<p> EDA软件方面早已形成了三巨头——Synopsys、Cadence、Mentor。Synopsys是EDA三巨头之首，国内从事EDA软件开发的华大九天和这三家比起来不是一个数量级。国内IC设计公司几乎100%采用国外EDA工具，在未来的相当长的一段时间里，我们应该看不到缩小和Synopsys、Cadence、Mentor技术差距的可能性。</p>
<h3 id="光刻"><a href="#光刻" class="headerlink" title="光刻"></a>光刻</h3><p>使用特定波长的光，透过光罩（类似印炒里面的母版），照射在涂有光刻胶的晶圆上，光罩上芯片的设计图像，就复制到晶圆上了，这就是光刻，这一步是由光刻机完成的，光刻机是芯片制造中光刻环节的核心设备。你可以把光刻理解为，就是用光罩这个母版，一次次在晶圆上印电路的过程。</p>
<p><img src="/images/951413iMgBlog/b62d2a87a74c1ba90a069624bdc91eee.jpeg" alt="img"></p>
<p>光刻是最贵的一个环节，一方面是光罩越来越多，越来越贵，另一方面光刻机也很贵。光刻机是半导体制造设备中价格占比最大，也是最核心的设备。2020 年荷兰公司 ASML 的极紫外光源（EUV）光刻机每台的平均售价是 1.45 亿欧元，而且全世界独家供货，年产量 31 台，有钱也未必能买得到。</p>
<p><img src="/images/951413iMgBlog/image-20210601160424815.png" alt="image-20210601160424815"></p>
<p>短波长光源是提高光刻机分辨力的有效方，光刻机的发展历史，就从紫外光源（UV）、深紫外光源（DUV），发展到了现在的极紫外光源（EUV）。</p>
<p>回顾光刻机的发展历史，从 1960 年代的接触式光刻机、接近式光刻机，到 1970 年代的投影式光刻机，1980 年代的步进式光刻机，到步进式扫描光刻机、浸入式光刻机和现在的深紫外光源（DUV）和极紫外光源（EUV）光刻机，一边是设备性能的不断提高，另一边是价格逐年上升，且供应商逐渐减少。到了 EUV 光刻机，ASML(阿斯麦) 就是独家供货了。英特尔有阿斯麦15%的股份，台积电有5%，三星有3%，另外美国弄了一个《瓦森纳协定》，敏感技术不能卖，中国、朝鲜、伊朗、利比亚均是被限制国家。</p>
<p>品质合格的die切割下去后，原来的晶圆成了下图的样子，是挑剩下的Downgrade Flash Wafer。残余的die是品质不合格的晶圆。黑色的部分是合格的die，会被原厂封装制作为成品NAND颗粒，而不合格的部分，也就是图中留下的部分则当做废品处理掉。</p>
<p>从晶圆上切割检测合格的Die（螺片），所以Die跟Wafer不一样不是圆的，而是是方形的，因为方形的在切割封测工艺上最简单</p>
<p><img src="/images/951413iMgBlog/weixin15664418828785.gif" alt="img"></p>
<p>一个大晶圆，拿走了合格的Die后剩下的次品：</p>
<p><img src="/images/951413iMgBlog/bba1cd11728b47103777e2dbcccec3fdfc032348.png" alt="img"></p>
<p>可见次品率不低，后面会谈到怎么降低次品率，次品率决定了CPU的价格。</p>
<p>台积电一片 5nm 晶圆的加工费高达 12500 美金。根据台积电的财报推算，台积电平均每片晶圆可以产生近 4000 美金（300mm 晶圆）的利润。无论是哪个数字，对比 400 美金的纯硅晶圆原料来说，这都是一个至少增值 10 倍的高价值的加工过程。</p>
<p>随着Die的缩小，浪费的比例也从36%缩小成为12.6%。根据极限知识，我们知道如果Die的大小足够小，我们理论上可以100%用上所有的Wafer大小。从中我们可以看出越小的Die，浪费越小，从而降低CPU价格，对CPU生产者和消费者都是好事。</p>
<p>光刻机有一个加工的最大尺寸，一般是 858mm²，而 Cerebras 和台积电紧密合作，做了一个 46255mm²，1.2T 个晶体管的世界第一大芯片。这也是超摩尔定律的一个突破。</p>
<p>AMD在工艺落后Intel的前提下，又想要堆核，只能采取一个Package封装4个独立Die的做法，推出了Zen1 EPYC服务器芯片，即不影响良率，又可以核心数目好看，可谓一举两得。</p>
<p>可惜连接四个Die的片外总线终归没有片内通信效率高，在好些benchmark中败下阵来，可见没有免费的午餐。</p>
<p><img src="/images/951413iMgBlog/v2-7d77aa1100b77261f2626791954e79ad_720w.jpg" alt="img"></p>
<p>Intel的Pakcage内部是一个Die, Core之间原来是Ring Bus，在Skylake后改为Mesh。<strong>AMD多Die封装的目的是省钱和增加灵活性！AMD每个Zeppelin Die都比Intel的小，这对良品率提高很大，节约了生产费用。</strong></p>
<p>这种胶水核强行将多个die拼一起是没考虑跨die之间的延迟，基本上跨die跟intel跨socket（numa）时延一样了。</p>
<p>一颗芯片的 1/3 的成本，是花在封测阶段的</p>
<p><img src="/images/951413iMgBlog/738303bb-e157-47d2-a085-6daac98f04ec.jpeg" alt="img"></p>
<h3 id="Die和core"><a href="#Die和core" class="headerlink" title="Die和core"></a>Die和core</h3><p>One die with multiple cores，下图是一个Die内部图:</p>
<p><img src="/images/951413iMgBlog/xCqqv.jpg" alt="enter image description here"></p>
<p>或者Skylake：</p>
<p><img src="/images/951413iMgBlog/1000px-skylake_sp_mesh_core_tile_zoom_with_client_shown.png" alt="skylake sp mesh core tile zoom with client shown.png"></p>
<p>将两个Die封装成一块CPU(core多，成本低):</p>
<p><img src="/images/951413iMgBlog/dataf1-1372099277050.jpg" alt="data f1"></p>
<p>第4代酷睿（Haswell）的die：</p>
<p><img src="/images/951413iMgBlog/image-20210601162558479.png" alt="image-20210601162558479"></p>
<p>第4代酷睿（Haswell）的die主要分为几个部分：GPU、4个core、System Agent(uncore,类似北桥)、cache和内存控制器和其他小部件。<strong>比如我们发现core 3和4有问题，我们可以直接关闭3和4。坏的关掉就是i5, 都是好的就当i7来卖。</strong></p>
<h2 id="北桥和南桥"><a href="#北桥和南桥" class="headerlink" title="北桥和南桥"></a>北桥和南桥</h2><p>早期CPU core和内存硬盘的连接方式(FSB 是瓶颈)：</p>
<p><img src="/images/951413iMgBlog/image-20210602113401202.png" alt="image-20210602113401202"></p>
<p>个人PC主板实物图：</p>
<p><img src="/images/951413iMgBlog/northsouth2.jpg" alt="img"></p>
<p>由于FSB变成了系统性能的瓶颈和对多CPU的制约，在台式机和笔记本电脑中，MCH(Memory Control Hub)被请进CPU中，服务器市场虽然短暂的出现了IOH。</p>
<p><img src="/images/951413iMgBlog/640.jpeg" alt="Image"></p>
<p>集成北桥后的内存实物图：</p>
<p><img src="/images/951413iMgBlog/image-20210602114931825.png" alt="image-20210602114931825"></p>
<p>北桥已经集成到CPU中，南桥还没有，主要是因为：集成后Die增大不少，生产良品率下降成本上升；不集成两者采用不同的工艺；另外就是CPU引脚不够了！</p>
<p><img src="/images/951413iMgBlog/640-20210601095028465" alt="Image"></p>
<p>SoC（System on Chip）：南桥北桥都集成在CPU中，单芯片解决方案。ATOM就是SoC</p>
<h2 id="一个Core的典型结构"><a href="#一个Core的典型结构" class="headerlink" title="一个Core的典型结构"></a>一个Core的典型结构</h2><p>Intel skylake 架构图</p>
<p><img src="/images/951413iMgBlog/950px-skylake_server_block_diagram.svg.png" alt="skylake server block diagram.svg"></p>
<p>iTLB:instruct TLB </p>
<p>dTLB:data TLB</p>
<p>多个core加上L3等组成一个Die：</p>
<p><img src="/images/951413iMgBlog/cache-ht-hierarchy-2.jpg" alt="img"></p>
<h2 id="多核和多个CPU"><a href="#多核和多个CPU" class="headerlink" title="多核和多个CPU"></a>多核和多个CPU</h2><p>如果要实现一台48core的计算能力的服务器，可以有如下三个方案</p>
<h3 id="方案1：一个大Die集成48core："><a href="#方案1：一个大Die集成48core：" class="headerlink" title="方案1：一个大Die集成48core："></a>方案1：一个大Die集成48core：<img src="/images/951413iMgBlog/Intel-Skylake-SP-Mesh-Architecture-Conceptual-Diagram.png" alt="Intel Skylake SP Mesh Architecture Conceptual Diagram"></h3><h3 id="方案2：一个CPU封装8个Die，也叫MCM（Multi-Chip-Module），每个Die-6个core"><a href="#方案2：一个CPU封装8个Die，也叫MCM（Multi-Chip-Module），每个Die-6个core" class="headerlink" title="方案2：一个CPU封装8个Die，也叫MCM（Multi-Chip-Module），每个Die 6个core"></a><a href="https://wccftech.com/amd-epyc-rome-zen-2-7nm-server-cpu-162-pcie-gen-4-lanes-report/" target="_blank" rel="external">方案2</a>：一个CPU封装8个Die，也叫MCM（Multi-Chip-Module），每个Die 6个core</h3><p><img src="/images/951413iMgBlog/image-20210602165525641.png" alt="image-20210602165525641"></p>
<p>四个Die之间的连接方法：</p>
<p><img src="/images/951413iMgBlog/image-20210602172555232.png" alt="image-20210602172555232"></p>
<p>上图最下面的方案为<a href="https://venturebeat.com/2017/03/28/intel-moves-tech-forward-by-putting-two-chips-in-a-single-package/" target="_blank" rel="external">Intel采用的EMIB</a>（Embedded Multi-die Interconnect Bridge）方案，cost 最低。中间的方案是使用“硅中介层”(Interposer，AMD采用的方案)。这意味着你能在两枚主要芯片的下面放置和使用第三枚芯片。这枚芯片的目的是使得多个设备的连接更加容易，但是也带来了更高的成本。</p>
<h3 id="方案3：四个物理CPU（多Socket），每个物理CPU（Package）里面一个Die，每个Die12个core："><a href="#方案3：四个物理CPU（多Socket），每个物理CPU（Package）里面一个Die，每个Die12个core：" class="headerlink" title="方案3：四个物理CPU（多Socket），每个物理CPU（Package）里面一个Die，每个Die12个core："></a>方案3：四个物理CPU（多Socket），每个物理CPU（Package）里面一个Die，每个Die12个core：</h3><p><img src="/images/951413iMgBlog/image-20210602171352551.png" alt="image-20210602171352551"></p>
<p>三者的比较：</p>
<p>性能肯定是大Die最好，但是良品率地，成本高；</p>
<p>方案2的多个Die节省了主板上的大量布线和VR成本，总成本略低，但是方案3更容易堆出更多的core和<strong>内存</strong></p>
<p><img src="/images/951413iMgBlog/image-20210602170727459.png" alt="image-20210602170727459"></p>
<h3 id="面积和性能"><a href="#面积和性能" class="headerlink" title="面积和性能"></a>面积和性能</h3><p>我们使用了当时Intel 用在数据中心计算的大核CPU IvyBridge与当时用于 存储系列的小核CPU Avoton（ATOM）, 分别测试阿里巴巴的workload，得到性能吞吐如下：</p>
<table>
<thead>
<tr>
<th>Intel 大小CPU 核心</th>
<th>阿里 Workload Output(QPS)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Avoton(8 cores) 2.4GHZ</td>
<td>10K on single core</td>
</tr>
<tr>
<td>Ivy Bridge(2650 v2 disable HT) 2.6GHZ</td>
<td>20K on single core</td>
</tr>
<tr>
<td>Ivy Bridge(2650 v2 enable HT) 2.4GHZ</td>
<td>25K on single core</td>
</tr>
<tr>
<td>Ivy Bridge(2650 v2 enable HT) 2.6GHZ</td>
<td>27K on single core</td>
</tr>
</tbody>
</table>
<ol>
<li>大小核心直观比较：超线程等于将一个大核CPU 分拆成两个小核，Ivy Bridge的数据显示超线程给 Ivy Bridge <strong>1.35倍</strong>(27K/20K) 的提升</li>
<li>性能与芯片面积方面比较：现在我们分别评判 两种CPU对应的性能密度 (performance/core die size) ，该数据越大越好，根据我们的计算和测量发现 Avoton(包含L1D, L1I, and L2 per core)大约是 3~4平方毫米，Ivy Bridge (包含L1D, L1I, L2 )大约是12~13平方毫米, L3/core是 6~7平方毫米, 所以 Ivy Bridge 单核心的芯片面积需要18 ~ 20平方毫米。基于上面的数据我们得到的 Avoton core的性能密度为 2.5 (10K/4sqmm)，而Ivy Bridge的性能密度是1.35 (27K/20sqmm)，因此相同的芯片面积下 Avoton 的性能是 Ivy Bridge的 <strong>1.85倍</strong>(2.5/1.35).</li>
<li>性能与功耗方面比较：  从功耗的角度看性能的提升的对比数据，E5-2650v2(Ivy Bridge) 8core TDP 90w， Avoton 8 core TDP 20瓦， 性能/功耗 Avoton 是 10K QPS/20瓦， Ivy Bridge是 27KQPS/90瓦， 因此 相同的功耗下 Avoton是 Ivy Bridge的 <strong>1.75倍</strong>（10K QPS/20）/ （27KQPS/95）</li>
<li>性能与价格方面比较：  从价格方面再进行比较，E5-2650v2(Ivy Bridge) 8core 官方价格是1107美元， Avoton 8 core官方价格是171美元性能/价格 Avoton是 10KQPS/171美元，Ivy Bridge 是 27KQPS/1107美元， 因此相同的美元 Avoton的性能是 Ivy Bridge 的<strong>2.3倍（</strong>1 10KQPS/171美元）/ （27KQPS/1107美元）</li>
</ol>
<p>总结：在数据中心的场景下，由于指令数据相关性较高，同时由于内存访问的延迟更多，复杂的CPU体系结构并不能获得相应性能提升，该原因导致我们需要的是更多的小核CPU，以达到高吞吐量的能力，因此2014 年我们向Intel提出数据中心的CPU倾向“小核”CPU，需要将现有的大核CPU的超线程由 2个升级到4个/8个， 或者直接将用更多的小核CPU增加服务器的吞吐能力，经过了近8年，最新数据表明Intel 会在每个大核CPU中引入4个超线程，和在相同的芯片面积下单socket CPU 引入200多个小核CPU，该方案与我们的建议再次吻合</p>
<h2 id="为什么这20年主频基本没有提升了"><a href="#为什么这20年主频基本没有提升了" class="headerlink" title="为什么这20年主频基本没有提升了"></a>为什么这20年主频基本没有提升了</h2><p>今天的2.5G CPU性能和20年前的2.5G比起来性能差别大吗？</p>
<p>因为能耗导致CPU的主频近些年基本不怎么提升了，不是技术上不能提升，是性价比不高. </p>
<p>在提升主频之外可以提升性能的有：提升跳转预测率，增加Decoded Cache，增加每周期的并发读个数，增加执行通道，增加ROB， RS，Read &amp; Write buffer等等，这些主要是为了增加IPC，当然增加core数量也是提升整体性能的王道。另外就是优化指令所需要的时钟周期、增加并行度更好的指令等等指令集相关的优化。</p>
<p><img src="/images/951413iMgBlog/main-qimg-7a34de25ee9d09ba88a1671d22d4b0f1.jpeg" alt="img"></p>
<p>the industry came up with many different solution to create better computers w/o (or almost without) increasing the clock speed. </p>
<h3 id="比较两代CPU性能变化"><a href="#比较两代CPU性能变化" class="headerlink" title="比较两代CPU性能变化"></a>比较两代CPU性能变化</h3><p>Intel 最新的CPU Ice Lake(8380)和其上一代(8280)的性能对比数据：</p>
<p><img src="/images/951413iMgBlog/intel-ice-lake-sunny-cove-core-table.jpg" alt="img"></p>
<p><img src="/images/951413iMgBlog/Intel-Ice-Lake-3rd-Gen-Xeon-overview-slide.png" alt="img"></p>
<p>上图最终结果导致了IPC提升了20%</p>
<blockquote>
<p>But tock Intel did with the <a href="https://www.nextplatform.com/2021/04/19/deep-dive-into-intels-ice-lake-xeon-sp-architecture/" target="_blank" rel="external">Ice Lake</a> processors and their Sunny Cove cores, and the tock, at 20 percent instructions per clock (IPC) improvement on integer work</p>
</blockquote>
<p><img src="/images/951413iMgBlog/intel-ice-lake-ipc-over-time.jpg" alt="img"></p>
<p>ICE Lake在网络转发上的延时更小、更稳定了：</p>
<p><img src="/images/951413iMgBlog/intel-ice-lake-sunny-cove-dpdk-latency.jpg" alt="img"></p>
<p><a href="https://wccftech.com/intel-unveils-ice-lake-sp-xeon-cpu-family-10nm-sunny-cove-cores-28-core-die/" target="_blank" rel="external">两代CPU整体性能差异</a>：</p>
<p><img src="/images/951413iMgBlog/Intel-Ice-Lake-improved-perf-per-core-April-2021.png" alt="img"></p>
<h3 id="指令集优化"><a href="#指令集优化" class="headerlink" title="指令集优化"></a>指令集优化</h3><p>新增等效于某种常见指令组合的指令。原来多个指令执行需要多个时钟周期，合并后的单条指令可以在一个时钟周期执行完成。例如FMA指令，就是一条指令计算A×B+C，而无需分两个时钟周期计算。这种指令一般来说现有程序直接就能用上，无需优化。限制在于只对特定代码有效，还是以FMA为例，更普遍的普通加法、乘法运算都不能从中获益。</p>
<p>案例， ssse3(<strong>Supplemental Streaming SIMD Extensions 3</strong> ) 是simd的一种，在libc-2.17.so中就有使用到，如下是mysqld进程中采集到的</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="number">2.79</span>%  mysqld                [.] MYSQLparse                                   </div><div class="line"><span class="number">2.27</span>%  libc<span class="number">-2.17</span>.so          [.] __memcpy_ssse3_back  <span class="comment">//ssse3                </span></div><div class="line"><span class="number">2.19</span>%  mysqld                [.] ha_insert_for_fold_func                         </div><div class="line"><span class="number">1.95</span>%  mysqld                [.] rec_get_offsets_func                           </div><div class="line"><span class="number">1.35</span>%  mysqld                [.] <span class="built_in">malloc</span></div></pre></td></tr></table></figure>
<h4 id="AVX-Advanced-Vector-Extension，高级矢量扩展指令集"><a href="#AVX-Advanced-Vector-Extension，高级矢量扩展指令集" class="headerlink" title="AVX(Advanced Vector Extension，高级矢量扩展指令集)"></a>AVX(Advanced Vector Extension，高级矢量扩展指令集)</h4><p>英特尔在1996年率先引入了MMX（Multi Media eXtensions）多媒体扩展指令集，也开创了<strong>SIMD</strong>（Single Instruction Multiple Data，单指令多数据）指令集之先河，即在一个周期内一个指令可以完成多个数据操作，MMX指令集的出现让当时的MMX Pentium处理器大出风头。</p>
<p><strong>SSE</strong>（Streaming SIMD Extensions，流式单指令多数据扩展）指令集是1999年英特尔在Pentium III处理器中率先推出的，并将矢量处理能力从64位扩展到了128位。</p>
<p>AVX 所代表的单指令多数据（Single Instruction Multi Data，SIMD）指令集，是近年来 CPU 提升 IPC（每时钟周期指令数）上为数不多的重要革新。随着每次数据宽度的提升，CPU 的性能都会大幅提升，但同时晶体管数量和能耗也会有相应的提升。因此在对功耗有较高要求的场景，如笔记本电脑或服务器中，CPU 运行 AVX 应用时需要降低频率从而降低功耗。</p>
<blockquote>
<p>2013 年， 英特尔 发布了<strong>AVX</strong>-<strong>512 指令</strong>集，其<strong>指令</strong>宽度扩展为512bit，每个时钟周期内可打包32 次双精度或64 次单精度浮点运算，因此在图像/ 音视频处理、数据分析、科学计算、数据加密和压缩和 深度学习 等应用场景中，会带来更强大的性能表现，理论上浮点性能翻倍，整数计算则增加约33% 的性能。</p>
</blockquote>
<p>Linus Torvalds ：</p>
<blockquote>
<p>AVX512 有很明显的缺点。我宁愿看到那些晶体管被用于其他更相关的事情。即使同样是用于进行浮点数学运算（通过 GPU 来做，而不是通过 AVX512 在 CPU 上），或者直接给我更多的核心（有着更多单线程性能，而且没有 AVX512 这样的垃圾），就像 AMD 所做的一样。</p>
<p>我希望通过常规的整数代码来达到自己能力的极限，而不是通过 AVX512 这样的功率病毒来达到最高频率（因为人们最终还是会拿它来做 memory-to-memory copy），还占据了核心的很大面积。</p>
</blockquote>
<h3 id="关于性能提升的小结"><a href="#关于性能提升的小结" class="headerlink" title="关于性能提升的小结"></a>关于性能提升的小结</h3><p>所以今天的2.6G单核skylake，能秒掉20年前2.6G的酷睿, 尤其是复杂场景。</p>
<p><img src="/images/951413iMgBlog/image-20210715094527563.png" alt="image-20210715094527563"></p>
<p><img src="/images/951413iMgBlog/image-20210715094637227.png" alt="image-20210715094637227"></p>
<p>CPU能耗公式：</p>
<blockquote>
<p>P = C V<em>V </em> f</p>
</blockquote>
<p>C是常数，f就是频率，V 电压。 f频率加大后因为充放电带来的Gate Delay，也就是频率增加，充放电时间短，为了保证信号的完整性就一定要增加电压来加快充放电。</p>
<p>所以最终能耗和f频率是 f^3 的指数关系。</p>
<blockquote>
<p>The successive nodes of CMOS technologies lead to x1.4 decrease of the gate delays. It led to a 25% increase per year of clock frequencies from 740 kHz (Intel 4004) to 3 GHz (Intel Xeons with 45-nm nodes).</p>
<p>每一代光刻工艺的改进可以降低1.4倍的门延迟</p>
</blockquote>
<p>即使不考虑散热问题，Core也没法做到无限大，目前光刻机都有最大加工尺寸限制。光刻机加工的最大尺寸，一般是 858mm²，而 Cerebras 和台积电紧密合作，做了一个 46255mm²，1.2T 个晶体管的世界第一大芯片。这也是超摩尔定律的一个突破。</p>
<p><img src="/images/951413iMgBlog/image-20210715100609552.png" alt="image-20210715100609552"></p>
<h2 id="主频和外频"><a href="#主频和外频" class="headerlink" title="主频和外频"></a>主频和外频</h2><p><strong>主频=外频×倍频系数</strong></p>
<p>不只是CPU需要一个切换频率，像GPU、cache、内存都需要一个外频来指导他们的电压脉冲的切换频率。CPU的发展比其它设备快，所以没法统一一个，于是就各自在外频的基础上X倍频系数。</p>
<p>超频：认为加大CPU的倍频系数，切换变快以后最大的问题是电容在短时间内充电不完整，这样导致信号失真，所以一般配套需要增加电压（充电更快），带来的后果是温度更高。</p>
<p>睿频：大多时候多核用不上，如果能智能地关掉无用的核同时把这些关掉的核的电源累加到在用的核上（通过增加倍频来实现），这样单核拥有更高的主频。也就是把其它核的电源指标和发热指标给了这一个核来使用。</p>
<p><img src="/images/951413iMgBlog/1000.jpeg" alt="img"></p>
<h2 id="多core通讯和NUMA"><a href="#多core通讯和NUMA" class="headerlink" title="多core通讯和NUMA"></a>多core通讯和NUMA</h2><h3 id="uma下cpu访问内存"><a href="#uma下cpu访问内存" class="headerlink" title="uma下cpu访问内存"></a>uma下cpu访问内存</h3><p>早期core不多统一走北桥总线访问内存，对所有core时延统一</p>
<p><img src="/images/951413iMgBlog/numa-fsb-3.png" alt="x86 UMA"></p>
<h3 id="NUMA"><a href="#NUMA" class="headerlink" title="NUMA"></a>NUMA</h3><p>如下图，左右两边的是内存条，每个NUMA的cpu访问直接插在自己CPU上的内存必然很快，如果访问插在其它NUMA上的内存条还要走QPI，所以要慢很多。</p>
<p><img src="/images/951413iMgBlog/1620954546311-096702b9-9929-4f47-8811-dc4d08829f31.png" alt="undefined"> </p>
<p>如上架构是4路CPU，每路之间通过QPI相连，每个CPU内部8core用的是双Ring Bus相连，Memory Control Hub集成到了Die里面。一路CPU能连4个SMB，每个SMB有两个channel，每个channel最多接三个内存条（图中只画了2个）。</p>
<p><strong>快速通道互联</strong><a href="https://zh.wikipedia.org/wiki/快速通道互联#cite_note-1" target="_blank" rel="external">[1]</a><a href="https://zh.wikipedia.org/wiki/快速通道互联#cite_note-2" target="_blank" rel="external">[2]</a>（英语：Intel <strong>Q</strong>uick<strong>P</strong>ath <strong>I</strong>nterconnect，<a href="https://zh.wikipedia.org/wiki/縮寫" target="_blank" rel="external">缩写</a>：<strong>QPI</strong>）<a href="https://zh.wikipedia.org/wiki/快速通道互联#cite_note-Intel_QPI-3" target="_blank" rel="external">[3]</a><a href="https://zh.wikipedia.org/wiki/快速通道互联#cite_note-4" target="_blank" rel="external">[4]</a>，是一种由英特尔开发并使用的点对点处理器互联架构，用来实现CPU之间的互联。英特尔在2008年开始用QPI取代以往用于<a href="https://zh.wikipedia.org/wiki/Intel_Xeon" target="_blank" rel="external">至强</a>、<a href="https://zh.wikipedia.org/wiki/Intel_Itanium" target="_blank" rel="external">安腾</a>处理器的<a href="https://zh.wikipedia.org/wiki/前端匯流排" target="_blank" rel="external">前端总线</a>（<a href="https://zh.wikipedia.org/wiki/FSB" target="_blank" rel="external">FSB</a>），<strong>用来实现芯片之间的直接互联，而不是再通过FSB连接到北桥</strong>。Intel于2017年发布的SkyLake-SP Xeon中，用UPI（<strong>U</strong>ltra<strong>P</strong>ath <strong>I</strong>nterconnect）取代QPI。</p>
<h4 id="Ring-Bus"><a href="#Ring-Bus" class="headerlink" title="Ring Bus"></a>Ring Bus</h4><p>2012年英特尔发布了业界期待已久的Intel Sandy Bridge架构至强E5-2600系列处理器。该系列处理器采用 Intel Sandy Bridge微架构和32nm工艺，与前一代的至强5600系列相比，具有更多的内核、更大的缓存、更多的内存通道，Die内采用的是Ring Bus。</p>
<p>Ring Bus设计简单，双环设计可以保证任何两个ring stop之间距离不超过Ring Stop总数的一半，延迟控制在60ns，带宽100G以上，但是core越多，ring bus越长性能下降迅速，在12core之后性能下降明显。</p>
<p>于是采用如下两个Ring Bus并列，然后再通过双向总线把两个Ring Bus连起来。</p>
<p>在至强HCC(High Core Count, 核很多版)版本中，又加入了一个ring bus。两个ring bus各接12个Core，将延迟控制在可控的范围内。俩个Ring Bus直接用两个双向Pipe Line连接，保证通讯顺畅。与此同时由于Ring 0中的模块访问Ring 1中的模块延迟明显高于本Ring，亲缘度不同，所以两个Ring分属于不同的NUMA（Non-Uniform Memory Access Architecture）node。这点在BIOS设计中要特别注意。</p>
<p><img src="/images/951413iMgBlog/Intel-Xeon-E5-2600-V4-High-Core-Count-Die.png" alt="Intel Xeon E5-2600 V4 High Core Count Die"></p>
<p>或者这个更清晰点的图：</p>
<p><img src="/images/951413iMgBlog/03-05-Broadwell_HCC_Architecture.svg" alt="03-05-Broadwell_HCC_Architecture"></p>
<h4 id="Mesh网络"><a href="#Mesh网络" class="headerlink" title="Mesh网络"></a><a href="https://www.servethehome.com/the-new-intel-mesh-interconnect-architecture-and-platform-implications/" target="_blank" rel="external">Mesh网络</a></h4><p>Intel在Skylake和Knight Landing中引入了新的片内总线：Mesh。它是一种2D的Mesh网络：</p>
<p><img src="/images/951413iMgBlog/Intel-Skylake-SP-Mesh-Architecture-Conceptual-Diagram.png" alt="Intel Skylake SP Mesh Architecture Conceptual Diagram"></p>
<p><img src="/images/951413iMgBlog/1620956208262-c20677c5-8bf5-4cd4-81c6-1bf492159394.png" alt="undefined"></p>
<p>一个skylake 28core die的实现：</p>
<p><img src="/images/951413iMgBlog/Skylake-SP-28-Core-Die-Mesh-800x666.jpg" alt="Skylake SP 28 Core Die Mesh"></p>
<p>Mesh网络引入片内总线是一个巨大的进步，它有很多优点：</p>
<ol>
<li>首先当然是灵活性。新的模块或者节点在Mesh中增加十分方便，它带来的延迟不是像ring bus一样线性增加，而是非线性的。从而可以容纳更多的内核。</li>
<li>设计弹性很好，不需要1.5 ring和2ring的委曲求全。</li>
<li>双向mesh网络减小了两个node之间的延迟。过去两个node之间通讯，最坏要绕过半个ring。而mesh整体node之间距离大大缩减。</li>
<li>外部延迟大大缩短</li>
</ol>
<p>RAM延迟大大缩短：</p>
<p><img src="/images/951413iMgBlog/Broadwell-Ring-v-Skylake-Mesh-DRAM-Example-696x272.jpg" alt="Broadwell Ring V Skylake Mesh DRAM Example"></p>
<p>上图左边的是ring bus，从一个ring里面访问另一个ring里面的内存控制器。最坏情况下是那条绿线，拐了一个大圈才到达内存控制器，需要310个cycle。而在Mesh网络中则路径缩短很多。</p>
<p>Mesh网络带来了这么多好处，那么缺点有没有呢？网格化设计带来复杂性的增加，从而对Die的大小带来了负面影响</p>
<p>CPU的总线为铜薄膜，虽然摩尔定律使单位面积晶体管的密度不断增加，但是对于连接导线的电阻却没有明显的下降，导线的RC延迟几乎决定现有CPU性能，因此数据传输在CPU的角度来看是个极为沉重的负担。 虽然2D-mesh为数据提供了更多的迁移路径减少了数据堵塞，但也同样为数据一致性带来更多问题，例如过去ring-bus 结构下对于存在于某个CPU私用缓存的数据争抢请求只有两个方向（左和右）， 但是在2D-mesh环境下会来自于4个方向（上，下，左，右）</p>
<p><img src="/images/951413iMgBlog/image-20210602104851803.png" alt="image-20210602104851803"></p>
<h3 id="SUB-NUMA-Cluster-SNC"><a href="#SUB-NUMA-Cluster-SNC" class="headerlink" title="SUB_NUMA Cluster(SNC)"></a>SUB_NUMA Cluster(SNC)</h3><p>在intel 8269的CPU中，core比较多，core之间通信采取的是mesh架构，实际在BIOS中的NUMA NODE设置上，还有个sub_numa的设置，开启后，一个Die拆成了两个node</p>
<p><img src="/images/951413iMgBlog/image-20220418101937564.png" alt="image-20220418101937564"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">[root@registry Linux]# lscpu</div><div class="line">Architecture:          x86_64</div><div class="line">CPU op-mode(s):        32-bit, 64-bit</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                104</div><div class="line">On-line CPU(s) list:   0-103</div><div class="line">Thread(s) per core:    2</div><div class="line">Core(s) per socket:    26</div><div class="line">座：                 2</div><div class="line">NUMA 节点：         4</div><div class="line">厂商 ID：           GenuineIntel</div><div class="line">CPU 系列：          6</div><div class="line">型号：              85</div><div class="line">型号名称：        Intel(R) Xeon(R) Platinum 8269CY CPU @ 2.50GHz</div><div class="line">步进：              7</div><div class="line">CPU MHz：             1200.000</div><div class="line">CPU max MHz:           2501.0000</div><div class="line">CPU min MHz:           1200.0000</div><div class="line">BogoMIPS：            5000.00</div><div class="line">虚拟化：           VT-x</div><div class="line">L1d 缓存：          32K</div><div class="line">L1i 缓存：          32K</div><div class="line">L2 缓存：           1024K</div><div class="line">L3 缓存：           36608K</div><div class="line">NUMA 节点0 CPU：    0-3,7-9,13-15,20-22,52-55,59-61,65-67,72-74</div><div class="line">NUMA 节点1 CPU：    4-6,10-12,16-19,23-25,56-58,62-64,68-71,75-77</div><div class="line">NUMA 节点2 CPU：    26-29,33-35,39-41,46-48,78-81,85-87,91-93,98-100</div><div class="line">NUMA 节点3 CPU：    30-32,36-38,42-45,49-51,82-84,88-90,94-97,101-103</div></pre></td></tr></table></figure>
<p>不过在8269上开启sub_numa对性能的影响不是特别大，mlc测试如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div></pre></td><td class="code"><pre><div class="line">[root@registry Linux]# ./mlc</div><div class="line">Intel(R) Memory Latency Checker - v3.9</div><div class="line">Measuring idle latencies (in ns)...</div><div class="line">		Numa node</div><div class="line">Numa node	     0	     1	     2	     3</div><div class="line">       0	  77.3	  81.6	 129.8	 136.1</div><div class="line">       1	  82.1	  78.1	 134.1	 137.6</div><div class="line">       2	 129.8	 135.8	  73.5	  81.7</div><div class="line">       3	 134.4	 137.7	  81.7	  78.5</div><div class="line"></div><div class="line">Measuring Peak Injection Memory Bandwidths for the system</div><div class="line">Bandwidths are in MB/sec (1 MB/sec = 1,000,000 Bytes/sec)</div><div class="line">Using all the threads from each core if Hyper-threading is enabled</div><div class="line">Using traffic with the following read-write ratios</div><div class="line">ALL Reads        :	232777.7</div><div class="line">3:1 Reads-Writes :	216680.7</div><div class="line">2:1 Reads-Writes :	213856.4</div><div class="line">1:1 Reads-Writes :	197430.7</div><div class="line">Stream-triad like:	194310.3</div><div class="line"></div><div class="line">Measuring Memory Bandwidths between nodes within system</div><div class="line">Bandwidths are in MB/sec (1 MB/sec = 1,000,000 Bytes/sec)</div><div class="line">Using all the threads from each core if Hyper-threading is enabled</div><div class="line">Using Read-only traffic type</div><div class="line">		Numa node</div><div class="line">Numa node	     0	     1	     2	     3</div><div class="line">       0	58908.9	59066.0	50548.0	50479.6</div><div class="line">       1	59111.3	58882.6	50539.0	50479.3</div><div class="line">       2	50541.7	50495.8	58950.2	58934.0</div><div class="line">       3	50526.3	50492.4	59171.9	58701.5</div><div class="line"></div><div class="line">Measuring Loaded Latencies for the system</div><div class="line">Using all the threads from each core if Hyper-threading is enabled</div><div class="line">Using Read-only traffic type</div><div class="line">Inject	Latency	Bandwidth</div><div class="line">Delay	(ns)	MB/sec</div><div class="line">==========================</div><div class="line"> 00000	242.78	 232249.0</div><div class="line"> 00002	242.90	 232248.8</div><div class="line"> 00008	242.63	 232226.0</div><div class="line"> 00015	247.47	 233159.0</div><div class="line"> 00050	250.26	 233489.7</div><div class="line"> 00100	245.88	 233253.4</div><div class="line"> 00200	109.72	 183071.9</div><div class="line"> 00300	 93.95	 128676.2</div><div class="line"> 00400	 88.51	  98678.4</div><div class="line"> 00500	 85.15	  80026.2</div><div class="line"> 00700	 83.74	  58136.1</div><div class="line"> 01000	 82.16	  41372.4</div><div class="line"> 01300	 81.59	  32184.0</div><div class="line"> 01700	 81.14	  24896.1</div><div class="line"> 02500	 80.80	  17248.5</div><div class="line"> 03500	 80.32	  12571.3</div><div class="line"> 05000	 79.58	   9060.5</div><div class="line"> 09000	 78.27	   5411.6</div><div class="line"> 20000	 76.09	   2911.5</div><div class="line"></div><div class="line">Measuring cache-to-cache transfer latency (in ns)...</div><div class="line">Local Socket L2-&gt;L2 HIT  latency	45.0</div><div class="line">Local Socket L2-&gt;L2 HITM latency	45.1</div><div class="line">Remote Socket L2-&gt;L2 HITM latency (data address homed in writer socket)</div><div class="line">			Reader Numa Node</div><div class="line">Writer Numa Node     0	     1	     2	     3</div><div class="line">            0	     -	  48.2	 107.2	 109.2</div><div class="line">            1	  50.6	     -	 111.2	 113.1</div><div class="line">            2	 107.6	 109.6	     -	  48.0</div><div class="line">            3	 111.6	 113.5	  49.7	     -</div><div class="line">Remote Socket L2-&gt;L2 HITM latency (data address homed in reader socket)</div><div class="line">			Reader Numa Node</div><div class="line">Writer Numa Node     0	     1	     2	     3</div><div class="line">            0	     -	  48.6	 169.1	 175.0</div><div class="line">            1	  46.3	     -	 167.9	 172.1</div><div class="line">            2	 171.4	 175.3	     -	  48.6</div><div class="line">            3	 169.7	 173.6	  45.1	     -</div><div class="line">            </div><div class="line">[root@registry Linux]# numactl -H</div><div class="line">available: 4 nodes (0-3)</div><div class="line">node 0 cpus: 0 1 2 3 7 8 9 13 14 15 20 21 22 52 53 54 55 59 60 61 65 66 67 72 73 74</div><div class="line">node 0 size: 64162 MB</div><div class="line">node 0 free: 60072 MB</div><div class="line">node 1 cpus: 4 5 6 10 11 12 16 17 18 19 23 24 25 56 57 58 62 63 64 68 69 70 71 75 76 77</div><div class="line">node 1 size: 65536 MB</div><div class="line">node 1 free: 63575 MB</div><div class="line">node 2 cpus: 26 27 28 29 33 34 35 39 40 41 46 47 48 78 79 80 81 85 86 87 91 92 93 98 99 100</div><div class="line">node 2 size: 65536 MB</div><div class="line">node 2 free: 63834 MB</div><div class="line">node 3 cpus: 30 31 32 36 37 38 42 43 44 45 49 50 51 82 83 84 88 89 90 94 95 96 97 101 102 103</div><div class="line">node 3 size: 65536 MB</div><div class="line">node 3 free: 63867 MB</div><div class="line">node distances:</div><div class="line">node   0   1   2   3</div><div class="line">  0:  10  11  21  21</div><div class="line">  1:  11  10  21  21</div><div class="line">  2:  21  21  10  11</div><div class="line">  3:  21  21  11  10</div><div class="line">[root@registry Linux]# lscpu</div><div class="line">Architecture:          x86_64</div><div class="line">CPU op-mode(s):        32-bit, 64-bit</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                104</div><div class="line">On-line CPU(s) list:   0-103</div><div class="line">Thread(s) per core:    2</div><div class="line">Core(s) per socket:    26</div><div class="line">座：                 2</div><div class="line">NUMA 节点：         4</div><div class="line">厂商 ID：           GenuineIntel</div><div class="line">CPU 系列：          6</div><div class="line">型号：              85</div><div class="line">型号名称：        Intel(R) Xeon(R) Platinum 8269CY CPU @ 2.50GHz</div><div class="line">步进：              7</div><div class="line">CPU MHz：             1200.000</div><div class="line">CPU max MHz:           2501.0000</div><div class="line">CPU min MHz:           1200.0000</div><div class="line">BogoMIPS：            5000.00</div><div class="line">虚拟化：           VT-x</div><div class="line">L1d 缓存：          32K</div><div class="line">L1i 缓存：          32K</div><div class="line">L2 缓存：           1024K</div><div class="line">L3 缓存：           36608K</div><div class="line">NUMA 节点0 CPU：    0-3,7-9,13-15,20-22,52-55,59-61,65-67,72-74</div><div class="line">NUMA 节点1 CPU：    4-6,10-12,16-19,23-25,56-58,62-64,68-71,75-77</div><div class="line">NUMA 节点2 CPU：    26-29,33-35,39-41,46-48,78-81,85-87,91-93,98-100</div><div class="line">NUMA 节点3 CPU：    30-32,36-38,42-45,49-51,82-84,88-90,94-97,101-103</div></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th></th>
<th>SKL-SP H0</th>
<th>SKL-SP H0</th>
<th>SKL-SP H0</th>
<th>SKL-SP H0</th>
</tr>
</thead>
<tbody>
<tr>
<td>DDR4 speed MT/s (32GB RDIMMs)</td>
<td>2666</td>
<td>2666</td>
<td>2400</td>
<td>2400</td>
</tr>
<tr>
<td>Page Policy</td>
<td>Adaptive</td>
<td>Adaptive</td>
<td>Adaptive</td>
<td>Adaptive</td>
</tr>
<tr>
<td>SNC (sub-NUMA cluster)</td>
<td>disabled</td>
<td>enabled</td>
<td>disabled</td>
<td>enabled</td>
</tr>
<tr>
<td>Uncore frequency (Mhz)</td>
<td>2400</td>
<td>2400</td>
<td>2400</td>
<td>2400</td>
</tr>
<tr>
<td>L1 cache latency (nsec)</td>
<td>1.1</td>
<td>1.1</td>
<td>1.1</td>
<td>1.1</td>
</tr>
<tr>
<td>L2 cache latency (nsec)</td>
<td>4.7</td>
<td>4.6</td>
<td>4.7</td>
<td>4.6</td>
</tr>
<tr>
<td>L3 cache latency (nsec)</td>
<td>19.5</td>
<td>17.8</td>
<td>19.5</td>
<td>17.8</td>
</tr>
<tr>
<td>Local mem latency (nsec)</td>
<td>83</td>
<td>81</td>
<td>85</td>
<td>83</td>
</tr>
<tr>
<td>Remote mem latency (nsec)</td>
<td>143</td>
<td>139</td>
<td>145</td>
<td>141</td>
</tr>
</tbody>
</table>
<h3 id="uncore"><a href="#uncore" class="headerlink" title="uncore"></a>uncore</h3><p>“<strong>Uncore</strong>“ is a term used by <a href="https://en.wikipedia.org/wiki/Intel" target="_blank" rel="external">Intel</a> to describe the functions of a <a href="https://en.wikipedia.org/wiki/Microprocessor" target="_blank" rel="external">microprocessor</a> that are not in the core, but which must be closely connected to the core to achieve high performance.<a href="https://en.wikipedia.org/wiki/Uncore#cite_note-modular_uncore-1" target="_blank" rel="external">[1]</a> It has been called “<strong>system agent</strong>“ since the release of the <a href="https://en.wikipedia.org/wiki/Sandy_Bridge" target="_blank" rel="external">Sandy Bridge</a> <a href="https://en.wikipedia.org/wiki/Microarchitecture" target="_blank" rel="external">microarchitecture</a>.<a href="https://en.wikipedia.org/wiki/Uncore#cite_note-sandybridge-2" target="_blank" rel="external">[2]</a></p>
<p>The core contains the components of the processor involved in executing instructions, including the <a href="https://en.wikipedia.org/wiki/Arithmetic_logic_unit" target="_blank" rel="external">ALU</a>, <a href="https://en.wikipedia.org/wiki/Floating_point_unit" target="_blank" rel="external">FPU</a>, <a href="https://en.wikipedia.org/wiki/L1_cache" target="_blank" rel="external">L1</a> and <a href="https://en.wikipedia.org/wiki/L2_cache" target="_blank" rel="external">L2 cache</a>. Uncore functions include <a href="https://en.wikipedia.org/wiki/Intel_QuickPath_Interconnect" target="_blank" rel="external">QPI</a> controllers, <a href="https://en.wikipedia.org/wiki/L3_cache" target="_blank" rel="external">L3 cache</a>, <a href="https://en.wikipedia.org/wiki/Memory_coherence" target="_blank" rel="external">snoop agent</a> <a href="https://en.wikipedia.org/wiki/Instruction_pipeline" target="_blank" rel="external">pipeline</a>, on-die <a href="https://en.wikipedia.org/wiki/Memory_controller" target="_blank" rel="external">memory controller</a>, on-die <a href="https://en.wikipedia.org/wiki/PCI_Express_Root_Complex" target="_blank" rel="external">PCI Express Root Complex</a>, and <a href="https://en.wikipedia.org/wiki/Thunderbolt_(interface" target="_blank" rel="external">Thunderbolt controller</a>).<a href="https://en.wikipedia.org/wiki/Uncore#cite_note-thunderbolt-3" target="_blank" rel="external">[3]</a> Other bus controllers such as <a href="https://en.wikipedia.org/wiki/Serial_Peripheral_Interface_Bus" target="_blank" rel="external">SPI</a> and <a href="https://en.wikipedia.org/wiki/Low_Pin_Count" target="_blank" rel="external">LPC</a> are part of the <a href="https://en.wikipedia.org/wiki/Chipset" target="_blank" rel="external">chipset</a>.<a href="https://en.wikipedia.org/wiki/Uncore#cite_note-Anandtech:_Nehalem:_The_Unwritten_Chapters-4" target="_blank" rel="external">[4]</a></p>
<h2 id="一些Intel-CPU-NUMA结构参考"><a href="#一些Intel-CPU-NUMA结构参考" class="headerlink" title="一些Intel CPU NUMA结构参考"></a>一些Intel CPU NUMA结构参考</h2><p>Intel Xeon Platinum 8163（Skylake）阿里云第四代服务器采用的CPU，Skylake架构，主频2.5GHz，计算性能问题。8163这款型号在intel官网上并没有相关信息，应该是阿里云向阿里云定制的，与之相近的Intel Xeon Platinum 8168，价格是$5890，约合￥38900元。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div></pre></td><td class="code"><pre><div class="line">lscpu:</div><div class="line">      Architecture:        x86_64</div><div class="line">      CPU op-mode(s):      32-bit, 64-bit</div><div class="line">      Byte Order:          Little Endian</div><div class="line">      CPU(s):              96</div><div class="line">      On-line CPU(s) list: 0-95</div><div class="line">      Thread(s) per core:  2</div><div class="line">      Core(s) per socket:  24</div><div class="line">      Socket(s):           2</div><div class="line">      NUMA node(s):        4</div><div class="line">      Vendor ID:           GenuineIntel</div><div class="line">      CPU family:          6</div><div class="line">      Model:               85</div><div class="line">      Model name:          Intel(R) Xeon(R) Platinum 8260 CPU @ 2.40GHz</div><div class="line">      Stepping:            6</div><div class="line">      CPU MHz:             2400.000</div><div class="line">      CPU max MHz:         3900.0000</div><div class="line">      CPU min MHz:         1000.0000</div><div class="line">      BogoMIPS:            4800.00</div><div class="line">      Virtualization:      VT-x</div><div class="line">      L1d cache:           32K</div><div class="line">      L1i cache:           32K</div><div class="line">      L2 cache:            1024K</div><div class="line">      L3 cache:            36608K</div><div class="line">      NUMA node0 CPU(s):   0-3,7-9,13-15,19,20,48-51,55-57,61-63,67,68</div><div class="line">      NUMA node1 CPU(s):   4-6,10-12,16-18,21-23,52-54,58-60,64-66,69-71</div><div class="line">      NUMA node2 CPU(s):   24-27,31-33,37-39,43,44,72-75,79-81,85-87,91,92</div><div class="line">      NUMA node3 CPU(s):   28-30,34-36,40-42,45-47,76-78,82-84,88-90,93-95</div><div class="line">      </div><div class="line"> Model: 85</div><div class="line"> Model name: Intel(R) Xeon(R) Platinum 8268 CPU @ 2.90GHz</div><div class="line"> Stepping: 6</div><div class="line"> CPU MHz: 3252.490</div><div class="line"> BogoMIPS: 5800.00</div><div class="line"> Virtualization: VT-x</div><div class="line"> L1d cache: 32K</div><div class="line"> L1i cache: 32K</div><div class="line"> L2 cache: 1024K</div><div class="line"> L3 cache: 36608K</div><div class="line"> NUMA node0 CPU(s):</div><div class="line"> 0,4,8,12,16,20,24,28,32,36,40,44,48,52,56,60,64,68,72,76,80,84,88,92</div><div class="line"> NUMA node1 CPU(s):</div><div class="line"> 1,5,9,13,17,21,25,29,33,37,41,45,49,53,57,61,65,69,73,77,81,85,89,93</div><div class="line"> NUMA node2 CPU(s):</div><div class="line"> 2,6,10,14,18,22,26,30,34,38,42,46,50,54,58,62,66,70,74,78,82,86,90,94</div><div class="line"> NUMA node3 CPU(s):</div><div class="line"> 3,7,11,15,19,23,27,31,35,39,43,47,51,55,59,63,67,71,75,79,83,87,91,95   </div><div class="line"> </div><div class="line"> </div><div class="line">  lscpu:</div><div class="line"> Architecture: x86_64</div><div class="line"> CPU op-mode(s): 32-bit, 64-bit</div><div class="line"> Byte Order: Little Endian</div><div class="line"> CPU(s): 192</div><div class="line"> On-line CPU(s) list: 0-191</div><div class="line"> Thread(s) per core: 1</div><div class="line"> Core(s) per socket: 24</div><div class="line"> Socket(s): 8 //每个物理CPU 24个物理core，这24个core应该是分布在2个Die中</div><div class="line"> NUMA node(s): 16</div><div class="line"> Vendor ID: GenuineIntel</div><div class="line"> CPU family: 6</div><div class="line"> Model: 85</div><div class="line"> Model name: Intel(R) Xeon(R) Platinum 8260 CPU @ 2.40GHz</div><div class="line"> Stepping: 7</div><div class="line"> CPU MHz: 2400.000</div><div class="line"> CPU max MHz: 3900.0000</div><div class="line"> CPU min MHz: 1000.0000</div><div class="line"> BogoMIPS: 4800.00</div><div class="line"> Virtualization: VT-x</div><div class="line"> L1d cache: 32K</div><div class="line"> L1i cache: 32K</div><div class="line"> L2 cache: 1024K</div><div class="line"> L3 cache: 36608K</div><div class="line"> NUMA node0 CPU(s): 0-3,7-9,13-15,19,20</div><div class="line"> NUMA node1 CPU(s): 4-6,10-12,16-18,21-23</div><div class="line"> NUMA node2 CPU(s): 24-27,31-33,37-39,43,44</div><div class="line"> NUMA node3 CPU(s): 28-30,34-36,40-42,45-47</div><div class="line"> NUMA node4 CPU(s): 48-51,55,56,60-62,66-68</div><div class="line"> NUMA node5 CPU(s): 52-54,57-59,63-65,69-71</div><div class="line"> NUMA node6 CPU(s): 72-75,79-81,85-87,91,92</div><div class="line"> NUMA node7 CPU(s): 76-78,82-84,88-90,93-95</div><div class="line"> NUMA node8 CPU(s): 96-99,103,104,108-110,114-116</div><div class="line"> NUMA node9 CPU(s): 100-102,105-107,111-113,117-119</div><div class="line"> NUMA node10 CPU(s): 120-123,127,128,132-134,138-140</div><div class="line"> NUMA node11 CPU(s): 124-126,129-131,135-137,141-143</div><div class="line"> NUMA node12 CPU(s): 144-147,151-153,157-159,163,164</div><div class="line"> NUMA node13 CPU(s): 148-150,154-156,160-162,165-167</div><div class="line"> NUMA node14 CPU(s): 168-171,175-177,181-183,187,188</div><div class="line"> NUMA node15 CPU(s): 172-174,178-180,184-186,189-191</div><div class="line"> </div><div class="line"> //v62</div><div class="line"> #lscpu</div><div class="line">Architecture:          x86_64</div><div class="line">CPU op-mode(s):        32-bit, 64-bit</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                104</div><div class="line">On-line CPU(s) list:   0-103</div><div class="line">Thread(s) per core:    2</div><div class="line">Core(s) per socket:    26</div><div class="line">Socket(s):             2</div><div class="line">NUMA node(s):          2</div><div class="line">Vendor ID:             GenuineIntel</div><div class="line">CPU family:            6</div><div class="line">Model:                 85</div><div class="line">Model name:            Intel(R) Xeon(R) Platinum 8269CY CPU @ 2.50GHz</div><div class="line">Stepping:              7</div><div class="line">CPU MHz:               3200.097</div><div class="line">CPU max MHz:           3800.0000</div><div class="line">CPU min MHz:           1200.0000</div><div class="line">BogoMIPS:              4998.89</div><div class="line">Virtualization:        VT-x</div><div class="line">L1d cache:             32K</div><div class="line">L1i cache:             32K</div><div class="line">L2 cache:              1024K</div><div class="line">L3 cache:              36608K</div><div class="line">NUMA node0 CPU(s):     0-25,52-77</div><div class="line">NUMA node1 CPU(s):     26-51,78-103</div><div class="line"></div><div class="line">//2016Intel开始出售Intel Xeon E5-2682 v4。 这是一种基于Broadwell架构的桌面处理器，主要为办公系统而设计。 它具有16 核心和32 数据流并使用, 售价约为7000人民币</div><div class="line">#lscpu</div><div class="line">Architecture:          x86_64</div><div class="line">CPU op-mode(s):        32-bit, 64-bit</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                64</div><div class="line">On-line CPU(s) list:   0-63</div><div class="line">Thread(s) per core:    2</div><div class="line">Core(s) per socket:    16</div><div class="line">Socket(s):             2</div><div class="line">NUMA node(s):          2</div><div class="line">Vendor ID:             GenuineIntel</div><div class="line">CPU family:            6</div><div class="line">Model:                 79</div><div class="line">Model name:            Intel(R) Xeon(R) CPU E5-2682 v4 @ 2.50GHz</div><div class="line">Stepping:              1</div><div class="line">CPU MHz:               2499.902</div><div class="line">CPU max MHz:           3000.0000</div><div class="line">CPU min MHz:           1200.0000</div><div class="line">BogoMIPS:              5000.06</div><div class="line">Virtualization:        VT-x</div><div class="line">L1d cache:             32K</div><div class="line">L1i cache:             32K</div><div class="line">L2 cache:              256K</div><div class="line">L3 cache:              40960K</div><div class="line">NUMA node0 CPU(s):     0-15,32-47</div><div class="line">NUMA node1 CPU(s):     16-31,48-63</div><div class="line">Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 ds_cpl vmx smx est tm2 ssse3 fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch ida arat epb invpcid_single pln pts dtherm spec_ctrl ibpb_support tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local cat_l3</div></pre></td></tr></table></figure>
<h3 id="intel-架构迭代"><a href="#intel-架构迭代" class="headerlink" title="intel 架构迭代"></a><a href="https://jcf94.com/2018/02/13/2018-02-13-intel/" target="_blank" rel="external">intel 架构迭代</a></h3><p><img src="/images/oss/94d79c38-b577-4d31-b40c-fbec4cdc5f2e.png" alt="Intel processor roadmap"></p>
<p>2006年90、65纳米工艺酷睿core Yonah上市，32位架构，仍然算是奔腾Pro系列；2006推出酷睿处理器是介于NetBurst和Core之间，其实是NetBurst的改版，Core 2是第一个基于Core架构的原生双核处理器，65nm工艺，使得AMD K8架构优势全无，直接投入开发原生四核架构K10去了。</p>
<p>2006年7月<a href="https://zh.wikipedia.org/wiki/酷睿2" target="_blank" rel="external">酷睿2</a>处理器代号为“<a href="https://zh.wikipedia.org/w/index.php?title=Conroe&amp;action=edit&amp;redlink=1" target="_blank" rel="external">Conroe</a>”，采用<a href="https://zh.wikipedia.org/wiki/X86-64" target="_blank" rel="external">x86-64</a>指令集与65纳米双核心架构。该处理器基于全新的酷睿微架构，虽然时脉大大降低，但在效率方面和性能方面有了重大改进。从这一时期开始，在深度流水线和资源混乱的运行引擎上维持每个周期的高指令（IPC）</p>
<p>2008年的 Nehalem （酷睿i7）是采用 45nm 工艺的新架构，主要优势来自重新设计的I/O和存储系统，这些系统具有新的Intel QuickPath Interconnect和集成的内存控制器，可支持三通道的DDR3内存。引入片内4-12MB的L3 Cache；重新加入超线程；分支预测分级；取消北桥，IMC(集成内存控制器）从北桥挪到片内</p>
<p>2009年的 Westmere 升级到 32nm；退出第一代I5/I3，Xeon 系列也开始推出第一代E命名的E7-x8xx系列。</p>
<p>2010年的 Lynnfield/Clarkdale 基于 45nm/32nm 工艺的新架构，第一代智能酷睿处理器；</p>
<p>2011年的 Sandy Bridge ，基于 32nm 工艺的新架构，第二代智能酷睿处理器，增加AVX指令集扩展， 对虚拟化提供更好支持；实现了GPU和CPU的融合</p>
<p>2012年的 IVY Bridge，是 Sandy Bridge 的 22nm 升级版，第三代智能酷睿处理器，Tick级改进；</p>
<p>2013年的 Haswell ，基于 22nm 工艺的新架构，第四代智能酷睿处理器，Tock级改进；</p>
<p>2014年的 Broadwell，是 Haswell 的 14nm 升级版，第五代智能酷睿处理器；</p>
<p>2015年则推出 SkyLake，基于 14nm 工艺的新架构， Tock级改进，Ring-Bus改成了Mesh架构，第6代Core i系列，8163就是这款；socket之间UPI互联，内存频率通道增强。不再使用Xeon命名，而是改用Bronze/Silver/Gold/Platinum 4个系列。青铜和白银系列支持双路（原本的 E5-24xx、E7-28xx 系列），黄金系列支持四路（原本的 E5-46xx、E7-48xx 系列），白金系列支持八路（原本的 E7-88xx 系列）；</p>
<p>2019年的Cascade Lake也是Skylake的优化，是Intel首个支持基于3D XPoint的内存模块的微体系结构。同年也正式宣布了十代酷睿处理器，即i9-10900k，还是Skylake微内核不变。</p>
<p>2020年的10nm Ice Lake自家工厂无能，改由台积电加工。</p>
<p>Core 架构代号是 Yonah，把 NetBurst 做深了的流水线级数又砍下来了，主频虽然降下来了（而且即使后来工艺提升到 45nm 之后也没有超过 NetBurst 的水平），但是却提高了整个流水线中的资源利用率，所以性能还是提升了；把奔腾 4 上曾经用过的超线程也砍掉了；对各个部分进行了强化，双核共享 L2 cache 等等。</p>
<p>从 Core 架构开始是真的走向多核了，就不再是以前 “胶水粘的” 伪双核了，这时候已经有最高 4 核的处理器设计了。</p>
<p>Core 从 65nm 改到 45nm 之后，基于 45nm 又推出了新一代架构叫 Nehalem，新架构Nehalem<strong>采用 Intel QPI 来代替原来的前端总线</strong>，<strong>PCIE 和 DMI 控制器直接做到片内了</strong>，不再需要北桥。</p>
<p>2006年Intel也提出了Tick-Tock架构战略。Tick年改进制程工艺，微架构基本不做大改，重点在把晶体管的工艺水平往上提升;Tock年改进微架构设计，保持工艺水平不变，重点在用更复杂、更高级的架构设计。然后就是一代 Tick 再一代 Tock交替演进。</p>
<p>从2006年酷睿架构开始，基本是摁着AMD在地上摩擦，直到2017年的AMD Zen杀回来，性能暴增。<img src="/images/951413iMgBlog/f5e72f61ed8b6c2ba163e00491c7db40.png" alt="img"></p>
<p><strong>Sandy Bridge 引入核间的ring bus</strong></p>
<p>感觉Broadwell前面这几代都是在优化cache、通信；接下来的Broadwell和SkyLake就开始改进不大了，疯狂挤牙膏（唯一比较大的改进就是<strong>Ring bus到Mesh</strong>）</p>
<p><img src="/images/951413iMgBlog/image-20210602154509596.png" alt="image-20210602154509596"></p>
<h3 id="不同的架构下的参数"><a href="#不同的架构下的参数" class="headerlink" title="不同的架构下的参数"></a>不同的架构下的参数</h3><p><img src="/images/oss/e4a2fb522be7aa65158778b7ea825207.png" alt="image.png"></p>
<h2 id="UEFI和Bios"><a href="#UEFI和Bios" class="headerlink" title="UEFI和Bios"></a>UEFI和Bios</h2><p><strong>UEFI</strong>，全称Unified Extensible Firmware Interface，即“统一的可扩展固件接口”，是一种详细描述全新类型接口的标准，是适用于电脑的标准固件接口，旨在代替BIOS（基本输入/输出系统）</p>
<p>电脑中有一个BIOS设置，它主要负责开机时检测硬件功能和引导操作系统启动的功能。而UEFI则是用于操作系统自动从预启动的操作环境，加载到一种操作系统上从而节省开机时间。</p>
<p>UEFI启动是一种新的主板引导项，它被看做是bios的继任者。UEFI最主要的特点是图形界面，更利于用户对象图形化的操作选择。</p>
<p><img src="/images/951413iMgBlog/webp" alt="img"></p>
<p>UEFI 图形界面：</p>
<p><img src="/images/951413iMgBlog/webp-20210601102242967" alt="img"></p>
<p>简单的来说UEFI启动是新一代的BIOS，功能更加强大，而且它是以图形图像模式显示，让用户更便捷的直观操作。</p>
<p>如今很多新产品的电脑都支持UEFI启动模式，甚至有的电脑都已抛弃BIOS而仅支持UEFI启动。这不难看出UEFI正在取代传统的BIOS启动。</p>
<p>UEFI固件通过ACPI报告给OS NUMA的组成结构，其中最重要的是SRAT（System Resource Affinity Table）和SLIT（System Locality Information Table）表。</p>
<h2 id="socket"><a href="#socket" class="headerlink" title="socket"></a>socket</h2><p>socket对应主板上的一个插槽，也可以简单理解为一块物理CPU。同一个socket对应着 /proc/cpuinfo 里面的physical id一样。</p>
<p>一个socket至少对应着一个或多个node/NUMA</p>
<h2 id="GPU"><a href="#GPU" class="headerlink" title="GPU"></a>GPU</h2><p>GPU只处理有限的计算指令（主要是浮点运算–矩阵操作），不需要分支预测、乱序执行等，所以将Core里面的电路简化（如下图左边），同时通过SIMT（Single Instruction，Multiple Threads， 类似 SIMD）在取指令和指令译码的阶段，取出的指令可以给到后面多个不同的 ALU 并行进行运算。这样，我们的一个 GPU 的核里，就可以放下更多的 ALU，同时进行更多的并行运算了（如下图右边） 。 在 SIMD 里面，CPU 一次性取出了固定长度的多个数据，放到寄存器里面，用一个指令去执行。<strong>而 SIMT，可以把多条数据，交给不同的线程去处理。</strong></p>
<p><img src="/images/951413iMgBlog/3d7ce9c053815f6a32a6fbf6f7fb9628.jpeg" alt="img"></p>
<p>GPU的core在流水线stall的时候和超线程一样，可以调度别的任务给ALU，既然要调度一个不同的任务过来，我们就需要针对这个任务，提供更多的执行上下文。所以，一个 Core 里面的执行上下文的数量，需要比 ALU 多。</p>
<p><img src="/images/951413iMgBlog/c971c34e0456dea9e4a87857880bb5b8.jpeg" alt="img"></p>
<p>在通过芯片瘦身、SIMT 以及更多的执行上下文，我们就有了一个更擅长并行进行暴力运算的 GPU。这样的芯片，也正适合我们今天的深度学习和挖矿的场景。</p>
<p>NVidia 2080 显卡的技术规格，就可以算出，它到底有多大的计算能力。2080 一共有 46 个 SM（Streaming Multiprocessor，流式处理器），这个 SM 相当于 GPU 里面的 GPU Core，所以你可以认为这是一个 46 核的 GPU，有 46 个取指令指令译码的渲染管线。每个 SM 里面有 64 个 Cuda Core。你可以认为，这里的 Cuda Core 就是我们上面说的 ALU 的数量或者 Pixel Shader 的数量，46x64 呢一共就有 2944 个 Shader。然后，还有 184 个 TMU，TMU 就是 Texture Mapping Unit，也就是用来做纹理映射的计算单元，它也可以认为是另一种类型的 Shader。</p>
<p><img src="/images/951413iMgBlog/14d05a43f559cecff2b0813e8d5bdde2.png" alt="img"></p>
<p>2080 的主频是 1515MHz，如果自动超频（Boost）的话，可以到 1700MHz。而 NVidia 的显卡，根据硬件架构的设计，每个时钟周期可以执行两条指令。所以，能做的浮点数运算的能力，就是：</p>
<blockquote>
<p> （2944 + 184）× 1700 MHz × 2  = 10.06  TFLOPS</p>
</blockquote>
<p>最新的 Intel i9 9900K 的性能是多少呢？不到 1TFLOPS。而 2080 显卡和 9900K 的价格却是差不多的。所以，在实际进行深度学习的过程中，用 GPU 所花费的时间，往往能减少一到两个数量级。而大型的深度学习模型计算，往往又是多卡并行，要花上几天乃至几个月。这个时候，用 CPU 显然就不合适了。</p>
<h3 id="为什么GPU比CPU快"><a href="#为什么GPU比CPU快" class="headerlink" title="为什么GPU比CPU快"></a><a href="https://medium.com/@shachishah.ce/do-we-really-need-gpu-for-deep-learning-47042c02efe2#:~:text=Bandwidth%20is%20one%20of%20the,be%20used%20for%20other%20tasks." target="_blank" rel="external">为什么GPU比CPU快</a></h3><p>GPU拥有更多的计算单元</p>
<p>GPU像是大卡车，每次去内存取数据取得多，但是Latency高（AP）；CPU像是法拉利，更在意处理速度而不是一次处理很多数据，所以CPU有多级cache，都是围绕速度在优化（TP）。在GPU中取数据和处理是流水线所以能消除高Latency。</p>
<p>GPU的每个core拥有更小更快的cache和registry，但是整个GPU的registry累加起来能比CPU大30倍，同时带宽也是后者的16倍</p>
<p><img src="/images/951413iMgBlog/image-20210615105019238.png" alt="image-20210615105019238"></p>
<p>总之GPU相对于CPU像是一群小学生和一个大学教授一起比赛计算10以内的加减法。</p>
<h3 id="英伟达的GPU出圈"><a href="#英伟达的GPU出圈" class="headerlink" title="英伟达的GPU出圈"></a>英伟达的GPU出圈</h3><p>2016年之前英伟达的营收和市值基本跟intel一致，但是2021 年 4 月中旬的数字，Intel 是英伟达的近 5 倍，但是如果论市值，英伟达是 Intel 的 1.5 倍。</p>
<p><strong>GPGPU：点亮并行计算的科技树</strong></p>
<p>2007 年，英伟达首席科学家 David Kirk 非常前瞻性地提出 GPGPU 的概念，把英伟达和 GPU 从单纯图形计算拓展为通用计算，强调并行计算，鼓励开发者用 GPU 做计算，而不是局限在图形加速这个传统的领域。GPGPU，前面这个 GP，就是 General Purpose 通用的意思。</p>
<p>CUDA（Compute Unified Device Architecture，统一计算架构），CUDA 不仅仅是一个 GPU 计算的框架，它对下抽象了所有的英伟达出品的 GPU，对上构建了一个通用的编程框架，它实质上制定了一个 GPU 和上层软件之间的接口标准。</p>
<p>在 GPU 市场的早期竞争中，英伟达认识到软硬件之间的标准的重要性，花了 10 年苦功，投入 CUDA 软件生态建设，把软硬件之间的标准，变成自己的核心竞争力。</p>
<p>英伟达可以说是硬件公司中软件做得最好的。同样是生态强大，Wintel 的生态是微软帮忙建的，ARM-Android 的生态是 Google 建的，而 GPU-CUDA 的生态是英伟达自建的。</p>
<p>这个标准有多重要？这么说吧，一流企业定标准，二流企业做品牌，三流企业做产品。在所有的半导体公司中，制定出软件与硬件之间的标准，而且现在还算成功的，只有 3 个，一个是 x86 指令集，一个是 ARM 指令集，还有一个就是 CUDA 了。</p>
<p><img src="/images/951413iMgBlog/313d469d57e6b92eyy03dee63614a72c.png" alt="img"></p>
<p>GPU 相对 CPU 的 TOPS per Watt（花费每瓦特电能可以获得的算力）的差异竞争优势，它的本质就是将晶体管花在计算上，而不是逻辑判断上</p>
<p>2020 年超级计算机 TOP500 更新榜单，可以看到 TOP10 的超级计算机中有 8 台采用了英伟达 GPU、InfiniBand 网络技术，或同时采用了两种技术。TOP500 榜单中，有 333 套（三分之二）采用了英伟达的技术。</p>
<p>挖矿和深度学习撑起了英伟达的市值。</p>
<h2 id="现场可编程门阵列FPGA（Field-Programmable-Gate-Array）"><a href="#现场可编程门阵列FPGA（Field-Programmable-Gate-Array）" class="headerlink" title="现场可编程门阵列FPGA（Field-Programmable Gate Array）"></a>现场可编程门阵列FPGA（Field-Programmable Gate Array）</h2><p>设计芯片十分复杂，还要不断验证。</p>
<p>那么不用单独制造一块专门的芯片来验证硬件设计呢？能不能设计一个硬件，通过不同的程序代码，来操作这个硬件之前的电路连线，通过“编程”让这个硬件变成我们设计的电路连线的芯片呢？这就是FPGA</p>
<ul>
<li>P 代表 Programmable，这个很容易理解。也就是说这是一个可以通过编程来控制的硬件。</li>
<li>G 代表 Gate 也很容易理解，它就代表芯片里面的门电路。我们能够去进行编程组合的就是这样一个一个门电路。</li>
<li>A 代表的 Array，叫作阵列，说的是在一块 FPGA 上，密密麻麻列了大量 Gate 这样的门电路。</li>
<li>最后一个 F，不太容易理解。它其实是说，一块 FPGA 这样的板子，可以在“现场”多次进行编程。它不像 PAL（Programmable Array Logic，可编程阵列逻辑）这样更古老的硬件设备，只能“编程”一次，把预先写好的程序一次性烧录到硬件里面，之后就不能再修改了。</li>
</ul>
<p>FPGA 通过“软件”来控制“硬件”</p>
<h2 id="专用集成电路ASIC（Application-Specific-Integrated-Circuit）"><a href="#专用集成电路ASIC（Application-Specific-Integrated-Circuit）" class="headerlink" title="专用集成电路ASIC（Application-Specific Integrated Circuit）"></a>专用集成电路ASIC（Application-Specific Integrated Circuit）</h2><p>为解决特定应用问题而定制设计的集成电路，就是 ASIC（Application Specific IC）。当 ASIC 规模够大，逐渐通用起来，某类 ASIC 就会有一个专有名称，成为一个品类。例如现在用来解决人工智能问题的神经网络处理器。</p>
<p>除了 CPU、GPU，以及刚刚的 FPGA，我们其实还需要用到很多其他芯片。比如，现在手机里就有专门用在摄像头里的芯片；录音笔里会有专门处理音频的芯片。尽管一个 CPU 能够处理好手机拍照的功能，也能处理好录音的功能，但是我们直接在手机或者录音笔里塞上一个 Intel CPU，显然比较浪费。</p>
<p>因为 ASIC 是针对专门用途设计的，所以它的电路更精简，单片的制造成本也比 CPU 更低。而且，因为电路精简，所以通常能耗要比用来做通用计算的 CPU 更低。而我们所说的早期的图形加速卡，其实就可以看作是一种 ASIC。</p>
<p>因为 ASIC 的生产制造成本，以及能耗上的优势，过去几年里，有不少公司设计和开发 ASIC 用来“挖矿”。这个“挖矿”，说的其实就是设计专门的数值计算芯片，用来“挖”比特币、ETH 这样的数字货币。</p>
<p>如果量产的ASIC比较小的话可以直接用FPGA来实现，FPGA介于ASIC和PLA之间，PLA（可编程控制器）太简单，直接上ASIC又过于复杂、能耗高、成本高。</p>
<h2 id="张量处理器TPU-（tensor-processing-unit）"><a href="#张量处理器TPU-（tensor-processing-unit）" class="headerlink" title="张量处理器TPU （tensor processing unit）"></a>张量处理器TPU （tensor processing unit）</h2><p><strong>张量处理器</strong>（英语：tensor processing unit，缩写：TPU）是<a href="https://baike.baidu.com/item/Google" target="_blank" rel="external">Google</a>为<a href="https://baike.baidu.com/item/机器学习" target="_blank" rel="external">机器学习</a>定制的专用芯片（ASIC），专为Google的<a href="https://baike.baidu.com/item/深度学习" target="_blank" rel="external">深度学习</a>框架<a href="https://baike.baidu.com/item/TensorFlow" target="_blank" rel="external">TensorFlow</a>而设计。</p>
<p>在性能上，TPU 比现在的 CPU、GPU 在深度学习的推断任务上，要快 15～30 倍。而在能耗比上，更是好出 30～80 倍。另一方面，Google 已经用 TPU 替换了自家数据中心里 95% 的推断任务，可谓是拿自己的实际业务做了一个明证。</p>
<h2 id="其它基础知识"><a href="#其它基础知识" class="headerlink" title="其它基础知识"></a>其它基础知识</h2><p><strong>晶振频率</strong>：控制CPU上的晶体管开关切换频率。一次晶振就是一个cycle。</p>
<p>从最简单的单指令周期 CPU 来说，其实时钟周期应该是放下最复杂的一条指令的时间长度。但是，我们现在实际用的都没有单指令周期 CPU 了，而是采用了流水线技术。采用了流水线技术之后，单个时钟周期里面，能够执行的就不是一个指令了。我们会把一条机器指令，拆分成很多个小步骤。不同的指令的步骤数量可能还不一样。不同的步骤的执行时间，也不一样。所以，一个时钟周期里面，能够放下的是最耗时间的某一个指令步骤。</p>
<p>不过没有pipeline，一条指令最少也要N个circle（N就是流水线深度）；但是理想情况下流水线跑满的话一个指令也就只需要一个circle了，也就是IPC能到理论最大值1； 加上超标流水线一般IPC都能4，就是一般CPU的超标量。</p>
<p><strong>制程</strong>：7nm、14nm、4nm都是指的晶体大小，用更小的晶体可以在相同面积CPU上集成更多的晶体数量，那么CPU的运算能力也更强。增加晶体管可以增加硬件能够支持的指令数量，增加数字通路的位数，以及利用好电路天然的并行性，从硬件层面更快地实现特定的指。打个比方，比如我们最简单的电路可以只有加法功能，没有乘法功能。乘法都变成很多个加法指令，那么实现一个乘法需要的指令数就比较多。但是如果我们增加晶体管在电路层面就实现了这个，那么需要的指令数就变少了，执行时间也可以缩短。</p>
<blockquote>
<p>功耗 ~= 1/2 ×负载电容×电压的平方×开关频率×晶体管数量</p>
</blockquote>
<p>功耗和电压的平方是成正比的。这意味着电压下降到原来的 1/5，整个的功耗会变成原来的 1/25。</p>
<p>堆栈溢出：函数调用用压栈来保存地址、变量等相关信息。没有选择直接嵌套扩展代码是避免循环调用下嵌套是个无尽循环，inline函数内联就是一种嵌套代码扩展优化。</p>
<p>windows下的exe文件之所以没法放到linux上运行（都是intel x86芯片），是因为可执行程序要经过链接，将所依赖的库函数调用合并进来形成可执行文件。这个可执行文件在Linux 下的 ELF（Execuatable and Linkable File Format） 文件格式，而 Windows 的可执行文件格式是一种叫作 PE（Portable Executable Format）的文件格式。Linux 下的装载器只能解析 ELF 格式而不能解析 PE 格式。而且windows和linux的库函数必然不一样，没法做到兼容。</p>
<p><strong>链接器</strong>: 扫描所有输入的目标文件，然后把所有符号表里的信息收集起来，构成一个全局的符号表。然后再根据重定位表，把所有不确定要跳转地址的代码，根据符号表里面存储的地址，进行一次修正。最后，把所有的目标文件的对应段进行一次合并，变成了最终的可执行代码。这也是为什么，可执行文件里面的函数调用的地址都是正确的。</p>
<p><img src="/images/951413iMgBlog/997341ed0fa9018561c7120c19cfa2a7.jpg" alt="img"></p>
<p><strong>虚拟内存地址</strong>：应用代码可执行地址必须是连续，这也就意味着一个应用的内存地址必须连续，实际一个OS上会运行多个应用，没办法保证地址连续，所以可以通过虚拟地址来保证连续，虚拟地址再映射到实际零散的物理地址上（可以解决碎片问题），这个零散地址的最小组织形式就是Page。虚拟地址本来是连续的，使用一阵后数据部分也会变成碎片，代码部分是不可变的，一直连续。另外虚拟地址也方便了OS层面的库共享。</p>
<p>为了扩大虚拟地址到物理地址的映射范围同时又要尽可能少地节约空间，虚拟地址到物理地址的映射一般分成了四级Hash，这样4Kb就能管理256T内存。但是带来的问题就是要通过四次查找使得查找慢，这时引入TLAB来换成映射关系。</p>
<p><strong>共享库</strong>：在 Windows 下，这些共享库文件就是.dll 文件，也就是 Dynamic-Link Libary（DLL，动态链接库）。在 Linux 下，这些共享库文件就是.so 文件，也就是 Shared Object（一般我们也称之为动态链接库). 不同的进程，调用同样的 lib.so，各自 全局偏移表（GOT，Global Offset Table） 里面指向最终加载的动态链接库里面的虚拟内存地址是不同的, 各个程序各自维护好自己的 GOT，能够找到对应的动态库就好了, 有点像函数指针。</p>
<p><img src="/images/951413iMgBlog/1144d3a2d4f3f4f87c349a93429805c8.jpg" alt="img"></p>
<p>符号表：/boot/System.map 和 /proc/kallsyms </p>
<p><strong>超线程（Hyper-Threading）</strong>: 在CPU内部增加寄存器等硬件设施，但是ALU、译码器等关键单元还是共享。在一个物理 CPU 核心内部，会有双份的 PC 寄存器、指令寄存器乃至条件码寄存器。超线程的目的，是在一个线程 A 的指令，在流水线里停顿的时候，让另外一个线程去执行指令。因为这个时候，CPU 的译码器和 ALU 就空出来了，那么另外一个线程 B，就可以拿来干自己需要的事情。这个线程 B 可没有对于线程 A 里面指令的关联和依赖。</p>
<h2 id="宏观认识集成电路半导体行业"><a href="#宏观认识集成电路半导体行业" class="headerlink" title="宏观认识集成电路半导体行业"></a>宏观认识集成电路半导体行业</h2><p>先从市场分布和市场占有率等几个行业宏观概念来了解半导体行业</p>
<h3 id="半导体产业的产值分布"><a href="#半导体产业的产值分布" class="headerlink" title="半导体产业的产值分布"></a>半导体产业的产值分布</h3><p>下图中的处理器就是我们日常所说的CPU，当然还包含了GPU等</p>
<p>我们常说的内存、固态硬盘这些存储器也是数字IC，后面你会看到一个CPU core里面还会有用于存储的cache电路</p>
<p><img src="/images/951413iMgBlog/be159461be7c0a5569be21b30a24db50.png" alt="img"></p>
<h3 id="从一台iPhone来看集成电路和芯片"><a href="#从一台iPhone来看集成电路和芯片" class="headerlink" title="从一台iPhone来看集成电路和芯片"></a>从一台iPhone来看集成电路和芯片</h3><p>先看一台iPhone X拆解分析里面的所有芯片：</p>
<p><img src="/images/951413iMgBlog/8bbc7b771359dfc07c81ca2a064cb30c.jpg" alt="img"></p>
<h3 id="全球半导体营收分布"><a href="#全球半导体营收分布" class="headerlink" title="全球半导体营收分布"></a>全球半导体营收分布</h3><p><img src="/images/951413iMgBlog/d3a2690aaf6be233d08404c108fc4449.png" alt="img"></p>
<p>美光：美国；Hynix海力士：韩国现代；美国双通：高通(CDMA)、博通(各种买买买、并购，网络设备芯片)；欧洲双雄(汽车芯片)：恩智浦和英飞凌</p>
<p>半导体行业近 5 年的行业前十的公司列了如下：</p>
<p><img src="/images/951413iMgBlog/639990db9d26a8a54d1baaf3d6e513d4.png" alt="img"></p>
<h4 id="半导体产品的十大买家"><a href="#半导体产品的十大买家" class="headerlink" title="半导体产品的十大买家"></a>半导体产品的十大买家</h4><p>BBK是步步高集团，包含vivo、oppo、oneplus、realme等</p>
<p><img src="/images/951413iMgBlog/3bb8531b7ab4c503436838ab15434310.png" alt="img"></p>
<h3 id="国内半导体市场情况"><a href="#国内半导体市场情况" class="headerlink" title="国内半导体市场情况"></a>国内半导体市场情况</h3><p>中国半导体协会总结过国产芯片的比例，2014 年出台的《国家集成电路产业发展纲要》和 2015 年的《中国制造 2025》文件中有明确提出：到 2020 年，集成电路产业与国际先进水平的差距逐步缩小；2020 年中国芯片自给率要达到 40%，2025 年要达到 50%。</p>
<p><img src="/images/951413iMgBlog/a37bd5e13f2920fb2e85a7907cdc852a.jpeg" alt="img"></p>
<p>国产化国家主导：紫光， 紫光的策略从收购转为自建，2016 年 12 月，合并武汉新芯，成立长江存储，与西数合资成立紫光西数。</p>
<p>长江存储在量产 64 层 NAND Flash 之后，2020 年首发 192 层 3D NAND，被预测 2021 会拿下 8% 的 NAND Flash 份额。同时，在存储芯片领域，中国还有一家公司叫做长鑫存储，长鑫存储以唯一一家中国公司的名号，杀入 DRAM 领域。在世界著名的行业分析公司 Yole 公司的报告上，显示长江存储和长鑫存储与三星、SK 海力士、美光和 Intel 齐头并进。</p>
<p>市场份额上，国产存储芯片市场，也许还有望达到 2025 的目标。</p>
<p>以上是我们对集成电路半导体行业的宏观认识。接下来我们从一颗CPU的生产制造开始讲</p>
<h3 id="工艺"><a href="#工艺" class="headerlink" title="工艺"></a>工艺</h3><p>光刻的粒度越来越细，玩家也越来越少，基本主流都是代工模式：</p>
<p><img src="/images/951413iMgBlog/beebe27eacd37075dyy37a4182169f04.png" alt="img"></p>
<p><img src="/images/951413iMgBlog/5eb09cde20395b84ff8c746c27d9f7b7.jpg" alt="img"></p>
<p>晶体管密度比较</p>
<p><img src="/images/951413iMgBlog/image-20210728095829384.png" alt="image-20210728095829384"></p>
<h2 id="计算机芯片发展总结和展望"><a href="#计算机芯片发展总结和展望" class="headerlink" title="计算机芯片发展总结和展望"></a><a href="https://weibo.com/ttarticle/p/show?id=2309404745052319777615" target="_blank" rel="external">计算机芯片发展总结和展望</a></h2><p>从最早集成工艺驱动了CPU的性能符合摩尔定律发展，到现在工艺受限于物理上的客观因素（门延迟、电路间的绝缘层越薄漏电越严重–高温导致漏电呈指数级增加、电压无法随着尺寸降低而线性降低–130nm之前电压随现款而线性下降，到90nm工艺之后工作电压始终在1V左右无法进一步下降）越来越难进一步优化，导致摩尔定律基本已经做不到了。</p>
<p>下图显示最近几年CPU性能改进都在3%左右了（红色部分）</p>
<p><img src="/images/951413iMgBlog/f6.jpg" alt="f6.jpg"></p>
<p>从上图可以看到性能的优化从最早CISC每年22%来自于指令本身优化，然后RISC（CISC内部也学习RISC将复杂指令编译成简单指令来适应流水线）每年52%，再到简单多核，然后到大规模多核，最后到红色无所改进。</p>
<p><strong>登纳德缩放定律</strong>（Dennard scaling）指出，随着晶体管密度的增加，每个晶体管的能耗将降低，因此硅芯片上每平方毫米上的能耗几乎保持恒定。由于每平方毫米硅芯片的计算能力随着技术的迭代而不断增强，计算机将变得更加节能。登纳德缩放定律从 2007 年开始大幅放缓，2012 年左右接近失效（见下图）。</p>
<p><img src="/images/951413iMgBlog/f3.jpg" alt="f3.jpg"></p>
<p><strong>阿姆达尔定律（Amdahl’s Law）</strong>认为，并行计算机的加速受限于串行计算的部分。如下图假设只在一个处理器上执行时的串行执行的部分所占比例不同，与单个内核相比，最多 64 个内核的应用程序运行速度能快多少。例如，如果只有 1% 的时间是串行的，那么 64 核配置可加速大约 35 倍，但所需能量与 64 个处理器成正比，因此大约有 45% 的能量被浪费了。核数越多多核带来的提升效果越来越差（程序总有地方是串行的）</p>
<p><img src="/images/951413iMgBlog/f5.jpg" alt="f5.jpg"></p>
<p>大概从2000年左右CPU的性能增长开始放缓，到2018年实际性能比摩尔定律预估的差了15倍（注意纵坐标是指数级），因为CMOS技术已经接近极限</p>
<p><img src="/images/951413iMgBlog/f2.jpg" alt="f2.jpg"></p>
<blockquote>
<p><a href="https://baike.baidu.com/item/CMOS" target="_blank" rel="external">CMOS</a>电路是互补型金属<a href="https://baike.baidu.com/item/氧化物半导体/6199658" target="_blank" rel="external">氧化物半导体</a>电路(Complementary Metal-Oxide-Semiconductor)的英文字头缩写，它由绝缘<a href="https://baike.baidu.com/item/场效应晶体管/2293646" target="_blank" rel="external">场效应晶体管</a>组成，由于只有一种<a href="https://baike.baidu.com/item/载流子/7163305" target="_blank" rel="external">载流子</a>，因‘而是一种<a href="https://baike.baidu.com/item/单极型晶体管/9003337" target="_blank" rel="external">单极型晶体管</a>集成电路，其基本结构是一个N沟道<a href="https://baike.baidu.com/item/MOS管/8703611" target="_blank" rel="external">MOS管</a>和一个P沟道MOS管</p>
</blockquote>
<p>过去一些对性能或者便利性的改进以及对这些改进的打分：</p>
<blockquote>
<p>虚拟地址在计算机体系结构里可以评为特优的一项技术，非性能上的改进，甚至对性能有负面影响；</p>
<p>超线程、流水线、多发射只是优；</p>
<p>cache 只是良好（成本高），cache整体肯定比超线程对性能提升要大，但是因为高成本导致得分不高</p>
</blockquote>
<h3 id="计算机架构的未来机遇"><a href="#计算机架构的未来机遇" class="headerlink" title="计算机架构的未来机遇"></a><a href="https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext#body-6" target="_blank" rel="external">计算机架构的未来机遇</a></h3><p>当实际集成度（性能）已经不再增长后，我们必须找到新的办法</p>
<p>如下图是用Python实现的矩阵相乘的性能优化过程，简单地将 Python 语言代码重写为 C 代码就可以将性能提升 46 倍（Python 是典型的高级、动态类型语言）。在多核上运行并行循环（parallel loops）又将性能提升接近 7 倍。优化内存配置又将性能提升了近 19 倍，而通过单指令多数据（SIMD）并行化操作（一个指令执行 16 个 32-bit 运算）的硬件扩展，性能又提升了 8 倍多。也就是说，最终的高度优化版本在多核英特尔处理器上的运行速度是初始 Python 版本的 62,000 多倍。这当然只是一个很小的例子，但我们会期望程序员使用优化库。尽管这夸大了常见的性能差距，但很多程序的性能差距可能达到 100 到 1000 倍。</p>
<p><img src="/images/951413iMgBlog/f7.jpg" alt="f7.jpg"></p>
<h4 id="特定领域的体系结构（DSA）"><a href="#特定领域的体系结构（DSA）" class="headerlink" title="特定领域的体系结构（DSA）"></a>特定领域的体系结构（DSA）</h4><p>特定领域的体系结构（DSA）–针对具体领域的特定优化和改进可以能是一个大的改进方向。比如SIMD，同时DSA和cache、内存的层次结构更匹配。</p>
<p>对特定领域降低精度，通用任务的 CPU 通常支持 32 和 64 位整型数和浮点数数据。对于很多机器学习和图像应用来说，这种准确率有点浪费了。例如在深度神经网络中（DNN），推理通常使用 4、8 或 16 位整型数，从而提高数据和计算吞吐量。同样，对于 DNN 训练程序，浮点数很有意义，但 32 位就够了，16 为经常也能用。</p>
<p>还可以在特定领域通过<strong>特定领域语言（DSL）编写的目标程序，这些程序可以实现更高的并行性</strong>（比如TPU、GPU）</p>
<h4 id="开放式架构（Open-Architectures）"><a href="#开放式架构（Open-Architectures）" class="headerlink" title="开放式架构（Open Architectures）"></a>开放式架构（Open Architectures）</h4><p>RISC-V</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Wafer：晶圆，一片大的纯硅圆盘，新闻里常说的12寸、30寸晶圆厂说的就是它，光刻机在晶圆上蚀刻出电路</p>
<p>Die：从晶圆上切割下来的裸片(包含多个core、北桥、GPU等)，Die的大小可以自由决定，得考虑成本和性能, Die做成方形便于切割和测试</p>
<p>封装：将一个或多个Die封装成一个物理上可以售卖的CPU</p>
<p>路：就是socket、也就是封装后的物理CPU</p>
<p>node：同一个Die下的多个core以及他们对应的内存，对应着NUMA</p>
<p>现在计算机系统的CPU和芯片组内核Die都是先封装到一个印制板上（PCB，printed circuit board），再通过LGA等等插槽（Socket）连上主板或直接焊接在主板上。这个过程叫做封装（Package），相关技术叫做封装技术。</p>
<h2 id="系列文章-1"><a href="#系列文章-1" class="headerlink" title="系列文章"></a>系列文章</h2><p><a href="/2021/06/01/CPU的制造和概念/">CPU的制造和概念</a></p>
<p><a href="/2021/05/16/CPU Cache Line 和性能/">CPU 性能和Cache Line</a></p>
<p><a href="/2021/05/16/Perf IPC以及CPU利用率/">Perf IPC以及CPU性能</a></p>
<p><a href="/2021/06/18/几款CPU性能对比/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></p>
<p><a href="/2021/05/15/飞腾ARM芯片(FT2500">飞腾ARM芯片(FT2500)的性能测试</a>的性能测试/)</p>
<p><a href="/2021/05/14/十年后数据库还是不敢拥抱NUMA/">十年后数据库还是不敢拥抱NUMA？</a></p>
<p><a href="/2021/03/07/一次海光物理机资源竞争压测的记录/">一次海光物理机资源竞争压测的记录</a></p>
<p><a href="/2019/12/16/Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的/">Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/05/16/CPU_Cache_Line和性能/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/05/16/CPU_Cache_Line和性能/" itemprop="url">CPU 性能和Cache Line</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-05-16T12:30:03+08:00">
                2021-05-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CPU/" itemprop="url" rel="index">
                    <span itemprop="name">CPU</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="CPU-性能和Cache-Line"><a href="#CPU-性能和Cache-Line" class="headerlink" title="CPU 性能和Cache Line"></a>CPU 性能和Cache Line</h1><p>为了让程序能快点，特意了解了CPU的各种原理，比如多核、超线程、NUMA、睿频、功耗、GPU、大小核再到分支预测、cache_line失效、加锁代价、IPC等各种指标（都有对应的代码和测试数据）都会在这系列文章中得到答案。当然一定会有程序员最关心的分支预测案例、Disruptor无锁案例、cache_line伪共享案例等等。</p>
<p>这次让我们从最底层的沙子开始用8篇文章来回答各种疑问以及大量的实验对比案例和测试数据。</p>
<p>大的方面主要是从这几个疑问来写这些文章：</p>
<ul>
<li>同样程序为什么CPU跑到800%还不如CPU跑到200%快？</li>
<li>IPC背后的原理和和程序效率的关系？</li>
<li>为什么数据库领域都爱把NUMA关了，这对吗？</li>
<li>几个国产芯片的性能到底怎么样？</li>
</ul>
<h2 id="系列文章"><a href="#系列文章" class="headerlink" title="系列文章"></a>系列文章</h2><p><a href="/2021/06/01/CPU的制造和概念/">CPU的制造和概念</a></p>
<p><a href="/2021/05/16/Perf IPC以及CPU利用率/">Perf IPC以及CPU性能</a></p>
<p><a href="/2021/05/16/CPU Cache Line 和性能/">CPU 性能和Cache Line</a></p>
<p><a href="/2021/05/14/十年后数据库还是不敢拥抱NUMA/">十年后数据库还是不敢拥抱NUMA？</a></p>
<p><a href="/2019/12/16/Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的/">Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的</a></p>
<p><a href="/2021/06/18/几款CPU性能对比/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></p>
<p><a href="/2021/03/07/一次海光物理机资源竞争压测的记录/">一次海光物理机资源竞争压测的记录</a></p>
<p><a href="/2021/05/15/飞腾ARM芯片-FT2500的性能测试/">飞腾ARM芯片(FT2500)的性能测试</a></p>
<p>CPU为什么要CACHE，请看这篇</p>
<h2 id="什么是-cache-line"><a href="#什么是-cache-line" class="headerlink" title="什么是 cache_line"></a>什么是 cache_line</h2><p>CPU从内存中读取数据的时候是一次读一个cache_line到 cache中以提升效率，一般情况下cache_line的大小是64 byte，也就是每次读取64byte到CPU cache中，按照热点逻辑还是大概率会依次被访问到（详见后面的例子）</p>
<p>Cache Line 是 CPU 和主存之间数据传输的最小单位。当一行 Cache Line 被从内存拷贝到 Cache 里，Cache 里会为这个 Cache Line 创建一个条目。这个 Cache 条目里既包含了拷贝的内存数据，即 Cache Line，又包含了这行数据在内存里的位置等元数据信息。</p>
<p>处理器都实现了 Cache 一致性 (Cache Coherence）协议。如历史上 x86 曾实现了<a href="https://en.wikipedia.org/wiki/MESI_protocol" target="_blank" rel="external"> MESI 协议</a>，以及 MESIF 协议。</p>
<h3 id="cache-失效"><a href="#cache-失效" class="headerlink" title="cache 失效"></a>cache 失效</h3><p>假设两个处理器 A 和 B, 都在各自本地 Cache Line 里有同一个变量的拷贝时，此时该 Cache Line 处于 Shared 状态。当处理器 A 在本地修改了变量，除去把本地变量所属的 Cache Line 置为 Modified 状态以外，还必须在另一个处理器 B 读同一个变量前，对该变量所在的 B 处理器本地 Cache Line 发起 Invaidate 操作，标记 B 处理器的那条 Cache Line 为 Invalidate 状态。随后，若处理器 B 在对变量做读写操作时，如果遇到这个标记为 Invalidate 的状态的 Cache Line，即会引发 Cache Miss，从而将内存中最新的数据拷贝到 Cache Line 里，然后处理器 B 再对此 Cache Line 对变量做读写操作。</p>
<p>cache ping-pong(cache-line ping-ponging) 是指不同的CPU共享位于同一个cache-line里边的变量，当不同的CPU频繁的对该变量进行读写时，会导致其他CPU cache-line的失效。</p>
<p>显而易见的是一旦cache失效就需要访问内存重新从内存中读取数据到CPU cache中，这个过程会很慢。</p>
<h2 id="查看-cache-line"><a href="#查看-cache-line" class="headerlink" title="查看 cache_line"></a>查看 cache_line</h2><p>如下 Linux <code>getconf</code> 命令的输出，除了 <code>*_LINESIZE</code> 指示了系统的 Cache Line 的大小是 64 字节外，还给出了 Cache 类别，大小。 其中 <code>*_ASSOC</code> 则指示了该 Cache 是几路关联 (Way Associative) 的。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">$sudo getconf -a |grep CACHE</div><div class="line">LEVEL1_ICACHE_SIZE                 32768</div><div class="line">LEVEL1_ICACHE_ASSOC                8</div><div class="line">LEVEL1_ICACHE_LINESIZE             64</div><div class="line">LEVEL1_DCACHE_SIZE                 32768</div><div class="line">LEVEL1_DCACHE_ASSOC                8</div><div class="line">LEVEL1_DCACHE_LINESIZE             64</div><div class="line">LEVEL2_CACHE_SIZE                  262144</div><div class="line">LEVEL2_CACHE_ASSOC                 4</div><div class="line">LEVEL2_CACHE_LINESIZE              64</div><div class="line">LEVEL3_CACHE_SIZE                  3145728</div><div class="line">LEVEL3_CACHE_ASSOC                 12</div><div class="line">LEVEL3_CACHE_LINESIZE              64</div><div class="line">LEVEL4_CACHE_SIZE                  0</div><div class="line">LEVEL4_CACHE_ASSOC                 0</div><div class="line">LEVEL4_CACHE_LINESIZE              0</div></pre></td></tr></table></figure>
<p>比如，对于下面的FT2500 ARM芯片下，L1D是32K，是因为32K=256*2*64（64就是cache_line大小，16个int）, 这32K是256个组，每组2行（x86一般是每组8行），每行就是一个cache_line</p>
<p><img src="/images/951413iMgBlog/image-20210914175307651.png" alt="image-20210914175307651"></p>
<h2 id="cache-line-影响性能的案例"><a href="#cache-line-影响性能的案例" class="headerlink" title="cache_line 影响性能的案例"></a>cache_line 影响性能的案例</h2><p>如下两个循环执行次数循环2是循环1的十六分之一。但是在x86和arm下执行时间都是循环2是循环1的四分之一左右。</p>
<p>之所以执行时间不是十六分之一是因为循环一重用了cache_line. </p>
<p>Xeon(R) Platinum 8260跑这个程序的性能是鲲鹏920的2倍左右。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line">#include &quot;stdio.h&quot;</div><div class="line">#include &lt;stdlib.h&gt;</div><div class="line">#include &lt;time.h&gt;</div><div class="line"></div><div class="line">long timediff(clock_t t1, clock_t t2) &#123;</div><div class="line">    long elapsed;</div><div class="line">    elapsed = ((double)t2 - t1) / CLOCKS_PER_SEC * 1000;</div><div class="line">    return elapsed;</div><div class="line">&#125;</div><div class="line"></div><div class="line">int main(int argc, char *argv[])</div><div class="line">&#123;</div><div class="line">	long length=64*1024*1024;</div><div class="line">	int* arr=malloc(64*1024*1024 * sizeof(int));</div><div class="line">	long i=0;</div><div class="line">	long j=0;</div><div class="line">	for (i = 0; i &lt; length; i++) arr[i] = i;</div><div class="line"></div><div class="line">	clock_t start=clock();</div><div class="line">	// 循环1</div><div class="line">	for(j=0; j&lt;10; j++)&#123;</div><div class="line">	    for (i = 0; i &lt; length; i++) arr[i] *= 3; //每取一次arr[i], 通过cache_line顺便把后面15个arr[i]都取过来了</div><div class="line">	&#125;</div><div class="line">  clock_t end =clock();</div><div class="line">	printf(&quot;%lu\n&quot;, timediff(start,end));</div><div class="line"></div><div class="line">  start=clock();</div><div class="line">	// 循环2</div><div class="line">	for(j=0; j&lt;10; j++)&#123;</div><div class="line">	    for (i = 0; i &lt; length; i += 16) arr[i] *= 3;</div><div class="line">	&#125;</div><div class="line">  end =clock();</div><div class="line">  printf(&quot;%lu\n&quot;, timediff(start,end));</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>鲲鹏920上循环一的perf结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">#perf stat -- ./cache_line_loop.out</div><div class="line">2790</div><div class="line"></div><div class="line">failed to read counter branches</div><div class="line"></div><div class="line"> Performance counter stats for &apos;./cache_line_loop.out&apos;:</div><div class="line"></div><div class="line">       3238.892820      task-clock (msec)         #    1.000 CPUs utilized</div><div class="line">                 4      context-switches          #    0.001 K/sec</div><div class="line">                 0      cpu-migrations            #    0.000 K/sec</div><div class="line">            65,582      page-faults               #    0.020 M/sec</div><div class="line">     8,420,900,487      cycles                    #    2.600 GHz</div><div class="line">        23,284,432      stalled-cycles-frontend   #    0.28% frontend cycles idle</div><div class="line">     4,709,527,283      stalled-cycles-backend    #   55.93% backend  cycles idle</div><div class="line">    14,553,892,976      instructions              #    1.73  insns per cycle</div><div class="line">                                                  #    0.32  stalled cycles per insn //因为有cache_line的命中，stall是循环二的四分之一</div><div class="line">   &lt;not supported&gt;      branches</div><div class="line">           141,482      branch-misses             #    0.00% of all branches</div><div class="line"></div><div class="line">       3.239729660 seconds time elapsed</div></pre></td></tr></table></figure>
<p>鲲鹏920上循环二的perf结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">#perf stat -- ./cache_line_loop.out</div><div class="line">730</div><div class="line">failed to read counter branches</div><div class="line"></div><div class="line"> Performance counter stats for &apos;./cache_line_loop.out&apos;:</div><div class="line"></div><div class="line">       1161.126720      task-clock (msec)         #    0.999 CPUs utilized</div><div class="line">                 1      context-switches          #    0.001 K/sec</div><div class="line">                 0      cpu-migrations            #    0.000 K/sec</div><div class="line">            65,583      page-faults               #    0.056 M/sec</div><div class="line">     3,018,882,346      cycles                    #    2.600 GHz</div><div class="line">        21,846,222      stalled-cycles-frontend   #    0.72% frontend cycles idle</div><div class="line">     2,456,150,941      stalled-cycles-backend    #   81.36% backend  cycles idle</div><div class="line">     1,970,906,199      instructions              #    0.65  insns per cycle</div><div class="line">                                                  #    1.25  stalled cycles per insn</div><div class="line">   &lt;not supported&gt;      branches</div><div class="line">           138,051      branch-misses             #    0.00% of all branches</div><div class="line"></div><div class="line">       1.161791340 seconds time elapsed</div></pre></td></tr></table></figure>
<p> 在Xeon(R) Platinum 8260 CPU @ 2.40GHz 上运行上面两个循环的时间：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">#perf stat -- ./cache_line_loop.out</div><div class="line">1770</div><div class="line">370</div></pre></td></tr></table></figure>
<p>更多案例请参考7个示例科普CPU CACHE：<a href="http://igoro.com/archive/gallery-of-processor-cache-effects/" target="_blank" rel="external">Gallery of Processor Cache Effects</a></p>
<p>如下图，表示的是for循环每次跳K个int，在K小于16的时候虽然循环次数逐渐减少到原来的1/16, 但是总时间没变，因为一直是访问的同一个cache里面的数据。 到16个之后就会产生突变（跨了cache_line），再后面32、64、128的时间减少来源于循环次数的减少，因为如论如何每次循环都需要访问内存加载数据到cache_line中</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">for (int i = 0; i &lt; arr.Length; i += K) arr[i] *= 3;</div></pre></td></tr></table></figure>
<p><img src="/images/951413iMgBlog/image6.png" alt="running times of this loop for different step values (K)"></p>
<p>更典型的案例是对一个二维数组逐行遍历和逐列遍历的时间差异，变量次数一样，但是因为二维数组按行保存，所以逐行遍历对cache line 更友好</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">const int row = 1024;</div><div class="line">const int col = 512</div><div class="line">int matrix[row][col];</div><div class="line">//逐行遍历  0.081ms</div><div class="line">int sum_row=0;</div><div class="line">for(int _r=0; _r&lt;row; _r++) &#123;</div><div class="line">    for(int _c=0; _c&lt;col; _c++)&#123;</div><div class="line">        sum_row += matrix[_r][_c];</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line">//逐列遍历 1.069ms</div><div class="line">int sum_col=0;</div><div class="line">for(int _c=0; _c&lt;col; _c++) &#123;</div><div class="line">    for(int _r=0; _r&lt;row; _r++)&#123;</div><div class="line">        sum_col += matrix[_r][_c];</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="Disruptor"><a href="#Disruptor" class="headerlink" title="Disruptor"></a><a href="https://lmax-exchange.github.io/disruptor/disruptor.html" target="_blank" rel="external">Disruptor</a></h2><p>Disruptor论文中讲述了我们所做的一个实验。这个测试程序调用了一个函数，该函数会对一个64位的计数器循环自增5亿次。当单线程无锁时，程序耗时300ms。如果增加一个锁（仍是单线程、没有竞争、仅仅增加锁），程序需要耗时10000ms，慢了两个数量级。更令人吃惊的是，如果增加一个线程（简单从逻辑上想，应该比单线程加锁快一倍），耗时224000ms。使用两个线程对计数器自增5亿次比使用无锁单线程慢1000倍。<strong>并发很难而锁的性能糟糕。</strong>单线程使用CAS耗时5700ms。所以它比使用锁耗时少，但比不需要考虑竞争的单线程耗时多。</p>
<p>We will illustrate the cost of locks with a simple demonstration. The focus of this experiment is to call a function which increments a 64-bit counter in a loop 500 million times. This can be executed by a single thread on a 2.4Ghz Intel Westmere EP in just 300ms if written in Java. The language is unimportant to this experiment and results will be similar across all languages with the same basic primitives.</p>
<p>Once a lock is introduced to provide mutual exclusion, even when the lock is as yet un-contended, the cost goes up significantly. The cost increases again, by orders of magnitude, when two or more threads begin to contend. The results of this simple experiment are shown in the table below:</p>
<p><em>Table 1. Comparative costs of contention</em></p>
<table>
<thead>
<tr>
<th style="text-align:left">Method</th>
<th style="text-align:left">Time (ms)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Single thread</td>
<td style="text-align:left">300</td>
</tr>
<tr>
<td style="text-align:left">Single thread with lock</td>
<td style="text-align:left">10,000</td>
</tr>
<tr>
<td style="text-align:left">Two threads with lock</td>
<td style="text-align:left">224,000</td>
</tr>
<tr>
<td style="text-align:left">Single thread with CAS</td>
<td style="text-align:left">5,700</td>
</tr>
<tr>
<td style="text-align:left">Two threads with CAS</td>
<td style="text-align:left">30,000</td>
</tr>
<tr>
<td style="text-align:left">Single thread with volatile write</td>
<td style="text-align:left">4,700</td>
</tr>
</tbody>
</table>
<p>如下测试代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div></pre></td><td class="code"><pre><div class="line">package test;</div><div class="line"></div><div class="line">import java.util.concurrent.atomic.AtomicLong;</div><div class="line">import java.util.concurrent.locks.Lock;</div><div class="line">import java.util.concurrent.locks.ReentrantLock;</div><div class="line"></div><div class="line">public class LockBenchmark&#123;</div><div class="line">    public static void runIncrement()</div><div class="line">    &#123;</div><div class="line">        long counter = 0;</div><div class="line">        long max  = 50000000000L;</div><div class="line">        long start = System.currentTimeMillis();</div><div class="line">        while (counter &lt; max) &#123;</div><div class="line">            counter++;</div><div class="line">        &#125;</div><div class="line">        long end = System.currentTimeMillis();</div><div class="line">        System.out.println(&quot;Time spent is &quot; + (end-start) + &quot;ms without lock&quot;);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    public static void runIncrementWithLock()</div><div class="line">    &#123;</div><div class="line">        Lock lock = new ReentrantLock();</div><div class="line">        long counter = 0;</div><div class="line">        long max = 500000000L;</div><div class="line">        long start = System.currentTimeMillis();</div><div class="line">        while (counter &lt; max) &#123;</div><div class="line">            if (lock.tryLock())&#123;</div><div class="line">                counter++;</div><div class="line">                lock.unlock();</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        long end = System.currentTimeMillis();</div><div class="line">        System.out.println(&quot;Time spent is &quot; + (end-start) + &quot;ms with lock&quot;);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    public static void main(String[] args) &#123;</div><div class="line">        runIncrement();</div><div class="line">	      System.out.println(&quot;start runIncrementWithLock.&quot;);</div><div class="line">        runIncrementWithLock();</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">[root@ARM 14:14 /root]</div><div class="line">#java test.LockBenchmark</div><div class="line">Time spent is 19261ms without lock</div><div class="line">start runIncrementWithLock.</div><div class="line">Time spent is 17267ms with lock</div><div class="line"></div><div class="line">//单线程加锁在没有任何竞争的情况下慢了两个数量级是因为加锁动作本身需要几十个指令</div><div class="line">reentrantLock.tryLock()实现：</div><div class="line"> 11   final boolean nonfairTryAcquire(int);</div><div class="line"> 12     Code:</div><div class="line"> 13        0: invokestatic  #2                  // Method java/lang/Thread.currentThread:()Ljava/lang/Thread;</div><div class="line"> 14        3: astore_2</div><div class="line"> 15        4: aload_0</div><div class="line"> 16        5: invokevirtual #3                  // Method getState:()I</div><div class="line"> 17        8: istore_3</div><div class="line"> 18        9: iload_3</div><div class="line"> 19       10: ifne          29</div><div class="line"> 20       13: aload_0</div><div class="line"> 21       14: iconst_0</div><div class="line"> 22       15: iload_1</div><div class="line"> 23       16: invokevirtual #4                  // Method compareAndSetState:(II)Z</div><div class="line"> 24       19: ifeq          65</div><div class="line"> 25       22: aload_0</div><div class="line"> 26       23: aload_2</div><div class="line"> 27       24: invokevirtual #5                  // Method setExclusiveOwnerThread:(Ljava/lang/Thread;)V</div><div class="line"> 28       27: iconst_1</div><div class="line"> 29       28: ireturn</div><div class="line"> 30       29: aload_2</div><div class="line"> 31       30: aload_0</div><div class="line"> 32       31: invokevirtual #6                  // Method getExclusiveOwnerThread:()Ljava/lang/Thread;</div><div class="line"> 33       34: if_acmpne     65</div><div class="line"> 34       37: iload_3</div><div class="line"> 35       38: iload_1</div><div class="line"> 36       39: iadd</div><div class="line"> 37       40: istore        4</div><div class="line"> 38       42: iload         4</div><div class="line"> 39       44: ifge          57</div><div class="line"> 40       47: new           #7                  // class java/lang/Error</div><div class="line"> 41       50: dup</div><div class="line"> 42       51: ldc           #8                  // String Maximum lock count exceeded</div><div class="line"> 43       53: invokespecial #9                  // Method java/lang/Error.&quot;&lt;init&gt;&quot;:(Ljava/lang/String;)V</div><div class="line"> 44       56: athrow</div><div class="line"> 45       57: aload_0</div><div class="line"> 46       58: iload         4</div><div class="line"> 47       60: invokevirtual #10                 // Method setState:(I)V</div><div class="line"> 48       63: iconst_1</div><div class="line"> 49       64: ireturn</div><div class="line"> 50       65: iconst_0</div><div class="line"> 51       66: ireturn</div></pre></td></tr></table></figure>
<p>不加锁的循环执行500亿次循环，加锁的只执行5亿次，最终耗时差不多。对应两个阶段的IPC数据：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line">#perf stat -p 92098</div><div class="line"> Performance counter stats for process id &apos;92098&apos;:</div><div class="line"></div><div class="line">       3978.381920      task-clock (msec)         #    1.001 CPUs utilized</div><div class="line">               121      context-switches          #    0.030 K/sec</div><div class="line">                 7      cpu-migrations            #    0.002 K/sec</div><div class="line">                71      page-faults               #    0.018 K/sec</div><div class="line">    10,343,414,319      cycles                    #    2.600 GHz</div><div class="line">         2,091,748      stalled-cycles-frontend   #    0.02% frontend cycles idle</div><div class="line">        11,011,682      stalled-cycles-backend    #    0.11% backend  cycles idle</div><div class="line">    41,311,635,225      instructions              #    3.99  insns per cycle      //不加锁循环++</div><div class="line">                                                  #    0.00  stalled cycles per insn</div><div class="line">   &lt;not supported&gt;      branches</div><div class="line">            32,675      branch-misses             #    0.00% of all branches</div><div class="line"></div><div class="line">       3.972534070 seconds time elapsed</div><div class="line"></div><div class="line">[root@ARM 13:55 /root]</div><div class="line">#perf stat -p 92098</div><div class="line">^Cfailed to read counter branches</div><div class="line"></div><div class="line"> Performance counter stats for process id &apos;92098&apos;:</div><div class="line"></div><div class="line">      10599.558340      task-clock (msec)         #    1.001 CPUs utilized</div><div class="line">               292      context-switches          #    0.028 K/sec</div><div class="line">                 1      cpu-migrations            #    0.000 K/sec</div><div class="line">               202      page-faults               #    0.019 K/sec</div><div class="line">    27,557,631,981      cycles                    #    2.600 GHz</div><div class="line">     1,079,785,178      stalled-cycles-frontend   #    3.92% frontend cycles idle</div><div class="line">    15,669,652,101      stalled-cycles-backend    #   56.86% backend  cycles idle</div><div class="line">    14,456,635,493      instructions              #    0.52  insns per cycle     //加锁循环++</div><div class="line">                                                  #    1.08  stalled cycles per insn</div><div class="line">   &lt;not supported&gt;      branches</div><div class="line">            69,722      branch-misses             #    0.00% of all branches</div><div class="line"></div><div class="line">      10.592190690 seconds time elapsed</div></pre></td></tr></table></figure>
<p>可以看到最终时间差了100倍，IPC差了8倍，从指令数来看加锁后指令数会略多，但是加锁造成了stall（即使没有实际竞争）。</p>
<p>上述代码如果是在：Intel(R) Xeon(R) CPU E5-2682 v4 @ 2.50GHz 上运行，差距要小很多，也可以看出intel x86芯片优化比较好。不加锁的循环X86比ARM要慢一点点是因为ARM芯片的主频是2.6G，要高一点点。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">#java test.LockBenchmark  //x86</div><div class="line">Time spent is 20135ms without lock</div><div class="line">start runIncrementWithLock.</div><div class="line">Time spent is 13056ms with lock</div></pre></td></tr></table></figure>
<p><strong>此时Intel CPU上对应的IPC分别是3.99和1.</strong></p>
<p>这里加锁和不加锁最终性能差了将近2个数量级，但是IPC只差了8倍，另外的差异在加锁后增加了很多的指令、函数调用等。如果两个函数都增加每个循环里面的指令数量，那么他们的时间差距会缩小。如果增加的指令是乘法、除法会大幅降低IPC</p>
<p>比如代码改成如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div></pre></td><td class="code"><pre><div class="line">#cat LockBenchmark.java</div><div class="line">package test;</div><div class="line"></div><div class="line">import java.util.concurrent.atomic.AtomicLong;</div><div class="line">import java.util.concurrent.locks.Lock;</div><div class="line">import java.util.concurrent.locks.ReentrantLock;</div><div class="line"></div><div class="line">public class LockBenchmark&#123;</div><div class="line">    public static void runIncrement()</div><div class="line">    &#123;</div><div class="line">        long counter = 0;</div><div class="line">        long max  = 500000000L;</div><div class="line">				double sum =100.0;</div><div class="line">        long start = System.currentTimeMillis();</div><div class="line">        while (counter &lt; max) &#123;</div><div class="line">            counter++;</div><div class="line">						sum=3.251;</div><div class="line">						for(int i=0; i&lt;10; ++i)&#123;</div><div class="line">							sum += sum*3.75/3;</div><div class="line">						&#125;</div><div class="line">        &#125;</div><div class="line">        long end = System.currentTimeMillis();</div><div class="line">        System.out.println(&quot;Time spent is &quot; + (end-start) + &quot;ms without lock:&quot;+sum);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    public static void runIncrementWithLock()</div><div class="line">    &#123;</div><div class="line">        Lock lock = new ReentrantLock();</div><div class="line">        long counter = 0;</div><div class="line">				double sum=100.0;</div><div class="line">        long max = 500000000L;</div><div class="line">        long start = System.currentTimeMillis();</div><div class="line">        while (counter &lt; max) &#123;</div><div class="line">            if (lock.tryLock())&#123;</div><div class="line">		    			counter++;</div><div class="line">							sum=3.253;</div><div class="line">							for(int i=0; i&lt;10; ++i)&#123;</div><div class="line">								sum += sum*3.75/3;</div><div class="line">							&#125;</div><div class="line">              lock.unlock();</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        long end = System.currentTimeMillis();</div><div class="line">        System.out.println(&quot;Time spent is &quot; + (end-start) + &quot;ms with lock:&quot;+sum);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    public static void main(String[] args) &#123;</div><div class="line">        runIncrement();</div><div class="line">	    	System.out.println(&quot;start runIncrementWithLock.&quot;);</div><div class="line">        runIncrementWithLock();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在Intel芯片下，加锁运行时间慢了1倍，IPC差不多，运行时间和IPC 分别为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line">#java test.LockBenchmark  //如上代码循环次数都是5亿次， intel cpu</div><div class="line">Time spent is 11884ms without lock:10810.40962948895</div><div class="line">start runIncrementWithLock.</div><div class="line">Time spent is 22662ms with lock:10817.060142949109</div><div class="line"></div><div class="line">#perf stat -p `jps | grep LockBenchmark | awk &apos;&#123; print $1 &#125;&apos;`</div><div class="line">^C</div><div class="line"> Performance counter stats for process id &apos;117862&apos;:</div><div class="line"></div><div class="line">       7144.193030      task-clock (msec)         #    1.002 CPUs utilized            (100.00%)</div><div class="line">               227      context-switches          #    0.032 K/sec                    (100.00%)</div><div class="line">                26      cpu-migrations            #    0.004 K/sec                    (100.00%)</div><div class="line">               199      page-faults               #    0.028 K/sec</div><div class="line">    17,842,543,877      cycles                    #    2.497 GHz                      (100.00%)</div><div class="line">   &lt;not supported&gt;      stalled-cycles-frontend</div><div class="line">   &lt;not supported&gt;      stalled-cycles-backend</div><div class="line">    17,153,665,963      instructions              #    0.96  insns per cycle          (100.00%)</div><div class="line">     2,408,676,080      branches                  #  337.152 M/sec                    (100.00%)</div><div class="line">            39,593      branch-misses             #    0.00% of all branches</div><div class="line"></div><div class="line">       7.133030625 seconds time elapsed</div><div class="line"></div><div class="line"></div><div class="line">#perf stat -p `jps | grep LockBenchmark | awk &apos;&#123; print $1 &#125;&apos;`</div><div class="line">^C</div><div class="line"> Performance counter stats for process id &apos;117862&apos;:</div><div class="line"></div><div class="line">       3962.496661      task-clock (msec)         #    1.002 CPUs utilized            (100.00%)</div><div class="line">               123      context-switches          #    0.031 K/sec                    (100.00%)</div><div class="line">                 3      cpu-migrations            #    0.001 K/sec                    (100.00%)</div><div class="line">                77      page-faults               #    0.019 K/sec</div><div class="line">     9,895,900,342      cycles                    #    2.497 GHz                      (100.00%)</div><div class="line">   &lt;not supported&gt;      stalled-cycles-frontend</div><div class="line">   &lt;not supported&gt;      stalled-cycles-backend</div><div class="line">    10,504,412,147      instructions              #    1.06  insns per cycle          (100.00%)</div><div class="line">     1,925,721,763      branches                  #  485.987 M/sec                    (100.00%)</div><div class="line">            55,018      branch-misses             #    0.00% of all branches</div><div class="line"></div><div class="line">       3.955251872 seconds time elapsed</div></pre></td></tr></table></figure>
<p>在鲲鹏920下的运行时间和IPC，两个循环最终执行时间一样，但是加锁的循环 IPC 反而要高，应该是加锁指令简单，比乘法对流水线更友好</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div></pre></td><td class="code"><pre><div class="line">#java test.LockBenchmark  //鲲鹏920</div><div class="line">Time spent is 37037ms without lock:10810.40962948895</div><div class="line">start runIncrementWithLock.</div><div class="line">Time spent is 37045ms with lock:10817.060142949109  //极低的概率这里能跑出来15秒，应该是偷鸡优化了</div><div class="line"></div><div class="line"></div><div class="line">#perf stat -p `jps | grep LockBenchmark | awk &apos;&#123; print $1 &#125;&apos;`</div><div class="line">^Cfailed to read counter branches</div><div class="line"></div><div class="line"> Performance counter stats for process id &apos;104166&apos;:</div><div class="line"></div><div class="line">       3459.850580      task-clock (msec)         #    1.002 CPUs utilized</div><div class="line">               122      context-switches          #    0.035 K/sec</div><div class="line">                 1      cpu-migrations            #    0.000 K/sec</div><div class="line">               257      page-faults               #    0.074 K/sec</div><div class="line">     8,995,482,376      cycles                    #    2.600 GHz</div><div class="line">       344,461,881      stalled-cycles-frontend   #    3.83% frontend cycles idle</div><div class="line">     7,060,741,196      stalled-cycles-backend    #   78.49% backend  cycles idle</div><div class="line">     2,667,443,624      instructions              #    0.30  insns per cycle         //不带Lock 乘除法拉低了IPC</div><div class="line">                                                  #    2.65  stalled cycles per insn</div><div class="line">   &lt;not supported&gt;      branches</div><div class="line">        93,302,896      branch-misses             #    0.00% of all branches</div><div class="line"></div><div class="line">       3.453102950 seconds time elapsed</div><div class="line">       </div><div class="line">#perf stat -p `jps | grep LockBenchmark | awk &apos;&#123; print $1 &#125;&apos;`</div><div class="line">^Cfailed to read counter branches</div><div class="line"></div><div class="line"> Performance counter stats for process id &apos;100351&apos;:</div><div class="line"></div><div class="line">       3205.548380      task-clock (msec)         #    1.002 CPUs utilized</div><div class="line">                97      context-switches          #    0.030 K/sec</div><div class="line">                 0      cpu-migrations            #    0.000 K/sec</div><div class="line">                93      page-faults               #    0.029 K/sec</div><div class="line">     8,334,345,888      cycles                    #    2.600 GHz</div><div class="line">        10,217,474      stalled-cycles-frontend   #    0.12% frontend cycles idle</div><div class="line">     6,389,615,752      stalled-cycles-backend    #   76.67% backend  cycles idle</div><div class="line">     4,374,642,352      instructions              #    0.52  insns per cycle         //带lock</div><div class="line">                                                  #    1.46  stalled cycles per insn</div><div class="line">   &lt;not supported&gt;      branches</div><div class="line">         2,053,478      branch-misses             #    0.00% of all branches</div><div class="line"></div><div class="line">       3.199261610 seconds time elapsed</div></pre></td></tr></table></figure>
<p>这个代码加锁后指令多了1倍，所以intel CPU下体现出来的时间就差了一倍（IPC一样的）；鲲鹏 CPU下时间差不多是因为没加锁的IPC太低了（乘除法对流水线没优化好），最终IPC差了一倍，就把执行时间拉平了。另外就就是Intel和鲲鹏的执行时间对比和IPC也是一致的，IPC高执行就快。</p>
<h3 id="Disruptor中对cache-line的使用"><a href="#Disruptor中对cache-line的使用" class="headerlink" title="Disruptor中对cache_line的使用"></a>Disruptor中对cache_line的使用</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">abstract class RingBufferPad</div><div class="line">&#123;</div><div class="line">    protected long p1, p2, p3, p4, p5, p6, p7;</div><div class="line">&#125;</div><div class="line">  </div><div class="line">abstract class RingBufferFields&lt;E&gt; extends RingBufferPad</div><div class="line">&#123;</div><div class="line">    ......    </div><div class="line">    private final long indexMask;</div><div class="line">    private final Object[] entries;</div><div class="line">    protected final int bufferSize;</div><div class="line">    protected final Sequencer sequencer;</div><div class="line">    ......    </div><div class="line">&#125;</div><div class="line"></div><div class="line">public final class RingBuffer&lt;E&gt; extends RingBufferFields&lt;E&gt; implements Cursored, EventSequencer&lt;E&gt;, EventSink&lt;E&gt;</div><div class="line">&#123;</div><div class="line">    ......    </div><div class="line">    protected long p1, p2, p3, p4, p5, p6, p7;</div><div class="line">    ......</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>重点留意上述代码中的p1-p7这几个没有用的long变量，实际使用来占位，占住实际变量前后的位置，这样避免这些变量被其他变量的修改而失效。</p>
<p><img src="/images/951413iMgBlog/1620984677390-81694fd0-0323-4052-98d1-32be39a02248-4505908.png" alt="image.png"></p>
<p>队列大部分时候都是空的（head挨着tail），也就导致head 和 tail在一个cache line中，读和写会造成没必要的cache ping-pong，一般可以通过将head 和 tail 中间填充其它内容来实现错开到不同的cache line中</p>
<p><img src="/images/oss/1577093636588-6b58c36c-1617-4f2c-aba9-156c52972689.png" alt="image"></p>
<p>数组(RingBuffer)基本能保证元素在内存中是连续的，但是Queue（链表）就不一定了，连续的话更利于CPU cache</p>
<h2 id="Intel-PAUSE指令变化是如何影响自旋锁以及MySQL的性能的"><a href="#Intel-PAUSE指令变化是如何影响自旋锁以及MySQL的性能的" class="headerlink" title="Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的"></a>Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的</h2><p>MySQL利用Intel 的Pause指令在spinlock(自旋锁)的时候尽量避免cache line ping-pong，但是不同的Intel芯片每个Pause指令背后实际执行的circle是不一样的，从而导致MySQL性能差异很大</p>
<p>详细请看：</p>
<p><a href="/2019/12/16/Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的/">《Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的》 从一个参数引起的rt抖动定位到OS锁等待再到CPU Pause指令，以及不同CPU型号对Pause使用cycles不同的影响，最终反馈到应用层面的rt全过程。在MySQL内核开发的时候考虑了Pause，但是没有考虑不同的CPU型号，所以换了CPU型号后性能差异比较大</a></p>
<h3 id="pause-和-spinlock"><a href="#pause-和-spinlock" class="headerlink" title="pause 和 spinlock"></a>pause 和 spinlock</h3><p><a href="http://linuxperf.com/?p=138" target="_blank" rel="external">spinlock(自旋锁)</a>是内核中最常见的锁，它的特点是：等待锁的过程中不休眠，而是占着CPU空转，优点是避免了上下文切换的开销，缺点是该CPU空转属于浪费, 同时还有可能导致cache ping-pong，<strong>spinlock适合用来保护快进快出的临界区</strong>。持有spinlock的CPU不能被抢占，持有spinlock的代码不能休眠</p>
<h3 id="pause-和-cpu-relax"><a href="#pause-和-cpu-relax" class="headerlink" title="pause 和 cpu_relax"></a>pause 和 cpu_relax</h3><p>内核频繁使用 cpu_relax 函数，顺序锁 (seqlock) 就是其中的典型代表。cpu_relax 人如其名，它有两个作用：</p>
<ul>
<li>主动让出cpu，小憩一会儿（一般是100ns左右），避免恶性竞争；</li>
<li>释放cpu占用的流水线资源。既可以降低功耗，在SMT中还可以让邻居HyperThread跑的更快；</li>
</ul>
<p>对于顺序锁而言，cpu_relax 尤为关键：</p>
<ul>
<li>锁一般是全局变量，各个cpu持续不断的轮询锁状态（读操作），会给系统总线（CCIX / UPI）、内存控制器造成很大的带宽压力，使得访存延迟恶化。</li>
<li>cache coherence 维护代价增加；一旦某个cpu获得锁，需要写全局变量，然后会逐一通知其它cpu上的cacheline 失效； 这也会增加延迟。</li>
</ul>
<p>由此可见，正确实现 cpu_relax 函数的语义，对内核是很有意义的。cpu_relax 的实现与处理器微架构有关，x86下是用pause来实现，而arm下是用的yield来实现，yield 指令的实现退化为 nop 指令，执行非常非常快，也就是一个circle。yield指令的IPC能达到3.99，而pause的IPC才0.03(intel 8260芯片)。</p>
<p>当然在ARM芯片下这个问题就不一样了：<a href="https://topic.atatech.org/articles/173194" target="_blank" rel="external">ARM软硬件协同设计：锁优化</a>, arm不同于x86，用的是yield来代替pause，yield 指令的实现退化为 nop 指令，执行时间非常非常短，也就是一个circle。yield指令的IPC能达到3.99，而pause的IPC才0.03(intel 8260芯片). </p>
<p>在ARM芯片里因为yield很快，那么上层软件的spinlock就要用不一样的方式来优化了。</p>
<h2 id="ECS-cache-line-miss导致整个物理机响应慢"><a href="#ECS-cache-line-miss导致整个物理机响应慢" class="headerlink" title="ECS cache_line miss导致整个物理机响应慢"></a>ECS cache_line miss导致整个物理机响应慢</h2><p><a href="https://topic.atatech.org/articles/100065" target="_blank" rel="external">如果一台ECS运行大量的cache_line miss逻辑</a>，也就是利用spinlock所保护的区域没有按照cacheline对齐的时候，CPU为了保证数据一致性，会触发Super Queue lock splits，将总线锁住，哪怕是其他socket，而这个时候，其他CPU CORE访问L2cache、L3cahe、以及内存就会阻塞，直到Super Queue lock splits释放。</p>
<p>这个影响不是socket、node内部，而是整个物理机总线被锁，所以影响的是整个物理机。</p>
<h3 id="从地址不对齐访问到split-lock"><a href="#从地址不对齐访问到split-lock" class="headerlink" title="从地址不对齐访问到split lock"></a><a href="https://kernel.taobao.org/2019/07/Detecting-and-handling-split-locks/" target="_blank" rel="external">从地址不对齐访问到split lock</a></h3><p>Intel CPU微架构允许不对齐的内存访问，但ARM、RISC-V等架构却不允许。在众多的不对齐中，一个特殊的场景是：<a href="https://lwn.net/Articles/790464/" target="_blank" rel="external">原子操作的操作数（由于地址不对齐）跨越两个cache lines，Intel将之叫做split lock。</a>它有两个特征：</p>
<ol>
<li>原子操作，即汇编指令包含Lock前缀；</li>
<li>操作数地址不对齐，还跨越两个cache lines；</li>
</ol>
<p>其实大部分吃瓜群众都不知道这个特性，但是它却对应用性能影响极大。Intel工程师Fenghua Yu同学正在开发一组内核补丁，用于检测和处理split lock，现在已经发出了第8版<a href="https://lwn.net/ml/linux-kernel/1556134382-58814-1-git-send-email-fenghua.yu%40intel.com/" target="_blank" rel="external">code review</a>。阿里巴巴在多年前就意识到split lock的危害，在线上实施了大规模监控，并采取必要隔离措施。</p>
<p>学过体系结构的同学都应该知道，缓存一制性协议MESI只能保证cache line粒度的一致性。同时访问两个cache lines不是常见操作，为保证split lock的原子性，设计硬件时使用特殊逻辑（冷路径）来处理：<strong>锁住整个访存总线，阻止其它逻辑cpu访存</strong>。</p>
<p>从原理出发，我们很容易想到，锁住总线将导致其它core上访存操作受阻，宏观表现为平均访存延时显著上升。为不让各位看官白走一趟，小编在自己的skylake机器上测了一组数据，随着split lock速率的增加，访存延迟呈指数恶化。</p>
<p><img src="/images/951413iMgBlog/1.png" alt="img"></p>
<h2 id="分支预测案例"><a href="#分支预测案例" class="headerlink" title="分支预测案例"></a>分支预测案例</h2><p>这个案例总循环次数一样多，但是里外循环次数不一样：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line">#include &quot;stdio.h&quot;</div><div class="line">#include &lt;stdlib.h&gt;</div><div class="line">#include &lt;time.h&gt;</div><div class="line"></div><div class="line">long timediff(clock_t t1, clock_t t2) &#123;</div><div class="line">    long elapsed;</div><div class="line">    elapsed = ((double)t2 - t1) / CLOCKS_PER_SEC * 1000;</div><div class="line">    return elapsed;</div><div class="line">&#125;</div><div class="line"></div><div class="line">int main(int argc, char *argv[])</div><div class="line">&#123;</div><div class="line">    int j=0;</div><div class="line">    int k=0;</div><div class="line">    int c=0;</div><div class="line">    clock_t start=clock();</div><div class="line">    for(j=0; j&lt;100000; j++)&#123;</div><div class="line">        for(k=0; k&lt;1000; k++)&#123;</div><div class="line">					for(c=0; c&lt;100; c++)&#123;</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line">    &#125;</div><div class="line">    clock_t end =clock();</div><div class="line">    printf(&quot;%lu\n&quot;, timediff(start,end));    //case1</div><div class="line"></div><div class="line">    start=clock();</div><div class="line">    for(j=0; j&lt;100; j++)&#123;</div><div class="line">        for(k=0; k&lt;1000; k++)&#123;</div><div class="line">					for(c=0; c&lt;100000; c++)&#123;</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line">    &#125;</div><div class="line">    end =clock();</div><div class="line">    printf(&quot;%lu\n&quot;, timediff(start,end));   //case2</div><div class="line">    return 0;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>x86_64下的执行结果，确实是case2略快</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">#taskset -c 0 ./for_prediction.out</div><div class="line">25560</div><div class="line">23420</div><div class="line"></div><div class="line">#taskset -c 0 ./for_prediction.out</div><div class="line">25510</div><div class="line">23410</div></pre></td></tr></table></figure>
<p>case1的branch miss大概接近1%（看0 core上的 BrchMiss%， 数据由 xperf 1.3.8采集）</p>
<p><img src="/images/951413iMgBlog/image-20210517111209985.png" alt="image-20210517111209985"></p>
<p>case2的branch miss降到了0，不过两者在x86上的IPC都是0.49，所以最终的执行时间差异不大</p>
<p><img src="/images/951413iMgBlog/image-20210517111244550.png" alt="image-20210517111244550"></p>
<p><img src="/images/951413iMgBlog/image-20210512133536939.png" alt="image-20210512133536939"></p>
<p>在arm下case1反而更快，如截图</p>
<p><img src="/images/951413iMgBlog/image-20210512132121856.png" alt="image-20210512132121856"></p>
<h2 id="系列文章-1"><a href="#系列文章-1" class="headerlink" title="系列文章"></a>系列文章</h2><p><a href="/2021/06/01/CPU的制造和概念/">CPU的制造和概念</a></p>
<p><a href="/2021/05/16/CPU Cache Line 和性能/">CPU 性能和Cache Line</a></p>
<p><a href="/2021/05/16/Perf IPC以及CPU利用率/">Perf IPC以及CPU性能</a></p>
<p><a href="/2021/06/18/几款CPU性能对比/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></p>
<p><a href="/2021/05/15/飞腾ARM芯片(FT2500">飞腾ARM芯片(FT2500)的性能测试</a>的性能测试/)</p>
<p><a href="/2021/05/14/十年后数据库还是不敢拥抱NUMA/">十年后数据库还是不敢拥抱NUMA？</a></p>
<p><a href="/2021/03/07/一次海光物理机资源竞争压测的记录/">一次海光物理机资源竞争压测的记录</a></p>
<p><a href="/2019/12/16/Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的/">Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的</a></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://scholarworks.sjsu.edu/cgi/viewcontent.cgi?referer=https://www.google.com/&amp;httpsredir=1&amp;article=1001&amp;context=etd_projects" target="_blank" rel="external">Analysis of False Cache Line Sharing Effects on Multicore CPUs</a></p>
<p><a href="https://software.intel.com/content/www/us/en/develop/articles/avoiding-and-identifying-false-sharing-among-threads.html" target="_blank" rel="external">Avoiding and Identifying False Sharing Among Threads</a></p>
<p><a href="http://igoro.com/archive/gallery-of-processor-cache-effects/" target="_blank" rel="external">Gallery of Processor Cache Effects</a></p>
<p><a href="https://coolshell.cn/articles/10249.html" target="_blank" rel="external">7个示例科普CPU CACHE</a></p>
<p><a href="https://coolshell.cn/articles/20793.html" target="_blank" rel="external">与程序员相关的CPU缓存知识</a></p>
<p><a href="http://stackoverflow.com/questions/11413855/why-is-transposing-a-matrix-of-512x512-much-slower-than-transposing-a-matrix-of?spm=ata.21736010.0.0.43c1e11aGARvVj" target="_blank" rel="external">Why is transposing a matrix of 512×512 much slower than transposing a matrix of 513×513 ?</a> 矩阵倒置的时候因为同一个cache_line的数据频繁被update导致cache_line失效，也就是FALSE share</p>
<p><a href="https://zhuanlan.zhihu.com/p/58881925" target="_blank" rel="external">CPU时间都去哪了：一步步定位数据库代码中的性能瓶颈</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/05/16/Perf_IPC以及CPU利用率/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/05/16/Perf_IPC以及CPU利用率/" itemprop="url">Perf IPC以及CPU性能</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-05-16T12:30:03+08:00">
                2021-05-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CPU/" itemprop="url" rel="index">
                    <span itemprop="name">CPU</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Perf-IPC以及CPU性能"><a href="#Perf-IPC以及CPU性能" class="headerlink" title="Perf IPC以及CPU性能"></a>Perf IPC以及CPU性能</h1><p>为了让程序能快点，特意了解了CPU的各种原理，比如多核、超线程、NUMA、睿频、功耗、GPU、大小核再到分支预测、cache_line失效、加锁代价、IPC等各种指标（都有对应的代码和测试数据）都会在这系列文章中得到答案。当然一定会有程序员最关心的分支预测案例、Disruptor无锁案例、cache_line伪共享案例等等。</p>
<p>这次让我们从最底层的沙子开始用8篇文章来回答各种疑问以及大量的实验对比案例和测试数据。</p>
<p>大的方面主要是从这几个疑问来写这些文章：</p>
<ul>
<li>同样程序为什么CPU跑到800%还不如CPU跑到200%快？</li>
<li>IPC背后的原理和和程序效率的关系？</li>
<li>为什么数据库领域都爱把NUMA关了，这对吗？</li>
<li>几个国产芯片的性能到底怎么样？</li>
</ul>
<h2 id="系列文章"><a href="#系列文章" class="headerlink" title="系列文章"></a>系列文章</h2><p><a href="/2021/06/01/CPU的制造和概念/">CPU的制造和概念</a></p>
<p><a href="/2021/05/16/Perf IPC以及CPU利用率/">Perf IPC以及CPU性能</a></p>
<p><a href="https://plantegg.github.io/2021/07/19/CPU性能和CACHE/">CPU性能和CACHE</a></p>
<p><a href="/2021/05/16/CPU Cache Line 和性能/">CPU 性能和Cache Line</a></p>
<p><a href="/2021/05/14/十年后数据库还是不敢拥抱NUMA/">十年后数据库还是不敢拥抱NUMA？</a></p>
<p><a href="/2019/12/16/Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的/">Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的</a></p>
<p><a href="/2021/06/18/几款CPU性能对比/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></p>
<p><a href="/2021/03/07/一次海光物理机资源竞争压测的记录/">一次海光物理机资源竞争压测的记录</a></p>
<p><a href="/2021/05/15/飞腾ARM芯片-FT2500的性能测试/">飞腾ARM芯片(FT2500)的性能测试</a></p>
<p><img src="/images/951413iMgBlog/image-20210802161455950.png" alt="image-20210802161455950"></p>
<h2 id="程序性能"><a href="#程序性能" class="headerlink" title="程序性能"></a>程序性能</h2><blockquote>
<p> 程序的 CPU 执行时间 = 指令数/(主频*IPC)</p>
</blockquote>
<p>IPC: insns per cycle  insn/cycles</p>
<h2 id="CPU-流水线工作原理"><a href="#CPU-流水线工作原理" class="headerlink" title="CPU 流水线工作原理"></a>CPU 流水线工作原理</h2><p>cycles：CPU时钟周期。CPU从它的指令集(instruction set)中选择指令执行。</p>
<p>一个指令包含以下的步骤，每个步骤由CPU的一个叫做功能单元(functional unit)的组件来进行处理，每个步骤的执行都至少需要花费一个时钟周期。</p>
<ul>
<li>指令读取(instruction fetch， IF)</li>
<li>指令解码(instruction decode， ID)</li>
<li>执行(execute， EXE)</li>
<li>内存访问(memory access，MEM)</li>
<li>寄存器回写(register write-back， WB)</li>
</ul>
<p><img src="/images/951413iMgBlog/950px-skylake_server_block_diagram.svg.png" alt="skylake server block diagram.svg"></p>
<p>以上结构简化成流水线就是：</p>
<p><img src="/images/951413iMgBlog/image-20210511154816751.png" alt="image-20210511154816751"></p>
<p>IF/ID 就是我们常说的前端，他负责不停地取指和译指，然后为后端提供译指之后的指令，最核心的优化就是要做好<strong>分支预测</strong>，终归取指是要比执行慢，只有提前做好预测才能尽量匹配上后端。后端核心优化是要做好执行单元的并发量，以及乱序执行能力，最终要将乱序执行结果正确组合并输出。</p>
<p>在流水线指令之前是单周期处理器：也就是一个周期完成一条指令。每个时钟周期必须完成取指、译码、读寄存器、 执行、访存等很多组合逻辑工作，为了保证在下一个时钟上升沿到来之前准备好寄存器堆的写数 据，需要将每个时钟周期的间隔拉长，导致处理器的主频无法提高。</p>
<p>使用流水线技术可以提高处 理器的主频。五个步骤只能串行，<strong>但是可以做成pipeline提升效率</strong>，也就是第一个指令做第二步的时候，指令读取单元可以去读取下一个指令了，如果有一个指令慢就会造成stall，也就是pipeline有地方卡壳了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">$sudo perf stat -a -- sleep 10</div><div class="line"></div><div class="line">Performance counter stats for &apos;system wide&apos;:</div><div class="line"></div><div class="line"> 239866.330098      task-clock (msec)         #   23.985 CPUs utilized    /10*1000        (100.00%)</div><div class="line">        45,709      context-switches          #    0.191 K/sec                    (100.00%)</div><div class="line">         1,715      cpu-migrations            #    0.007 K/sec                    (100.00%)</div><div class="line">        79,586      page-faults               #    0.332 K/sec</div><div class="line"> 3,488,525,170      cycles                    #    0.015 GHz                      (83.34%)</div><div class="line"> 9,708,140,897      stalled-cycles-frontend   #  278.29% /cycles frontend cycles idle     (83.34%)</div><div class="line"> 9,314,891,615      stalled-cycles-backend    #  267.02% /cycles backend  cycles idle     (66.68%)</div><div class="line"> 2,292,955,367      instructions              #    0.66  insns per cycle  insn/cycles</div><div class="line">                                              #    4.23  stalled cycles per insn stalled-cycles-frontend/insn (83.34%)</div><div class="line">   447,584,805      branches                  #    1.866 M/sec                    (83.33%)</div><div class="line">     8,470,791      branch-misses             #    1.89% of all branches          (83.33%)</div></pre></td></tr></table></figure>
<p>stalled-cycles，则是指令管道未能按理想状态发挥并行作用，发生停滞的时钟周期。stalled-cycles-frontend指指令读取或解码的指令步骤，而stalled-cycles-backend则是指令执行步骤。第二列中的cycles idle其实意思跟stalled是一样的，由于指令执行停滞了，所以指令管道也就空闲了，千万不要误解为CPU的空闲率。这个数值是由stalled-cycles-frontend或stalled-cycles-backend除以上面的cycles得出的。</p>
<p>另外cpu可以同时有多条pipeline，这就是理论上最大的IPC.</p>
<h3 id="pipeline效率和IPC"><a href="#pipeline效率和IPC" class="headerlink" title="pipeline效率和IPC"></a>pipeline效率和IPC</h3><p>虽然一个指令需要5个步骤，也就是完全执行完需要5个cycles，这样一个时钟周期最多能执行0.2条指令，IPC就是0.2，显然太低了。</p>
<ul>
<li>非流水线：</li>
</ul>
<p><img src="/images/951413iMgBlog/image-20210511154859711.png" alt="image-20210511154859711"></p>
<p>如果把多个指令的五个步骤用pipeline流水线跑起来，在理想情况下一个时钟周期就能跑完一条指令了，这样IPC就能达到1了。</p>
<p>这种非流水线的方式将一个指令分解成多个步骤后，能提升主频，但是一个指令执行需要的时间基本没变</p>
<ul>
<li>标量流水线, 标量（Scalar）流水计算机是<strong>只有一条指令流水线</strong>的计算机:</li>
</ul>
<p><img src="/images/951413iMgBlog/image-20210511155530477.png" alt="image-20210511155530477"></p>
<p>进一步优化，如果我们加大流水线的条数，让多个指令并行执行，就能得到更高的IPC了，但是这种并行必然会有指令之间的依赖，比如第二个指令依赖第一个的结果，所以多个指令并行更容易出现互相等待(stall).</p>
<p><img src="/images/951413iMgBlog/58c7dc9084fa648f204a6468209ca788.png" alt="img"></p>
<p>在每个时钟周期的开始，指令的部分数据和控制信息都保存在流水线锁存器中，并且该信息形成了下一个流水线的逻辑电路输入。在时钟周期内，信号通过组合逻辑传播，从而在时钟周期结束时及时产生输出，以供下一个pipeline锁存器捕获。</p>
<p>早期的RISC处理器，例如IBM的801原型，MIPS R2000（基于斯坦福MIPS机器）和原始的SPARC（来自Berkeley RISC项目），都实现了一个简单的5阶段流水线，与上面所示的流水线不同（ 额外的阶段是内存访问，在执行后存放结果）。在那个时代，主流的CISC架构80386、68030和VAX处理器使用微码顺序工作（通过RISC进行流水作业比较容易，因为指令都是简单的寄存器到寄存器操作，与x86、68k或VAX不同）。导致的结果，以20 MHz运行的SPARC比以33 MHz运行的386快得多。从那以后，每个处理器都至少在某种程度上进行了流水线处理。</p>
<p><img src="/images/951413iMgBlog/e6d5e70e0cbdc4ba662d79f2306758b6.png" alt="img"></p>
<ul>
<li>超标量流水线：所谓超标量（Superscalar）流 水计算机，是指它<strong>具有两条以上的指令流水线</strong>, 超标流水线数量也就是ALU执行单元的并行度</li>
</ul>
<p><img src="/images/951413iMgBlog/image-20210511155708234.png" alt="image-20210511155708234"></p>
<p>一般而言流水线的超标量不能超过单条流水线的深度</p>
<p>每个功能单元都有独立的管道，甚至可以具有不同的长度。 这使更简单的指令可以更快地完成，从而减少了等待时间。 在各个管道内部之间也有许多旁路，但是为简单起见，这些旁路已被省略。</p>
<p>下图中，处理器可能每个周期执行3条不同的指令，例如，一个整数，一个浮点和一个存储器操作。 甚至可以添加更多的功能单元，以便处理器能够在每个周期执行两个整数指令，或两个浮点指令，或使用任何其他方式。</p>
<p><img src="/images/951413iMgBlog/b0f6c495a6794d0a1e9a8ea93d87795b.png" alt="img"></p>
<p>流水线的设计可以实现不间断取指、解码、执行、写回，也可以同时做几条流水线一起取指、解码、执行、写回，也就引出了超标量设计。</p>
<p> 超标量处理器可以在一个时钟周期内执行多个指令。需要注意的是，每个执行单元不是单独的处理器，而是单个CPU内(也可以理解成单core)的执行资源，在上面图中也由体现。</p>
<p>三路超标量四工位流水线的指令/周期，将CPI从1变成0.33，即每周期执行3.33条指令，这样的改进幅度实在是令人着迷的，因此在初期的时候超标量甚至被人们赞美为标量程序的向量式处理。</p>
<p>理想是丰满的，现实却是骨感的，现实中的CPI是不可能都这样的，因为现在的处理器执行不同指令时候的“执行”段的工位并不完全一样，例如整数可能短一些，浮点或者向量和 Load/Store 指令需要长一些(这也是为什么AVX512指令下，CPU会降频的原因，因为一个工位太费时间了，不得不降速,频率快了也没啥用)，加上一些别的因素，实际大部分程序的实际 CPI 都是 1.x 甚至更高。</p>
<p>多发射分发逻辑的复杂性随着发射数量呈现平方和指数的变化。也就是说，5发射处理器的调度逻辑几乎是4发射设计的两倍，其中6发射是4倍，而7发射是8倍，依此类推。</p>
<h3 id="流水线案例"><a href="#流水线案例" class="headerlink" title="流水线案例"></a>流水线案例</h3><p>在Linux Kernel中有大量的 likely/unlikely</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//ip 层收到消息后，如果是tcp就调用tcp_v4_rcv作为tcp协议的入口</span></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">tcp_v4_rcv</span><span class="params">(struct sk_buff *skb)</span></span></div><div class="line">&#123;</div><div class="line">  ...</div><div class="line">	<span class="keyword">if</span> (unlikely(th-&gt;doff &lt; <span class="keyword">sizeof</span>(struct tcphdr) / <span class="number">4</span>))</div><div class="line">		<span class="keyword">goto</span> bad_packet; <span class="comment">//概率很小</span></div><div class="line">	<span class="keyword">if</span> (!pskb_may_pull(skb, th-&gt;doff * <span class="number">4</span>))</div><div class="line">		<span class="keyword">goto</span> discard_it;</div><div class="line">  </div><div class="line"><span class="comment">//file: net/ipv4/tcp_input.c</span></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">tcp_rcv_established</span><span class="params">(struct sock *sk, ...)</span></span></div><div class="line">&#123;</div><div class="line"> <span class="keyword">if</span> (unlikely(sk-&gt;sk_rx_dst == <span class="literal">NULL</span>))</div><div class="line">  ......</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//file: include/linux/compiler.h</span></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> likely(x)   __builtin_expect(!!(x),1)</span></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> unlikely(x) __builtin_expect(!!(x),0)</span></div></pre></td></tr></table></figure>
<p>__builtin_expect 这个指令是 gcc 引入的。该函数作用是允许程序员将最有可能执行的分支告诉编译器，来辅助系统进行分支预测。(参见 <a href="https://gcc.gnu.org/onlinedocs/gcc/Other-Builtins.html" target="_blank" rel="external">https://gcc.gnu.org/onlinedocs/gcc/Other-Builtins.html</a>)</p>
<p>它的用法为：__builtin_expect(EXP, N)。意思是：EXP == N的概率很大。那么上面 likely 和 unlikely 这两句的具体含义就是：</p>
<ul>
<li><strong>builtin_expect(!!(x),1) x 为真的可能性更大  //0两次取反还是0，非0两次取反都是1，这样可以适配</strong>builtin_expect(EXP, N)的N，要不N的参数没法传</li>
<li>__builtin_expect(!!(x),0) x 为假的可能性更大</li>
</ul>
<p>当正确地使用了__builtin_expect后，编译器在编译过程中会根据程序员的指令，将可能性更大的代码紧跟着前面的代码，从而减少指令跳转带来的性能上的下降。</p>
<p>这样可以让 CPU流水线分支预测的时候默认走可能性更大的分支。如果分支预测错误所有流水线都要取消重新计算。</p>
<h3 id="流水线的实际效果"><a href="#流水线的实际效果" class="headerlink" title="流水线的实际效果"></a>流水线的实际效果</h3><p>假如一个15级的流水线，如果处理器要将做无用功的时间限制在 10%，那么它必须在正确预测每个分支的准确率达到 99.3%（因为错误一次，15级流水线都要重置，所以错误会放大15倍，0.7*15=10） 。很少有通用程序能够如此准确地预测分支。</p>
<p>下图是不同场景在英特尔酷睿 i7 基准测试，可以看到有19% 的指令都被浪费了，但能耗的浪费情况更加严重，因为处理器必须利用额外的能量才能在推测失误时恢复原来的状态。这样的度量导致许多人得出结论，架构师需要一种不同的方法来实现性能改进。于是多级流水线不能疯狂增加，这样只能往多核发展。</p>
<p><img src="/images/951413iMgBlog/f4.jpg" alt="f4.jpg"></p>
<h3 id="Deeper-Pipelines深度流水线"><a href="#Deeper-Pipelines深度流水线" class="headerlink" title="Deeper Pipelines深度流水线"></a>Deeper Pipelines深度流水线</h3><p>由于时钟速度受流水线中最长阶段的长度的限制，因此每个级的逻辑门可以再细分，尤其是较长的逻辑门，从而将流水线转换为更深的深度流水线,各阶段的数量长度变小而阶段总数量变多，如下图。</p>
<p><img src="/images/951413iMgBlog/ffdf76ae7c34c3445594657466b1a8fe.png" alt="img"></p>
<p>​    这样整个处理器可以更高的时钟速度运行。当然，每个指令将需要更多的周期来完成（等待时间），但是处理器仍将在每个周期中完成1条指令，这样每秒将有更多的周期，处理器每秒将完成更多的指令。</p>
<p>​    Alpha架构师尤其喜欢这个深度流水线，这也是为什么早期的Alpha拥有非常深的流水线，并且在那个时代以很高的时钟速度运行。 当然还有Intel的NetBurst架构，唯主频论。。</p>
<p>​    如今，现代处理器努力将每个流水线阶段的门延迟数量降低到很少（大约12-25个）。</p>
<p>​    在PowerPC G4e中为7-12，在ARM11和Cortex-A9中为8+，在Athlon中为10-15，在Pentium-Pro/II/III/M中为12+，在Athlon64/Phenom/Fusion-A中为12-17，在Cortex-A8中为13+，在UltraSPARC-III/IV中为14，在Core 2中为14+，在Core i*2中为14-18+，在Core i中为16+，在PowerPC G5中为16-25，在Pentium-4中为20+， 在奔腾4E中为31+。 与RISC相比，x86处理器通常具有更深的流水线，因为它们需要做更多的工作来解码复杂的x86指令。UltraSPARC-T1/T2/T3是深度流水线趋势的例外（UltraSPARC-T1仅6个，T2/T3是8-12，因为其倾向让单核简化的方式来堆叠核数量）。</p>
<p>​    例如 Cortex-A15、Sandy Bridge 都分别具备 15 级、14 级流水线，而 Intel NetBurst（Pentium 4）、AMD Bulldozer 都是 20 级流水线，它们的工位数都远超出基本的四（或者五）工位流水线设计。更长的流水线虽然能提高频率，但是代价是耗电更高而且可能会有各种性能惩罚。</p>
<h3 id="指令延时"><a href="#指令延时" class="headerlink" title="指令延时"></a>指令延时</h3><p>​    考虑一个非流水线机器，具有6个执行阶段，长度分别为50 ns，50 ns，60 ns，60 ns，50 ns和50 ns。</p>
<p>​    -这台机器上的指令等待时间是多少？</p>
<p>​    -执行100条指令需要多少时间？</p>
<p>​    指令等待时间 = 50+50+60+60+50+50= 320 ns<br>​    执行100条指令需 = 100*320 = 32000 ns</p>
<h3 id="对比流水线延时"><a href="#对比流水线延时" class="headerlink" title="对比流水线延时"></a>对比流水线延时</h3><p>​    假设在上面这台机器上引入了流水线技术，但引入流水线技术时，时钟偏移会给每个执行阶段增加5ns的开销。</p>
<p>​    -流水线机器上的指令等待时间是多少？</p>
<p>​    -执行100条指令需要多少时间？</p>
<p>​    这里需要注意的是，在流水线实现中，流水线级的长度必须全部相同，即最慢级的速度加上开销，开销为5ns。</p>
<p>​    流水线级的长度= MAX（非流水线级的长度）+开销= 60 + 5 = 65 ns</p>
<p>​    指令等待时间= 65 ns</p>
<p>​    执行100条指令的时间= 65 <em> 6 </em> 1 + 65 <em> 1 </em> 99 = 390 + 6435 = 6825 ns</p>
<h3 id="从流水线获得加速"><a href="#从流水线获得加速" class="headerlink" title="从流水线获得加速"></a>从流水线获得加速</h3><p>​    加速是没有流水线的平均指令时间与有流水线的平均指令时间之比。（这里不考虑由不同类型的危害引起的任何失速）</p>
<p>​    假设：</p>
<p>​    未流水线的平均指令时间= 320 ns</p>
<p>​    流水线的平均指令时间= 65 ns</p>
<p>​    那么，100条指令的加速= 32000/6825 = 4.69，这种理想情况下效率提升了4.69倍。</p>
<p>每一个功能单元的流水线的长度是不同的。事实上，不同的功能单元的流水线长度本来就不一样。我们平时所说的 14 级流水线，指的通常是进行整数计算指令的流水线长度。如果是浮点数运算，实际的流水线长度则会更长一些。</p>
<p><img src="/images/951413iMgBlog/85f15ec667d09fd2d368822904029b32.jpeg" alt="img"></p>
<h3 id="指令缓存（Instruction-Cache）和数据缓存（Data-Cache）"><a href="#指令缓存（Instruction-Cache）和数据缓存（Data-Cache）" class="headerlink" title="指令缓存（Instruction Cache）和数据缓存（Data Cache）"></a>指令缓存（Instruction Cache）和数据缓存（Data Cache）</h3><p>在第 1 条指令执行到访存（MEM）阶段的时候，流水线里的第 4 条指令，在执行取指令（Fetch）的操作。访存和取指令，都要进行内存数据的读取。我们的内存，只有一个地址译码器的作为地址输入，那就只能在一个时钟周期里面读取一条数据，没办法同时执行第 1 条指令的读取内存数据和第 4 条指令的读取指令代码。</p>
<p><img src="/images/951413iMgBlog/c2a4c0340cb835350ea954cdc520704e.jpeg" alt="img"></p>
<p>把内存拆成两部分的解决方案，在计算机体系结构里叫作哈佛架构（Harvard Architecture），来自哈佛大学设计Mark I 型计算机时候的设计。我们今天使用的 CPU，仍然是冯·诺依曼体系结构的，并没有把内存拆成程序内存和数据内存这两部分。因为如果那样拆的话，对程序指令和数据需要的内存空间，我们就没有办法根据实际的应用去动态分配了。虽然解决了资源冲突的问题，但是也失去了灵活性。</p>
<p><img src="/images/951413iMgBlog/e7508cb409d398380753b292b6df8391.jpeg" alt="img"></p>
<p>在流水线产生依赖的时候必须pipeline stall，也就是让依赖的指令执行NOP。</p>
<h3 id="Intel-X86每个指令需要的cycle"><a href="#Intel-X86每个指令需要的cycle" class="headerlink" title="Intel X86每个指令需要的cycle"></a>Intel X86每个指令需要的cycle</h3><p>Intel xeon</p>
<p><img src="/images/951413iMgBlog/v2-73a5cce599828b6c28f6f29bb310687a_1440w.jpg" alt="img"></p>
<p>不同架构带来IPC变化：</p>
<p><img src="/images/951413iMgBlog/intel-ice-lake-ipc-over-time.jpg" alt="img"></p>
<p>Intel 最新的CPU Ice Lake和其上一代的性能对比数据：</p>
<p><img src="/images/951413iMgBlog/intel-ice-lake-sunny-cove-core-table.jpg" alt="img"></p>
<p>上图最终结果导致了IPC提升了20%，以及整体效率的提升：</p>
<p><img src="/images/951413iMgBlog/Intel-Ice-Lake-improved-perf-per-core-April-2021.png" alt="img"></p>
<h2 id="perf-使用"><a href="#perf-使用" class="headerlink" title="perf 使用"></a>perf 使用</h2><p>主要是通过采集 PMU（Performance Monitoring Unit – CPU内部提供）数据来做性能监控</p>
<p><img src="/images/951413iMgBlog/5edebc74-f8ac-483c-8bcd-24e09abfd06b.png" alt="img"></p>
<p>Perf 是一个包含 22 种子工具的工具集，每个工具分别作为一个子命令。</p>
<p>annotate 命令读取 perf.data 并显示注释过的代码;diff 命令读取两个 perf.data 文件并显示两份剖析信息之间的差异; </p>
<p>evlist 命令列出一个 perf.data 文件的事件名称;</p>
<p>inject 命令过滤以加强事件流，在其中加入额外的信 息;</p>
<p>kmem 命令为跟踪和测量内核中 slab 子系统属性的工具;</p>
<p>kvm 命令为跟踪和测量 kvm 客户机操 作系统的工具;</p>
<p>list 命令列出所有符号事件类型;</p>
<p>lock 命令分析锁事件;</p>
<p>probe 命令定义新的动态跟 踪点;</p>
<p>record 命令运行一个程序，并把剖析信息记录在 perf.data 中;</p>
<p>report 命令读取 perf.data 并显 示剖析信息;</p>
<p>sched 命令为跟踪和测量内核调度器属性的工具;</p>
<p>script 命令读取 perf.data 并显示跟踪 输出;</p>
<p>stat 命令运行一个程序并收集性能计数器统计信息;</p>
<p>timechart 命令为可视化某个负载在某时 间段的系统总体性能的工具;</p>
<p>top 命令为系统剖析工具。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div></pre></td><td class="code"><pre><div class="line">sudo perf record -g -a -e skb:kfree_skb //perf 记录丢包调用栈 然后sudo perf script 查看 （网络报文被丢弃时会调用该函数kfree_skb）</div><div class="line">perf record -e &apos;skb:consume_skb&apos; -ag  //记录网络消耗</div><div class="line">perf probe --add tcp_sendmsg //增加监听probe  perf record -e probe:tcp_sendmsg -aR sleep 1</div><div class="line">sudo perf sched record -- sleep 1 //记录cpu调度的延时</div><div class="line">sudo perf sched latency //查看</div><div class="line"></div><div class="line">perf record --call-graph dwarf</div><div class="line">perf report </div><div class="line">perf report --call-graph -G //反转调用关系</div><div class="line"></div><div class="line"></div><div class="line">展开汇编结果</div><div class="line"></div><div class="line">  占比   行号  指令</div><div class="line">       │      mov    %r13,%rax</div><div class="line">       │      mov    %r8,%rbx</div><div class="line">  0.56 │      mov    %r9,%rcx</div><div class="line">  0.19 │      lock   cmpxchg16b 0x10(%rsi) //加锁占89.53，下一行</div><div class="line"> 89.53 │      sete   %al</div><div class="line">  1.50 │      mov    %al,%r13b</div><div class="line">  0.19 │      mov    $0x1,%al</div><div class="line">       │      test   %r13b,%r13b</div><div class="line">       │    ↓ je     eb</div><div class="line">       │    ↓ jmpq   ef</div><div class="line">       │47:   mov    %r9,(%rsp)</div><div class="line">       </div><div class="line"></div><div class="line">//如下代码的汇编</div><div class="line">void main() &#123;</div><div class="line"></div><div class="line">	while(1) &#123;</div><div class="line">		 __asm__ (&quot;pause\n\t&quot;</div><div class="line">				 &quot;pause\n\t&quot;</div><div class="line">				 &quot;pause\n\t&quot;</div><div class="line">				 &quot;pause\n\t&quot;</div><div class="line">				 &quot;pause&quot;);</div><div class="line">	&#125;</div><div class="line">&#125;       </div><div class="line"></div><div class="line">//每行pause占20%</div><div class="line">       │</div><div class="line">       │    Disassembly of section .text:</div><div class="line">       │</div><div class="line">       │    00000000004004ed &lt;main&gt;:</div><div class="line">       │    main():</div><div class="line">       │      push   %rbp</div><div class="line">       │      mov    %rsp,%rbp</div><div class="line">  0.71 │ 4:   pause</div><div class="line"> 19.35 │      pause</div><div class="line"> 20.20 │      pause</div><div class="line"> 19.81 │      pause</div><div class="line"> 19.88 │      pause</div><div class="line"> 20.04 │    ↑ jmp    4</div></pre></td></tr></table></figure>
<p>网络收包软中断</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line">_raw_spin_lock_irqsave  /proc/kcore</div><div class="line">       │    Disassembly of section load2:</div><div class="line">       │</div><div class="line">       │    ffffffff81662b00 &lt;load2+0x662b00&gt;:</div><div class="line">  0.30 │      nop</div><div class="line">       │      push   %rbp</div><div class="line">  0.21 │      mov    %rsp,%rbp</div><div class="line">  0.15 │      push   %rbx</div><div class="line">  0.12 │      pushfq</div><div class="line">  0.57 │      pop    %rax</div><div class="line">  0.45 │      nop</div><div class="line">  0.15 │      mov    %rax,%rbx</div><div class="line">  0.21 │      cli</div><div class="line">  1.20 │      nop</div><div class="line">       │      mov    $0x20000,%edx</div><div class="line">       │      lock   xadd   %edx,(%rdi) //加锁耗时83%</div><div class="line"> 83.42 │      mov    %edx,%ecx</div><div class="line">       │      shr    $0x10,%ecx</div><div class="line">  0.66 │      cmp    %dx,%cx</div><div class="line">       │    ↓ jne    34</div><div class="line">  0.06 │2e:   mov    %rbx,%rax</div><div class="line">       │      pop    %rbx</div><div class="line">       │      pop    %rbp</div><div class="line">  0.57 │    ← retq</div><div class="line">  0.12 │34:   mov    %ecx,%r8d</div><div class="line">  0.03 │      movzwl %cx,%esi</div><div class="line">       │3a:   mov    $0x8000,%eax</div><div class="line">       │    ↓ jmp    4f</div><div class="line">       │      nop</div><div class="line">  0.06 │48:   pause</div><div class="line">  4.67 │      sub    $0x1,%eax</div><div class="line">       │    ↓ je     69</div><div class="line">  0.12 │4f:   movzwl (%rdi),%edx  //慢操作</div><div class="line">  6.73 │      mov    %edx,%ecx</div><div class="line">       │      xor    %r8d,%ecx</div><div class="line">       │      and    $0xfffe,%ecx</div><div class="line">       │    ↑ jne    48</div><div class="line">  0.12 │      movzwl %dx,%esi</div><div class="line">  0.09 │      callq  0xffffffff8165501c</div><div class="line">       │    ↑ jmp    2e</div><div class="line">       │69:   nop</div><div class="line">       │    ↑ jmp    3a</div></pre></td></tr></table></figure>
<p>可以通过perf看到cpu的使用情况：</p>
<pre><code>$sudo perf stat -a -- sleep 10

Performance counter stats for &apos;system wide&apos;:

 239866.330098      task-clock (msec)         #   23.985 CPUs utilized    /10*1000        (100.00%)
        45,709      context-switches          #    0.191 K/sec                    (100.00%)
         1,715      cpu-migrations            #    0.007 K/sec                    (100.00%)
        79,586      page-faults               #    0.332 K/sec
 3,488,525,170      cycles                    #    0.015 GHz                      (83.34%)
 9,708,140,897      stalled-cycles-frontend   #  278.29% /cycles frontend cycles idle     (83.34%)
 9,314,891,615      stalled-cycles-backend    #  267.02% /cycles backend  cycles idle     (66.68%)
 2,292,955,367      instructions              #    0.66  insns per cycle  insn/cycles
                                             #    4.23  stalled cycles per insn stalled-cycles-frontend/insn (83.34%)
   447,584,805      branches                  #    1.866 M/sec                    (83.33%)
     8,470,791      branch-misses             #    1.89% of all branches          (83.33%)
</code></pre><p><img src="/images/oss/f96e50b5f3d0825b68be5b654624f839.png" alt="image.png"></p>
<h2 id="IPC测试"><a href="#IPC测试" class="headerlink" title="IPC测试"></a>IPC测试</h2><p>实际运行的时候增加如下nop到100个以上</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">void main() &#123;</div><div class="line">    while(1) &#123;</div><div class="line">         __asm__ (&quot;nop\n\t&quot;</div><div class="line">                 &quot;nop\n\t&quot;</div><div class="line">                 &quot;nop&quot;);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>如果同时运行两个如上测试程序，鲲鹏920运行，每个程序的IPC都是3.99</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">#perf stat -- ./nop.out</div><div class="line">failed to read counter branches</div><div class="line"></div><div class="line"> Performance counter stats for &apos;./nop.out&apos;:</div><div class="line"></div><div class="line">       8826.948260      task-clock (msec)         #    1.000 CPUs utilized</div><div class="line">                 8      context-switches          #    0.001 K/sec</div><div class="line">                 0      cpu-migrations            #    0.000 K/sec</div><div class="line">                37      page-faults               #    0.004 K/sec</div><div class="line">    22,949,862,030      cycles                    #    2.600 GHz</div><div class="line">         2,099,719      stalled-cycles-frontend   #    0.01% frontend cycles idle</div><div class="line">        18,859,839      stalled-cycles-backend    #    0.08% backend  cycles idle</div><div class="line">    91,465,043,922      instructions              #    3.99  insns per cycle</div><div class="line">                                                  #    0.00  stalled cycles per insn</div><div class="line">   &lt;not supported&gt;      branches</div><div class="line">            33,262      branch-misses             #    0.00% of all branches</div><div class="line"></div><div class="line">       8.827886000 seconds time elapsed</div></pre></td></tr></table></figure>
<p>intel X86 8260</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">#perf stat -- ./nop.out</div><div class="line"></div><div class="line"> Performance counter stats for &apos;./nop.out&apos;:</div><div class="line"></div><div class="line">      65061.160345      task-clock (msec)         #    1.001 CPUs utilized</div><div class="line">                46      context-switches          #    0.001 K/sec</div><div class="line">                92      cpu-migrations            #    0.001 K/sec</div><div class="line">               108      page-faults               #    0.002 K/sec</div><div class="line">   155,659,827,263      cycles                    #    2.393 GHz</div><div class="line">   &lt;not supported&gt;      stalled-cycles-frontend</div><div class="line">   &lt;not supported&gt;      stalled-cycles-backend</div><div class="line">   603,247,401,995      instructions              #    3.88  insns per cycle</div><div class="line">     4,742,051,659      branches                  #   72.886 M/sec</div><div class="line">         1,799,428      branch-misses             #    0.04% of all branches</div><div class="line"></div><div class="line">      65.012821629 seconds time elapsed</div></pre></td></tr></table></figure>
<p>这两块CPU理论IPC最大值都是4，实际x86离理论值更远一些. 增加while循环中的nop数量（从132增加到432个）IPC能提升到3.92</p>
<h2 id="IPC和超线程"><a href="#IPC和超线程" class="headerlink" title="IPC和超线程"></a>IPC和超线程</h2><p>ipc是指每个core的IPC</p>
<h3 id="超线程-Hyper-Threading-原理"><a href="#超线程-Hyper-Threading-原理" class="headerlink" title="超线程(Hyper-Threading)原理"></a>超线程(Hyper-Threading)原理</h3><p><strong>概念</strong>：一个核还可以进一步分成几个逻辑核，来执行多个控制流程，这样可以进一步提高并行程度，这一技术就叫超线程，有时叫做 simultaneous multi-threading（SMT）。</p>
<p>超线程技术主要的出发点是，当处理器在运行一个线程，执行指令代码时，很多时候处理器并不会使用到全部的计算能力，部分计算能力就会处于空闲状态。而超线程技术就是通过多线程来进一步“压榨”处理器。<strong>pipeline进入stalled状态就可以切到其它超线程上</strong></p>
<p>举个例子，如果一个线程运行过程中，必须要等到一些数据加载到缓存中以后才能继续执行，此时 CPU 就可以切换到另一个线程，去执行其他指令，而不用去处于空闲状态，等待当前线程的数据加载完毕。<strong>通常，一个传统的处理器在线程之间切换，可能需要几万个时钟周期。而一个具有 HT 超线程技术的处理器只需要 1 个时钟周期。因此就大大减小了线程之间切换的成本，从而最大限度地让处理器满负荷运转。</strong></p>
<blockquote>
<p>ARM芯片基本不做超线程，另外请思考为什么有了应用层的多线程切换还需要CPU层面的超线程？</p>
</blockquote>
<p><strong>超线程(Hyper-Threading)物理实现</strong>: 在CPU内部增加寄存器等硬件设施，但是ALU、译码器等关键单元还是共享。在一个物理 CPU 核心内部，会有双份的 PC 寄存器、指令寄存器乃至条件码寄存器。超线程的目的，是在一个线程 A 的指令，在流水线里停顿的时候，让另外一个线程去执行指令。因为这个时候，CPU 的译码器和 ALU 就空出来了，那么另外一个线程 B，就可以拿来干自己需要的事情。这个线程 B 可没有对于线程 A 里面指令的关联和依赖。</p>
<p>CPU超线程设计过程中会引入5%的硬件，但是有30%的提升（经验值，场景不一样效果不一样，阿里的OB/MySQL/ODPS业务经验是提升35%），这是引入超线程的理论基础。如果是一个core 4个HT的话提升会是 50%</p>
<h3 id="超线程如何查看"><a href="#超线程如何查看" class="headerlink" title="超线程如何查看"></a>超线程如何查看</h3><p>如果physical id和core id都一样的话，说明这两个core实际是一个物理core，其中一个是HT。</p>
<p><img src="/images/951413iMgBlog/191276e2a1a1731969da748f1690bc9b.png" alt="image.png"></p>
<p>physical id对应socket，也就是物理上购买到的一块CPU； core id对应着每个物理CPU里面的一个物理core，同一个phyiscal id下core id一样说明开了HT</p>
<h3 id="IPC和超线程的关系"><a href="#IPC和超线程的关系" class="headerlink" title="IPC和超线程的关系"></a>IPC和超线程的关系</h3><p>IPC 和一个core上运行多少个进程没有关系。实际测试将两个运行nop指令的进程绑定到一个core上，IPC不变, 因为IPC就是从core里面取到的，不针对具体进程。但是如果是这两个进程绑定到一个物理core以及对应的超线程core上那么IPC就会减半。如果程序是IO bound（比如需要频繁读写内存）首先IPC远远低于理论值4的，这个时候超线程同时工作的话IPC基本能翻倍</p>
<p><img src="/images/951413iMgBlog/image-20210513123233344.png" alt="image-20210513123233344"></p>
<p>对应的CPU使用率, 两个进程的CPU使用率是200%，实际产出IPC是2.1+1.64=3.75，比单个进程的IPC为3.92小多了。而单个进程CPU使用率才100%</p>
<p><img src="/images/951413iMgBlog/image-20210513130252565.png" alt="image-20210513130252565"></p>
<p>以上测试CPU为Intel(R) Xeon(R) Platinum 8260 CPU @ 2.40GHz (Thread(s) per core:    2)</p>
<h3 id="Intel和AMD单核以及HT性能比较"><a href="#Intel和AMD单核以及HT性能比较" class="headerlink" title="Intel和AMD单核以及HT性能比较"></a>Intel和AMD单核以及HT性能比较</h3><p>测试命令，这个测试命令无论在哪个CPU下，用2个物理核用时都是一个物理核的一半，所以这个计算是可以完全并行的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">taskset -c 1,53 /usr/bin/sysbench --num-threads=2 --test=cpu --cpu-max-prime=50000 run //单核用一个threads，绑核， HT用2个threads，绑一对HT</div></pre></td></tr></table></figure>
<p>测试结果为耗时，单位秒，Hygon 7280 就是Zen2架构</p>
<table>
<thead>
<tr>
<th style="text-align:left">Family Name</th>
<th style="text-align:left">Intel 8269CY CPU @ 2.50GHz</th>
<th style="text-align:left">Intel E5-2682 v4 @ 2.50GHz</th>
<th style="text-align:left">Hygon 7280 2.1G</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">单核  prime 50000</td>
<td style="text-align:left">83</td>
<td style="text-align:left">109</td>
<td style="text-align:left">89</td>
</tr>
<tr>
<td style="text-align:left">HT  prime 50000</td>
<td style="text-align:left">48</td>
<td style="text-align:left">74</td>
<td style="text-align:left">87</td>
</tr>
</tbody>
</table>
<h2 id="主频和性价比"><a href="#主频和性价比" class="headerlink" title="主频和性价比"></a>主频和性价比</h2><p>拿Intel 在数据中心计算的大核CPU IvyBridge与当时用于 存储系列的小核CPU Avoton（ATOM）, 分别测试阿里巴巴(Oceanbase ，MySQL, ODPS)的workload，得到性能吞吐如下：</p>
<p>Intel 大小CPU 核心                   阿里 Workload Output(QPS)</p>
<p>Avoton(8 cores) 2.4GHZ                 10K on single core</p>
<p>Ivy Bridge(2650 v2 disable HT) 2.6GHZ      20K on single core</p>
<p>Ivy Bridge(2650 v2 enable HT) 2.4GHZ       25K on single core</p>
<p>Ivy Bridge(2650 v2 enable HT) 2.6GHZ       27K on single core</p>
<ol>
<li>超线程等于将一个大核CPU 分拆成两个小核，Ivy Bridge的数据显示超线程给 Ivy Bridge <strong>1.35倍</strong>(27K/20K) 的提升</li>
<li>现在我们分别评判 两种CPU对应的性能密度 (performance/core die size) ，该数据越大越好，根据我们的计算和测量发现：Avoton(包含L1D, L1I, and L2 per core)大约是 3~4平方毫米，Ivy Bridge (包含L1D, L1I, L2 )大约是12~13平方毫米, L3/core是 6~7平方毫米, 所以 Ivy Bridge 单核心的芯片面积需要18 ~ 20平方毫米。基于上面的数据我们得到的 Avoton core的性能密度为 2.5 (10K/4sqmm)，而Ivy Bridge的性能密度是1.35 (27K/20sqmm)，因此相同的芯片面积下 Avoton 的性能是 Ivy Bridge的 <strong>1.85倍</strong>(2.5/1.35).</li>
<li>从功耗的角度看性能的提升的对比数据，E5-2650v2(Ivy Bridge) 8core TDP 90w， Avoton 8 core TDP 20瓦， 性能/功耗 Avoton 是 10K QPS/20瓦， Ivy Bridge是 27KQPS/90瓦， 因此 相同的功耗下 Avoton是 Ivy Bridge的 <strong>1.75倍</strong>（10K QPS/20）/ （27KQPS/95）</li>
<li>从价格方面再进行比较，E5-2650v2(Ivy Bridge) 8core 官方价格是1107美元， Avoton 8 core官方价格是171美元。性能/价格 Avoton是 10KQPS/171美元，Ivy Bridge 是 27KQPS/1107美元， 因此相同的美元 Avoton的性能是 Ivy Bridge 的<strong>2.3倍（</strong>1 10KQPS/171美元）/ （27KQPS/1107美元）</li>
</ol>
<p>从以上结论可以看到在数据中心的场景下，由于指令数据相关性较高，同时由于内存访问的延迟更多，因此复杂的CPU体系结构并不能获得相应性能提升，该原因导致我们需要的是更多的小核CPU，以此达到高吞吐量的能力，因此2014年我们向Intel提出需要将物理CPU的超线程由 2个升级到4个/8个， 或者直接将用更多的小核CPU增加服务器的吞吐能力，最新数据表明Intel 会在大核CPU中引入4个超线程，和在相同的芯片面积下引入更多的小核CPU。</p>
<p>预测：为了减少数据中心的功耗，我们需要提升单位面积下的计算密度，因此将来会引入Rack Computing的计算模式，每台服务器将会有4～5百个CPU core，如果使用4个CPU socket，每台机器将会达到～1000个CPU core，结合Compute Express Link (CXL), 一个机架内允许16台服务器情况下，可以引入共享内存，那么一个进程可以运行在上万个CPU core中，这样复杂环境下，我们需要对于这样的软件环境做出更多的布局和优化。</p>
<h2 id="perf-top-和-pause-的案例"><a href="#perf-top-和-pause-的案例" class="headerlink" title="perf top 和 pause 的案例"></a><a href="https://topic.atatech.org/articles/85549" target="_blank" rel="external">perf top 和 pause 的案例</a></h2><p>在Skylake的架构中，将pause由10个时钟周期增加到了140个时钟周期。主要用在spin lock当中因为spin loop 多线程竞争差生的内存乱序而引起的性能下降。pause的时钟周期高过了绝大多数的指令cpu cycles，那么当我们利用perf top统计cpu 性能的时候，pause会有什么影响呢？我们可以利用一段小程序来测试一下.</p>
<p>测试机器：<br>CPU: Intel(R) Xeon(R) Platinum 8163 CPU @ 2.50GHz * 2, 共96个超线程</p>
<p>案例：</p>
<p><img src="/images/oss/864427c491497acb02d37c02cb35eeb2.png" alt="image.png"></p>
<p>对如上两个pause指令以及一个 count++（addq），进行perf top：</p>
<p><img src="/images/oss/40945b005eb9f716e429fd30be55b6d1.png" alt="image.png"></p>
<p>可以看到第一个pasue在perf top中cycles为0，第二个为46.85%，另外一个addq也有48.83%，基本可以猜测perf top在这里数据都往后挪了一个。</p>
<p><strong>问题总结：</strong><br> 我们知道perf top是通过读取PMU的PC寄存器来获取当前执行的指令进而根据汇编的symbol信息获得是执行的哪条指令。所以看起来CPU在执行pause指令的时候，从PMU中看到的PC值指向到了下一条指令，进而导致我们看到的这个现象。通过查阅《Intel® 64 and IA-32 Architectures Optimization Reference Manual》目前还无法得知这是CPU的一个设计缺陷还是PMU的一个bug(需要对pause指令做特殊处理)。<strong>不管怎样，这个实验证明了我们统计spin lock的CPU占比还是准确的，不会因为pause指令导致PMU采样出错导致统计信息的整体失真。只是对于指令级的CPU统计，我们能确定的就是它把pause的执行cycles 数统计到了下一条指令。</strong></p>
<p><strong>补充说明：</strong> <strong>经过测试，非skylake CPU也同样存在perf top会把pause(执行数cycles是10)的执行cycles数统计到下一条指令的问题，看来这是X86架构都存在的问题。</strong></p>
<h2 id="perf-和火焰图"><a href="#perf-和火焰图" class="headerlink" title="perf 和火焰图"></a>perf 和火焰图</h2><p>调用 perf record 采样几秒钟，一般需要加 -g 参数，也就是 call-graph，还需要抓取函数的调用关系。在多核的机器上，还要记得加上 -a 参数，保证获取所有 CPU Core 上的函数运行情况。至于采样数据的多少，在讲解 perf 概念的时候说过，我们可以用 -c 或者 -F 参数来控制。</p>
<pre><code>   83  07/08/19 13:56:26 sudo perf record -ag -p 4759
   84  07/08/19 13:56:50 ls /tmp/
   85  07/08/19 13:57:06 history |tail -16
   86  07/08/19 13:57:20 sudo chmod 777 perf.data
   87  07/08/19 13:57:33 perf script &gt;out.perf
   88  07/08/19 13:59:24 ~/tools/FlameGraph-master/./stackcollapse-perf.pl ~/out.perf &gt;out.folded
   89  07/08/19 14:01:01 ~/tools/FlameGraph-master/flamegraph.pl out.folded &gt; kernel-perf.svg
   90  07/08/19 14:01:07 ls -lh
   91  07/08/19 14:03:33 history


$ sudo perf record -F 99 -a -g -- sleep 60 //-F 99 指采样每秒钟做 99 次
</code></pre><p>　　执行这个命令将生成一个 perf.data 文件：</p>
<p>执行sudo perf report -n可以生成报告的预览。<br>执行sudo perf report -n –stdio可以生成一个详细的报告。<br>执行sudo perf script可以 dump 出 perf.data 的内容。</p>
<pre><code># 折叠调用栈
$ FlameGraph/stackcollapse-perf.pl out.perf &gt; out.folded
# 生成火焰图
$ FlameGraph/flamegraph.pl out.folded &gt; out.svg
</code></pre><h2 id="ECS和perf"><a href="#ECS和perf" class="headerlink" title="ECS和perf"></a>ECS和perf</h2><p>在ECS会采集不到 cycles等，cpu-clock、page-faults都是内核中的软事件，cycles/instructions得采集cpu的PMU数据，ECS采集不到这些PMU数据。</p>
<p><img src="/images/oss/a120388ff72d712a4fd176e7cea005cf.png" alt="image.png"></p>
<h2 id="Perf-和-false-share-cache-line"><a href="#Perf-和-false-share-cache-line" class="headerlink" title="Perf 和 false share cache_line"></a>Perf 和 false share cache_line</h2><p><a href="https://joemario.github.io/blog/2016/09/01/c2c-blog/" target="_blank" rel="external">从4.2kernel开始，perf支持perf c2c (cache 2 cahce) 来监控cache_line的伪共享</a></p>
<h2 id="系列文章-1"><a href="#系列文章-1" class="headerlink" title="系列文章"></a>系列文章</h2><p><a href="/2021/06/01/CPU的制造和概念/">CPU的制造和概念</a></p>
<p><a href="/2021/05/16/CPU Cache Line 和性能/">CPU 性能和Cache Line</a></p>
<p><a href="/2021/05/16/Perf IPC以及CPU利用率/">Perf IPC以及CPU性能</a></p>
<p><a href="/2021/06/18/几款CPU性能对比/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></p>
<p><a href="/2021/05/15/飞腾ARM芯片(FT2500">飞腾ARM芯片(FT2500)的性能测试</a>的性能测试/)</p>
<p><a href="/2021/05/14/十年后数据库还是不敢拥抱NUMA/">十年后数据库还是不敢拥抱NUMA？</a></p>
<p><a href="/2021/03/07/一次海光物理机资源竞争压测的记录/">一次海光物理机资源竞争压测的记录</a></p>
<p><a href="/2019/12/16/Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的/">Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的</a></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://zhengheng.me/2015/11/12/perf-stat/" target="_blank" rel="external">perf详解</a></p>
<p><a href="https://www.atatech.org/articles/109158" target="_blank" rel="external">CPU体系结构</a></p>
<p><a href="https://mp.weixin.qq.com/s/KaDJ1EF5Y-ndjRv2iUO3cA" target="_blank" rel="external">震惊，用了这么多年的 CPU 利用率，其实是错的</a>cpu占用不代表在做事情，可能是stalled，也就是流水线卡顿，但是cpu占用了，实际没事情做。</p>
<p><a href="http://www.brendangregg.com/blog/2017-05-09/cpu-utilization-is-wrong.html" target="_blank" rel="external">CPU Utilization is Wrong</a></p>
<p><a href="https://mp.weixin.qq.com/s?__biz=MzUxNjE3MTcwMg==&amp;mid=2247483755&amp;idx=1&amp;sn=5324f7e46c91739b566dfc1d0847fc4a&amp;chksm=f9aa33b2ceddbaa478729383cac89967cc515bafa472001adc4ad42fb37e3ce473eddc3b591a&amp;mpshare=1&amp;scene=1&amp;srcid=0127mp3WJ6Kd1UOQISFg3SIC#rd" target="_blank" rel="external">https://mp.weixin.qq.com/s?__biz=MzUxNjE3MTcwMg==&amp;mid=2247483755&amp;idx=1&amp;sn=5324f7e46c91739b566dfc1d0847fc4a&amp;chksm=f9aa33b2ceddbaa478729383cac89967cc515bafa472001adc4ad42fb37e3ce473eddc3b591a&amp;mpshare=1&amp;scene=1&amp;srcid=0127mp3WJ6Kd1UOQISFg3SIC#rd</a> </p>
<p><a href="https://kernel.taobao.org/2019/03/Top-down-Microarchitecture-Analysis-Method/" target="_blank" rel="external">https://kernel.taobao.org/2019/03/Top-down-Microarchitecture-Analysis-Method/</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/05/15/飞腾ARM芯片(FT2500)的性能测试/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/05/15/飞腾ARM芯片(FT2500)的性能测试/" itemprop="url">飞腾ARM芯片-FT2500的性能测试</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-05-15T17:30:03+08:00">
                2021-05-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CPU/" itemprop="url" rel="index">
                    <span itemprop="name">CPU</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="飞腾ARM芯片-FT2500的性能测试"><a href="#飞腾ARM芯片-FT2500的性能测试" class="headerlink" title="飞腾ARM芯片-FT2500的性能测试"></a>飞腾ARM芯片-FT2500的性能测试</h1><h2 id="ARM"><a href="#ARM" class="headerlink" title="ARM"></a>ARM</h2><p> ARM公司最早是由赫尔曼·豪泽（Hermann Hauser）和工程师Chris Curry在1978年创立（早期全称是 Acorn RISC Machine），后来改名为现在的ARM公司（Advanced RISC Machine）</p>
<p><img src="/images/951413iMgBlog/ac0bac75ae745316e0c011ffdc5a78a5.png" alt="img"></p>
<h3 id="ARM-芯片厂家"><a href="#ARM-芯片厂家" class="headerlink" title="ARM 芯片厂家"></a>ARM 芯片厂家</h3><p>查看厂家</p>
<blockquote>
<p>#cat /proc/cpuinfo |grep implementer</p>
<p>CPU implementer    : 0x70</p>
<p>#cat /sys/devices/system/cpu/cpu0/regs/identification/midr_el1<br>0x00000000701f6633  // 70 表示厂家</p>
</blockquote>
<p>vendor id对应厂家</p>
<table>
<thead>
<tr>
<th style="text-align:left">Vendor Name</th>
<th style="text-align:left">Vendor ID</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">ARM</td>
<td style="text-align:left">0x41</td>
</tr>
<tr>
<td style="text-align:left">Broadcom</td>
<td style="text-align:left">0x42</td>
</tr>
<tr>
<td style="text-align:left">Cavium</td>
<td style="text-align:left">0x43</td>
</tr>
<tr>
<td style="text-align:left">DigitalEquipment</td>
<td style="text-align:left">0x44</td>
</tr>
<tr>
<td style="text-align:left">HiSilicon</td>
<td style="text-align:left">0x48</td>
</tr>
<tr>
<td style="text-align:left">Infineon</td>
<td style="text-align:left">0x49</td>
</tr>
<tr>
<td style="text-align:left">Freescale</td>
<td style="text-align:left">0x4D</td>
</tr>
<tr>
<td style="text-align:left">NVIDIA</td>
<td style="text-align:left">0x4E</td>
</tr>
<tr>
<td style="text-align:left">APM</td>
<td style="text-align:left">0x50</td>
</tr>
<tr>
<td style="text-align:left">Qualcomm</td>
<td style="text-align:left">0x51</td>
</tr>
<tr>
<td style="text-align:left">Marvell</td>
<td style="text-align:left">0x56</td>
</tr>
<tr>
<td style="text-align:left">Intel</td>
<td style="text-align:left">0x69</td>
</tr>
<tr>
<td style="text-align:left">飞腾</td>
<td style="text-align:left">0x70</td>
</tr>
</tbody>
</table>
<h2 id="飞腾ARM芯片介绍"><a href="#飞腾ARM芯片介绍" class="headerlink" title="飞腾ARM芯片介绍"></a>飞腾ARM芯片介绍</h2><p><strong>飞腾处理器</strong>，又称<strong>银河飞腾处理器</strong>，是由<a href="https://zh.wikipedia.org/wiki/中國人民解放軍國防科學技術大學" target="_blank" rel="external">中国人民解放军国防科学技术大学</a>研制的一系列嵌入式<a href="https://zh.wikipedia.org/wiki/数字信号处理器" target="_blank" rel="external">数字信号处理器</a>（DSP）和<a href="https://zh.wikipedia.org/wiki/中央处理器" target="_blank" rel="external">中央处理器</a>（CPU）芯片。<a href="https://zh.wikipedia.org/wiki/飞腾处理器#cite_note-cw-1" target="_blank" rel="external">[1]</a>这个处理器系列的研发，是由国防科技大的<a href="https://zh.wikipedia.org/w/index.php?title=邢座程&amp;action=edit&amp;redlink=1" target="_blank" rel="external">邢座程</a>教授<a href="https://zh.wikipedia.org/wiki/飞腾处理器#cite_note-2" target="_blank" rel="external">[2]</a>带领的团队负责研发。<a href="https://zh.wikipedia.org/wiki/飞腾处理器#cite_note-Xing_671-3" target="_blank" rel="external">[3]</a>其<a href="https://zh.wikipedia.org/w/index.php?title=商業化&amp;action=edit&amp;redlink=1" target="_blank" rel="external">商业化</a><a href="https://zh.wikipedia.org/wiki/推廣" target="_blank" rel="external">推广</a>则是由<a href="https://zh.wikipedia.org/wiki/中国电子信息产业集团有限公司" target="_blank" rel="external">中国电子信息产业集团有限公司</a>旗下的天津飞腾信息技术有限公司负责。</p>
<p>飞腾公司在早期，考察了SPARC、MIPS、ALPHA架构，这三种指令集架构都可以以极其低廉的价格（据说SPARC的授权价只有99美元，ALPHA不要钱）获得授权，飞腾选择了SPARC架构进行了CPU的研发。</p>
<p>2012年ARM正式推出了自己的第一个64位指令集处理器架构ARMv8，进入服务器等新的领域。此后飞腾放弃了SPARC，拿了ARMv8指令集架构的授权，全面转向了ARM阵营，芯片roadmap如下：</p>
<p><img src="/images/951413iMgBlog/3407604faa7ca9a87fa26610606081ab.png" alt="img"></p>
<h3 id="测试芯片详细信息"><a href="#测试芯片详细信息" class="headerlink" title="测试芯片详细信息"></a><a href="https://pdf.dfcfw.com/pdf/H3_AP202010201422468889_1.pdf?1603181661000.pdf" target="_blank" rel="external">测试芯片详细信息</a></h3><p>2020 年 7 月 23 日，飞腾发布新一代高可扩展多路服务器芯片腾云 S2500，采用 16nm 工艺， 主频 2.0~2.2Ghz，拥有 64 个 FTC663 内核，片内集成 64MB 三级 Cache，支持 8 个 DDR4-3200 存 储通道，功耗 150W。 </p>
<p>基于 ARM 架构，兼具高可拓展性和低功耗，扩展支持 2 路到 8 路直连。与主流架构 X86 相比， ARM 架构具备低功耗、低发热和低成本的优势，ARM 单核的面积仅为 X86 核的 1/7，同样芯片尺寸下可以继承更多核心数，可以通过增加核心数提高性能，在性能快速提升下，也能保持较低的功耗，符合云计算场景下并行计算上高并发和高效率的要求，也能有效控制服务器的能耗和成本支出。腾云 S2500 增加了 4 个直连接口，总带宽 800Gbps，支持 2 路、4 路和 8 路直连，具备高可 拓展性，可以形成 128 核到 512 核的计算机系统，带动算力提升。</p>
<p>飞腾(FT2500), ARMv8架构，主频2.1G，服务器两路，每路64个物理core，没有超线程，总共16个numa，每个numa 8个core</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div></pre></td><td class="code"><pre><div class="line">#dmidecode -t processor</div><div class="line"># dmidecode 3.0</div><div class="line">Getting SMBIOS data from sysfs.</div><div class="line">SMBIOS 3.2.0 present.</div><div class="line"># SMBIOS implementations newer than version 3.0 are not</div><div class="line"># fully supported by this version of dmidecode.</div><div class="line"></div><div class="line">Handle 0x0004, DMI type 4, 48 bytes</div><div class="line">Processor Information</div><div class="line">    Socket Designation: BGA3576</div><div class="line">    Type: Central Processor</div><div class="line">    Family: &lt;OUT OF SPEC&gt;</div><div class="line">    Manufacturer: PHYTIUM</div><div class="line">    ID: 00 00 00 00 70 1F 66 22</div><div class="line">    Version: FT2500</div><div class="line">    Voltage: 0.8 V</div><div class="line">    External Clock: 50 MHz</div><div class="line">    Max Speed: 2100 MHz</div><div class="line">    Current Speed: 2100 MHz</div><div class="line">    Status: Populated, Enabled</div><div class="line">    Upgrade: Other</div><div class="line">    L1 Cache Handle: 0x0005</div><div class="line">    L2 Cache Handle: 0x0007</div><div class="line">    L3 Cache Handle: 0x0008</div><div class="line">    Serial Number: 1234567</div><div class="line">    Asset Tag: No Asset Tag</div><div class="line">    Part Number: NULL</div><div class="line">    Core Count: 64</div><div class="line">    Core Enabled: 64</div><div class="line">    Thread Count: 64</div><div class="line">    Characteristics:</div><div class="line">        64-bit capable</div><div class="line">        Multi-Core</div><div class="line">        Hardware Thread</div><div class="line">        Execute Protection</div><div class="line">        Enhanced Virtualization</div><div class="line">        Power/Performance Control</div><div class="line"></div><div class="line">#lscpu</div><div class="line">Architecture:          aarch64</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                128</div><div class="line">On-line CPU(s) list:   0-127</div><div class="line">Thread(s) per core:    1</div><div class="line">Core(s) per socket:    64</div><div class="line">Socket(s):             2</div><div class="line">NUMA node(s):          16</div><div class="line">Model:                 3</div><div class="line">BogoMIPS:              100.00</div><div class="line">L1d cache:             32K</div><div class="line">L1i cache:             32K</div><div class="line">L2 cache:              2048K</div><div class="line">L3 cache:              65536K</div><div class="line">NUMA node0 CPU(s):     0-7</div><div class="line">NUMA node1 CPU(s):     8-15</div><div class="line">NUMA node2 CPU(s):     16-23</div><div class="line">NUMA node3 CPU(s):     24-31</div><div class="line">NUMA node4 CPU(s):     32-39</div><div class="line">NUMA node5 CPU(s):     40-47</div><div class="line">NUMA node6 CPU(s):     48-55</div><div class="line">NUMA node7 CPU(s):     56-63</div><div class="line">NUMA node8 CPU(s):     64-71</div><div class="line">NUMA node9 CPU(s):     72-79</div><div class="line">NUMA node10 CPU(s):    80-87</div><div class="line">NUMA node11 CPU(s):    88-95</div><div class="line">NUMA node12 CPU(s):    96-103</div><div class="line">NUMA node13 CPU(s):    104-111</div><div class="line">NUMA node14 CPU(s):    112-119</div><div class="line">NUMA node15 CPU(s):    120-127</div><div class="line">Flags:                 fp asimd evtstrm aes pmull sha1 sha2 crc32 cpuid</div><div class="line"></div><div class="line">node distances:</div><div class="line">node   0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15</div><div class="line">  0:  10  20  40  30  20  30  50  40  100  100  100  100  100  100  100  100</div><div class="line">  1:  20  10  30  40  50  20  40  50  100  100  100  100  100  100  100  100</div><div class="line">  2:  40  30  10  20  40  50  20  30  100  100  100  100  100  100  100  100</div><div class="line">  3:  30  40  20  10  30  20  40  50  100  100  100  100  100  100  100  100</div><div class="line">  4:  20  50  40  30  10  50  30  20  100  100  100  100  100  100  100  100</div><div class="line">  5:  30  20  50  20  50  10  50  40  100  100  100  100  100  100  100  100</div><div class="line">  6:  50  40  20  40  30  50  10  30  100  100  100  100  100  100  100  100</div><div class="line">  7:  40  50  30  50  20  40  30  10  100  100  100  100  100  100  100  100</div><div class="line">  8:  100  100  100  100  100  100  100  100  10  20  40  30  20  30  50  40</div><div class="line">  9:  100  100  100  100  100  100  100  100  20  10  30  40  50  20  40  50</div><div class="line"> 10:  100  100  100  100  100  100  100  100  40  30  10  20  40  50  20  30</div><div class="line"> 11:  100  100  100  100  100  100  100  100  30  40  20  10  30  20  40  50</div><div class="line"> 12:  100  100  100  100  100  100  100  100  20  50  40  30  10  50  30  20</div><div class="line"> 13:  100  100  100  100  100  100  100  100  30  20  50  20  50  10  50  40</div><div class="line"> 14:  100  100  100  100  100  100  100  100  50  40  20  40  30  50  10  30</div><div class="line"> 15:  100  100  100  100  100  100  100  100  40  50  30  50  20  40  30  10</div></pre></td></tr></table></figure>
<p><img src="/images/951413iMgBlog/image-20210422121346490.png" alt="image-20210422121346490"></p>
<p>cpu详细信息：</p>
<p><img src="/images/oss/e177902c-73b2-4535-9c1f-2726451820db.png" alt="img"></p>
<p>飞腾芯片，按如下distance绑核基本没区别！展示出来的distance是假的一样</p>
<p><img src="/images/oss/5a19ff61-68db-4c65-be4c-6b6c155a8a29.png" alt="img"></p>
<p>FT2500芯片集成的 64 个处理器核心，划分为 8 个 Panel，每个 Panel 中有两个 Cluster (每个 Cluster 包含 4 个处理器核心及共享的 2M 二级 cache)、两个本地目录控 制部件(DCU)、一个片上网络路由器节点(Cell)和一个紧密耦合的访存控制 器(MCU)。Panel 之间通过片上网络接口连接，一致性维护报文、数据报文、 调测试报文、中断报文等统一从同一套网络接口进行路由和通信</p>
<p>一个Panel的实现是FTC663版本，采用四发射乱序超标量流水线结构，兼容 ARMv8 指令集，支持 EL0~EL3 多个特权级。流水线分为取指、译码、分派、执 行和写回五个阶段，采用顺序取指、乱序执行、顺序提交的多发射执行机制，取 值宽度、译码宽度、分派宽度均是 4 条指令，共有 9 个执行部件(或者称为 9 条功能流水线)，分别是 4 个整数部件、2 个浮点部件、1 个 load 部件、1 个 load/store 部件和 1 个系统管理指令执行部件。浮点流水线能够合并执行双路浮点 SIMD 指 令，实现每拍可以执行 4 条双精度浮点操作的峰值性能。</p>
<p><img src="/images/951413iMgBlog/image-20210910120438276.png" alt="image-20210910120438276"></p>
<p>猜测FT2500 64core用的是一个Die, 但是core之间的连接是Ring Bus，而Ring Bus下core太多后延迟会快速增加，所以一个Die 内部做了8个小的Ring Bus，每个Ring Bus下8个core。</p>
<h3 id="飞腾官方提供的测试结果"><a href="#飞腾官方提供的测试结果" class="headerlink" title="飞腾官方提供的测试结果"></a>飞腾官方提供的测试结果</h3><p><img src="/images/951413iMgBlog/image-20210909175954574.png" alt="image-20210909175954574"></p>
<h3 id="飞腾2500-和-鲲鹏9200-参数对比"><a href="#飞腾2500-和-鲲鹏9200-参数对比" class="headerlink" title="飞腾2500 和 鲲鹏9200 参数对比"></a>飞腾2500 和 鲲鹏9200 参数对比</h3><p><img src="/images/951413iMgBlog/image-20210422095217195.png" alt="image-20210422095217195"></p>
<h3 id="FT2000与FT2500差异"><a href="#FT2000与FT2500差异" class="headerlink" title="FT2000与FT2500差异"></a>FT2000与FT2500差异</h3><p>下表是FT2000和FT2500产品规格对比表，和芯片的单核内部结构变化较少，多了L3，主频提高了，其他基本没有变化。</p>
<table>
<thead>
<tr>
<th><strong>特征</strong></th>
<th><strong>FT-2000+/64</strong></th>
<th><strong>FT-2500</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>指令</td>
<td>兼容 ARM V8 指令集 FTC662 内核</td>
<td>兼容 ARM V8 指令集FTC663 内核</td>
</tr>
<tr>
<td>Core数</td>
<td>64个</td>
<td>64个</td>
</tr>
<tr>
<td>频率</td>
<td>2.2GHZ/2.0GHZ/1.8GHZ</td>
<td><strong>2.0~2.3GHz</strong></td>
</tr>
<tr>
<td>体系架构</td>
<td>NUMA</td>
<td>NUMA</td>
</tr>
<tr>
<td>RAS</td>
<td>无</td>
<td>支持</td>
</tr>
<tr>
<td>加解密</td>
<td>无</td>
<td><strong>ASE128、SHA1、SHA2-256、PMULL</strong></td>
</tr>
<tr>
<td>L1 Cache</td>
<td>每个核独占32KB指令Cache与32KB数据Cache</td>
<td>每个核独占32K指令Cache与32K数据Cache</td>
</tr>
<tr>
<td>L2 Cache</td>
<td>共32MB，每4个核共享2MB</td>
<td>共32MB，每4个核共享2MB</td>
</tr>
<tr>
<td>L3 Cache</td>
<td>无</td>
<td><strong>64MB</strong></td>
</tr>
<tr>
<td>LMU数量</td>
<td>8个</td>
<td>8个</td>
</tr>
<tr>
<td>支持最大容量</td>
<td>1TB</td>
<td>1TB*socket数量</td>
</tr>
<tr>
<td>支持最大频率</td>
<td>3200MHZ</td>
<td>支持3200MHZ</td>
</tr>
<tr>
<td>外接设备</td>
<td>支持带 ECC 的 DDR4 DIMM，支持 RDIMM、UDIMM、SODIMM、 LR-DIMM，电压 1.2V</td>
<td>支持带 ECC 的 DDR4 DIMM，支持 RDIMM、UDIMM、SODIMM、LR-DIMM，电压 1.2V</td>
</tr>
<tr>
<td>镜像存储</td>
<td>无</td>
<td>每两个MCU互为备份</td>
</tr>
<tr>
<td>PCIe</td>
<td>PCIE3.02 个 x16 和 1 个 x1每个 x16 可拆分成 2 个 x8，支持翻转</td>
<td>PCIE3.01 个 x16 和 1 个 x1x16 可拆分成 2 个 x8，支持翻转</td>
</tr>
<tr>
<td>SPI</td>
<td>支持 4 个片选，单片最大支持容量为 512MB，电压 1.8V</td>
<td>支持 4 个片选，单片最大支持容量为 512MB，电压 1.8V</td>
</tr>
<tr>
<td>UART</td>
<td>4个 UART，其中 1 个为 9 线全功能串口，3 个为 3 线调试串口</td>
<td>4个 UART，其中 1 个为 9 线全功能串口，3 个为 3 线调试串口</td>
</tr>
<tr>
<td>GPIO</td>
<td>4 个 8 位 GPIO 接口，GPIOA[0:7]，GPIOB[0:7]，GPIOC[0:7]， GPIOD[0:7]</td>
<td>4 个 8 位 GPIO 接口，GPIOA[0:7]，GPIOB[0:7]，GPIOC[0:7]， GPIOD[0:7]</td>
</tr>
<tr>
<td>LPC</td>
<td>1 个 LPC 接口，兼容 Intel Low Pin Count 协议, 电压 1.8V</td>
<td>1 个 LPC 接口，兼容 Intel Low Pin Count 协议, 电压 1.8V</td>
</tr>
<tr>
<td>I2C</td>
<td>2 个 I2C master 控制器</td>
<td>2 个 I2C master /Slave控制器,2个slave控制器</td>
</tr>
<tr>
<td>直连</td>
<td>无</td>
<td>四个直连通路，每路X4个lane，每条lane速率为25Gbps，支持2路、4路、8路</td>
</tr>
</tbody>
</table>
<h2 id="飞腾ARM芯片性能测试数据"><a href="#飞腾ARM芯片性能测试数据" class="headerlink" title="飞腾ARM芯片性能测试数据"></a>飞腾ARM芯片性能测试数据</h2><p>以下测试场景基本都是运行CPU和网络瓶颈的业务逻辑，绑核前IPC只有0.08</p>
<p><img src="/images/oss/16b271c8-5132-4273-a26a-4b35e8f92882.png" alt="img"></p>
<p>绑核后对性能提升非常明显：</p>
<p><img src="/images/oss/4d4fdebb-6146-407e-881d-19170fbfd82b.png" alt="img"></p>
<p>点查场景：</p>
<p><img src="/images/951413iMgBlog/image-20210425092158127.png" alt="image-20210425092158127"></p>
<p>如上是绑48-63号核</p>
<p><img src="/images/951413iMgBlog/image-20210425091727122.png" alt="image-20210425091727122"></p>
<p><img src="/images/951413iMgBlog/image-20210425091557750.png" alt="image-20210425091557750"></p>
<p><img src="/images/951413iMgBlog/image-20210425093630438.png" alt="image-20210425093630438"></p>
<p>绑不同的核性能差异比较大，比如同样绑第一个socket最后16core和绑第二个socket最后16core，第二个socket的最后16core性能要好25-30%—<strong>这是因为网卡软中断，如果将软中断绑定到0-4号cpu后差异基本消失</strong>,因为网卡队列设置的是60，基本跑在前60core上，也就是第一个socket上。</p>
<p>点查场景绑核和不绑核性能能差1倍, 将table分表后，物理rt稳定了(<strong>截图中物理rt下降是因为压力小了</strong>–待证)</p>
<h3 id="点查场景压测16个core的节点"><a href="#点查场景压测16个core的节点" class="headerlink" title="点查场景压测16个core的节点"></a>点查场景压测16个core的节点</h3><p>一个节点16core，16个core绑定到14、15号NUMA上，然后压测</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div></pre></td><td class="code"><pre><div class="line">#perl numa-maps-summary.pl &lt;/proc/79694/numa_maps //16core</div><div class="line">N0        :         1103 (  0.00 GB)</div><div class="line">N1        :       107368 (  0.41 GB)</div><div class="line">N10       :       144736 (  0.55 GB)</div><div class="line">N11       :        16919 (  0.06 GB)</div><div class="line">N12       :       551987 (  2.11 GB)</div><div class="line">N13       :        59499 (  0.23 GB)</div><div class="line">N14       :      5621573 ( 21.44 GB)  //内存就近分配</div><div class="line">N15       :      6200398 ( 23.65 GB)</div><div class="line">N2        :          700 (  0.00 GB)</div><div class="line">N3        :           89 (  0.00 GB)</div><div class="line">N4        :         5784 (  0.02 GB)</div><div class="line">N5        :           77 (  0.00 GB)</div><div class="line">N6        :          426 (  0.00 GB)</div><div class="line">N7        :          472 (  0.00 GB)</div><div class="line">N8        :          107 (  0.00 GB)</div><div class="line">N9        :         6137 (  0.02 GB)</div><div class="line">active    :           85 (  0.00 GB)</div><div class="line">anon      :     12712675 ( 48.50 GB)</div><div class="line">dirty     :     12712679 ( 48.50 GB)</div><div class="line">kernelpagesize_kB:        17444 (  0.07 GB)</div><div class="line">mapmax    :         1598 (  0.01 GB)</div><div class="line">mapped    :         4742 (  0.02 GB)</div><div class="line"></div><div class="line">#perf stat -e branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-store-misses,L1-dcache-stores,L1-icache-load-misses,L1-icache-loads,branch-load-misses,branch-loads,dTLB-load-misses,iTLB-load-misses -a -p 79694</div><div class="line">^C</div><div class="line"> Performance counter stats for process id &apos;79694&apos;:</div><div class="line"></div><div class="line">        1719788217      branch-misses                                                 (39.70%)</div><div class="line">      311069393237      bus-cycles                                                    (38.07%)</div><div class="line">        2021349865      cache-misses              #    6.669 % of all cache refs      (38.32%)</div><div class="line">       30308501243      cache-references                                              (39.67%)</div><div class="line">      310980728138      cpu-cycles                                                    (46.46%)</div><div class="line">       67298903097      instructions              #    0.22  insns per cycle          (47.63%)</div><div class="line">        1983728595      L1-dcache-load-misses     #    6.62% of all L1-dcache hits    (48.76%)</div><div class="line">       29943167305      L1-dcache-loads                                               (47.89%)</div><div class="line">        1957152091      L1-dcache-store-misses                                        (46.14%)</div><div class="line">       29572767575      L1-dcache-stores                                              (44.91%)</div><div class="line">        4223808613      L1-icache-load-misses                                         (43.08%)</div><div class="line">       49122358099      L1-icache-loads                                               (38.15%)</div><div class="line">        1724605628      branch-load-misses                                            (37.63%)</div><div class="line">       15225535577      branch-loads                                                  (36.61%)</div><div class="line">         997458038      dTLB-load-misses                                              (35.81%)</div><div class="line">         542426693      iTLB-load-misses                                              (34.98%)</div><div class="line"></div><div class="line">      10.489297296 seconds time elapsed</div><div class="line"></div><div class="line">[  29s] threads: 160, tps: 0.00, reads/s: 15292.01, writes/s: 0.00, response time: 25.82ms (95%)</div><div class="line">[  30s] threads: 160, tps: 0.00, reads/s: 16399.99, writes/s: 0.00, response time: 23.58ms (95%)</div><div class="line">[  31s] threads: 160, tps: 0.00, reads/s: 17025.00, writes/s: 0.00, response time: 20.73ms (95%)</div><div class="line">[  32s] threads: 160, tps: 0.00, reads/s: 16991.01, writes/s: 0.00, response time: 22.83ms (95%)</div><div class="line">[  33s] threads: 160, tps: 0.00, reads/s: 18400.94, writes/s: 0.00, response time: 21.29ms (95%)</div><div class="line">[  34s] threads: 160, tps: 0.00, reads/s: 17760.05, writes/s: 0.00, response time: 20.69ms (95%)</div><div class="line">[  35s] threads: 160, tps: 0.00, reads/s: 17935.00, writes/s: 0.00, response time: 20.23ms (95%)</div><div class="line">[  36s] threads: 160, tps: 0.00, reads/s: 18296.98, writes/s: 0.00, response time: 20.10ms (95%)</div><div class="line">[  37s] threads: 160, tps: 0.00, reads/s: 18111.02, writes/s: 0.00, response time: 20.56ms (95%)</div><div class="line">[  38s] threads: 160, tps: 0.00, reads/s: 17782.99, writes/s: 0.00, response time: 20.54ms (95%)</div><div class="line">[  38s] threads: 160, tps: 0.00, reads/s: 21412.13, writes/s: 0.00, response time: 11.96ms (95%)</div><div class="line">[  40s] threads: 160, tps: 0.00, reads/s: 18027.85, writes/s: 0.00, response time: 20.18ms (95%)</div><div class="line">[  41s] threads: 160, tps: 0.00, reads/s: 17907.04, writes/s: 0.00, response time: 20.02ms (95%)</div><div class="line">[  42s] threads: 160, tps: 0.00, reads/s: 13860.96, writes/s: 0.00, response time: 23.58ms (95%)</div><div class="line">[  43s] threads: 160, tps: 0.00, reads/s: 18491.02, writes/s: 0.00, response time: 20.18ms (95%)</div><div class="line">[  44s] threads: 160, tps: 0.00, reads/s: 17673.02, writes/s: 0.00, response time: 20.85ms (95%)</div><div class="line">[  45s] threads: 160, tps: 0.00, reads/s: 18048.96, writes/s: 0.00, response time: 21.47ms (95%)</div><div class="line">[  46s] threads: 160, tps: 0.00, reads/s: 18130.03, writes/s: 0.00, response time: 22.13ms (95%)</div></pre></td></tr></table></figure>
<h3 id="点查场景压测8个core的节点"><a href="#点查场景压测8个core的节点" class="headerlink" title="点查场景压测8个core的节点"></a>点查场景压测8个core的节点</h3><p>因为每个NUMA才8个core，所以测试一下8core的节点绑核前后性能对比。实际结果看起来和16core节点绑核性能提升差不多。</p>
<p>绑核前后对比：绑核后QPS翻倍，绑核后的服务rt从7.5降低到了2.2，rt下降非常明显，可以看出主要是绑核前跨numa访问慢。<strong>实际这个测试是先跑的不绑核，内存分布在所有NUMA上，没有重启再绑核就直接测试了，所以性能提升不明显，因为内存已经跨NUMA分配完毕了</strong>。</p>
<p><img src="/images/951413iMgBlog/image-20210427093424116.png" alt="image-20210427093424116"></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash">perl numa-maps-summary.pl &lt;/proc/33727/numa_maps //绑定8core后，在如下内存分配下QPS能到11000，但是抖动略大，应该是一个numa内存不够了</span></div><div class="line">N0        :          551 (  0.00 GB)</div><div class="line">N1        :      1023418 (  3.90 GB)</div><div class="line">N10       :        52065 (  0.20 GB)</div><div class="line">N11       :       190737 (  0.73 GB)</div><div class="line">N12       :       516115 (  1.97 GB)</div><div class="line">N13       :       186556 (  0.71 GB)</div><div class="line">N14       :      1677489 (  6.40 GB)</div><div class="line">N15       :       324531 (  1.24 GB)</div><div class="line">N2        :          397 (  0.00 GB)</div><div class="line">N3        :            8 (  0.00 GB)</div><div class="line">N4        :          398 (  0.00 GB)</div><div class="line">N6        :          349 (  0.00 GB)</div><div class="line">N7        :          437 (  0.00 GB)</div><div class="line">N8        :       108508 (  0.41 GB)</div><div class="line">N9        :        69162 (  0.26 GB)</div><div class="line">active    :         2296 (  0.01 GB)</div><div class="line">anon      :      4144997 ( 15.81 GB)</div><div class="line">dirty     :      4145002 ( 15.81 GB)</div><div class="line">kernelpagesize_kB:         7508 (  0.03 GB)</div><div class="line">mapmax    :         1548 (  0.01 GB)</div><div class="line">mapped    :         5724 (  0.02 GB)</div><div class="line"></div><div class="line">[ 349s] threads: 100, tps: 0.00, reads/s: 11088.99, writes/s: 0.00, response time: 20.18ms (95%)</div><div class="line">[ 350s] threads: 100, tps: 0.00, reads/s: 8778.98, writes/s: 0.00, response time: 26.20ms (95%)</div><div class="line">[ 351s] threads: 100, tps: 0.00, reads/s: 7995.01, writes/s: 0.00, response time: 31.79ms (95%)</div><div class="line">[ 352s] threads: 100, tps: 0.00, reads/s: 9549.01, writes/s: 0.00, response time: 23.90ms (95%)</div><div class="line">[ 353s] threads: 100, tps: 0.00, reads/s: 8757.99, writes/s: 0.00, response time: 24.60ms (95%)</div><div class="line">[ 354s] threads: 100, tps: 0.00, reads/s: 10288.02, writes/s: 0.00, response time: 21.85ms (95%)</div><div class="line">[ 355s] threads: 100, tps: 0.00, reads/s: 11003.97, writes/s: 0.00, response time: 18.90ms (95%)</div><div class="line">[ 356s] threads: 100, tps: 0.00, reads/s: 11111.01, writes/s: 0.00, response time: 20.51ms (95%)</div><div class="line">[ 357s] threads: 100, tps: 0.00, reads/s: 11426.00, writes/s: 0.00, response time: 17.98ms (95%)</div><div class="line">[ 358s] threads: 100, tps: 0.00, reads/s: 11007.01, writes/s: 0.00, response time: 19.35ms (95%)</div><div class="line">[ 359s] threads: 100, tps: 0.00, reads/s: 10425.00, writes/s: 0.00, response time: 20.92ms (95%)</div><div class="line">[ 360s] threads: 100, tps: 0.00, reads/s: 10024.00, writes/s: 0.00, response time: 23.17ms (95%)</div><div class="line">[ 361s] threads: 100, tps: 0.00, reads/s: 10100.98, writes/s: 0.00, response time: 22.94ms (95%)</div><div class="line">[ 362s] threads: 100, tps: 0.00, reads/s: 8164.01, writes/s: 0.00, response time: 27.48ms (95%)</div><div class="line">[ 363s] threads: 100, tps: 0.00, reads/s: 6593.00, writes/s: 0.00, response time: 37.10ms (95%)</div><div class="line">[ 364s] threads: 100, tps: 0.00, reads/s: 7008.00, writes/s: 0.00, response time: 32.32ms (95%)</div><div class="line"><span class="meta"></span></div><div class="line">#<span class="bash">调整这个实例到内存充足的NUMA7上 QPS峰值能到14000，稳定在11000-13000之间，RT明显更稳定了</span></div><div class="line"><span class="meta">#</span><span class="bash">perl numa-maps-summary.pl &lt;/proc/78245/numa_maps</span></div><div class="line">N0        :          551 (  0.00 GB)</div><div class="line">N1        :          115 (  0.00 GB)</div><div class="line">N11       :          695 (  0.00 GB)</div><div class="line">N12       :          878 (  0.00 GB)</div><div class="line">N13       :         2019 (  0.01 GB)</div><div class="line">N14       :           25 (  0.00 GB)</div><div class="line">N15       :           60 (  0.00 GB)</div><div class="line">N2        :          394 (  0.00 GB)</div><div class="line">N3        :            8 (  0.00 GB)</div><div class="line">N4        :       197713 (  0.75 GB)</div><div class="line">N6        :          349 (  0.00 GB)</div><div class="line">N7        :      3957844 ( 15.10 GB)</div><div class="line">N8        :            1 (  0.00 GB)</div><div class="line">active    :           10 (  0.00 GB)</div><div class="line">anon      :      4154693 ( 15.85 GB)</div><div class="line">dirty     :      4154698 ( 15.85 GB)</div><div class="line">kernelpagesize_kB:         7452 (  0.03 GB)</div><div class="line">mapmax    :         1567 (  0.01 GB)</div><div class="line">mapped    :         5959 (  0.02 GB)</div><div class="line"></div><div class="line">[ 278s] threads: 100, tps: 0.00, reads/s: 13410.99, writes/s: 0.00, response time: 15.36ms (95%)</div><div class="line">[ 279s] threads: 100, tps: 0.00, reads/s: 14049.99, writes/s: 0.00, response time: 15.54ms (95%)</div><div class="line">[ 280s] threads: 100, tps: 0.00, reads/s: 13107.02, writes/s: 0.00, response time: 16.72ms (95%)</div><div class="line">[ 281s] threads: 100, tps: 0.00, reads/s: 12431.99, writes/s: 0.00, response time: 17.79ms (95%)</div><div class="line">[ 282s] threads: 100, tps: 0.00, reads/s: 13164.01, writes/s: 0.00, response time: 16.33ms (95%)</div><div class="line">[ 283s] threads: 100, tps: 0.00, reads/s: 13455.01, writes/s: 0.00, response time: 16.19ms (95%)</div><div class="line">[ 284s] threads: 100, tps: 0.00, reads/s: 12932.01, writes/s: 0.00, response time: 16.22ms (95%)</div><div class="line">[ 285s] threads: 100, tps: 0.00, reads/s: 12790.99, writes/s: 0.00, response time: 17.00ms (95%)</div><div class="line">[ 286s] threads: 100, tps: 0.00, reads/s: 12706.00, writes/s: 0.00, response time: 17.88ms (95%)</div><div class="line">[ 287s] threads: 100, tps: 0.00, reads/s: 11886.00, writes/s: 0.00, response time: 19.43ms (95%)</div><div class="line">[ 288s] threads: 100, tps: 0.00, reads/s: 12700.00, writes/s: 0.00, response time: 16.97ms (95%)</div><div class="line"><span class="meta"></span></div><div class="line">#<span class="bash">perl numa-maps-summary.pl &lt;/proc/54723/numa_maps  //54723绑定在NUMA6上</span></div><div class="line">N0        :          551 (  0.00 GB)</div><div class="line">N1        :          115 (  0.00 GB)</div><div class="line">N11       :          682 (  0.00 GB)</div><div class="line">N12       :          856 (  0.00 GB)</div><div class="line">N13       :         2018 (  0.01 GB)</div><div class="line">N14       :           25 (  0.00 GB)</div><div class="line">N15       :           60 (  0.00 GB)</div><div class="line">N2        :      1270166 (  4.85 GB) //不应该分配这里的内存，实际是因为N6内存被PageCache使用掉了</div><div class="line"></div><div class="line">N3        :            8 (  0.00 GB)</div><div class="line">N4        :          398 (  0.00 GB)</div><div class="line">N6        :      3662400 ( 13.97 GB)</div><div class="line">N7        :          460 (  0.00 GB)</div><div class="line">N8        :            1 (  0.00 GB)</div><div class="line">active    :            9 (  0.00 GB)</div><div class="line">anon      :      4931796 ( 18.81 GB)</div><div class="line">dirty     :      4931801 ( 18.81 GB)</div><div class="line">kernelpagesize_kB:         7920 (  0.03 GB)</div><div class="line">mapmax    :         1580 (  0.01 GB)</div><div class="line">mapped    :         5944 (  0.02 GB)</div><div class="line"><span class="meta"></span></div><div class="line">#<span class="bash">cat /proc/meminfo | grep -i active</span></div><div class="line">Active:         22352360 kB</div><div class="line">Inactive:       275173756 kB</div><div class="line">Active(anon):      16984 kB</div><div class="line">Inactive(anon): 240344208 kB</div><div class="line">Active(file):   22335376 kB</div><div class="line">Inactive(file): 34829548 kB</div><div class="line"><span class="meta"></span></div><div class="line">#<span class="bash"><span class="built_in">echo</span> 3 &gt; /proc/sys/vm/drop_caches</span></div><div class="line"><span class="meta"></span></div><div class="line">#<span class="bash">cat /proc/meminfo | grep -i active</span></div><div class="line">Active:          1865724 kB</div><div class="line">Inactive:       242335632 kB</div><div class="line">Active(anon):       7108 kB</div><div class="line">Inactive(anon): 240199020 kB</div><div class="line">Active(file):    1858616 kB  //回收了大量PageCache内存</div><div class="line">Inactive(file):  2136612 kB</div><div class="line"><span class="meta">#</span><span class="bash">perl numa-maps-summary.pl &lt;/proc/54723/numa_maps</span></div><div class="line">N0        :          552 (  0.00 GB)</div><div class="line">N1        :          115 (  0.00 GB)</div><div class="line">N11       :          682 (  0.00 GB)</div><div class="line">N12       :          856 (  0.00 GB)</div><div class="line">N13       :         2018 (  0.01 GB)</div><div class="line">N14       :           25 (  0.00 GB)</div><div class="line">N15       :           60 (  0.00 GB)</div><div class="line">N2        :         1740 (  0.01 GB)</div><div class="line">N3        :            8 (  0.00 GB)</div><div class="line">N4        :          398 (  0.00 GB)</div><div class="line">N6        :      4972492 ( 18.97 GB)</div><div class="line">N7        :          459 (  0.00 GB)</div><div class="line">N8        :            1 (  0.00 GB)</div><div class="line">active    :           16 (  0.00 GB)</div><div class="line">anon      :      4973486 ( 18.97 GB)</div><div class="line">dirty     :      4973491 ( 18.97 GB)</div><div class="line">kernelpagesize_kB:         8456 (  0.03 GB)</div><div class="line">mapmax    :         1564 (  0.01 GB)</div><div class="line">mapped    :         5920 (  0.02 GB)</div></pre></td></tr></table></figure>
<p><img src="/images/951413iMgBlog/image-20210427164953340.png" alt="image-20210427164953340"></p>
<p>绑核前的IPC：</p>
<p><img src="/images/951413iMgBlog/image-20210427093625575.png" alt="image-20210427093625575"></p>
<p>绑核后的IPC：</p>
<p><img src="/images/951413iMgBlog/image-20210427095130343.png" alt="image-20210427095130343"></p>
<p><strong>如果是两个8core对一个16core在都最优绑核场景下从上面的数据来看能有40-50%的性能提升，并且RT抖动更小</strong>，这两个8core绑定在同一个Socket下，验证是否争抢，同时可以看到<strong>绑核后性能可以随着加节点线性增加</strong></p>
<p><img src="/images/951413iMgBlog/image-20210427172612685.png" alt="image-20210427172612685"></p>
<p><img src="/images/951413iMgBlog/image-20210427173047815.png" alt="image-20210427173047815"></p>
<p><img src="/images/951413iMgBlog/image-20210427173417673.png" alt="image-20210427173417673"></p>
<p>结论：不绑核一个FT2500的core点查只有500 QPS，绑核后能到1500QPS, 在Intel 8263下一个core能到6000以上(开日志、没开协程)</p>
<h3 id="MySQL-数据库场景绑核"><a href="#MySQL-数据库场景绑核" class="headerlink" title="MySQL 数据库场景绑核"></a>MySQL 数据库场景绑核</h3><p>通过同一台物理上6个Tomcat节点，总共96个core，压6台MySQL，MySQL基本快打挂了。sysbench 点查，32个分表，增加Tomcat节点进来物理rt就增加，从最初的的1.2ms加到6个Tomcat节点后变成8ms。</p>
<p><img src="/images/951413iMgBlog/image-20210425180535225.png" alt="image-20210425180535225"></p>
<p>MySQL没绑好核，BIOS默认关闭了NUMA，外加12个MySQL分布在物理机上不均匀，3个节点3个MySQL，剩下的物理机上只有一个MySQL实例。</p>
<p>MySQL每个实例32core，管控默认已经做了绑核，但是如果两个MySQL绑在了一个socket上竞争会很激烈，ipc比单独的降一半。</p>
<p>比如这三个MySQL，qps基本均匀，上面两个cpu高，但是没效率，每个MySQL绑了32core，上面两个绑在一个socket上，下面的MySQL绑在另一个socket上，第一个socket还有网络软中断在争抢cpu，飞腾环境下性能真要冲高还有很大空间。</p>
<p><img src="/images/951413iMgBlog/image-20210425180518926.png" alt="image-20210425180518926"></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash">第二个MySQL IPC只有第三个的30%多点，这就是为什么CPU高这么多，但是QPS差不多</span></div><div class="line">perf stat -e branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-store-misses,L1-dcache-stores,L1-icache-load-misses,L1-icache-loads,branch-load-misses,branch-loads,dTLB-load-misses,iTLB-load-misses  -a -p 61238</div><div class="line">^C</div><div class="line"> Performance counter stats for process id '61238':</div><div class="line"></div><div class="line">        86,491,052      branch-misses                                                 (58.55%)</div><div class="line">    98,481,418,793      bus-cycles                                                    (55.64%)</div><div class="line">       113,095,618      cache-misses              #    6.169 % of all cache refs      (53.20%)</div><div class="line">     1,833,344,484      cache-references                                              (52.00%)</div><div class="line">   101,516,165,898      cpu-cycles                                                    (57.09%)</div><div class="line">     4,229,190,014      instructions              #    0.04  insns per cycle          (55.91%)</div><div class="line">       111,780,025      L1-dcache-load-misses     #    6.34% of all L1-dcache hits    (55.40%)</div><div class="line">     1,764,421,570      L1-dcache-loads                                               (52.62%)</div><div class="line">       112,261,128      L1-dcache-store-misses                                        (49.34%)</div><div class="line">     1,814,998,338      L1-dcache-stores                                              (48.51%)</div><div class="line">       219,372,119      L1-icache-load-misses                                         (49.56%)</div><div class="line">     2,816,279,627      L1-icache-loads                                               (49.15%)</div><div class="line">        85,321,093      branch-load-misses                                            (50.38%)</div><div class="line">     1,038,572,653      branch-loads                                                  (50.65%)</div><div class="line">        45,166,831      dTLB-load-misses                                              (51.98%)</div><div class="line">        29,892,473      iTLB-load-misses                                              (52.56%)</div><div class="line"></div><div class="line">       1.163750756 seconds time elapsed</div><div class="line"><span class="meta"></span></div><div class="line">#<span class="bash">第三个MySQL</span></div><div class="line">perf stat -e branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-store-misses,L1-dcache-stores,L1-icache-load-misses,L1-icache-loads,branch-load-misses,branch-loads,dTLB-load-misses,iTLB-load-misses  -a -p 53400</div><div class="line">^C</div><div class="line"> Performance counter stats for process id '53400':</div><div class="line"></div><div class="line">       295,575,513      branch-misses                                                 (40.51%)</div><div class="line">   110,934,600,206      bus-cycles                                                    (39.30%)</div><div class="line">       537,938,496      cache-misses              #    8.310 % of all cache refs      (38.99%)</div><div class="line">     6,473,688,885      cache-references                                              (39.80%)</div><div class="line">   110,540,950,757      cpu-cycles                                                    (46.10%)</div><div class="line">    14,766,013,708      instructions              #    0.14  insns per cycle          (46.85%)</div><div class="line">       538,521,226      L1-dcache-load-misses     #    8.36% of all L1-dcache hits    (48.00%)</div><div class="line">     6,440,728,959      L1-dcache-loads                                               (46.69%)</div><div class="line">       533,693,357      L1-dcache-store-misses                                        (45.91%)</div><div class="line">     6,413,111,024      L1-dcache-stores                                              (44.92%)</div><div class="line">       673,725,952      L1-icache-load-misses                                         (42.76%)</div><div class="line">     9,216,663,639      L1-icache-loads                                               (38.27%)</div><div class="line">       299,202,001      branch-load-misses                                            (37.62%)</div><div class="line">     3,285,957,082      branch-loads                                                  (36.10%)</div><div class="line">       149,348,740      dTLB-load-misses                                              (35.20%)</div><div class="line">       102,444,469      iTLB-load-misses                                              (34.78%)</div><div class="line"></div><div class="line">       8.080841166 seconds time elapsed</div></pre></td></tr></table></figure>
<p>12个MySQL流量基本均匀：</p>
<p><img src="/images/951413iMgBlog/image-20210426083033989.png" alt="image-20210426083033989"></p>
<h3 id="numa太多，每个numa下core比较少"><a href="#numa太多，每个numa下core比较少" class="headerlink" title="numa太多，每个numa下core比较少"></a>numa太多，每个numa下core比较少</h3><p>导致跨numa高概率发生，如下是在正常部署下的测试perf 数据，可以看到IPC极低，才0.08，同样的场景在其他家芯片都能打到0.6</p>
<p><img src="/images/oss/16b271c8-5132-4273-a26a-4b35e8f92882.png" alt="img"></p>
<p>执行绑核，将一个进程限制在2个numa内，因为进程需要16core，理论上用8core的进程性能会更好</p>
<p><img src="/images/oss/4d4fdebb-6146-407e-881d-19170fbfd82b.png" alt="img"></p>
<p>可以看到IPC从0.08提升到了0.22，实际能到0.27，对应的业务测试QPS也是原来的4倍。 </p>
<p>用numactl 在启动的时候绑定cpu在 node0、1上，优先使用node0、1的内存，不够再用其它node的内存</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">numactl --cpunodebind 0,1 --preferred 0,1 /u01/xcluster80/bin/mysqld_safe  --defaults-file=/polarx/xcluster3308/my.cnf  --basedir=/u01/xcluster80_current  --datadir=/polarx/xcluster3308/data  --plugin-dir=/u01/xcluster80/lib/plugin  --user=mysql  --log-error=/polarx/xcluster3308/log/alert.log  --open-files-limit=615350  --pid-file=/polarx/xcluster3308/run/mysql.pid  --socket=/polarx/xcluster3308/run/mysql.sock  --cluster-info=11.158.239.200:11308@1  --mysqlx-port=13308  --port=3308</div></pre></td></tr></table></figure>
<h3 id="网卡队列调整"><a href="#网卡队列调整" class="headerlink" title="网卡队列调整"></a>网卡队列调整</h3><p>这批机器默认都是双网卡做bond，但是两块网卡是HA，默认网卡队列是60，基本都跑在前面60个core上</p>
<p>将MySQL网卡队列从60个改成6个后MySQL性能提升大概10%</p>
<p><img src="/images/951413iMgBlog/image-20210426085534983.png" alt="image-20210426085534983"></p>
<p>默认第一个MySQL都绑在0-31号核上,其实改少队列加大了0-5号core的压力，但是实际数据表现要好。</p>
<h2 id="比较其它"><a href="#比较其它" class="headerlink" title="比较其它"></a>比较其它</h2><p>绑核的时候还要考虑磁盘、网卡在哪个socket上，相对来说node和磁盘、网卡在同一个socket下性能要好一些。</p>
<p>左边的mysqld绑定在socket1的64core上，磁盘、网卡都在socket1上；右边的mysqld绑定在0-31core上，网卡在socket0上，但是磁盘在socket1上</p>
<p>右边这个刚好是跨socket访问磁盘，不知道是不是巧合log_flush排位比较高</p>
<p><img src="/images/951413iMgBlog/image-20210910180305752.png" alt="image-20210910180305752"></p>
<p>此时对应的IPC：</p>
<p><img src="/images/951413iMgBlog/image-20210910181820803.png" alt="image-20210910181820803"></p>
<p>如果上面两个进程在没有刷日志的场景下时候对应的IPC两者基本一样：</p>
<p><img src="/images/951413iMgBlog/image-20210910181909962.png" alt="image-20210910181909962"></p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>FT2500比同主频Intel x86芯片差了快一个数量级的性能，在对FT2500上的业务按node绑核后性能提升了几倍，但是离Intel x86还有很大的距离</p>
<p>用循环跑多个nop指令在飞腾2500下IPC只能跑到1，据说这是因为nop指令被扔掉了，所以一直在跑跳转循环判断；</p>
<p>对寄存器变量进行++运算，IPC是0.5； </p>
<p>用如下代码能将IPC跑到2.49，也是我能跑出来的最高IPC了，去掉nop那行，IPC是1.99</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">        register unsigned i=0;</div><div class="line">for (i=0;i&lt;(1u&lt;&lt;31);i++) &#123;</div><div class="line">        __asm__ (&quot;nop&quot;); </div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="系列文章"><a href="#系列文章" class="headerlink" title="系列文章"></a>系列文章</h2><p><a href="/2021/06/01/CPU的制造和概念/">CPU的制造和概念</a></p>
<p><a href="/2021/05/16/CPU Cache Line 和性能/">CPU 性能和Cache Line</a></p>
<p><a href="/2021/05/16/Perf IPC以及CPU利用率/">Perf IPC以及CPU性能</a></p>
<p><a href="/2021/06/18/几款CPU性能对比/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></p>
<p><a href="/2021/05/15/飞腾ARM芯片(FT2500">飞腾ARM芯片(FT2500)的性能测试</a>的性能测试/)</p>
<p><a href="/2021/05/14/十年后数据库还是不敢拥抱NUMA/">十年后数据库还是不敢拥抱NUMA？</a></p>
<p><a href="/2021/03/07/一次海光物理机资源竞争压测的记录/">一次海光物理机资源竞争压测的记录</a></p>
<p><a href="/2019/12/16/Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的/">Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的</a></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="http://www.brendangregg.com/blog/2017-05-09/cpu-utilization-is-wrong.html" target="_blank" rel="external">CPU Utilization is Wrong</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/05/14/十年后数据库还是不敢拥抱NUMA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/05/14/十年后数据库还是不敢拥抱NUMA/" itemprop="url">十年后数据库还是不敢拥抱NUMA？</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-05-14T17:30:03+08:00">
                2021-05-14
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CPU/" itemprop="url" rel="index">
                    <span itemprop="name">CPU</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="十年后数据库还是不敢拥抱NUMA？"><a href="#十年后数据库还是不敢拥抱NUMA？" class="headerlink" title="十年后数据库还是不敢拥抱NUMA？"></a>十年后数据库还是不敢拥抱NUMA？</h1><p>在2010年前后MySQL、PG、Oracle数据库在使用NUMA的时候碰到了性能问题，流传最广的这篇  <a href="http://blog.jcole.us/2010/09/28/mysql-swap-insanity-and-the-numa-architecture/" target="_blank" rel="external">MySQL – The MySQL “swap insanity” problem and the effects of the NUMA architecture</a> 描述了性能问题的原因(文章中把原因找错了)以及解决方案：关闭NUMA。 实际这个原因是kernel实现的一个低级bug，这个Bug在<a href="https://github.com/torvalds/linux/commit/4f9b16a64753d0bb607454347036dc997fd03b82" target="_blank" rel="external">2014年修复了</a>，但是修复这么多年后仍然以讹传讹，这篇文章希望正本清源、扭转错误的认识。</p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>最近在做一次性能测试的时候发现MySQL实例有一个奇怪现象，在128core的物理机上运行三个MySQL实例，每个实例分别绑定32个物理core，绑定顺序就是第一个0-31、第二个32-63、第三个64-95，实际运行结果让人大跌眼镜，如下图</p>
<p><img src="/images/951413iMgBlog/1620953504602-30988926-85d8-4af1-996d-f35aa5fede00.png" alt="undefined"> </p>
<p>从CPU消耗来看差异巨大，高的实例CPU用到了2500%，低的才488%，差了5倍。但是神奇的是他们的QPS一样，执行的SQL也是一样</p>
<p><img src="/images/951413iMgBlog/1620953709047-cbe4b59c-aa2b-4845-8b59-9ed6d07e3916.png" alt="undefined"><br>所有MySQL实例流量一样</p>
<p>那么问题来了为什么在同样的机器上、同样的流量下CPU使用率差了这么多？ 换句话来问就是CPU使用率高就有效率吗？</p>
<p>这台物理机CPU 信息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">#lscpu</div><div class="line">Architecture:          aarch64</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                128</div><div class="line">On-line CPU(s) list:   0-127</div><div class="line">Thread(s) per core:    1</div><div class="line">Core(s) per socket:    64</div><div class="line">Socket(s):             2</div><div class="line">NUMA node(s):          1</div><div class="line">Model:                 3</div><div class="line">BogoMIPS:              100.00</div><div class="line">L1d cache:             32K</div><div class="line">L1i cache:             32K</div><div class="line">L2 cache:              2048K</div><div class="line">L3 cache:              65536K</div><div class="line">NUMA node0 CPU(s):     0-127</div><div class="line">Flags:                 fp asimd evtstrm aes pmull sha1 sha2 crc32 cpuid</div></pre></td></tr></table></figure></p>
<h2 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h2><p>先来看这两个MySQL 进程的Perf数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line">#第二个 MySQL IPC只有第三个的30%多点，这就是为什么CPU高这么多，但是QPS差不多</div><div class="line">perf stat -e branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-store-misses,L1-dcache-stores,L1-icache-load-misses,L1-icache-loads,branch-load-misses,branch-loads,dTLB-load-misses,iTLB-load-misses  -a -p 61238</div><div class="line">^C</div><div class="line"> Performance counter stats for process id &apos;61238&apos;:</div><div class="line"></div><div class="line">        86,491,052      branch-misses                                                 (58.55%)</div><div class="line">    98,481,418,793      bus-cycles                                                    (55.64%)</div><div class="line">       113,095,618      cache-misses              #    6.169 % of all cache refs      (53.20%)</div><div class="line">     1,833,344,484      cache-references                                              (52.00%)</div><div class="line">   101,516,165,898      cpu-cycles                                                    (57.09%)</div><div class="line">     4,229,190,014      instructions              #    0.04  insns per cycle          (55.91%)</div><div class="line">       111,780,025      L1-dcache-load-misses     #    6.34% of all L1-dcache hits    (55.40%)</div><div class="line">     1,764,421,570      L1-dcache-loads                                               (52.62%)</div><div class="line">       112,261,128      L1-dcache-store-misses                                        (49.34%)</div><div class="line">     1,814,998,338      L1-dcache-stores                                              (48.51%)</div><div class="line">       219,372,119      L1-icache-load-misses                                         (49.56%)</div><div class="line">     2,816,279,627      L1-icache-loads                                               (49.15%)</div><div class="line">        85,321,093      branch-load-misses                                            (50.38%)</div><div class="line">     1,038,572,653      branch-loads                                                  (50.65%)</div><div class="line">        45,166,831      dTLB-load-misses                                              (51.98%)</div><div class="line">        29,892,473      iTLB-load-misses                                              (52.56%)</div><div class="line"></div><div class="line">       1.163750756 seconds time elapsed</div><div class="line"></div><div class="line">#第三个 MySQL</div><div class="line">perf stat -e branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-store-misses,L1-dcache-stores,L1-icache-load-misses,L1-icache-loads,branch-load-misses,branch-loads,dTLB-load-misses,iTLB-load-misses  -a -p 53400</div><div class="line">^C</div><div class="line"> Performance counter stats for process id &apos;53400&apos;:</div><div class="line"></div><div class="line">       295,575,513      branch-misses                                                 (40.51%)</div><div class="line">   110,934,600,206      bus-cycles                                                    (39.30%)</div><div class="line">       537,938,496      cache-misses              #    8.310 % of all cache refs      (38.99%)</div><div class="line">     6,473,688,885      cache-references                                              (39.80%)</div><div class="line">   110,540,950,757      cpu-cycles                                                    (46.10%)</div><div class="line">    14,766,013,708      instructions              #    0.14  insns per cycle          (46.85%)</div><div class="line">       538,521,226      L1-dcache-load-misses     #    8.36% of all L1-dcache hits    (48.00%)</div><div class="line">     6,440,728,959      L1-dcache-loads                                               (46.69%)</div><div class="line">       533,693,357      L1-dcache-store-misses                                        (45.91%)</div><div class="line">     6,413,111,024      L1-dcache-stores                                              (44.92%)</div><div class="line">       673,725,952      L1-icache-load-misses                                         (42.76%)</div><div class="line">     9,216,663,639      L1-icache-loads                                               (38.27%)</div><div class="line">       299,202,001      branch-load-misses                                            (37.62%)</div><div class="line">     3,285,957,082      branch-loads                                                  (36.10%)</div><div class="line">       149,348,740      dTLB-load-misses                                              (35.20%)</div><div class="line">       102,444,469      iTLB-load-misses                                              (34.78%)</div><div class="line"></div><div class="line">       8.080841166 seconds time elapsed</div></pre></td></tr></table></figure>
<p>从上面可以看到 IPC 差异巨大0.04 VS 0.14 ，也就是第一个MySQL的CPU效率很低，我们看到的CPU running实际是CPU在等待(stall)。</p>
<h3 id="CPU的实际信息"><a href="#CPU的实际信息" class="headerlink" title="CPU的实际信息"></a>CPU的实际信息</h3><p>找到同一个机型，但是NUMA开着的查了一下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line">#lscpu</div><div class="line">Architecture:          aarch64</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                128</div><div class="line">On-line CPU(s) list:   0-127</div><div class="line">Thread(s) per core:    1</div><div class="line">Core(s) per socket:    64</div><div class="line">Socket(s):             2</div><div class="line">NUMA node(s):          16</div><div class="line">Model:                 3</div><div class="line">BogoMIPS:              100.00</div><div class="line">L1d cache:             32K</div><div class="line">L1i cache:             32K</div><div class="line">L2 cache:              2048K</div><div class="line">L3 cache:              65536K</div><div class="line">NUMA node0 CPU(s):     0-7</div><div class="line">NUMA node1 CPU(s):     8-15</div><div class="line">NUMA node2 CPU(s):     16-23</div><div class="line">NUMA node3 CPU(s):     24-31</div><div class="line">NUMA node4 CPU(s):     32-39</div><div class="line">NUMA node5 CPU(s):     40-47</div><div class="line">NUMA node6 CPU(s):     48-55</div><div class="line">NUMA node7 CPU(s):     56-63</div><div class="line">NUMA node8 CPU(s):     64-71</div><div class="line">NUMA node9 CPU(s):     72-79</div><div class="line">NUMA node10 CPU(s):    80-87</div><div class="line">NUMA node11 CPU(s):    88-95</div><div class="line">NUMA node12 CPU(s):    96-103</div><div class="line">NUMA node13 CPU(s):    104-111</div><div class="line">NUMA node14 CPU(s):    112-119</div><div class="line">NUMA node15 CPU(s):    120-127</div><div class="line">Flags:                 fp asimd evtstrm aes pmull sha1 sha2 crc32 cpuid</div></pre></td></tr></table></figure>
<p>这告诉我们实际上这个机器有16个NUMA，跨NUMA访问内存肯定比访问本NUMA内的要慢几倍。</p>
<h2 id="关于NUMA"><a href="#关于NUMA" class="headerlink" title="关于NUMA"></a>关于NUMA</h2><p>如下图，是一个Intel Xeon E5 CPU的架构信息，左右两边的大红框分别是两个NUMA，每个NUMA的core访问直接插在自己红环上的内存必然很快，如果访问插在其它NUMA上的内存还要走两个红环之间上下的黑色箭头线路，所以要慢很多。</p>
<p><img src="/images/951413iMgBlog/1623830161880-c4c74f4d-785e-4274-a579-5d1aa8b5e990.png" alt="img"></p>
<p>实际测试Intel的E5-2682（对应V42机型）和8269（对应V62机型） 的CPU跨Socket（这两块CPU内部不再是上图的红环Bus,而是改用了Mesh Bus一个Die就是一个NUMA，服务器有两路，也就是一个Socket就是一个NUMA），也就是跨NUMA访问内存的延迟是本Node延迟的将近2倍。<a href="https://software.intel.com/content/www/us/en/develop/articles/intelr-memory-latency-checker.html" target="_blank" rel="external">测试工具从这里下载</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">//E5-2682</div><div class="line">Intel(R) Memory Latency Checker - v3.9</div><div class="line">Measuring idle latencies (in ns)...</div><div class="line">		Numa node</div><div class="line">Numa node	     0	     1</div><div class="line">       0	  85.0	 136.3</div><div class="line">       1	 137.2	  84.2</div><div class="line"></div><div class="line">//8269</div><div class="line">Intel(R) Memory Latency Checker - v3.9  </div><div class="line">Measuring idle latencies (in ns)...</div><div class="line">    Numa node</div><div class="line">Numa node      0       1</div><div class="line">       0    78.6   144.1</div><div class="line">       1   144.7    78.5</div></pre></td></tr></table></figure>
<p>开启NUMA会优先就近使用内存，在本NUMA上的内存不够的时候可以选择回收本地的PageCache还是到其它NUMA 上分配内存，这是可以通过Linux参数 zone_reclaim_mode 来配置的，默认是到其它NUMA上分配内存，也就是跟关闭NUMA是一样的。</p>
<p><strong>这个架构距离是物理上就存在的不是你在BIOS里关闭了NUMA差异就消除了，我更愿意认为在BIOS里关掉NUMA只是掩耳盗铃。</strong></p>
<p>以上理论告诉我们：<strong>也就是在开启NUMA和 zone_reclaim_mode 默认在内存不够的如果去其它NUMA上分配内存，比关闭NUMA要快很多而没有任何害处。</strong></p>
<h4 id="UMA和NUMA对比"><a href="#UMA和NUMA对比" class="headerlink" title="UMA和NUMA对比"></a>UMA和NUMA对比</h4><p>The SMP/UMA architecture</p>
<p><img src="/images/951413iMgBlog/uma-architecture.png" alt="img"></p>
<p>The NUMA architecture</p>
<p><img src="/images/951413iMgBlog/numa-architecture.png" alt="img"></p>
<p>Modern multiprocessor systems mix these basic architectures as seen in the following diagram:</p>
<p><img src="/images/951413iMgBlog/39354-figure-3-184398.jpg" alt="img"></p>
<p>In this complex hierarchical scheme, processors are grouped by their physical location on one or the other multi-core CPU package or “node.” Processors within a node share access to memory modules as per the UMA shared memory architecture. At the same time, they may also access memory from the remote node using a shared interconnect, but with slower performance as per the NUMA shared memory architecture.</p>
<p><img src="/images/951413iMgBlog/03-05-Broadwell_HCC_Architecture.svg" alt="03-05-Broadwell_HCC_Architecture"></p>
<h2 id="对比测试Intel-NUMA-性能"><a href="#对比测试Intel-NUMA-性能" class="headerlink" title="对比测试Intel NUMA 性能"></a>对比测试Intel NUMA 性能</h2><p>对如下Intel CPU进行一些测试，在开启NUMA的情况下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line">#lscpu</div><div class="line">Architecture:          x86_64</div><div class="line">CPU op-mode(s):        32-bit, 64-bit</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                64</div><div class="line">On-line CPU(s) list:   0-63</div><div class="line">Thread(s) per core:    2</div><div class="line">Core(s) per socket:    16</div><div class="line">Socket(s):             2</div><div class="line">NUMA node(s):          2</div><div class="line">Vendor ID:             GenuineIntel</div><div class="line">CPU family:            6</div><div class="line">Model:                 79</div><div class="line">Model name:            Intel(R) Xeon(R) CPU E5-2682 v4 @ 2.50GHz</div><div class="line">Stepping:              1</div><div class="line">CPU MHz:               2500.000</div><div class="line">CPU max MHz:           3000.0000</div><div class="line">CPU min MHz:           1200.0000</div><div class="line">BogoMIPS:              5000.06</div><div class="line">Virtualization:        VT-x</div><div class="line">L1d cache:             32K</div><div class="line">L1i cache:             32K</div><div class="line">L2 cache:              256K</div><div class="line">L3 cache:              40960K</div><div class="line">NUMA node0 CPU(s):     0-15,32-47</div><div class="line">NUMA node1 CPU(s):     16-31,48-63</div><div class="line">Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 ds_cpl vmx smx est tm2 ssse3 fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch ida arat epb invpcid_single pln pts dtherm spec_ctrl ibpb_support tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local cat_l3</div><div class="line"></div><div class="line">#numastat</div><div class="line">                           node0           node1</div><div class="line">numa_hit               129600200        60501102</div><div class="line">numa_miss                      0               0</div><div class="line">numa_foreign                   0               0</div><div class="line">interleave_hit            108648          108429</div><div class="line">local_node             129576548        60395061</div><div class="line">other_node                 23652          106041</div></pre></td></tr></table></figure>
<p>我在这个64core的物理机上运行一个MySQL 实例，先将MySQL进程绑定在0-63core，0-31core，以及0-15,32-47上</p>
<p>用sysbench对一亿条记录跑点查，数据都加载到内存中了：</p>
<ul>
<li>绑0-63core qps 不到8万，总cpu跑到5000%，降低并发的话qps能到11万；</li>
<li>如果绑0-31core qps 12万，总cpu跑到3200%，IPC 0.29；</li>
<li>如果绑同一个numa下的32core，qps飙到27万，总CPU跑到3200%  IPC: 0.42；</li>
<li>绑0-15个物理core，qps能到17万，绑32-47也是一样的效果；</li>
</ul>
<p><img src="/images/951413iMgBlog/1620954918277-c669bd74-df58-4d69-8185-a93f37046972.png" alt="undefined"> </p>
<p>从这个数据看起来<strong>即使Intel在只有两个NUMA的情况下跨性能差异也有2倍，可见正确的绑核方法收益巨大，尤其是在刷榜的情况下</strong>， NUMA更多性能差异应该会更大。</p>
<p>说明前面的理论是正确的。</p>
<p>来看看不通绑核情况下node之间的带宽利用情况：</p>
<p><img src="/images/951413iMgBlog/image-20210525151537507.png" alt="image-20210525151537507"></p>
<p><img src="/images/951413iMgBlog/image-20210525151622425.png" alt="image-20210525151622425"></p>
<p>实际在不开NUMA的同样CPU上，进行以上各种绑核测试，测试结果也完全一样。</p>
<p>如果比较读写混合场景的话肯定会因为写锁导致CPU跑起来，最终的性能差异也不会这么大，但是绑在同一个NUMA下的性能肯定要好，IPC也会高一些。具体好多少取决于锁的竞争程度。</p>
<h2 id="为什么集团内外所有物理机都把NUMA关掉了呢？"><a href="#为什么集团内外所有物理机都把NUMA关掉了呢？" class="headerlink" title="为什么集团内外所有物理机都把NUMA关掉了呢？"></a>为什么集团内外所有物理机都把NUMA关掉了呢？</h2><p>10年前几乎所有的运维都会多多少少被NUMA坑害过，让我们看看究竟有多少种在NUMA上栽的方式：</p>
<ul>
<li><a href="http://blog.jcole.us/2010/09/28/mysql-swap-insanity-and-the-numa-architecture/" target="_blank" rel="external">MySQL – The MySQL “swap insanity” problem and the effects of the NUMA architecture</a></li>
<li><a href="http://frosty-postgres.blogspot.com/2012/08/postgresql-numa-and-zone-reclaim-mode.html" target="_blank" rel="external">PostgreSQL – PostgreSQL, NUMA and zone reclaim mode on linux</a></li>
<li><a href="http://blog.yannickjaquier.com/hpux/non-uniform-memory-access-numa-architecture-with-oracle-database-by-examples.html" target="_blank" rel="external">Oracle – Non-Uniform Memory Access (NUMA) architecture with Oracle database by examples</a></li>
<li><a href="http://engineering.linkedin.com/performance/optimizing-linux-memory-management-low-latency-high-throughput-databases" target="_blank" rel="external">Java – Optimizing Linux Memory Management for Low-latency / High-throughput Databases</a></li>
</ul>
<p>最有名的是这篇  <a href="http://blog.jcole.us/2010/09/28/mysql-swap-insanity-and-the-numa-architecture/" target="_blank" rel="external">MySQL – The MySQL “swap insanity” problem and the effects of the NUMA architecture</a></p>
<p>我总结下这篇2010年的文章说的是啥：</p>
<ul>
<li>如果本NUMA内存不够的时候，Linux会优先回收PageCache内存，即使其它NUMA还有内存</li>
<li>回收PageCache经常会造成系统卡顿，这个卡顿不能接受</li>
</ul>
<p>所以文章给出的解决方案就是（三选一）：</p>
<ul>
<li>关掉NUMA</li>
<li>或者启动MySQL的时候指定不分NUMA,比如：/usr/bin/numactl –interleave all $cmd</li>
<li>或者启动MySQL的时候先回收所有PageCache</li>
</ul>
<p>我想这就是这么多人在上面栽了跟头，所以干脆一不做二不休干脆关了NUMA 一了百了。</p>
<p>但真的NUMA有这么糟糕？或者说Linux Kernel有这么笨，默认优先去回收PageCache吗？</p>
<h2 id="Linux-Kernel对NUMA内存的使用"><a href="#Linux-Kernel对NUMA内存的使用" class="headerlink" title="Linux Kernel对NUMA内存的使用"></a>Linux Kernel对NUMA内存的使用</h2><p>实际我们使用NUMA的时候期望是：优先使用本NUMA上的内存，如果本NUMA不够了不要优先回收PageCache而是优先使用其它NUMA上的内存。</p>
<h3 id="zone-reclaim-mode"><a href="#zone-reclaim-mode" class="headerlink" title="zone_reclaim_mode"></a>zone_reclaim_mode</h3><p>事实上Linux识别到NUMA架构后，默认的内存分配方案就是：优先尝试在请求线程当前所处的CPU的Local内存上分配空间。<strong>如果local内存不足，优先淘汰local内存中无用的Page（Inactive，Unmapped）</strong>。然后才到其它NUMA上分配内存。</p>
<p>intel 芯片跨node延迟远低于其他家，所以跨node性能损耗不大</p>
<p>zone_reclaim_mode，它用来管理当一个内存区域(zone)内部的内存耗尽时，是从其内部进行内存回收还是可以从其他zone进行回收的选项：</p>
<p>zone_reclaim_mode:</p>
<blockquote>
<p>Zone_reclaim_mode allows someone to set more or less aggressive approaches to<br>reclaim memory when a zone runs out of memory. If it is set to zero then no<br>zone reclaim occurs. Allocations will be satisfied from other zones / nodes<br>in the system.</p>
</blockquote>
<p>zone_reclaim_mode的四个参数值的意义分别是：</p>
<p>0   = Allocate from all nodes before reclaiming memory<br>1   = Reclaim memory from local node vs allocating from next node<br>2   = Zone reclaim writes dirty pages out<br>4   = Zone reclaim swaps pages</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># cat /proc/sys/vm/zone_reclaim_mode</div><div class="line">0</div></pre></td></tr></table></figure>
<p>我查了2.6.32以及4.19.91内核的机器 zone_reclaim_mode 都是默认0 ，也就是kernel会：优先使用本NUMA上的内存，如果本NUMA不够了不要优先回收PageCache而是优先使用其它NUMA上的内存。这也是我们想要的</p>
<p>Kernel文档也告诉大家默认就是0，但是为什么会出现优先回收了PageCache呢？</p>
<h3 id="查看kernel提交记录"><a href="#查看kernel提交记录" class="headerlink" title="查看kernel提交记录"></a>查看kernel提交记录</h3><p><a href="https://github.com/torvalds/linux/commit/4f9b16a64753d0bb607454347036dc997fd03b82" target="_blank" rel="external">github kernel commit</a></p>
<p><img src="/images/951413iMgBlog/1620956491058-09a1ebc6-c248-41db-9def-67b4f489c4f4.png" alt="undefined"> </p>
<p><img src="/images/951413iMgBlog/1620956524069-85ec2c06-ff55-48e9-8c26-96e738456ed4.png" alt="undefined"> </p>
<p><img src="/images/951413iMgBlog/1620956551990-6e376a3d-de40-4180-a05b-b21a9cbf33bc.png" alt="undefined"> </p>
<p>关键是上图红框中的代码，node distance比较大（也就是开启了NUMA的话），强制将 zone_reclaim_mode设为1，这是2014年提交的代码，将这个强制设为1的逻辑去掉了。</p>
<p>这也就是为什么之前大佬们碰到NUMA问题后尝试修改 zone_reclaim_mode 没有效果，<strong>也就是2014年前只要开启了NUMA就强制线回收PageCache，即使设置zone_reclaim_mode也没有意义，真是个可怕的Bug。</strong></p>
<h3 id="验证一下zone-reclaim-mode-0是生效的"><a href="#验证一下zone-reclaim-mode-0是生效的" class="headerlink" title="验证一下zone_reclaim_mode 0是生效的"></a>验证一下zone_reclaim_mode 0是生效的</h3><p>内核版本：3.10.0-327.ali2017.alios7.x86_64</p>
<h4 id="测试方法"><a href="#测试方法" class="headerlink" title="测试方法"></a><a href="https://github.com/torvalds/linux/commit/e02dc017c3032dcdce1b993af0db135462e1b4b7" target="_blank" rel="external">测试方法</a></h4><p>先将一个160G的文件加载到内存里，然后再用代码分配64G的内存出来使用。<br>单个NUMA node的内存为256G，本身用掉了60G，加上这次的160G的PageCache，和之前的一些其他PageCache,总的 PageCache用了179G，那么这个node总内存还剩256G-60G-179G，</p>
<p>如果这个时候再分配64G内存的话，本node肯定不够了，我们来看在 zone_reclaim_mode=0 的时候是优先回收PageCache还是分配了到另外一个NUMA node(这个NUMA node 有240G以上的内存空闲）</p>
<h4 id="测试过程"><a href="#测试过程" class="headerlink" title="测试过程"></a>测试过程</h4><p>分配64G内存</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">#taskset -c 0 ./alloc 64</div><div class="line">To allocate 64GB memory</div><div class="line">Used time: 39 seconds</div></pre></td></tr></table></figure>
<p><img src="/images/951413iMgBlog/1620966121309-a264fd7f-fe50-4fc6-940f-4cb603ec7874.png" alt="undefined"> </p>
<p>从如上截图来看，再分配64G内存的时候即使node0不够了也没有回收node0上的PageCache，而是将内存跨NUMA分配到了node1上，符合预期！</p>
<p>释放这64G内存后，如下图可以看到node0回收了25G，剩下的39G都是在node1上：<br><img src="/images/951413iMgBlog/1620967573650-b8400c2f-7b48-4502-b7d5-6c050e557126.png" alt="undefined"> </p>
<h3 id="将-proc-sys-vm-zone-reclaim-mode-改成-1-继续同样的测试"><a href="#将-proc-sys-vm-zone-reclaim-mode-改成-1-继续同样的测试" class="headerlink" title="将 /proc/sys/vm/zone_reclaim_mode 改成 1 继续同样的测试"></a>将 /proc/sys/vm/zone_reclaim_mode 改成 1 继续同样的测试</h3><p>可以看到zone_reclaim_mode 改成 1，node0内存不够了也没有分配node1上的内存，而是从PageCache回收了40G内存，整个分配64G内存的过程也比不回收PageCache慢了12秒，这12秒就是额外的卡顿</p>
<p><img src="/images/951413iMgBlog/1620977108922-a2f67827-cf00-43a0-bba1-4ba105a33201.png" alt="undefined"> </p>
<p>测试结论：<strong>从这个测试可以看到NUMA 在内存使用上不会优先回收 PageCache 了</strong></p>
<h3 id="innodb-numa-interleave"><a href="#innodb-numa-interleave" class="headerlink" title="innodb_numa_interleave"></a>innodb_numa_interleave</h3><p>从5.7开始，mysql增加了对NUMA的感知：<a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-parameters.html#sysvar_innodb_numa_interleave" target="_blank" rel="external">innodb_numa_interleave</a></p>
<p>当开启了 innodb_numa_interleave 的话在为innodb buffer pool分配内存的时候将 <a href="https://linux.die.net/man/2/set_mempolicy" target="_blank" rel="external">NUMA memory policy</a> 设置为 MPOL_INTERLEAVE 分配完后再设置回 MPOL_DEFAULT（OS默认内存分配行为，也就是zone_reclaim_mode指定的行为)。</p>
<p>innodb_numa_interleave参数是为innodb更精细化地分配innodb buffer pool 而增加的。很典型地innodb_numa_interleave为on只是更好地规避了前面所说的zone_reclaim_mode的kernel bug，<strong>修复后这个参数没有意义了</strong>。</p>
<h3 id="AUTOMATIC-NUMA-BALANCING"><a href="#AUTOMATIC-NUMA-BALANCING" class="headerlink" title="AUTOMATIC NUMA BALANCING"></a><a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/virtualization_tuning_and_optimization_guide/sect-virtualization_tuning_optimization_guide-numa-auto_numa_balancing" target="_blank" rel="external">AUTOMATIC NUMA BALANCING</a></h3><p>RedHat 7默认会自动让内存或者进程就近迁移，让内存和CPU距离更近以达到最好的效果</p>
<blockquote>
<p>Automatic NUMA balancing improves the performance of applications running on NUMA hardware systems. It is enabled by default on Red Hat Enterprise Linux 7 systems.</p>
<p>An application will generally perform best when the threads of its processes are accessing memory on the same NUMA node as the threads are scheduled. Automatic NUMA balancing moves tasks (which can be threads or processes) closer to the memory they are accessing. It also moves application data to memory closer to the tasks that reference it. This is all done automatically by the kernel when automatic NUMA balancing is active.</p>
</blockquote>
<p>对应参数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cat /proc/sys/kernel/numa_balancing shows 1</div></pre></td></tr></table></figure>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li>放弃对NUMA的偏见吧，优先回收 PageCache 这个Bug早已修复了</li>
<li>按NUMA绑定core收益巨大，即使只有两个NUMA的intel芯片，也有一倍以上的性能提升，在飞腾等其他芯片上收益更大</li>
<li>没必要自欺欺人关掉NUMA了</li>
<li>RDS这样独占物理机的服务可以做到按NUMA来绑定core，收益可观</li>
<li>ECS售卖如果能够精确地按NUMA绑核的话性能，超卖比能高很多</li>
<li>在刷tpcc数据的时候更应该开NUMA和正确绑核</li>
</ul>
<p>我个人一直对集团所有机器默认关闭NUMA耿耿于怀，因为定制的物理机（BIOS也是定制的）BIOS默认就是关闭NUMA的，装机还得一台台手工打开（跪了，几十万台啊），算是理清了来龙去脉。因为一个kernel的bug让大家对NUMA一直有偏见，即使14年已经修复了，大家还是以讹传讹，没必要。</p>
<p>关于cpu为什么高但是没有产出的原因是因为CPU流水线长期stall，导致很低的IPC，所以性能自然上不去，可以看<a href="http://www.brendangregg.com/blog/2017-05-09/cpu-utilization-is-wrong.html" target="_blank" rel="external">这篇文章</a> </p>
<p>其他同学测试的结论：</p>
<ul>
<li>Hadoop离线作业在 Intel(R) Xeon(R) Platinum 8163 CPU @ 2.50GHz 24 cores/socket * 2, Turbo Off 下打开NUMA后性能提升8%</li>
</ul>
<p>一些其它不好解释的现象：</p>
<ol>
<li>增加少量跨NUMA 的core进来时能增加QPS的，但是随着跨NUMA core越来越多（总core也越来越多）QPS反而会达到一个峰值后下降—效率低的core多了，抢走任务，执行得慢</li>
<li>压12-19和8-15同样8core，不跨NUMA的8-15性能只好5%左右(87873 VS 92801) — 难以解释</li>
<li>由1、2所知在测试少量core的时候跨NUMA性能下降体现不出来</li>
<li>在压0-31core的时候，如果运行 perf这个时候QPS反而会增加（13万上升到15万）— 抢走了一些CPU资源，让某个地方竞争反而减小了</li>
<li>综上在我个人理解是core越多的时候UPI压力到了瓶颈，才会出现加core性能反而下降</li>
</ol>
<h2 id="系列文章"><a href="#系列文章" class="headerlink" title="系列文章"></a>系列文章</h2><p><a href="/2021/06/01/CPU的制造和概念/">CPU的制造和概念</a></p>
<p><a href="/2021/05/16/CPU Cache Line 和性能/">CPU 性能和Cache Line</a></p>
<p><a href="/2021/05/16/Perf IPC以及CPU利用率/">Perf IPC以及CPU性能</a></p>
<p><a href="/2021/06/18/几款CPU性能对比/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></p>
<p><a href="/2021/05/15/飞腾ARM芯片(FT2500">飞腾ARM芯片(FT2500)的性能测试</a>的性能测试/)</p>
<p><a href="/2021/05/14/十年后数据库还是不敢拥抱NUMA/">十年后数据库还是不敢拥抱NUMA？</a></p>
<p><a href="/2021/03/07/一次海光物理机资源竞争压测的记录/">一次海光物理机资源竞争压测的记录</a></p>
<p><a href="/2019/12/16/Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的/">Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的</a></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://www.redhat.com/files/summit/session-assets/2018/Performance-analysis-and-tuning-of-Red-Hat-Enterprise-Linux-Part-1.pdf" target="_blank" rel="external">https://www.redhat.com/files/summit/session-assets/2018/Performance-analysis-and-tuning-of-Red-Hat-Enterprise-Linux-Part-1.pdf</a></p>
<p><a href="https://informixdba.wordpress.com/2015/10/16/zone-reclaim-mode/" target="_blank" rel="external">https://informixdba.wordpress.com/2015/10/16/zone-reclaim-mode/</a></p>
<p><a href="https://queue.acm.org/detail.cfm?id=2513149" target="_blank" rel="external">https://queue.acm.org/detail.cfm?id=2513149</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/04/06/为什么这么多CLOSE_WAIT/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/04/06/为什么这么多CLOSE_WAIT/" itemprop="url">为什么这么多CLOSE_WAIT</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-04-06T10:30:03+08:00">
                2021-04-06
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/TCP/" itemprop="url" rel="index">
                    <span itemprop="name">TCP</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="为什么这么多CLOSE-WAIT"><a href="#为什么这么多CLOSE-WAIT" class="headerlink" title="为什么这么多CLOSE_WAIT"></a>为什么这么多CLOSE_WAIT</h1><h2 id="案例1：服务响应慢，经常连不上"><a href="#案例1：服务响应慢，经常连不上" class="headerlink" title="案例1：服务响应慢，经常连不上"></a>案例1：服务响应慢，经常连不上</h2><p>应用发布新版本上线后，业务同学发现业务端口上的TCP连接处于CLOSE_WAIT状态的数量有积压，多的时候能堆积到几万个，有时候应用无法响应了</p>
<blockquote>
<p>从这个案例要获取：怎么样才能获取举三反一的秘籍， 普通人为什么要案例来深化对理论知识的理解。</p>
</blockquote>
<h2 id="检查机器状态"><a href="#检查机器状态" class="headerlink" title="检查机器状态"></a>检查机器状态</h2><p><img src="/images/oss/418b94ee-18ee-4976-857b-69f3016af2b0.png" alt="img"></p>
<p><img src="/images/oss/160490c8-56e9-46f2-9c48-713944b94a5c.png" alt="img"></p>
<p>从上述两个图中可以看到磁盘 sdb压力非常大，util经常会到 100%，这个时候对应地从top中也可以看到cpu wait%很高（这个ECS cpu本来竞争很激烈），st%一直非常高，所以整体留给应用的CPU不多，碰上磁盘缓慢的话，这时如果业务写日志是同步刷盘那么就会导致程序卡顿严重。</p>
<p>实际看到FGC的时间也是正常状态下的10倍了。</p>
<p>再看看实际上应用同步写日志到磁盘比较猛，平均20-30M，高的时候能到200M每秒。如果输出的时候磁盘卡住了那么就整个卡死了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">#dstat</div><div class="line">----total-cpu-usage---- -dsk/total- -net/total- ---paging-- ---system--</div><div class="line">usr sys idl wai hiq siq| read  writ| recv  send|  in   out | int   csw</div><div class="line">  4   1  89   5   0   0|1549M 8533M|   0     0 | 521k  830k|6065k 7134</div><div class="line">  3   1  95   0   0   0|3044k   19M|1765k   85k|   0    84k| 329k 7770</div><div class="line">  5   1  93   0   0   0|3380k   18M|4050k  142k|   0     0 | 300k 8008</div><div class="line">  7   1  91   1   0   1|2788k  227M|5094k  141k|   0    28k| 316k 8644</div><div class="line">  4   1  93   2   0   0|2788k   55M|2897k   63k|   0    68k| 274k 6453</div><div class="line">  6   1  91   1   0   0|4464k   24M|3683k   98k|   0    28k| 299k 7379</div><div class="line">  7   1  91   1   0   0|  10M   34M|3655k  130k|   0   208k| 375k 8417</div><div class="line">  3   1  87   8   0   0|6940k   33M|1335k   91k|   0   112k| 334k 7369</div><div class="line">  3   1  88   7   0   0|4932k   16M|1918k   61k|   0    44k| 268k 6542</div><div class="line">  7   1  86   6   0   0|5508k   20M|5377k  111k|   0     0 | 334k 7998</div><div class="line">  7   2  88   3   0   0|5628k  115M|4713k  104k|   0     0 | 280k 7392</div><div class="line">  4   1  95   0   0   0|   0   732k|2940k   85k|   0    76k| 189k 7682</div><div class="line">  3   1  96   0   0   0|   0   800k|1809k   68k|   0    16k| 181k 9640</div><div class="line">  7   2  76  14   0   1|6300k   38M|3834k  132k|   0     0 | 333k 7502</div><div class="line">  7   2  90   1   0   0|3896k   19M|3786k   93k|   0     0 | 357k 7578</div><div class="line">  4   1  94   0   0   0|5732k   29M|2906k  806k|   0     0 | 338k 8966</div><div class="line">  4   1  94   1   0   0|6044k   17M|2202k   95k|   0     0 | 327k 7573</div><div class="line">  4   1  95   1   0   0|3524k   17M|2277k   88k|   0     0 | 299k 6462</div><div class="line">  4   1  96   0   0   0| 456k   14M|2770k   91k|  60k    0 | 252k 6644</div><div class="line">  6   2  92   0   0   0|   0    12M|4251k  847k|   0     0 | 264k   10k</div><div class="line">  3   1  92   4   0   0| 788k  204M|1555k   43k|   0     0 | 249k 6215</div><div class="line">  6   1  86   6   0   0|7180k   20M|2073k   92k|   0     0 | 303k 7028</div><div class="line"> 11   4  84   1   0   0|6116k   29M|3079k   99k|  28k    0 | 263k 6605</div></pre></td></tr></table></figure>
<p>磁盘util 100%和CLOSE_WAIT强相关，也和理论比较符合，CLOSE_WAIT就是连接被动关闭端的应用没调socket.close</p>
<p><img src="/images/oss/3b7dedca-1c79-4317-8042-bb9ba8c957b9.png" alt="img"></p>
<p>大概的原因推断是：</p>
<p>1）新发布的代码需要消耗更多的CPU，代码增加了新的逻辑 //这只是一个微小的诱因</p>
<p>2）机器本身资源(CPU /IO）很紧张 这两个条件下导致应用响应缓慢。 目前看到的稳定重现条件就是重启一个业务节点，重启会触发业务节点之间重新同步数据，以及重新推送很多数据到客户端的新连接上，这两件事情都会让应用CPU占用飙升响应缓慢，响应慢了之后会导致更多的心跳失效进一步加剧数据同步，然后就雪崩恶化了。最后表现就是看到系统卡死了，也就是tcp buffer中的数据也不读走、连接也不close，连接大量堆积在close_wait状态</p>
<p><img src="/images/oss/227c69f1-0467-425c-a19d-26c03d50c36c.png" alt="img"></p>
<p>CLOSE_WAIT的原因分析</p>
<h2 id="先看TCP连接状态图"><a href="#先看TCP连接状态图" class="headerlink" title="先看TCP连接状态图"></a>先看TCP连接状态图</h2><p>这是网络、书本上凡是描述TCP状态一定会出现的状态图，理论上看这个图能解决任何TCP状态问题。</p>
<p><img src="/images/951413iMgBlog/b3d075782450b0c8d2615c5d2b75d923.png" alt="image.png"></p>
<p>反复看这个图的右下部分的CLOSE_WAIT ，从这个图里可以得到如下结论：</p>
<blockquote>
<p><strong>CLOSE_WAIT是被动关闭端在等待应用进程的关闭</strong></p>
</blockquote>
<p>基本上这一结论要能帮助解决所有CLOSE_WAIT相关的问题，如果不能说明对这个知识点理解的不够。</p>
<h2 id="案例1结论"><a href="#案例1结论" class="headerlink" title="案例1结论"></a>案例1结论</h2><p>机器超卖严重、IO卡顿，导致应用线程卡顿，来不及调用socket.close()</p>
<h2 id="案例2：server端大量close-wait"><a href="#案例2：server端大量close-wait" class="headerlink" title="案例2：server端大量close_wait"></a>案例2：server端大量close_wait</h2><p>用实际案例来检查自己对CLOSE_WAIT 理论（<strong>CLOSE_WAIT是被动关闭端在等待应用进程的关闭</strong>）的掌握 – 能不能用这个结论来解决实际问题。同时也可以看看自己从知识到问题的推理能力（跟前面的知识效率呼应一下）。</p>
<h3 id="问题描述："><a href="#问题描述：" class="headerlink" title="问题描述："></a>问题描述：</h3><blockquote>
<p>服务端出现大量CLOSE_WAIT ，并且个数正好 等于somaxconn（调整somaxconn大小后 CLOSE_WAIT 也会跟着变成一样的值）</p>
</blockquote>
<p>根据这个描述先不要往下看，自己推理分析下可能的原因。</p>
<p>我的推理如下：</p>
<p>从这里看起来，client跟server成功建立了somaxconn个连接（somaxconn小于backlog，所以accept queue只有这么大），但是应用没有accept这个连接，导致这些连接一直在accept queue中。但是这些连接的状态已经是ESTABLISHED了，也就是client可以发送数据了，数据发送到server后OS ack了，并放在os的tcp buffer中，应用一直没有accept也就没法读取数据。client于是发送fin（可能是超时、也可能是简单发送数据任务完成了得结束连接），这时Server上这个连接变成了CLOSE_WAIT .</p>
<p>也就是从开始到结束这些连接都在accept queue中，没有被应用accept，很快他们又因为client 发送 fin 包变成了CLOSE_WAIT ，所以始终看到的是服务端出现大量CLOSE_WAIT 并且个数正好等于somaxconn（调整somaxconn后 CLOSE_WAIT 也会跟着变成一样的值）。</p>
<p>如下图所示，在连接进入accept queue后状态就是ESTABLISED了，也就是可以正常收发数据和fin了。client是感知不到server是否accept()了，只是发了数据后server的os代为保存在OS的TCP buffer中，因为应用没来取自然在CLOSE_WAIT 后应用也没有close()，所以一直维持CLOSE_WAIT 。</p>
<p>得检查server 应用为什么没有accept。</p>
<p><img src="/images/951413iMgBlog/20190706093602331.png" alt="Recv-Q和Send-Q"></p>
<p>如上是老司机的思路靠经验缺省了一些理论推理，缺省还是对理论理解不够， 这个分析抓住了 大量CLOSE_WAIT 个数正好 等于somaxconn（调整somaxconn后 CLOSE_WAIT 也会跟着变成一样的值）但是没有抓住 CLOSE_WAIT 背后的核心原因</p>
<h3 id="更简单的推理"><a href="#更简单的推理" class="headerlink" title="更简单的推理"></a>更简单的推理</h3><p>如果没有任何实战经验，只看上面的状态图的学霸应该是这样推理的：</p>
<p>看到server上有大量的CLOSE_WAIT说明client主动断开了连接，server的OS收到client 发的fin，并回复了ack，这个过程不需要应用感知，进而连接从ESTABLISHED进入CLOSE_WAIT，此时在等待server上的应用调用close连关闭连接（处理完所有收发数据后才会调close()） —- 结论：server上的应用一直卡着没有调close().</p>
<h2 id="CLOSE-WAIT-状态拆解"><a href="#CLOSE-WAIT-状态拆解" class="headerlink" title="CLOSE_WAIT 状态拆解"></a>CLOSE_WAIT 状态拆解</h2><p>通常，CLOSE_WAIT 状态在服务器停留时间很短，如果你发现大量的 CLOSE_WAIT 状态，那么就意味着被动关闭的一方没有及时发出 FIN 包，一般有如下几种可能：</p>
<ul>
<li><strong>程序问题</strong>：如果代码层面忘记了 close 相应的 socket 连接，那么自然不会发出 FIN 包，从而导致 CLOSE_WAIT 累积；或者代码不严谨，出现死循环之类的问题，导致即便后面写了 close 也永远执行不到。</li>
<li>响应太慢或者超时设置过小：如果连接双方不和谐，一方不耐烦直接 timeout，另一方却还在忙于耗时逻辑，就会导致 close 被延后。响应太慢是首要问题，不过换个角度看，也可能是 timeout 设置过小。</li>
<li>BACKLOG 太大：此处的 backlog 不是 syn backlog，而是 accept 的 backlog，如果 backlog 太大的话，设想突然遭遇大访问量的话，即便响应速度不慢，也可能出现来不及消费的情况，导致多余的请求还在<a href="http://jaseywang.me/2014/07/20/tcp-queue-的一些问题/" target="_blank" rel="external">队列</a>里就被对方关闭了。</li>
</ul>
<p>如果你通过「netstat -ant」或者「ss -ant」命令发现了很多 CLOSE_WAIT 连接，请注意结果中的「Recv-Q」和「Local Address」字段，通常「Recv-Q」会不为空，它表示应用还没来得及接收数据，而「Local Address」表示哪个地址和端口有问题，我们可以通过「lsof -i:<port>」来确认端口对应运行的是什么程序以及它的进程号是多少。</port></p>
<p>如果是我们自己写的一些程序，比如用 HttpClient 自定义的蜘蛛，那么八九不离十是程序问题，如果是一些使用广泛的程序，比如 Tomcat 之类的，那么更可能是响应速度太慢或者 timeout 设置太小或者 BACKLOG 设置过大导致的故障。</p>
<p>看完这段 CLOSE_WAIT 更具体深入点的分析后再来分析上面的案例看看，能否推导得到正确的结论。</p>
<h2 id="一些疑问"><a href="#一些疑问" class="headerlink" title="一些疑问"></a>一些疑问</h2><h3 id="连接都没有被accept-client端就能发送数据了？"><a href="#连接都没有被accept-client端就能发送数据了？" class="headerlink" title="连接都没有被accept(), client端就能发送数据了？"></a>连接都没有被accept(), client端就能发送数据了？</h3><p>答：是的。只要这个连接在OS看来是ESTABLISHED的了就可以，因为握手、接收数据都是由内核完成的，内核收到数据后会先将数据放在内核的tcp buffer中，然后os回复ack。另外三次握手之后client端是没法知道server端是否accept()了。</p>
<h3 id="CLOSE-WAIT与accept-queue有关系吗？"><a href="#CLOSE-WAIT与accept-queue有关系吗？" class="headerlink" title="CLOSE_WAIT与accept queue有关系吗？"></a>CLOSE_WAIT与accept queue有关系吗？</h3><p>答：没有关系。只是本案例中因为open files不够了，影响了应用accept(), 导致accept queue满了，同时因为即使应用不accept（三次握手后，server端是否accept client端无法感知），client也能发送数据和发 fin断连接，这些响应都是os来负责，跟上层应用没关系，连接从握手到ESTABLISHED再到CLOSE_WAIT都不需要fd，也不需要应用参与。CLOSE_WAIT只跟应用不调 close() 有关系。 </p>
<h3 id="CLOSE-WAIT与accept-queue为什么刚好一致并且联动了？"><a href="#CLOSE-WAIT与accept-queue为什么刚好一致并且联动了？" class="headerlink" title="CLOSE_WAIT与accept queue为什么刚好一致并且联动了？"></a>CLOSE_WAIT与accept queue为什么刚好一致并且联动了？</h3><p>答：这里他们的数量刚好一致是因为所有新建连接都没有accept，堵在queue中。同时client发现问题后把所有连接都fin了，也就是所有queue中的连接从来没有被accept过，但是他们都是ESTABLISHED，过一阵子之后client端发了fin所以所有accept queue中的连接又变成了 CLOSE_WAIT, 所以二者刚好一致并且联动了</p>
<h3 id="CLOSE-WAIT与TIME-WAIT"><a href="#CLOSE-WAIT与TIME-WAIT" class="headerlink" title="CLOSE_WAIT与TIME_WAIT"></a>CLOSE_WAIT与TIME_WAIT</h3><p>简单说就是CLOSE_WAIT出现在被动断开连接端，一般过多就不太正常；TIME_WAIT出现在主动断开连接端，是正常现象，多出现在短连接场景下</p>
<h3 id="openfiles和accept-的关系是？"><a href="#openfiles和accept-的关系是？" class="headerlink" title="openfiles和accept()的关系是？"></a>openfiles和accept()的关系是？</h3><p>答：accept()的时候才会创建文件句柄，消耗openfiles</p>
<h3 id="一个连接如果在accept-queue中了，但是还没有被应用-accept，那么这个时候在server上看这个连接的状态他是ESTABLISHED的吗？"><a href="#一个连接如果在accept-queue中了，但是还没有被应用-accept，那么这个时候在server上看这个连接的状态他是ESTABLISHED的吗？" class="headerlink" title="一个连接如果在accept queue中了，但是还没有被应用 accept，那么这个时候在server上看这个连接的状态他是ESTABLISHED的吗？"></a>一个连接如果在accept queue中了，但是还没有被应用 accept，那么这个时候在server上看这个连接的状态他是ESTABLISHED的吗？</h3><p>答：是</p>
<h3 id="如果server的os参数-open-files到了上限（就是os没法打开新的文件句柄了）会导致这个accept-queue中的连接一直没法被accept对吗？"><a href="#如果server的os参数-open-files到了上限（就是os没法打开新的文件句柄了）会导致这个accept-queue中的连接一直没法被accept对吗？" class="headerlink" title="如果server的os参数 open files到了上限（就是os没法打开新的文件句柄了）会导致这个accept queue中的连接一直没法被accept对吗？"></a>如果server的os参数 open files到了上限（就是os没法打开新的文件句柄了）会导致这个accept queue中的连接一直没法被accept对吗？</h3><p>答：对</p>
<h3 id="如果通过gdb-attach-应用进程，故意让进程accept，这个时候client还能连上应用吗？"><a href="#如果通过gdb-attach-应用进程，故意让进程accept，这个时候client还能连上应用吗？" class="headerlink" title="如果通过gdb attach 应用进程，故意让进程accept，这个时候client还能连上应用吗？"></a>如果通过gdb attach 应用进程，故意让进程accept，这个时候client还能连上应用吗？</h3><p>答： 能，这个时候在client和server两边看到的连接状态都是 ESTABLISHED，只是Server上的全连接队列占用加1。连接握手并切换到ESTABLISHED状态都是由OS来负责的，应用不参与，ESTABLISHED后应用才能accept，进而收发数据。也就是能放入到全连接队列里面的连接肯定都是 ESTABLISHED 状态的了</p>
<h3 id="接着上面的问题，如果新连接继续连接进而全连接队列满了呢？"><a href="#接着上面的问题，如果新连接继续连接进而全连接队列满了呢？" class="headerlink" title="接着上面的问题，如果新连接继续连接进而全连接队列满了呢？"></a>接着上面的问题，如果新连接继续连接进而全连接队列满了呢？</h3><p>答：那就连不上了，server端的OS因为全连接队列满了直接扔掉第一个syn握手包，这个时候连接在client端是SYN_SENT，Server端没有这个连接，这是因为syn到server端就直接被OS drop 了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">//如下图，本机测试，只有一个client端发起的syn_send, 3306的server端没有任何连接</div><div class="line">$netstat -antp  |grep -i 127.0.0.1:3306</div><div class="line">tcp     0   1 127.0.0.1:61106      127.0.0.1:3306    SYN_SENT    21352/telnet</div></pre></td></tr></table></figure>
<p>能进入到accept queue中的连接都是 ESTABLISHED，不管用户态有没有accept，用户态accept后队列大小减1</p>
<h3 id="如果一个连接握手成功进入到accept-queue但是应用accept前被对方RESET了呢？"><a href="#如果一个连接握手成功进入到accept-queue但是应用accept前被对方RESET了呢？" class="headerlink" title="如果一个连接握手成功进入到accept queue但是应用accept前被对方RESET了呢？"></a>如果一个连接握手成功进入到accept queue但是应用accept前被对方RESET了呢？</h3><p>答： 如果此时收到对方的RESET了，那么OS会释放这个连接。但是内核认为所有 listen 到的连接, 必须要 accept 走, 因为用户有权利知道有过这么一个连接存在过。所以OS不会到全连接队列拿掉这个连接，全连接队列数量也不会减1，直到应用accept这个连接，然后read/write才发现这个连接断开了，报communication failure异常</p>
<h3 id="什么时候连接状态变成-ESTABLISHED"><a href="#什么时候连接状态变成-ESTABLISHED" class="headerlink" title="什么时候连接状态变成 ESTABLISHED"></a>什么时候连接状态变成 ESTABLISHED</h3><p>三次握手成功就变成 ESTABLISHED 了，不需要用户态来accept，如果握手第三步的时候OS发现全连接队列满了，这时OS会扔掉这个第三次握手ack，并重传握手第二步的syn+ack, 在OS端这个连接还是 SYN_RECV 状态的，但是client端是 ESTABLISHED状态的了。</p>
<p>这是在4000（tearbase）端口上<strong>全连接队列没满，但是应用不再accept了</strong>，nc用12346端口去连4000（tearbase）端口的结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"># netstat -at |grep &quot;:12346 &quot;</div><div class="line">tcp   0      0 dcep-blockchain-1:12346 dcep-blockchai:terabase ESTABLISHED //server</div><div class="line">tcp   0      0 dcep-blockchai:terabase dcep-blockchain-1:12346 ESTABLISHED //client</div><div class="line">[root@dcep-blockchain-1 cfl-sm2-sm3]# ss -lt</div><div class="line">State       Recv-Q Send-Q      Local Address:Port         Peer Address:Port   </div><div class="line">LISTEN      73     1024            *:terabase                 *:*</div></pre></td></tr></table></figure>
<p>这是在4000（tearbase）端口上<strong>全连接队列满掉</strong>后，nc用12346端口去连4000（tearbase）端口的结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"># netstat -at |grep &quot;:12346 &quot;  </div><div class="line">tcp   0      0 dcep-blockchai:terabase dcep-blockchain-1:12346 SYN_RECV    //server</div><div class="line">tcp   0      0 dcep-blockchain-1:12346 dcep-blockchai:terabase ESTABLISHED //client</div><div class="line"># ss -lt</div><div class="line">State       Recv-Q Send-Q      Local Address:Port       Peer Address:Port   </div><div class="line">LISTEN      1025   1024             *:terabase              *:*</div></pre></td></tr></table></figure>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/03/07/一次海光物理机资源竞争压测的记录/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/03/07/一次海光物理机资源竞争压测的记录/" itemprop="url">一次海光物理机资源竞争压测的记录</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-03-07T17:30:03+08:00">
                2021-03-07
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CPU/" itemprop="url" rel="index">
                    <span itemprop="name">CPU</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="一次海光物理机资源竞争压测的记录"><a href="#一次海光物理机资源竞争压测的记录" class="headerlink" title="一次海光物理机资源竞争压测的记录"></a>一次海光物理机资源竞争压测的记录</h1><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>问题描述如下</p>
<blockquote>
<p>sysbench 压200个服务节点(每个4c16G，总共800core), 发现qps不能线性增加（200节点比100节点好1.2倍而已)。</p>
<p>如果压单个服务节点节点QPS 2.4万，CPU跑到390%（每个服务节点独占4个核），如果压200个服务节点（分布在16台64核的海光物理机上）平均每个服务节点节点QPS才1.2万。但是每个服务节点的CPU也跑到了390%左右。 现在的疑问就是为什么CPU跑上去了QPS打了个5折。</p>
<p>机器集群为16*64core 为1024core，也就是每个服务节点独占4core还有冗余</p>
</blockquote>
<p>因为服务节点还需要通过LVS调用后端的多个MySQL集群，所以需要排除LVS、网络等链路瓶颈，然后找到根因是什么。</p>
<h3 id="海光物理机CPU相关信息"><a href="#海光物理机CPU相关信息" class="headerlink" title="海光物理机CPU相关信息"></a>海光物理机CPU相关信息</h3><p>总共有16台如下的海光服务器</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line">#lscpu</div><div class="line">Architecture:          x86_64</div><div class="line">CPU op-mode(s):        32-bit, 64-bit</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                64</div><div class="line">On-line CPU(s) list:   0-63</div><div class="line">Thread(s) per core:    2      //每个物理core有两个超线程</div><div class="line">Core(s) per socket:    16     //每路16个物理core</div><div class="line">Socket(s):             2      //2路</div><div class="line">NUMA node(s):          4</div><div class="line">Vendor ID:             HygonGenuine</div><div class="line">CPU family:            24</div><div class="line">Model:                 1</div><div class="line">Model name:            Hygon C86 5280 16-core Processor</div><div class="line">Stepping:              1</div><div class="line">CPU MHz:               2455.552</div><div class="line">CPU max MHz:           2500.0000</div><div class="line">CPU min MHz:           1600.0000</div><div class="line">BogoMIPS:              4999.26</div><div class="line">Virtualization:        AMD-V</div><div class="line">L1d cache:             32K</div><div class="line">L1i cache:             64K</div><div class="line">L2 cache:              512K</div><div class="line">L3 cache:              8192K</div><div class="line">NUMA node0 CPU(s):     0-7,32-39</div><div class="line">NUMA node1 CPU(s):     8-15,40-47</div><div class="line">NUMA node2 CPU(s):     16-23,48-55</div><div class="line">NUMA node3 CPU(s):     24-31,56-63</div><div class="line">Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid amd_dcm aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb hw_pstate sme ssbd sev ibpb vmmcall fsgsbase bmi1 avx2 smep bmi2 MySQLeed adx smap clflushopt sha_ni xsaveopt xsavec xgetbv1 xsaves clzero irperf xsaveerptr arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif overflow_recov succor smca</div><div class="line"></div><div class="line">#numactl -H</div><div class="line">available: 4 nodes (0-3)</div><div class="line">node 0 cpus: 0 1 2 3 4 5 6 7 32 33 34 35 36 37 38 39</div><div class="line">node 0 size: 128854 MB</div><div class="line">node 0 free: 89350 MB</div><div class="line">node 1 cpus: 8 9 10 11 12 13 14 15 40 41 42 43 44 45 46 47</div><div class="line">node 1 size: 129019 MB</div><div class="line">node 1 free: 89326 MB</div><div class="line">node 2 cpus: 16 17 18 19 20 21 22 23 48 49 50 51 52 53 54 55</div><div class="line">node 2 size: 128965 MB</div><div class="line">node 2 free: 86542 MB</div><div class="line">node 3 cpus: 24 25 26 27 28 29 30 31 56 57 58 59 60 61 62 63</div><div class="line">node 3 size: 129020 MB</div><div class="line">node 3 free: 98227 MB</div><div class="line">node distances:</div><div class="line">node   0   1   2   3</div><div class="line">  0:  10  16  28  22</div><div class="line">  1:  16  10  22  28</div><div class="line">  2:  28  22  10  16</div><div class="line">  3:  22  28  16  10</div></pre></td></tr></table></figure>
<p>AMD Zen 架构的CPU是胶水核，也就是把两个die拼一块封装成一块CPU，所以一块CPU内跨die之间延迟还是很高的。</p>
<h4 id="64-个-core-的分配策略"><a href="#64-个-core-的分配策略" class="headerlink" title="64 个 core 的分配策略"></a>64 个 core 的分配策略</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">physical         core      processor</div><div class="line">0                0~15         0~15</div><div class="line">1                0~15         16~31</div><div class="line">0                0~15         32~47</div><div class="line">1                0~15         48~63</div></pre></td></tr></table></figure>
<h4 id="海光bios配置"><a href="#海光bios配置" class="headerlink" title="海光bios配置"></a>海光bios配置</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">在grub.conf里面加入noibrs noibpb nopti nospectre_v2 nospectre_v1 l1tf=off nospec_store_bypass_disable no_stf_barrier mds=off tsx=on tsx_async_abort=off mitigations=off iommu.passthrough=1；持久化ip；挂盘参数defaults,noatime,nodiratime,lazytime,delalloc,nobarrier,data=writeback（因为后面步骤要重启，把一些OS优化也先做了）</div><div class="line">2. bios设置里面</div><div class="line">	配置 Hygon 设定 --- DF选项 --- 内存交错 --- Channel</div><div class="line">								 --- NB选项 --- 关闭iommu</div><div class="line">	打开CPB</div><div class="line">	风扇模式设置为高性能模式</div></pre></td></tr></table></figure>
<h4 id="海光简介"><a href="#海光简介" class="headerlink" title="海光简介"></a>海光简介</h4><p>公司成立于2016年3月，当前送测处理器为其第一代1.0版本的7185对标处理器为Intel的E5-2680V4，其服务器样机为曙光H620-G30。</p>
<p>其后续roadmap如下图，会包含1Die和2Die的处理器产品</p>
<p><img src="/images/951413iMgBlog/8faf9b906427972cb59ac4332d41d8a4.png" alt="img"></p>
<p><img src="/images/oss/376c93772606e5e237231ede0da64c0c.png" alt="img"></p>
<p>海光其产品规格如下，产品相对密集，但是产品之间差异化很小，频率总体接近。</p>
<p><img src="/images/951413iMgBlog/bad3d840f2d5017c50b77d47d4292eef.png" alt="img"></p>
<p>AMD授权Zen IP给海光的操作是先成立合资公司，授权给合资公司基于Zen 研发新的 CPU，而且转让给中国的所有信息都符合美国出口法规<strong>。</strong>天津海光和AMD成立的合资公司可以修改AMD的CPU核，变相享有X86授权，而海光公司可以通过购买合资公司研发的CPU核，开发服务器CPU，不过仅仅局限于中国市场。</p>
<p>AMD与国内公司A成立合资公司B，合资公司B由AMD控股，负责开发CPU核（其实就是拿AMD现成的内核），然后公司A购买合资公司B开发的CPU核，以此为基础开发CPU，最终实现ARM卖IP核的翻版。</p>
<h4 id="海光与AMD-的-Ryzen-EPYC-比较"><a href="#海光与AMD-的-Ryzen-EPYC-比较" class="headerlink" title="海光与AMD 的 Ryzen/EPYC 比较"></a>海光与AMD 的 Ryzen/EPYC 比较</h4><p>由于在 Zen 1 的基础上进行了大量的修改，海光 CPU 可以不用简单地称之为换壳 AMD 处理器了。但其性能相比同代原版 CPU 略差：整数性能基本相同，浮点性能显著降低——普通指令吞吐量只有基准水平的一半。海光 CPU 的随机数生成机制也被修改，加密引擎已被替换，不再对常见的 AES 指令进行加速，但覆盖了其他面向国内安全性的指令如 SM2、SM3 和 SM4。</p>
<h5 id="相同"><a href="#相同" class="headerlink" title="相同"></a>相同</h5><p>与 AMD 的 Ryzen/EPYC 相比，海光处理器究竟有哪些不同？总体而言，核心布局是相同的，缓存大小、TLB 大小和端口分配都相同，在基础级别上两者没有差异。CPU 仍然是 64KB 四路 L1 指令缓存，32KB 八路 L1 数据缓存，512KB 八路 L2 缓存以及 8MB 十六路 L3 缓存，与 Zen 1 核心完全相同。</p>
<h5 id="不同"><a href="#不同" class="headerlink" title="不同"></a>不同</h5><p><strong>加密方式变化</strong></p>
<p>在 Linux 内核升级中有关加密变化的信息已经明示。这些更新围绕 AMD 虚拟化功能（SEV）的安全加密进行。通常对于 EPYC 处理器来说，SEV 由 AMD 定义的加密协议控制，在这种情况下为 RSA、ECDSA、ECDH、SHA 和 AES。</p>
<p>但在海光 Dhyana 处理器中，SEV 被设计为使用 SM2、SM3 和 SM4 算法。在更新中有关 SM2 的部分声明道，这种算法基于椭圆曲线加密法，且需要其他私钥/公钥交换；SM3 是一种哈希算法，类似于 SHA-256；而 SM4 是类似于 AES-128 的分组密码算法。为支持这些算法所需的额外功能，其他指令也被加入到了 Linux 内核中。在说明文件中指出，这些算法已在 Hygon Dhyana Plus 处理器上成功进行测试，也已在 AMD 的 EPYC CPU 上成功测试。</p>
<p>此外，海光与 AMD 原版芯片最大的设计区别在于<strong>吞吐</strong>量，尽管整数性能相同，但海光芯片对于某些浮点指令并未做流水线处理，这意味着吞吐量和延迟都减小了：</p>
<p><img src="/images/951413iMgBlog/640-6077478.jpeg" alt="img"></p>
<p>这些对于最基础的任务来说也会有所影响，降低吞吐量的设计会让 CPU 在并行计算时性能受限。另外一个最大的变化，以及 Dhyana 与服务器版的「Dhyana Plus」版本之间的不同在于随机数生成的能力。</p>
<h2 id="验证是否是上下游的瓶颈"><a href="#验证是否是上下游的瓶颈" class="headerlink" title="验证是否是上下游的瓶颈"></a>验证是否是上下游的瓶颈</h2><p>需要先分析问题是否在LVS调用后端的多个MySQL集群上。</p>
<p>先写一个简单的测试程序：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line">#cat Test.java</div><div class="line">import java.sql.Connection;</div><div class="line">import java.sql.DriverManager;</div><div class="line">import java.sql.ResultSet;</div><div class="line">import java.sql.SQLException;</div><div class="line">import java.sql.Statement;</div><div class="line">/*</div><div class="line"> * 目录：/home/admin/jdbc</div><div class="line"> *</div><div class="line"> * 编译：</div><div class="line"> *  javac -cp /home/admin/lib/*:. Test.java</div><div class="line"> *</div><div class="line"> *  运行：</div><div class="line"> *   java -cp /home/admin/MySQL-server/lib/*:. Test &quot;jdbc:mysql://172.16.160.1:4261/qc_pay_0xwd_0002&quot; &quot;myhhzi0d&quot; &quot;jOXaC1Lbif-k&quot; &quot;select count(*) from pay_order where user_id=1169257092557639682 and order_no=&apos;201909292111250000102&apos;&quot; &quot;100&quot;</div><div class="line"> *   */</div><div class="line">public class Test &#123;</div><div class="line"></div><div class="line">    public static void main(String args[]) throws NumberFormatException, InterruptedException, ClassNotFoundException &#123;</div><div class="line">        Class.forName(&quot;com.mysql.jdbc.Driver&quot;);</div><div class="line">        String url = args[0];</div><div class="line">        String user = args[1];</div><div class="line">        String pass = args[2];</div><div class="line">        String sql = args[3];</div><div class="line">        String interval = args[4];</div><div class="line">        try &#123;</div><div class="line">            Connection conn = DriverManager.getConnection(url, user, pass);</div><div class="line">            while (true) &#123;</div><div class="line">                long start = System.currentTimeMillis();</div><div class="line">                for(int i=0; i&lt;1000; ++i)&#123;</div><div class="line">                    Statement stmt = conn.createStatement();</div><div class="line">                    ResultSet rs = stmt.executeQuery(sql);</div><div class="line">                    while (rs.next()) &#123;</div><div class="line">                    &#125;</div><div class="line">                    rs.close();</div><div class="line">                    stmt.close();</div><div class="line">                    Thread.sleep(Long.valueOf(interval));</div><div class="line">                &#125;</div><div class="line">                long end = System.currentTimeMillis();</div><div class="line">                System.out.println(&quot;rt : &quot; + (end - start));</div><div class="line">            &#125;</div><div class="line">        &#125; catch (SQLException e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>然后通过传入不同的jdbc参数跑2组测试:</p>
<ol>
<li>走服务节点执行指定id的点查； </li>
<li>直接从服务节点节点连MySQL指定id点查  </li>
</ol>
<p>上述2组测试同时跑在三组场景下：</p>
<ul>
<li>A) 服务节点和MySQL都没有压力； </li>
<li>B) 跑1、2测试的服务节点没有压力，但是sysbench 在压别的服务节点，这样后端的MySQL是有sysbench压侧压力，LVS也有流量压力的； </li>
<li>C) sysbench压所有服务节点, 包含运行 1、2测试程序节点） </li>
</ul>
<p>这样2组测试3个场景组合可以得到6组响应时间的测试数据</p>
<p>从最终得到6组数据来看可以排除链路以及MySQL的问题，瓶颈似乎还是在服务节点上</p>
<p><img src="/images/oss/595bc15fdd72860f2d1875c86384a14b.png" alt="image.png"></p>
<p>单独压一个服务节点节点并在上面跑测试，服务节点 CPU被压到 390%(每个服务节点 节点固定绑到4核), 这个时候整个宿主机压力不大，但是这四个核比较紧张了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">#cat rt.log  | awk &apos;&#123; print $3 &#125;&apos;  | awk &apos;&#123;if(min==&quot;&quot;)&#123;min=max=$1&#125;; if($1&gt;max) &#123;max=$1&#125;; if($1&lt;min) &#123;min=$1&#125;; total+=$1; count+=1&#125; END &#123;print &quot;avg &quot; total/count,&quot; | max &quot;max,&quot; | min &quot; min, &quot;| count &quot;, count&#125;&apos; ; cat MySQL.log  | awk &apos;&#123; print $3 &#125;&apos;  | awk &apos;&#123;if(min==&quot;&quot;)&#123;min=max=$1&#125;; if($1&gt;max) &#123;max=$1&#125;; if($1&lt;min) &#123;min=$1&#125;; total+=$1; count+=1&#125; END &#123;print &quot;avg &quot; total/count,&quot; | max &quot;max,&quot; | min &quot; min, &quot;| count &quot;, count &#125;&apos;;</div><div class="line">avg 2589.13  | max 3385  | min 2502 | count  69</div><div class="line">avg 1271.07  | max 1405  | min 1254 | count  141</div><div class="line"></div><div class="line">[root@d42a01107.cloud.a02.am78 /root]</div><div class="line">#taskset -pc 48759</div><div class="line">pid 48759&apos;s current affinity list: 19,52-54</div></pre></td></tr></table></figure>
<p>通过这6组测试数据可以看到，只有在整个系统都有压力（服务节点所在物理机、LVS、MySQL）的时候rt飙升最明显（C组数据），如果只是LVS、MySQL有压力，服务节点没有压力的时候可以看到数据还是很好的（B组数据）</p>
<h2 id="分析宿主机资源竞争"><a href="#分析宿主机资源竞争" class="headerlink" title="分析宿主机资源竞争"></a>分析宿主机资源竞争</h2><h3 id="perf分析"><a href="#perf分析" class="headerlink" title="perf分析"></a>perf分析</h3><p>只压单个服务节点</p>
<p><img src="/images/oss/7aea9045e50794fadc0439ee806f2496.png" alt="image.png"></p>
<p><img src="/images/oss/86c3f14887345a1d5f08cae985816564.png" alt="image.png"></p>
<p><strong>从以上截图，可以看到关键的 insn per cycle 能到0.51和0.66（这个数值越大性能越好）</strong></p>
<p>如果同时压物理机上的所有服务节点</p>
<p><img src="/images/oss/02f47474c612c2bf6e612efea3ab5de3.png" alt="image.png"></p>
<p><img src="/images/oss/c3d90e077d00a7a3db54770d9eea2dbb.png" alt="image.png"></p>
<p><strong>从以上截图，可以看到关键的 insn per cycle 能降到了0.27和0.31（这个数值越大性能越好），基本相当于单压的5折</strong></p>
<p>通过 perf list 找出所有Hardware event，然后对他们进行perf:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo perf stat -e branch-instructions,branch-misses,cache-references,cpu-cycles,instructions,stalled-cycles-backend,stalled-cycles-frontend,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-prefetches,L1-icache-load-misses,L1-icache-loads,branch-load-misses,branch-loads,dTLB-load-misses,dTLB-loads,iTLB-load-misses,iTLB-loads -a -- `pidof java`</div></pre></td></tr></table></figure>
<h3 id="尝试不同的绑核后的一些数据"><a href="#尝试不同的绑核后的一些数据" class="headerlink" title="尝试不同的绑核后的一些数据"></a>尝试不同的绑核后的一些数据</h3><p>通过以上perf数据以及numa结构，尝试将不同服务进程绑定到指定的4个核上</p>
<p>试了以下三种绑核的办法：</p>
<p>1）docker swarm随机绑（<strong>以上测试都是用的这种默认方案</strong>）；</p>
<p>2）一个服务节点绑连续4个core,这4个core都在同一个node； </p>
<p>3）一个服务节点绑4个core，这个4个core都在在同一个node，同时尽量HT在一起，也就是0，1，32，33 ； 2，3，34，35 这种绑法 </p>
<p><strong>结果是绑法2性能略好</strong>. </p>
<p>如果是绑法2，压单个服务节点 QPS能到2.3万；绑法1和3，压单个服务节点性能差别不明显，都是2万左右。 </p>
<h2 id="尝试将Java进程开启HugePage"><a href="#尝试将Java进程开启HugePage" class="headerlink" title="尝试将Java进程开启HugePage"></a>尝试将Java进程开启HugePage</h2><p>从perf数据来看压满后tlab miss比较高，得想办法降低这个值</p>
<h3 id="修改JVM启动参数"><a href="#修改JVM启动参数" class="headerlink" title="修改JVM启动参数"></a>修改JVM启动参数</h3><p>JVM启动参数增加如下三个(-XX:LargePageSizeInBytes=2m, 这个一定要，有些资料没提这个，在我的JDK8.0环境必须要)：</p>
<blockquote>
<p>-XX:+UseLargePages -XX:LargePageSizeInBytes=2m -XX:+UseHugeTLBFS</p>
</blockquote>
<h3 id="修改机器系统配置"><a href="#修改机器系统配置" class="headerlink" title="修改机器系统配置"></a>修改机器系统配置</h3><p>设置HugePage的大小</p>
<blockquote>
<p>cat /proc/sys/vm/nr_hugepages</p>
</blockquote>
<p>nr_hugepages设置多大参考如下计算方法：</p>
<blockquote>
<p>If you are using the option <code>-XX:+UseSHM</code> or <code>-XX:+UseHugeTLBFS</code>, then specify the number of large pages. In the following example, 3 GB of a 4 GB system are reserved for large pages (assuming a large page size of 2048kB, then 3 GB = 3 <em> 1024 MB = 3072 MB = 3072 </em> 1024 kB = 3145728 kB and 3145728 kB / 2048 kB = 1536):</p>
<p>echo 1536 &gt; /proc/sys/vm/nr_hugepages </p>
</blockquote>
<p>透明大页是没有办法减少系统tlab，tlab是对应于进程的，系统分给进程的透明大页还是由物理上的4K page组成。</p>
<p>Java进程用上HugePages后iTLB-load-misses从80%下降到了14%左右, dTLB也从30%下降到了20%，但是ipc变化不明显，QPS有不到10%的增加(不能确定是不是抖动所致)</p>
<p><img src="/images/oss/f6882f4c671b4c4b46feb01aa5e272fd.png" alt="image.png"></p>
<p>在公有云ecs虚拟机上测试对性能没啥帮助，实际看到用掉的HuagPage不多，如果/proc/sys/vm/nr_hugepages 设置比较大的话JVM会因为内存不足起不来，两者内存似乎是互斥的</p>
<h2 id="用sysbench验证一下海光服务器的多core能力"><a href="#用sysbench验证一下海光服务器的多core能力" class="headerlink" title="用sysbench验证一下海光服务器的多core能力"></a>用sysbench验证一下海光服务器的多core能力</h2><p>Intel E5 2682 2.5G VS hygon 7280 2.0G（Zen1）</p>
<p><img src="/images/951413iMgBlog/image-20210813095409553.png" alt="image-20210813095409553"></p>
<p><img src="/images/951413iMgBlog/image-20210813095757299.png" alt="image-20210813095757299"></p>
<p>由以上两个测试结果可以看出单核能力hygon 7280 强于 Intel 2682，但是hygon超线程能力还是没有任何提升。Intel用超线程计算能将耗时从109秒降到74秒。但是hygon(Zen1) 只是从89秒降到了87秒，基本没有变化。</p>
<p>再补充一个Intel(R) Xeon(R) Platinum 8269CY CPU @ 2.50GHz 对比数据 </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div></pre></td><td class="code"><pre><div class="line">#taskset -c 1,53 /usr/bin/sysbench --num-threads=2 --test=cpu --cpu-max-prime=50000 run</div><div class="line">sysbench 0.5:  multi-threaded system evaluation benchmark</div><div class="line"></div><div class="line">Running the test with following options:</div><div class="line">Number of threads: 2</div><div class="line">Random number generator seed is 0 and will be ignored</div><div class="line"></div><div class="line"></div><div class="line">Primer numbers limit: 50000</div><div class="line"></div><div class="line">Threads started!</div><div class="line"></div><div class="line"></div><div class="line">General statistics:</div><div class="line">    total time:                          48.5571s</div><div class="line">    total number of events:              10000</div><div class="line">    total time taken by event execution: 97.0944s</div><div class="line">    response time:</div><div class="line">         min:                                  8.29ms</div><div class="line">         avg:                                  9.71ms</div><div class="line">         max:                                 20.88ms</div><div class="line">         approx.  95 percentile:               9.71ms</div><div class="line"></div><div class="line">Threads fairness:</div><div class="line">    events (avg/stddev):           5000.0000/2.00</div><div class="line">    execution time (avg/stddev):   48.5472/0.01</div><div class="line"></div><div class="line">#taskset -c 1 /usr/bin/sysbench --num-threads=1 --test=cpu --cpu-max-prime=50000 run</div><div class="line">sysbench 0.5:  multi-threaded system evaluation benchmark</div><div class="line"></div><div class="line">Running the test with following options:</div><div class="line">Number of threads: 1</div><div class="line">Random number generator seed is 0 and will be ignored</div><div class="line"></div><div class="line"></div><div class="line">Primer numbers limit: 50000</div><div class="line"></div><div class="line">Threads started!</div><div class="line"></div><div class="line"></div><div class="line">General statistics:</div><div class="line">    total time:                          83.2642s</div><div class="line">    total number of events:              10000</div><div class="line">    total time taken by event execution: 83.2625s</div><div class="line">    response time:</div><div class="line">         min:                                  8.27ms</div><div class="line">         avg:                                  8.33ms</div><div class="line">         max:                                 10.03ms</div><div class="line">         approx.  95 percentile:               8.36ms</div><div class="line"></div><div class="line">Threads fairness:</div><div class="line">    events (avg/stddev):           10000.0000/0.00</div><div class="line">    execution time (avg/stddev):   83.2625/0.00</div><div class="line"></div><div class="line">#lscpu</div><div class="line">Architecture:          x86_64</div><div class="line">CPU op-mode(s):        32-bit, 64-bit</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                104</div><div class="line">On-line CPU(s) list:   0-103</div><div class="line">Thread(s) per core:    2</div><div class="line">Core(s) per socket:    26</div><div class="line">Socket(s):             2</div><div class="line">NUMA node(s):          2</div><div class="line">Vendor ID:             GenuineIntel</div><div class="line">CPU family:            6</div><div class="line">Model:                 85</div><div class="line">Model name:            Intel(R) Xeon(R) Platinum 8269CY CPU @ 2.50GHz</div><div class="line">Stepping:              7</div><div class="line">CPU MHz:               3200.097</div><div class="line">CPU max MHz:           3800.0000</div><div class="line">CPU min MHz:           1200.0000</div><div class="line">BogoMIPS:              4998.89</div><div class="line">Virtualization:        VT-x</div><div class="line">L1d cache:             32K</div><div class="line">L1i cache:             32K</div><div class="line">L2 cache:              1024K</div><div class="line">L3 cache:              36608K</div><div class="line">NUMA node0 CPU(s):     0-25,52-77</div><div class="line">NUMA node1 CPU(s):     26-51,78-103</div><div class="line">Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch ida arat epb invpcid_single pln pts dtherm spec_ctrl ibpb_support tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm mpx rdt avx512f avx512dq rdseed adx smap clflushopt avx512cdavx512bw avx512vl xsaveopt xsavec xgetbv1 cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local cat_l3 mba</div></pre></td></tr></table></figure>
<p>用sysbench 测试Hygon C86 5280 16-core Processor，分别1、8、16、24、32、40、48、56、64 个thread，32个thread前都是完美的线性增加，32core之后基本不增长了，这个应该能说明这个服务器就是32core的能力</p>
<blockquote>
<p>sysbench –threads=1 –cpu-max-prime=50000 cpu run</p>
</blockquote>
<p><img src="/images/oss/f86cd786f3a8297078579b547f78ec81.png" alt="image.png"></p>
<p>对比下intel的 Xeon 104core，也是物理52core，但是性能呈现完美线性</p>
<p><img src="/images/oss/8086f47b955d8d951e4dd4c7fe5e135e.png" alt="image.png"></p>
<h3 id="openssl场景多核能力验证"><a href="#openssl场景多核能力验证" class="headerlink" title="openssl场景多核能力验证"></a>openssl场景多核能力验证</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">openssl speed aes-256-ige -multi N</div></pre></td></tr></table></figure>
<p>intel 52 VS 26，可以看到52个线程的性能大概是26个的1.8倍</p>
<p><img src="/images/oss/4534d8e5901cc812aa54e610d1386445.png" alt="image.png"></p>
<p>intel 104 VS 52 线程，性能还能提升1.4倍</p>
<p><img src="/images/oss/6583f52e03b9753969e52d6a8b211725.png" alt="image.png"></p>
<p>海光32 VS 16, 性能能提升大概1.8倍，跟intel一致</p>
<p><img src="/images/oss/41e7f230ec27653c1b5ae5287971cd3a.png" alt="image.png"></p>
<p>海光64 VS 32, 性能能提升大概1.2倍</p>
<p><img src="/images/oss/2ad45a252392a06fa64d7475848e5601.png" alt="image.png"></p>
<p>总结下就是，在物理core数以内的线程数intel和海光性能基本增加一致；但如果超过物理core数开始使用HT后海光明显相比Intel差了很多。</p>
<p>intel超线程在openssl场景下性能能提升40%，海光就只能提升20%了。</p>
<h3 id="对比一下鲲鹏920-ARM架构的芯片"><a href="#对比一下鲲鹏920-ARM架构的芯片" class="headerlink" title="对比一下鲲鹏920 ARM架构的芯片"></a>对比一下鲲鹏920 ARM架构的芯片</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">#numactl -H</div><div class="line">available: 1 nodes (0)</div><div class="line">node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95</div><div class="line">node 0 size: 773421 MB</div><div class="line">node 0 free: 756092 MB</div><div class="line">node distances:</div><div class="line">node   0</div><div class="line">  0:  10</div></pre></td></tr></table></figure>
<p>96核一起跑openssl基本就是1核的96倍，完美线性，这是因为鲲鹏就没有超线程，都是物理核。如果并发增加到192个，性能和96个基本一样的。</p>
<p><img src="/images/oss/be30ab94eddc37f1d90c53204a0ed215.png" alt="image.png"></p>
<h3 id="用Sysbench直接压MySQL-oltp-read-only的场景"><a href="#用Sysbench直接压MySQL-oltp-read-only的场景" class="headerlink" title="用Sysbench直接压MySQL oltp_read_only的场景"></a>用Sysbench直接压MySQL oltp_read_only的场景</h3><p><img src="/images/oss/89c7a0228c45f79b688710206ba9d414.png" alt="image.png"></p>
<p>从1到10个thread的时候完美呈现线性，到20个thread就只比10个thread增加50%了，30thread比20增加40%，过了32个thread后增加10个core性能加不到10%了。</p>
<p>在32thread前，随着并发的增加 IPC也有所减少，这也是导致thread翻倍性能不能翻倍的一个主要原因。</p>
<p>基本也和openssl 场景一致，海光的HT基本可以忽略，做的不是很好。超过32个thread后（物理core数）性能增加及其微弱</p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p><a href="https://topic.atatech.org/articles/178985" target="_blank" rel="external">海光的一个core只有一个fpu</a>，所以超线程算除法完全没用.</p>
<blockquote>
<p>FP处理所有矢量操作。简单的整数向量运算（例如shift，add）都可以在一个周期内完成，是AMD以前架构延迟的一半。<strong>基本浮点数学运算具有三个周期的延迟</strong>，其中包括乘法（用于双精度需要一个额外周期）。<strong>融合乘加是五个周期。</strong></p>
<p>FP具有用于128位加载操作的单个管道。实际上，整个FP端都针对128位操作进行了优化。 Zen支持所有最新指令，例如SSE和AVX1/2。 256位AVX的设计方式是可以将它们作为两个独立的128位操作来执行。 Zen通过将这些指令作为两个操作。也就是说，<strong>Zen将256位操作分为两个µOP</strong>。同样，存储也是在128位块上完成的，从而使256位加载的有效吞吐量为每两个周期一个存储。这些管道之间的平衡相当好，因此大多数操作将安排至少两个管道，以保持每个周期至少一个这样的指令的吞吐量。暗示着，<strong>256位操作将占用两倍的资源来完成操作（即2x寄存器，调度程序和端口）。这是AMD采取的一种折衷方案，有助于节省芯片空间和功耗。</strong>相比之下，英特尔的竞争产品Skylake确实具有专用的256位电路。还应注意的是，英特尔的现代服务器级型号进一步扩展了此功能，以纳入支持AVX-512的专用512位电路，而性能最高的型号则具有二个专用的AVX-512单元。</p>
<p>此外，Zen还支持SHA和AES（并实现了2个AES单元），以提高加密性能。这些单位可以在浮点调度程序的管道0和1上找到。</p>
<p>这个也是为什么浮点比Intel X86会弱的原因。</p>
</blockquote>
<h3 id="一些其他对比结论"><a href="#一些其他对比结论" class="headerlink" title="一些其他对比结论"></a>一些其他对比结论</h3><ul>
<li>对纯CPU 运算场景，并发不超过物理core时，比如Prime运算，比如DRDS(CPU bound，IO在网络，可以加并发弥补)<ul>
<li>海光的IPC能保持稳定；</li>
<li>intel的IPC有所下降，但是QPS在IPC下降后还能完美线性</li>
</ul>
</li>
<li>在openssl和MySQL oltp_read_only场景下<ul>
<li>如果并发没超过物理core数时，海光和Intel都能随着并发的翻倍性能能增加80%</li>
<li>如果并发超过物理core数后，Intel还能随着并发的翻倍性能增加50%，海光增加就只有20%了</li>
<li>简单理解在这两个场景下Intel的HT能发挥半个物理core的作用，海光的HT就只能发挥0.2个物理core的作用了</li>
</ul>
</li>
<li>海光5280/7280 是Zen1/Zen2的AMD 架构，每个core只有一个fpu，综上在多个场景下HT基本上都可以忽略</li>
</ul>
<h2 id="系列文章"><a href="#系列文章" class="headerlink" title="系列文章"></a>系列文章</h2><p><a href="/2021/06/01/CPU的制造和概念/">CPU的制造和概念</a></p>
<p><a href="/2021/05/16/CPU Cache Line 和性能/">CPU 性能和Cache Line</a></p>
<p><a href="/2021/05/16/Perf IPC以及CPU利用率/">Perf IPC以及CPU性能</a></p>
<p><a href="/2021/06/18/几款CPU性能对比/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></p>
<p><a href="/2021/05/15/飞腾ARM芯片(FT2500">飞腾ARM芯片(FT2500)的性能测试</a>的性能测试/)</p>
<p><a href="/2021/05/14/十年后数据库还是不敢拥抱NUMA/">十年后数据库还是不敢拥抱NUMA？</a></p>
<p><a href="/2021/03/07/一次海光物理机资源竞争压测的记录/">一次海光物理机资源竞争压测的记录</a></p>
<p><a href="/2019/12/16/Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的/">Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的</a></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://dino.ciuffetti.info/2011/07/howto-java-huge-pages-linux/" target="_blank" rel="external">How to use Huge Pages with Java and Linux</a>这个资料中提到了Java使用HugePage的时候启动进程的用户权限问题，在我的docker容器中用的admin启动的进程，测试验证是不需要按资料中的设置。</p>
<p><a href="https://www.atatech.org/articles/157681" target="_blank" rel="external">Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的</a></p>
<p><a href="https://bbs.huaweicloud.com/blogs/146367" target="_blank" rel="external">华为TaiShan服务器ARMNginx应用调优案例 大量绑核、中断、Numa等相关调优信息</a></p>
<p><a href="https://topic.atatech.org/articles/178985" target="_blank" rel="external">主流处理器内部单核微架构细节1——AMD ZEN(即海光)微架构</a></p>
<p><a href="https://topic.atatech.org/articles/178986" target="_blank" rel="external">主流处理器内部单核微架构细节2——Skylake微架构</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/03/05/MacOS下如何使用iTerm2访问水木社区/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/03/05/MacOS下如何使用iTerm2访问水木社区/" itemprop="url">MacOS下如何使用iTerm2访问水木社区</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-03-05T17:30:03+08:00">
                2021-03-05
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Linux/" itemprop="url" rel="index">
                    <span itemprop="name">Linux</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="MacOS下如何使用iTerm2访问水木社区"><a href="#MacOS下如何使用iTerm2访问水木社区" class="headerlink" title="MacOS下如何使用iTerm2访问水木社区"></a>MacOS下如何使用iTerm2访问水木社区</h1><p>关键字： MacOS、iTerm 、Dracula、ssh、bbs.newsmth.net</p>
<p>windows下有各种Term软件来帮助我们通过ssh访问bbs.newsmth.net, 但是工作环境切换到MacOS后发现FTerm、CTerm这样的工具都没有对应的了。但是term下访问 bbs.newsmth.net 简直是太爽了，所以本文希望解决这个问题。</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>ssh 访问 bbs.newsmth.net 是没问题的，但是<strong>要解决配色和字符编码问题</strong></p>
<h3 id="解决编码"><a href="#解决编码" class="headerlink" title="解决编码"></a>解决编码</h3><p>在iTerm2的配置中增加一个profile，如下图 smth，主要是改字符编码集为 GB 18030，然后修改配色方案，我喜欢的Dracula不适合SMTH，十大完全看不了。</p>
<p><img src="/images/951413iMgBlog/image-20210602133111201.png" alt="image-20210602133111201"></p>
<p>执行脚本如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">#cat /usr/local/bin/smth</div><div class="line">echo -e &quot;\033]50;SetProfile=smth\a&quot;          //切换到smth的profile,也就是切换到了 GB18030</div><div class="line">sshpass -p&apos;密码&apos; ssh -o ServerAliveInterval=60 水木id@bbs.newsmth.net</div><div class="line">echo -e &quot;\033]50;SetProfile=Default\a&quot;       //切换回UTF8</div></pre></td></tr></table></figure>
<p>SetProfile=smth用来解决profile切换，连smth term前切换成GB 18030，断开的时候恢复成UTF-8，要不然的话正常工作的命令行就乱码了。</p>
<h3 id="解决配色问题"><a href="#解决配色问题" class="headerlink" title="解决配色问题"></a>解决配色问题</h3><p>然后还是在profile里面把smth的配色方案改成：Tango Dark, 一切简直是完美，工作灌水两不误，别人还发现不了</p>
<h2 id="最终效果"><a href="#最终效果" class="headerlink" title="最终效果"></a>最终效果</h2><p>目录（右边是工作窗口）：</p>
<p><img src="/images/oss/0265ed7a728bfdd6be940d838fc1feaf.png" alt="image.png"></p>
<p>十大，这个十大颜色和右边工作模式的配色方案不一样</p>
<p><img src="/images/oss/252b9295375f6e6078278a6e64e1d68c.png" alt="image.png"></p>
<p>断开后恢复成 Dracula 配色和UTF-8编码，不影响工作，别的工作tab也还是正常使用utf8</p>
<p><img src="/images/oss/cf8912c0634182b44fa92eeb9f854362.png" alt="image.png"></p>
<p>别的term网站也是类似，比如小百合、byr、ptt等</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/02/14/TCP疑难问题案例汇总/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/02/14/TCP疑难问题案例汇总/" itemprop="url">TCP疑难问题案例汇总</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-02-14T13:30:03+08:00">
                2021-02-14
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/TCP/" itemprop="url" rel="index">
                    <span itemprop="name">TCP</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="TCP疑难问题案例汇总"><a href="#TCP疑难问题案例汇总" class="headerlink" title="TCP疑难问题案例汇总"></a>TCP疑难问题案例汇总</h1><p>碰到各种奇葩的TCP相关问题，所以汇总记录一下。分析清楚这些问题的所有来龙去脉，就能帮你在TCP知识体系里建立几个坚固的抓手，让TCP知识慢慢在抓手之间生长和互通</p>
<h2 id="服务不响应的现象或者奇怪异常的原因分析"><a href="#服务不响应的现象或者奇怪异常的原因分析" class="headerlink" title="服务不响应的现象或者奇怪异常的原因分析"></a>服务不响应的现象或者奇怪异常的原因分析</h2><p> <a href="/2021/02/10/%E4%B8%80%E4%B8%AA%E9%BB%91%E7%9B%92%E7%A8%8B%E5%BA%8F%E5%A5%87%E6%80%AA%E7%9A%84%E8%A1%8C%E4%B8%BA%E5%88%86%E6%9E%90/">一个黑盒程序奇怪行为的分析</a> listen端口上很快就全连接队列溢出了，导致整个程序不响应了</p>
<p><a href="/2020/11/02/%E4%B8%BE%E4%B8%89%E5%8F%8D%E4%B8%80--%E4%BB%8E%E7%90%86%E8%AE%BA%E7%9F%A5%E8%AF%86%E5%88%B0%E5%AE%9E%E9%99%85%E9%97%AE%E9%A2%98%E7%9A%84%E6%8E%A8%E5%AF%BC/">举三反一–从理论知识到实际问题的推导</a> 服务端出现大量CLOSE_WAIT 个数正好 等于somaxconn（调整somaxconn大小后 CLOSE_WAIT 也会跟着变成一样的值）</p>
<p><a href="/2020/11/18/TCP%E8%BF%9E%E6%8E%A5%E4%B8%BA%E5%95%A5%E4%BA%92%E4%B8%B2%E4%BA%86/">活久见，TCP连接互串了</a>  应用每过一段时间总是会抛出几个连接异常的错误，需要查明原因。排查后发现是TCP连接互串了，这个案例实在是很珍惜，所以记录一下。</p>
<p> <a href="/2020/07/01/如何创建一个自己连自己的TCP连接/">如何创建一个自己连自己的TCP连接</a></p>
<h2 id="传输速度分析"><a href="#传输速度分析" class="headerlink" title="传输速度分析"></a>传输速度分析</h2><p>案例：<a href="/2021/01/15/TCP%E4%BC%A0%E8%BE%93%E9%80%9F%E5%BA%A6%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90/">TCP传输速度案例分析</a>（长肥网络、rt升高、delay ack的影响等）</p>
<p>原理：<a href="/2019/09/28/就是要你懂TCP--性能和发送接收Buffer的关系/">就是要你懂TCP–性能和发送接收Buffer的关系：发送窗口大小(Buffer)、接收窗口大小(Buffer)对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响。BDP、RT、带宽对传输速度又是怎么影响的</a></p>
<p><a href="/2018/06/14/就是要你懂TCP--最经典的TCP性能问题/">就是要你懂TCP–最经典的TCP性能问题 Nagle和Delay ack</a></p>
<p><a href="/2019/06/21/就是要你懂TCP--性能优化大全/">就是要你懂TCP–性能优化大全</a></p>
<h2 id="TCP队列问题以及连接数"><a href="#TCP队列问题以及连接数" class="headerlink" title="TCP队列问题以及连接数"></a>TCP队列问题以及连接数</h2><p> <a href="/2020/11/30/一台机器上最多能创建多少个TCP连接/">到底一台服务器上最多能创建多少个TCP连接</a></p>
<p> <a href="/2019/08/31/就是要你懂TCP队列--通过实战案例来展示问题/">就是要你懂TCP队列–通过实战案例来展示问题</a></p>
<p> <a href="/2017/06/07/就是要你懂TCP--半连接队列和全连接队列/">就是要你懂TCP–半连接队列和全连接队列</a></p>
<p> <a href="/2017/06/02/就是要你懂TCP--连接和握手/">就是要你懂TCP–握手和挥手</a></p>
<h2 id="防火墙和reset定位分析"><a href="#防火墙和reset定位分析" class="headerlink" title="防火墙和reset定位分析"></a>防火墙和reset定位分析</h2><p>对ttl、identification等的运用</p>
<p><a href="/2018/08/26/关于TCP连接的KeepAlive和reset/">关于TCP连接的Keepalive和reset</a></p>
<p><a href="/2019/11/06/谁动了我的TCP连接/">就是要你懂网络–谁动了我的TCP连接</a></p>
<h2 id="TCP相关参数"><a href="#TCP相关参数" class="headerlink" title="TCP相关参数"></a>TCP相关参数</h2><p> <a href="/2020/01/26/TCP相关参数解释/">TCP相关参数解释</a></p>
<p><a href="/2019/05/16/网络通不通是个大问题--半夜鸡叫/">网络通不通是个大问题–半夜鸡叫</a> </p>
<p><a href="/2018/12/26/网络丢包/">网络丢包</a></p>
<h2 id="工具技巧篇"><a href="#工具技巧篇" class="headerlink" title="工具技巧篇"></a>工具技巧篇</h2><p> <a href="/2019/04/21/netstat定位性能案例/">netstat定位性能案例</a></p>
<p> <a href="/2017/08/28/netstat --timer/">netstat timer keepalive explain</a></p>
<p><a href="/2016/10/12/ss用法大全/">就是要你懂网络监控–ss用法大全</a></p>
<p><a href="/2019/06/21/就是要你懂抓包--WireShark之命令行版tshark/">就是要你懂抓包–WireShark之命令行版tshark</a></p>
<p><a href="/2018/01/01/通过tcpdump对Unix Socket 进行抓包解析/">通过tcpdump对Unix Domain Socket 进行抓包解析</a></p>
<p><a href="/2017/12/07/如何追踪网络流量/">如何追踪网络流量</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/02/10/一个黑盒程序奇怪的行为分析/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/02/10/一个黑盒程序奇怪的行为分析/" itemprop="url">一个黑盒程序奇怪行为的分析</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-02-10T10:30:03+08:00">
                2021-02-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/TCP/" itemprop="url" rel="index">
                    <span itemprop="name">TCP</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="一个黑盒程序奇怪行为的分析"><a href="#一个黑盒程序奇怪行为的分析" class="headerlink" title="一个黑盒程序奇怪行为的分析"></a>一个黑盒程序奇怪行为的分析</h1><h2 id="问题描述："><a href="#问题描述：" class="headerlink" title="问题描述："></a>问题描述：</h2><blockquote>
<p>从银行金主baba手里拿到一个区块链程序，监听4000，在我们的环境中4000端口上很快就全连接队列溢出了，导致整个程序不响应了。这个程序是黑盒子，没有源代码，但是在金主baba自己的环境运行正常（一样的OS）</p>
</blockquote>
<p>如下图所示：</p>
<p><img src="/images/oss/623ca2f46084958efa447882cbb58e72.png" alt="image.png"></p>
<p>ss -lnt 看到全连接队列增长到了39，但是netstat -ant找不到这39个连接，本来是想看看队列堆了这么多连接，都是哪些ip连过来的，实际看不到这就奇怪了</p>
<p>同时验证过程发现我们的环境4000端口上开了slb，也就是slb会不停滴探活4000端口，关掉slb探活后一切正常了。</p>
<p>所以总结下来问题就是：</p>
<ol>
<li><p>为什么全连接队列里面的连接netstat看不到这些连接，但是ss能看到总数 </p>
</li>
<li><p>为什么关掉slb就正常了 </p>
</li>
<li><p>为什么应用不accept连接,也不close（应用是个黑盒子） </p>
</li>
</ol>
<h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><h3 id="为什么全连接队列里面的连接netstat-ss都看不到-ss能看到总数"><a href="#为什么全连接队列里面的连接netstat-ss都看不到-ss能看到总数" class="headerlink" title="为什么全连接队列里面的连接netstat/ss都看不到(ss能看到总数)"></a>为什么全连接队列里面的连接netstat/ss都看不到(ss能看到总数)</h3><p>这是因为这些连接都是探活连接，三次握手后很快被slb reset了，在OS层面这个连接已经被释放，所以肯定看不见。反过来想要是netstat能看见这个连接，那么它的状态是什么？ reset吗？tcp连接状态里肯定是没有reset状态的。</p>
<p>ss看到的总数是指只要这个连接没有被accept，那么连接队列里就还有这个连接，通过ss也能看到连接队列数量。</p>
<h4 id="为什么会产生这个错误理解–全连接队列里面的连接netstat一定要能看到？"><a href="#为什么会产生这个错误理解–全连接队列里面的连接netstat一定要能看到？" class="headerlink" title="为什么会产生这个错误理解–全连接队列里面的连接netstat一定要能看到？"></a>为什么会产生这个错误理解–全连接队列里面的连接netstat一定要能看到？</h4><p>那是因为正常情况都是能看到的，从没有考虑过握手后很快reset的情况。也没反问过如果能看到这个连接该是什么状态呢？</p>
<h4 id="这个连接被reset后，kernel会将全连接队列数量减1吗？"><a href="#这个连接被reset后，kernel会将全连接队列数量减1吗？" class="headerlink" title="这个连接被reset后，kernel会将全连接队列数量减1吗？"></a>这个连接被reset后，kernel会将全连接队列数量减1吗？</h4><p>不会，按照我们的理解连接被reset释放后，那么kernel要释放全连接队列里面的这个连接，因为这些动作都是kernel负责，上层没法处理这个reset。实际上内核认为所有 listen 到的连接, 必须要 accept 走, 用户有权利知道存在过这么一个连接。</p>
<p>也就是reset后，连接在内核层面释放了，所以netstat/ss看不到，但是全连接队列里面的应用数不会减1，只有应用accept后队列才会减1，accept这个空连接后读写会报错。基本可以认为全连接队列溢出了，主要是应用accept太慢导致的。</p>
<p>当应用从accept队列读取到已经被reset了的连接的时候应用层会得到一个报错信息。</p>
<h4 id="什么时候连接状态变成-ESTABLISHED"><a href="#什么时候连接状态变成-ESTABLISHED" class="headerlink" title="什么时候连接状态变成 ESTABLISHED"></a>什么时候连接状态变成 ESTABLISHED</h4><p>三次握手成功就变成 ESTABLISHED 了，三次握手成功的第一是收到第三步的ack并且全连接队列没有满，不需要用户态来accept，如果握手第三步的时候OS发现全连接队列满了，这时OS会扔掉这个第三次握手ack，并重传握手第二步的syn+ack, 在OS端这个连接还是 SYN_RECV 状态的，但是client端是 ESTABLISHED状态的了。</p>
<p>下面是在4000（tearbase）端口上<strong>全连接队列没满，但是应用不再accept了</strong>，nc用12346端口去连4000（tearbase）端口的结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"># netstat -at |grep &quot;:12346 &quot;</div><div class="line">tcp   0      0 dcep-blockchain-1:12346 dcep-blockchai:terabase ESTABLISHED //server</div><div class="line">tcp   0      0 dcep-blockchai:terabase dcep-blockchain-1:12346 ESTABLISHED //client</div><div class="line">[root@dcep-blockchain-1 cfl-sm2-sm3]# ss -lt</div><div class="line">State       Recv-Q Send-Q      Local Address:Port         Peer Address:Port   </div><div class="line">LISTEN      73     1024            *:terabase                 *:*</div></pre></td></tr></table></figure>
<p>这是在4000（tearbase）端口上<strong>全连接队列满掉</strong>后，nc用12346端口去连4000（tearbase）端口的结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"># netstat -at |grep &quot;:12346 &quot;  </div><div class="line">tcp   0      0 dcep-blockchai:terabase dcep-blockchain-1:12346 SYN_RECV    //server</div><div class="line">tcp   0      0 dcep-blockchain-1:12346 dcep-blockchai:terabase ESTABLISHED //client</div><div class="line"># ss -lt</div><div class="line">State       Recv-Q Send-Q      Local Address:Port       Peer Address:Port   </div><div class="line">LISTEN      1025   1024             *:terabase              *:*</div></pre></td></tr></table></figure>
<h3 id="为什么关掉slb就正常了"><a href="#为什么关掉slb就正常了" class="headerlink" title="为什么关掉slb就正常了"></a>为什么关掉slb就正常了</h3><p>slb探活逻辑是向监听端口发起三次握手，握手成功后立即发送一个reset断开连接</p>
<p>这是一个完整的探活过程：</p>
<p><img src="/images/oss/b81dcbaea26a5130383d0bc8317fd3c5.png" alt="image.png"></p>
<p>关掉就正常后要结合第三个问题来讲</p>
<h3 id="为什么应用不accept连接-也不close（应用是个黑盒子）"><a href="#为什么应用不accept连接-也不close（应用是个黑盒子）" class="headerlink" title="为什么应用不accept连接,也不close（应用是个黑盒子）"></a>为什么应用不accept连接,也不close（应用是个黑盒子）</h3><p>因为应用是个黑盒子，看不到源代码，只能从行为来分析了</p>
<p>从行为来看，这个应用在三次握手后，会主动给client发送一个12字节的数据，但是这个逻辑写在了accept主逻辑内部，一旦主动给client发12字节数据失败（比如这个连接reset了）那么一直卡在这里导致应用不再accept也不再close。</p>
<p>正确的实现逻辑是，accept在一个单独的线程里，一旦accept到一个新连接，那么就开启一个新的线程来处理这个新连接的读写。accept线程专注accept。</p>
<p>关掉slb后应用有机会发出这12个字节，然后accept就能继续了，否则就卡死了。</p>
<h2 id="一些验证"><a href="#一些验证" class="headerlink" title="一些验证"></a>一些验证</h2><h3 id="nc测试连接4000端口"><a href="#nc测试连接4000端口" class="headerlink" title="nc测试连接4000端口"></a>nc测试连接4000端口</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"># nc -p 12346 dcep-blockchain-1 4000</div><div class="line"> //握手后4000返回的内容</div><div class="line"></div><div class="line">抓包：</div><div class="line">11:03:16.762547 IP dcep-blockchain-1.12346 &gt; dcep-blockchain-1.terabase: Flags [S], seq 397659761, win 43690, options [mss 65495,sackOK,TS val 2329725964 ecr 0,nop,wscale 7], length 0</div><div class="line">04:42:24.466211 IP dcep-blockchain-1.terabase &gt; dcep-blockchain-1.12346: Flags [S.], seq 4239354556, ack 397659762, win 43690, options [mss 65495,sackOK,TS val 2329725964 ecr 2329725964,nop,wscale 7], length 0</div><div class="line">11:03:16.762571 IP dcep-blockchain-1.12346 &gt; dcep-blockchain-1.terabase: Flags [.], ack 1, win 342, options [nop,nop,TS val 2329725964 ecr 2329725964], length 0</div><div class="line"></div><div class="line">----到这三次握手完毕，下面是隔了大概1.5ms，4000发了12字节给nc</div><div class="line">11:03:16.763893 IP dcep-blockchain-1.terabase &gt; dcep-blockchain-1.12346: Flags [P.], seq 1:13, ack 1, win 342, options [nop,nop,TS val 2329725966 ecr 2329725964], length 12</div><div class="line">11:03:16.763904 IP dcep-blockchain-1.12346 &gt; dcep-blockchain-1.terabase: Flags [.], ack 13, win 342, options [nop,nop,TS val 2329725966 ecr 2329725966], length 0</div></pre></td></tr></table></figure>
<p>如果在上面的1.5ms之间nc  reset了这个连接，那么这12字节就发不出来了</p>
<h3 id="握手后Server主动发数据的行为非常像MySQL-Server"><a href="#握手后Server主动发数据的行为非常像MySQL-Server" class="headerlink" title="握手后Server主动发数据的行为非常像MySQL Server"></a>握手后Server主动发数据的行为非常像MySQL Server</h3><p>MySQL Server在收到mysql client连接后会主动发送 Server Greeting、版本号、认证方式等给client</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">#nc -p 12345 127.0.0.1 3306</div><div class="line">J</div><div class="line">5.6.29�CuaV9v0xo�!</div><div class="line">                  qCHRrGRIJqvzmysql_native_password  </div><div class="line">                  </div><div class="line">#tcpdump -i any port 12345 -ennt</div><div class="line">tcpdump: verbose output suppressed, use -v or -vv for full protocol decode</div><div class="line">listening on any, link-type LINUX_SLL (Linux cooked), capture size 262144 bytes</div><div class="line"> In 00:00:00:00:00:00 ethertype IPv4 (0x0800), length 76: 127.0.0.1.12345 &gt; 127.0.0.1.3306: Flags [S], seq 3186409724, win 43690, options [mss 65495,sackOK,TS val 3967896050 ecr 0,nop,wscale 7], length 0</div><div class="line"> In 00:00:00:00:00:00 ethertype IPv4 (0x0800), length 76: 127.0.0.1.3306 &gt; 127.0.0.1.12345: Flags [S.], seq 4188709983, ack 3186409725, win 43690, options [mss 65495,sackOK,TS val 3967896051 ecr 3967896050,nop,wscale 7], length 0</div><div class="line"> In 00:00:00:00:00:00 ethertype IPv4 (0x0800), length 68: 127.0.0.1.12345 &gt; 127.0.0.1.3306: Flags [.], ack 1, win 342, options [nop,nop,TS val 3967896051 ecr 3967896051], length 0 // 握手完毕</div><div class="line"> In 00:00:00:00:00:00 ethertype IPv4 (0x0800), length 146: 127.0.0.1.3306 &gt; 127.0.0.1.12345: Flags [P.], seq 1:79, ack 1, win 342, options [nop,nop,TS val 3967896051 ecr 3967896051], length 78 //Server 发出Greeting</div><div class="line"> In 00:00:00:00:00:00 ethertype IPv4 (0x0800), length 68: 127.0.0.1.12345 &gt; 127.0.0.1.3306: Flags [.], ack 79, win 342, options [nop,nop,TS val 3967896051 ecr 3967896051], length 0</div><div class="line"> In 00:00:00:00:00:00 ethertype IPv4 (0x0800), length 68: 127.0.0.1.3306 &gt; 127.0.0.1.12345: Flags [F.], seq 79, ack 1, win 342, options [nop,nop,TS val 3967913551 ecr 3967896051], length 0</div><div class="line"> In 00:00:00:00:00:00 ethertype IPv4 (0x0800), length 68: 127.0.0.1.12345 &gt; 127.0.0.1.3306: Flags [.], ack 80, win 342, options [nop,nop,TS val 3967913591 ecr 3967913551], length 0</div></pre></td></tr></table></figure>
<p>如下是Server发出的长度为 78 的 Server Greeting信息内容</p>
<p><img src="/images/oss/203c52d94018bbf72dfd4fc64d8a237b.png" alt="image.png"></p>
<p>理论上如果slb探活连接检查MySQL Server的状态的时候也是很快reset了，如果MySQL Server程序写得烂的话也会出现同样的情况。</p>
<p>但是比如我们有实验验证MySQL  Server 是否正常的时候会用 nc 去测试，一般以能看到</p>
<blockquote>
<p>5.6.29�CuaV9v0xo�!<br>                  qCHRrGRIJqvzmysql_native_password </p>
</blockquote>
<p>就认为MySQL Server是正常的。但是真的是这样吗？我们看看 nc 的如下案例</p>
<h4 id="nc-6-4-快速fin"><a href="#nc-6-4-快速fin" class="headerlink" title="nc 6.4 快速fin"></a>nc 6.4 快速fin</h4><blockquote>
<p>#nc –version<br>Ncat: Version 6.40 ( <a href="http://nmap.org/ncat" target="_blank" rel="external">http://nmap.org/ncat</a> )</p>
</blockquote>
<p>用 nc 测试发现有一定的概率没有出现上面的Server Greeting信息，那么这是因为MySQL Server服务不正常了吗？</p>
<p><img src="/images/oss/1607660605575-1305739f-1621-4a01-89ad-0f81eef94922.png?x-oss-process=image%2Fresize%2Cw_1500" alt="image.png"></p>
<blockquote>
<p> nc -i 3 10.97.170.11 3306 -w 4 -p 1234</p>
</blockquote>
<p>-i 3 表示握手成功后 等三秒钟nc退出（发fin）</p>
<p>nc 6.4 握手后立即发fin断开连接，导致可能收不到Greeting，换成7.5或者mysql client就OK了</p>
<p>nc 7.5的抓包，明显可以看到nc在发fin前会先等4秒钟：</p>
<p><img src="/images/oss/1607660937618-d66c4074-9aa2-44cb-8054-f7d3680d1181.png?x-oss-process=image%2Fresize%2Cw_1500" alt="image.png"></p>
<h3 id="tcpping-模拟slb-探活"><a href="#tcpping-模拟slb-探活" class="headerlink" title="tcpping 模拟slb 探活"></a>tcpping 模拟slb 探活</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python tcpping.py -R -i 0.1 -t 1 dcep-blockchain-1 4000</div></pre></td></tr></table></figure>
<p>-i 间隔0.1秒 </p>
<p>-R reset断开连接</p>
<p>-t 超时时间1秒</p>
<p>执行如上代码，跟4000端口握手，然后立即发出reset断开连接（完全模拟slb探活行为），很快重现了问题</p>
<p>增加延时</p>
<p>-D 0.01表示握手成功后10ms后再发出reset（让应用有机会成功发出那12个字节），应用工作正常</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python tcpping.py -R -i 0.1 -t 1 -D 0.01 dcep-blockchain-1 4000</div></pre></td></tr></table></figure>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>最大的错误认知就是 ss 看到的全连接队列数量，netstat也能看到。实际是不一定，而这个快速reset+应用不accept就导致了看不到这个现象</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/01/28/journald和rsyslog/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/01/28/journald和rsyslog/" itemprop="url">journald和rsyslogd</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-01-28T17:30:03+08:00">
                2021-01-28
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Linux/" itemprop="url" rel="index">
                    <span itemprop="name">Linux</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="journald和rsyslogd"><a href="#journald和rsyslogd" class="headerlink" title="journald和rsyslogd"></a>journald和rsyslogd</h1><p>碰到rsyslog-8.24.0-34.1.al7.x86_64 的 rsyslogd 占用内存过高，于是分析了一下原因并学习了一下系统日志、rsyslog、journald之间的关系，流水账记录此文。</p>
<h2 id="rsyslogd-占用内存过高的分析"><a href="#rsyslogd-占用内存过高的分析" class="headerlink" title="rsyslogd 占用内存过高的分析"></a>rsyslogd 占用内存过高的分析</h2><p>rsyslogd使用了大概1.6-2G内存，不正常（正常情况下内存占用30-50M之间）</p>
<p>现象：</p>
<p><img src="/images/oss/12d137f9416d7935dbe6540c626ca8b4.png" alt="image.png"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line">KiB Mem :  7971268 total,   131436 free,  7712020 used,   127812 buff/cache</div><div class="line">KiB Swap:        0 total,        0 free,        0 used.    43484 avail Mem</div><div class="line"></div><div class="line">  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND</div><div class="line">24850 admin     20   0 8743896   5.1g      0 S   2.0 66.9   1413:55 java</div><div class="line"> 1318 root      20   0 2380404   1.6g    536 S   0.0 21.6 199:09.36 rsyslogd</div><div class="line"> </div><div class="line"># systemctl status rsyslog</div><div class="line">● rsyslog.service - System Logging Service</div><div class="line">   Loaded: loaded (/usr/lib/systemd/system/rsyslog.service; enabled; vendor preset: disabled)</div><div class="line">   Active: active (running) since Tue 2020-10-20 16:01:01 CST; 3 months 8 days ago</div><div class="line">     Docs: man:rsyslogd(8)</div><div class="line">           http://www.rsyslog.com/doc/</div><div class="line"> Main PID: 1318 (rsyslogd)</div><div class="line">   CGroup: /system.slice/rsyslog.service</div><div class="line">           └─1318 /usr/sbin/rsyslogd -n</div><div class="line"></div><div class="line">Jan 28 09:10:07 iZwz95gaul6x9167sqdqz4Z rsyslogd[1318]: sd_journal_get_cursor() failed: &apos;Cannot assign requested address&apos;  [v8.24.0-34.1.al7]</div><div class="line">Jan 28 09:10:07 iZwz95gaul6x9167sqdqz4Z rsyslogd[1318]: imjournal: journal reloaded... [v8.24.0-34.1.al7 try http://www.rsyslog.com/e/0 ]</div><div class="line">Jan 28 10:27:48 iZwz95gaul6x9167sqdqz4Z rsyslogd[1318]: sd_journal_get_cursor() failed: &apos;Cannot assign requested address&apos;  [v8.24.0-34.1.al7]</div><div class="line">Jan 28 10:27:49 iZwz95gaul6x9167sqdqz4Z rsyslogd[1318]: imjournal: journal reloaded... [v8.24.0-34.1.al7 try http://www.rsyslog.com/e/0 ]</div><div class="line">Jan 28 11:45:23 iZwz95gaul6x9167sqdqz4Z rsyslogd[1318]: sd_journal_get_cursor() failed: &apos;Cannot assign requested address&apos;  [v8.24.0-34.1.al7]</div><div class="line">Jan 28 11:45:24 iZwz95gaul6x9167sqdqz4Z rsyslogd[1318]: imjournal: journal reloaded... [v8.24.0-34.1.al7 try http://www.rsyslog.com/e/0 ]</div><div class="line">Jan 28 13:03:00 iZwz95gaul6x9167sqdqz4Z rsyslogd[1318]: sd_journal_get_cursor() failed: &apos;Cannot assign requested address&apos;  [v8.24.0-34.1.al7]</div><div class="line">Jan 28 13:03:01 iZwz95gaul6x9167sqdqz4Z rsyslogd[1318]: imjournal: journal reloaded... [v8.24.0-34.1.al7 try http://www.rsyslog.com/e/0 ]</div><div class="line">Jan 28 14:20:42 iZwz95gaul6x9167sqdqz4Z rsyslogd[1318]: sd_journal_get_cursor() failed: &apos;Cannot assign requested address&apos;  [v8.24.0-34.1.al7]</div><div class="line">Jan 28 14:20:42 iZwz95gaul6x9167sqdqz4Z rsyslogd[1318]: imjournal: journal reloaded... [v8.24.0-34.1.al7 try http://www.rsyslog.com/e/0 ] </div><div class="line"></div><div class="line"></div><div class="line"># grep HUPed /var/log/messages</div><div class="line">Jan 24 03:39:15 iZwz95gaul6x9167sqdqz4Z rsyslogd: [origin software=&quot;rsyslogd&quot; swVersion=&quot;8.24.0-34.1.al7&quot; x-pid=&quot;1318&quot; x-info=&quot;http://www.rsyslog.com&quot;] rsyslogd was HUPed</div><div class="line"></div><div class="line"># journalctl --verify</div><div class="line">PASS: /var/log/journal/20190829214900434421844640356160/system@efef6fd56e2e4c9f861d0be25c8c0781-0000000001567546-0005b9e2e02a0a4f.journal</div><div class="line">PASS: /var/log/journal/20190829214900434421844640356160/system@efef6fd56e2e4c9f861d0be25c8c0781-00000000015ae56b-0005b9ea76e922e9.journal</div><div class="line">1be1e0: Data object references invalid entry at 1d03018</div><div class="line">File corruption detected at /var/log/journal/20190829214900434421844640356160/system.journal:1d02d80 (of 33554432 bytes, 90%).</div><div class="line">FAIL: /var/log/journal/20190829214900434421844640356160/system.journal (Bad message)</div></pre></td></tr></table></figure>
<p><code>journalctl --verify</code>命令检查发现系统日志卷文件损坏</p>
<h3 id="问题根因"><a href="#问题根因" class="headerlink" title="问题根因"></a>问题根因</h3><p><a href="https://access.redhat.com/solutions/3705051" target="_blank" rel="external">来自redhat官网的描述</a></p>
<p><img src="/images/oss/e1a1cd75553b5cbe2a64e835ba9f99a7.png" alt="image.png"></p>
<p>以下是现场收集到的日志：</p>
<p><img src="/images/oss/cdfe3fb8d50ee148b816a82a432f1b88.png" alt="image.png"></p>
<p>主要是rsyslogd的sd_journal_get_cursor报错，然后导致内存泄露。</p>
<p>journald 报Bad message, 跟rsyslogd内存泄露完全没关系，实际上升级rsyslogd后也有journald bad message,但是rsyslogd的内存一直稳定在30M以内</p>
<p><a href="https://blog.csdn.net/fanren224/article/details/103991748" target="_blank" rel="external">这个CSDN的文章中有完全一样的症状</a> 但是作者的结论是：这是systemd的bug，在journald需要压缩的时候就会发生这个问题。实际上我用的是 systemd-219-62.6.al7.9.x86_64 比他描述的已经修复的版本还要要新，也还是有这个问题，所以这个结论是不对的</p>
<h3 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h3><p>1、重启rsyslog <code>systemctl restart rsyslog</code> 可以释放内存</p>
<p>2、升级rsyslog到rsyslog-8.24.0-38.1.al7.x86_64或更新的版本才能彻底修复这个问题</p>
<h3 id="一些配置方法"><a href="#一些配置方法" class="headerlink" title="一些配置方法"></a>一些配置方法</h3><p>修改配置/etc/rsyslog.conf，增加如下两行，然后重启<code>systemctl restart rsyslog</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$imjournalRatelimitInterval 0</div><div class="line">$imjournalRatelimitBurst 0</div><div class="line">12</div></pre></td></tr></table></figure>
<p>1、关掉journal压缩配置</p>
<p>vi /etc/systemd/journald.conf，把#Compress=yes改成Compress=no，之后systemctl restart systemd-journald即可</p>
<p>2、限制rsyslogd 内存大小</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">cat /etc/systemd/system/multi-user.target.wants/rsyslog.service</div><div class="line"></div><div class="line">在Service配置中添加MemoryAccounting=yes，MemoryMax=80M，MemoryHigh=8M三项如下所示。</div><div class="line">[Service]</div><div class="line">Type=notify</div><div class="line">EnvironmentFile=-/etc/sysconfig/rsyslog</div><div class="line">ExecStart=/usr/sbin/rsyslogd -n $SYSLOGD_OPTIONS</div><div class="line">Restart=on-failure</div><div class="line">UMask=0066</div><div class="line">StandardOutput=null</div><div class="line">Restart=on-failure</div><div class="line">MemoryAccounting=yes</div><div class="line">MemoryMax=80M</div><div class="line">MemoryHigh=8M</div></pre></td></tr></table></figure>
<h2 id="OOM-kill"><a href="#OOM-kill" class="headerlink" title="OOM kill"></a>OOM kill</h2><p>rsyslogd内存消耗过高后导致了OOM Kill</p>
<p><img src="/images/oss/c7332f5b48506ea1faa015cfc6ae1709.png" alt="image.png"></p>
<p><strong>RSS对应物理内存，单位是4K（page大小）</strong>，红框两个进程用了5G+2G，总内存是8G，所以触发OOM killer了</p>
<p>每次OOM Kill日志前后总带着systemd-journald的重启</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">Jan 28 19:03:04 iZwz95gaul6x9167sqdqz5Z journal: Permanent journal is using 520.0M (max allowed 500.0M, trying to leave 4.0G free of 83.7G available → current limit 520.0M).</div><div class="line">Jan 28 19:03:04 iZwz95gaul6x9167sqdqz5Z journal: Journal started</div><div class="line">Jan 28 19:03:04 iZwz95gaul6x9167sqdqz5Z kernel: AliYunDun invoked oom-killer: gfp_mask=0x6200ca(GFP_HIGHUSER_MOVABLE), nodemask=(null), order=0, oom_score_adj=0</div><div class="line">Jan 28 19:03:04 iZwz95gaul6x9167sqdqz5Z kernel: AliYunDun cpuset=/ mems_allowed=0</div><div class="line">Jan 28 19:03:04 iZwz95gaul6x9167sqdqz5Z kernel: CPU: 3 PID: 13296 Comm: AliYunDun Tainted: G           OE     4.19.57-15.1.al7.x86_64 #1</div><div class="line">Jan 28 19:03:04 iZwz95gaul6x9167sqdqz5Z kernel: Hardware name: Alibaba Cloud Alibaba Cloud ECS, BIOS 8c24b4c 04/01/2014</div><div class="line">Jan 28 19:03:04 iZwz95gaul6x9167sqdqz5Z kernel: Call Trace:</div><div class="line">Jan 28 19:03:04 iZwz95gaul6x9167sqdqz5Z kernel: dump_stack+0x5c/0x7b</div><div class="line">Jan 28 19:03:04 iZwz95gaul6x9167sqdqz5Z kernel: dump_header+0x77/0x29f</div><div class="line">***</div><div class="line">Jan 28 19:03:04 iZwz95gaul6x9167sqdqz5Z kernel: [  18118]     0 18118    28218      255   245760        0             0 sshd</div><div class="line">Jan 28 19:03:04 iZwz95gaul6x9167sqdqz5Z kernel: Out of memory: Kill process 18665 (java) score 617 or sacrifice child</div><div class="line">Jan 28 19:03:04 iZwz95gaul6x9167sqdqz5Z kernel: Killed process 18665 (java) total-vm:8446992kB, anon-rss:4905856kB, file-rss:0kB, shmem-rss:0kB</div><div class="line">Jan 28 19:03:04 iZwz95gaul6x9167sqdqz5Z kernel: oom_reaper: reaped process 18665 (java), now anon-rss:0kB, file-rss:0kB, shmem-rss:0kB</div><div class="line">Jan 28 19:03:04 iZwz95gaul6x9167sqdqz5Z systemd: systemd-journald.service watchdog timeout (limit 3min)!</div><div class="line">Jan 28 19:03:04 iZwz95gaul6x9167sqdqz5Z rsyslogd: sd_journal_get_cursor() failed: &apos;Cannot assign requested address&apos;  [v8.24.0-34.1.al7]</div><div class="line">Jan 28 19:03:04 iZwz95gaul6x9167sqdqz5Z rsyslogd: imjournal: journal reloaded... [v8.24.0-34.1.al7 try http://www.rsyslog.com/e/0 ]</div><div class="line">Jan 28 20:14:38 iZwz95gaul6x9167sqdqz5Z rsyslogd: imjournal: journal reloaded... [v8.24.0-57.1.al7 try http://www.rsyslog.com/e/0 ]</div></pre></td></tr></table></figure>
<p><img src="/images/oss/45008a8323742fb7f145211a6281afbc.png" alt="image.png"></p>
<p>OOM kill前大概率伴随着systemd-journald 重启是因为watch dog timeout(limit 3min)，造成timeout的原因是journald定期要把日志刷到磁盘上，然后要么是内存不够，要么是io负载太重，导致刷磁盘这个过程非常慢，于是就timeout了。</p>
<p>当然systemd-journald 重启也不一定意味着OOM Killer，只是肯定是内存比较紧张了。</p>
<h2 id="What-is-the-difference-between-syslog-rsyslog-and-syslog-ng"><a href="#What-is-the-difference-between-syslog-rsyslog-and-syslog-ng" class="headerlink" title="What is the difference between syslog, rsyslog and syslog-ng? "></a><a href="https://serverfault.com/questions/692309/what-is-the-difference-between-syslog-rsyslog-and-syslog-ng" target="_blank" rel="external">What is the difference between syslog, rsyslog and syslog-ng? </a></h2><p>Basically, they are all the same, in the way they all permit the logging of data from different types of systems in a central repository.</p>
<p>But they are three different project, each project trying to improve the previous one with more reliability and functionalities.</p>
<p>The <code>Syslog</code> project was the very first project. It started in 1980. It is the root project to <code>Syslog</code> protocol. At this time Syslog is a very simple protocol. At the beginning it only supports UDP for transport, so that it does not guarantee the delivery of the messages.</p>
<p>Next came <code>syslog-ng</code> in 1998. It extends basic <code>syslog</code> protocol with new features like:</p>
<ul>
<li>content-based filtering</li>
<li>Logging directly into a database</li>
<li>TCP for transport</li>
<li>TLS encryption</li>
</ul>
<p>Next came <code>Rsyslog</code> in 2004. It extends <code>syslog</code> protocol with new features like:</p>
<ul>
<li>RELP Protocol support</li>
<li>Buffered operation support</li>
</ul>
<h2 id="rsyslog和journald的基础知识"><a href="#rsyslog和journald的基础知识" class="headerlink" title="rsyslog和journald的基础知识"></a>rsyslog和journald的基础知识</h2><p><code>systemd-journald</code>是用来协助<code>rsyslog</code>记录系统启动服务和服务启动失败的情况等等. <code>systemd-journald</code>使用内存保存记录, 系统重启记录会丢失. 所有还要用<code>rsyslog</code>来记录分类信息, 如上面<code>/etc/rsyslog.d/listen.conf</code>中的<code>syslog</code>分类.</p>
<p><code>systemd-journald</code>跟随systemd开机就启动，能及时记录所有日志：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"># systemd-analyze critical-chain systemd-journald.service</div><div class="line">The time after the unit is active or started is printed after the &quot;@&quot; character.</div><div class="line">The time the unit takes to start is printed after the &quot;+&quot; character.</div><div class="line"></div><div class="line">systemd-journald.service +13ms</div><div class="line">└─system.slice</div><div class="line">  └─-.slice</div></pre></td></tr></table></figure>
<p>systemd-journald 由于是使用于内存的登录文件记录方式，因此重新开机过后，开机前的登录文件信息当然就不会被记载了。 为此，我们还是建议启动 rsyslogd 来协助分类记录！也就是说， systemd-journald 用来管理与查询这次开机后的登录信息，而 rsyslogd 可以用来记录以前及现在的所以数据到磁盘文件中，方便未来进行查询喔！</p>
<p><strong>Tips</strong> 虽然 systemd-journald 所记录的数据其实是在内存中，但是系统还是利用文件的型态将它记录到 /run/log/ 下面！ 不过我们从前面几章也知道， /run 在 CentOS 7 其实是内存内的数据，所以重新开机过后，这个 /run/log 下面的数据当然就被刷新，旧的当然就不再存在了！</p>
<blockquote>
<p>其实鸟哥是这样想的，既然我们还有 rsyslog.service 以及 logrotate 的存在，因此这个 systemd-journald.service 产生的登录文件， 个人建议最好还是放置到 /run/log 的内存当中，以加快存取的速度！而既然 rsyslog.service 可以存放我们的登录文件， 似乎也没有必要再保存一份 journal 登录文件到系统当中就是了。单纯的建议！如何处理，依照您的需求即可喔！</p>
</blockquote>
<p><strong><code>system-journal</code>服务监听 <code>/dev/log</code> socket获取日志, 保存在内存中, 并间歇性的写入<code>/var/log/journal</code>目录中.</strong></p>
<p><code>rsyslog</code>服务启动后监听<code>/run/systemd/journal/socket</code> 获取syslog类型日志, 并写入<code>/var/log/messages</code>文件中. </p>
<p>获取日志时需要记录日志条目的<code>position</code>到<code>/var/lib/rsyslog/imjournal.state</code>文件中.</p>
<p>比如haproxy日志配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"># cat /etc/haproxy/haproxy.cfg</div><div class="line">global</div><div class="line"># log发给journald(journald监听 /dev/log)</div><div class="line">        log /dev/log    local1 warning</div></pre></td></tr></table></figure>
<p>以下是drds 的iptables日志配置，将tcp reset包记录下来，默认iptable日志输出到/varlog/messages中（dmesg也能看到），然后可以通过rsyslog.d 配置将这部分日志输出到单独的文件中：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"># 配置iptables 日志，增加 [drds] 标识</div><div class="line"># cat /home/admin/drds-worker/install/drds_filter.conf</div><div class="line"># Generated by iptables-save v1.4.21 on Wed Apr  1 11:39:31 2020</div><div class="line">*filter</div><div class="line">:INPUT ACCEPT [557:88127]</div><div class="line">:FORWARD ACCEPT [0:0]</div><div class="line">:OUTPUT ACCEPT [527:171711]</div><div class="line">-A INPUT -p tcp -m tcp ! --sport 3406  --tcp-flags RST RST -j LOG --log-prefix &quot;[drds] &quot; --log-level 7 --log-tcp-sequence --log-tcp-options --log-ip-options</div><div class="line"># -A INPUT -p tcp -m tcp ! --dport 3406  --tcp-flags RST RST -j LOG --log-prefix &quot;[drds] &quot; --log-level7 --log-tcp-sequence --log-tcp-options --log-ip-options</div><div class="line">-A OUTPUT -p tcp -m tcp ! --sport 3406 --tcp-flags RST RST -j LOG --log-prefix &quot;[drds] &quot; --log-level 7 --log-tcp-sequence --log-tcp-options --log-ip-options</div><div class="line">COMMIT</div><div class="line"># Completed on Wed Apr  1 11:39:31 2020</div><div class="line"></div><div class="line">#通过rsyslogd将日志写出到指定位置(不配置的话默认输出到 dmesg)</div><div class="line"># cat /etc/rsyslog.d/drds_filter_log.conf</div><div class="line">:msg, startswith, &quot;[drds]&quot; -/home/admin/logs/tcp-rt/drds-tcp.log</div></pre></td></tr></table></figure>
<h3 id="journald-log持久化"><a href="#journald-log持久化" class="headerlink" title="journald log持久化"></a>journald log持久化</h3><p>创建 /var/log/journal 文件夹后默认会持久化，设置持久化后 /run/log 里面就没有日志了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line"># cat /etc/systemd/journald.conf</div><div class="line">#  This file is part of systemd.</div><div class="line">#</div><div class="line">#  systemd is free software; you can redistribute it and/or modify it</div><div class="line">#  under the terms of the GNU Lesser General Public License as published by</div><div class="line">#  the Free Software Foundation; either version 2.1 of the License, or</div><div class="line">#  (at your option) any later version.</div><div class="line">#</div><div class="line"># Entries in this file show the compile time defaults.</div><div class="line"># You can change settings by editing this file.</div><div class="line"># Defaults can be restored by simply deleting this file.</div><div class="line">#</div><div class="line"># See journald.conf(5) for details.</div><div class="line"></div><div class="line">[Journal]</div><div class="line">#Storage=auto  //默认如果有 /var/log/journal 目录就会持久化到这里</div><div class="line">Compress=no</div><div class="line">#Seal=yes</div><div class="line">#SplitMode=uid</div><div class="line">#SyncIntervalSec=5m</div><div class="line">#RateLimitInterval=30s</div><div class="line">#RateLimitBurst=1000</div><div class="line">SystemMaxUse=500M   //最多保留500M日志文件，免得撑爆磁盘</div><div class="line">#SystemKeepFree=</div><div class="line">#SystemMaxFileSize=</div><div class="line">#RuntimeMaxUse=</div><div class="line">#RuntimeKeepFree=</div><div class="line">#RuntimeMaxFileSize=</div><div class="line">#MaxRetentionSec=</div><div class="line">#MaxFileSec=1month</div><div class="line">#ForwardToSyslog=yes</div><div class="line">#ForwardToKMsg=no</div><div class="line">#ForwardToConsole=no</div><div class="line">#ForwardToWall=yes</div><div class="line">#TTYPath=/dev/console</div><div class="line">#MaxLevelStore=debug</div><div class="line">#MaxLevelSyslog=debug</div><div class="line">#MaxLevelKMsg=notice</div><div class="line">#MaxLevelConsole=info</div><div class="line">#MaxLevelWall=emerg</div><div class="line">#LineMax=48K</div></pre></td></tr></table></figure>
<p>清理日志保留1M：journalctl –vacuum-size=1M </p>
<p>设置最大保留500M日志： journalctl –vacuum-size=500</p>
<h3 id="rsyslogd"><a href="#rsyslogd" class="headerlink" title="rsyslogd"></a>rsyslogd</h3><p>以下内容来自鸟哥的书：</p>
<p>CentOS 7 除了保有既有的 rsyslog.service 之外，其实最上游还使用了 systemd 自己的登录文件日志管理功能喔！他使用的是 systemd-journald.service 这个服务来支持的。基本上，系统由 systemd 所管理，那所有经由 systemd 启动的服务，如果再启动或结束的过程中发生一些问题或者是正常的讯息， 就会将该讯息由 systemd-journald.service 以二进制的方式记录下来，之后再将这个讯息发送给 rsyslog.service 作进一步的记载。</p>
<p>基本上， rsyslogd 针对各种服务与讯息记录在某些文件的配置文件就是 /etc/rsyslog.conf， 这个文件规定了“（1）什么服务 （2）的什么等级讯息 （3）需要被记录在哪里（设备或文件）” 这三个咚咚，所以设置的语法会是这样：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">$cat /etc/rsyslog.conf</div><div class="line">服务名称[.=!]讯息等级        讯息记录的文件名或设备或主机</div><div class="line"># 下面以 mail 这个服务产生的 info 等级为例：</div><div class="line">mail.info            /var/log/maillog_info</div><div class="line"># 这一行说明：mail 服务产生的大于等于 info 等级的讯息，都记录到</div><div class="line"># /var/log/maillog_info 文件中的意思。</div></pre></td></tr></table></figure>
<p><img src="/images/oss/1cce7612a84cf1a1addceeff6032cb5c.png" alt="syslog 所制订的服务名称与软件调用的方式"></p>
<p> CentOS 7.x 默认的 rsyslogd 本身就已经具有远程日志服务器的功能了， 只是默认并没有启动该功能而已。你可以通过 man rsyslogd 去查询一下相关的选项就能够知道啦！ 既然是远程日志服务器，那么我们的 Linux 主机当然会启动一个端口来监听了，那个默认的端口就是 UDP 或 TCP 的 port 514 </p>
<p><img src="/images/oss/40740cd5cfc8896c07c15b959420646f.png" alt="image.png"></p>
<p>Server配置如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">$ cat /etc/rsyslog.conf</div><div class="line"># 找到下面这几行：</div><div class="line"># Provides UDP syslog reception</div><div class="line">#$ModLoad imudp</div><div class="line">#$UDPServerRun 514</div><div class="line"></div><div class="line"># Provides TCP syslog reception</div><div class="line">#$ModLoad imtcp</div><div class="line">#$InputTCPServerRun 514</div><div class="line"># 上面的是 UDP 端口，下面的是 TCP 端口！如果你的网络状态很稳定，就用 UDP 即可。</div><div class="line"># 不过，如果你想要让数据比较稳定传输，那么建议使用 TCP 啰！所以修改下面两行即可！</div><div class="line">$ModLoad imtcp</div><div class="line">$InputTCPServerRun 514</div><div class="line"></div><div class="line"># 2\. 重新启动与观察 rsyslogd 喔！</div><div class="line">[root@study ~]# systemctl restart rsyslog.service</div><div class="line">[root@study ~]# netstat -ltnp &amp;#124; grep syslog</div><div class="line">Proto Recv-Q Send-Q Local Address  Foreign Address   State    PID/Program name</div><div class="line">tcp        0      0 0.0.0.0:514    0.0.0.0:*         LISTEN   2145/rsyslogd</div><div class="line">tcp6       0      0 :::514         :::*              LISTEN   2145/rsyslogd</div><div class="line"># 嘿嘿！你的登录文件主机已经设置妥当啰！很简单吧！</div></pre></td></tr></table></figure>
<p>client配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ cat /etc/rsyslog.conf</div><div class="line">*.*       @@192.168.1.100</div><div class="line">#*.*       @192.168.1.100  # 若用 UDP 传输，设置要变这样！</div></pre></td></tr></table></figure>
<p>常见的几个系统日志有哪些呢？一般而言，有下面几个：</p>
<ul>
<li>/var/log/boot.log： 开机的时候系统核心会去侦测与启动硬件，接下来开始各种核心支持的功能启动等。这些流程都会记录在 /var/log/boot.log 里面哩！ 不过这个文件只会存在这次开机启动的信息，前次开机的信息并不会被保留下来！</li>
<li>/var/log/cron： 还记得<a href="https://wizardforcel.gitbooks.io/vbird-linux-basic-4e/Text/index.html" target="_blank" rel="external">第十五章例行性工作调度</a>吧？你的 crontab 调度有没有实际被进行？ 进行过程有没有发生错误？你的 /etc/crontab 是否撰写正确？在这个登录文件内查询看看。</li>
<li>/var/log/dmesg： 记录系统在开机的时候核心侦测过程所产生的各项信息。由于 CentOS 默认将开机时核心的硬件侦测过程取消显示， 因此额外将数据记录一份在这个文件中；</li>
<li>/var/log/lastlog： 可以记录系统上面所有的帐号最近一次登陆系统时的相关信息。<a href="https://wizardforcel.gitbooks.io/vbird-linux-basic-4e/Text/index.html#uselinux_find" target="_blank" rel="external">第十三章讲到的 lastlog</a> 指令就是利用这个文件的记录信息来显示的。</li>
<li>/var/log/maillog 或 /var/log/mail/*： 记录邮件的往来信息，其实主要是记录 postfix （SMTP 协定提供者） 与 dovecot （POP3 协定提供者） 所产生的讯息啦。 SMTP 是发信所使用的通讯协定， POP3 则是收信使用的通讯协定。 postfix 与 dovecot 则分别是两套达成通讯协定的软件。</li>
<li>/var/log/messages： 这个文件相当的重要，几乎系统发生的错误讯息 （或者是重要的信息） 都会记录在这个文件中； 如果系统发生莫名的错误时，这个文件是一定要查阅的登录文件之一。</li>
<li>/var/log/secure： 基本上，只要牵涉到“需要输入帐号密码”的软件，那么当登陆时 （不管登陆正确或错误） 都会被记录在此文件中。 包括系统的 login 程序、图形接口登陆所使用的 gdm 程序、 su, sudo 等程序、还有网络连线的 ssh, telnet 等程序， 登陆信息都会被记载在这里；</li>
<li>/var/log/wtmp, /var/log/faillog： 这两个文件可以记录正确登陆系统者的帐号信息 （wtmp） 与错误登陆时所使用的帐号信息 （faillog） ！ 我们在<a href="https://wizardforcel.gitbooks.io/vbird-linux-basic-4e/Text/index.html#last" target="_blank" rel="external">第十章谈到的 last</a> 就是读取 wtmp 来显示的， 这对于追踪一般帐号者的使用行为很有帮助！</li>
<li>/var/log/httpd/<em>, /var/log/samba/</em>： 不同的网络服务会使用它们自己的登录文件来记载它们自己产生的各项讯息！上述的目录内则是个别服务所制订的登录文件。</li>
</ul>
<h2 id="journalctl-常用参数"><a href="#journalctl-常用参数" class="headerlink" title="journalctl 常用参数"></a><a href="https://linuxhint.com/journalctl-tail-and-cheatsheet/" target="_blank" rel="external">journalctl 常用参数</a></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">-n or –lines= Show the most recent **n** number of log lines</div><div class="line"></div><div class="line">-f or –follow Like a tail operation for viewing live updates</div><div class="line"></div><div class="line">-S, –since=, -U, –until= Search based on a date. “2019-07-04 13:19:17”, “00:00:00”, “yesterday”, “today”, “tomorrow”, “now” are valid formats. For complete time and date specification, see systemd.time(7)</div><div class="line"></div><div class="line">-u service unit</div></pre></td></tr></table></figure>
<p>清理journald日志</p>
<blockquote>
<p> journalctl –vacuum-size=1M &amp;&amp; journalctl –vacuum-size=500</p>
</blockquote>
<h2 id="logrotate"><a href="#logrotate" class="headerlink" title="logrotate"></a>logrotate</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">/var/log/cron</div><div class="line">&#123;</div><div class="line">    sharedscripts</div><div class="line">    postrotate</div><div class="line">        /bin/kill -HUP `cat /var/run/syslogd.pid 2&gt; /dev/null` 2&gt; /dev/null || true</div><div class="line">    endscript</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="kill-HUP"><a href="#kill-HUP" class="headerlink" title="kill -HUP"></a><a href="https://unix.stackexchange.com/questions/440004/why-is-kill-hup-used-in-logrotate-in-rhel-is-it-necessary-in-all-cases" target="_blank" rel="external">kill -HUP</a></h3><p>Generally services keep the log files opened while they are running. This mean that they do not care if the log files are renamed/moved or deleted they will continue to write to the open file handled.</p>
<p>When logrotate move the files, the services keep writing to the same file.</p>
<p>Example: syslogd will write to /var/log/cron.log. Then logrotate will rename the file to /var/log/cron.log.1, so syslogd will keep writing to the open file /var/log/cron.log.1.</p>
<p>Sending the HUP signal to syslogd will force him to close existing file handle and open new file handle to the original path /var/log/cron.log which will create a new file.</p>
<p>The use of the HUP signal instead of another one is at the discretion of the program. Some services like php-fpm will listen to the USR1 signal to reopen it’s file handle without terminating itself.</p>
<p>不过还得看应用是否屏蔽了 HUP 信号</p>
<h2 id="systemd"><a href="#systemd" class="headerlink" title="systemd"></a>systemd</h2><p>sudo systemctl list-unit-files –type=service | grep enabled //列出启动项</p>
<p> journalctl -b -1 //复审前一次启动， -2 复审倒数第 2 次启动. 重演你的系统启动的所有消息</p>
<p>sudo systemd-analyze blame   <strong>sudo systemd-analyze critical-chain</strong></p>
<p>systemd-analyze critical-chain –fuzz 1h</p>
<p>sudo systemd-analyze blame networkd</p>
<p>systemd-analyze critical-chain network.target local-fs.target</p>
<p><img src="/images/oss/bb21293e-9b52-40f9-9ab2-7c5aeb7beca1.png" alt="img"></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>一模一样的症状，但是根因找错了：<a href="https://blog.csdn.net/fanren224/article/details/103991748" target="_blank" rel="external">rsyslog占用内存高</a> </p>
<p><a href="https://access.redhat.com/solutions/3705051" target="_blank" rel="external">https://access.redhat.com/solutions/3705051</a></p>
<p><a href="https://sunsea.im/rsyslogd-systemd-journald-high-memory-solution.html" target="_blank" rel="external">https://sunsea.im/rsyslogd-systemd-journald-high-memory-solution.html</a></p>
<p><a href="https://wizardforcel.gitbooks.io/vbird-linux-basic-4e/content/160.html" target="_blank" rel="external">鸟哥 journald 介绍</a></p>
<p><a href="https://linuxhint.com/journalctl-tail-and-cheatsheet/" target="_blank" rel="external">journalctl tail and cheatsheet</a></p>
<p><a href="https://lp007819.wordpress.com/2015/01/17/systemd-journal-介绍/" target="_blank" rel="external">Journal的由来</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/01/15/TCP传输速度案例分析/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/01/15/TCP传输速度案例分析/" itemprop="url">TCP传输速度案例分析</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-01-15T17:30:03+08:00">
                2021-01-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/TCP/" itemprop="url" rel="index">
                    <span itemprop="name">TCP</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="TCP传输速度案例分析"><a href="#TCP传输速度案例分析" class="headerlink" title="TCP传输速度案例分析"></a>TCP传输速度案例分析</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>TCP传输速度受网络带宽和传输窗口的影响（接收、发送、拥塞窗口），带宽我们没办法改变，以下案例主要是讨论rt、窗口如何影响速度。</p>
<p>详细的buffer、rt对TCP传输速度的影响请看这篇：</p>
<p> <a href="/2019/09/28/就是要你懂TCP--性能和发送接收Buffer的关系/">就是要你懂TCP–性能和发送接收Buffer的关系：发送窗口大小(Buffer)、接收窗口大小(Buffer)对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响。BDP、RT、带宽对传输速度又是怎么影响的</a></p>
<p>以及 <a href="/2018/06/14/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E6%9C%80%E7%BB%8F%E5%85%B8%E7%9A%84TCP%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98/">就是要你懂TCP–最经典的TCP性能问题 Nagle和Delay ack</a></p>
<p>上面两篇以及下面几个案例读完，应该所有TCP传输速度问题都能解决了，Good Luck！</p>
<h2 id="前后端rtt差异大-vip下载慢的案例"><a href="#前后端rtt差异大-vip下载慢的案例" class="headerlink" title="前后端rtt差异大+vip下载慢的案例"></a>前后端rtt差异大+vip下载慢的案例</h2><p>来源：<a href="https://mp.weixin.qq.com/s/er8vTKZUcahA6-Pf8DZBng" target="_blank" rel="external">https://mp.weixin.qq.com/s/er8vTKZUcahA6-Pf8DZBng</a> 文章中的trace-cmd工具也不错</p>
<p>如下三个链路，有一个不正常了</p>
<p><img src="/images/oss/2422ae219d3b27cfe8c799642662d5b2.png" alt="image.png"></p>
<p>首先通过 ss -it dst “ip:port” 来分析cwnd、ssthresh、buffer，到底是什么导致了传输慢</p>
<h3 id="原因TCPLossProbe："><a href="#原因TCPLossProbe：" class="headerlink" title="原因TCPLossProbe："></a>原因TCPLossProbe：</h3><p>如果尾包发生了丢包，没有新包可发送触发多余的dup ack来实现快速重传，如果完全依赖RTO超时来重传，代价太大，那如何能优化解决这种尾丢包的情况。也就是在某些情况下一个可以的重传包就能触发ssthresh减半，从而导致传输速度上不来。</p>
<p>本案例中，因为client到TGW跨了地域，导致rtt增大，但是TGW和STGW之间的rtt很小，导致握手完毕后STGW认为和client的rtt很小，所以很快就触发了丢包重传，实际没有丢包，只是rtt变大了，所以触发了如上的TLP( PTO=max(2rtt, 10ms) ， 因为只有一次重传并收到了 dup，还是不应该触发TLP，但是因为老版本kernel bug导致，4.0的kernel修复了这个问题， 函数 is_tlp_dupack)</p>
<p>握手完毕后第七号包很快重传了</p>
<p><img src="/images/oss/2867daa600363af61f8f971479246858.png" alt="image.png"></p>
<h3 id="观察："><a href="#观察：" class="headerlink" title="观察："></a>观察：</h3><p>netstat -s |grep TCPLossProbes</p>
<h3 id="解决："><a href="#解决：" class="headerlink" title="解决："></a>解决：</h3><p>tcp_early_retrans可用于开启和关闭ER和TLP，默认是3（enable TLP and delayed ER），sysctl -w net.ipv4.tcp_early_retrans=2 关掉TLP</p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>kernel版本小于4.0+TLP开启+VIP代理导致RS认为rtt很小，实际比较大，这两个条件下就会出现如上问题。</p>
<p>这个问题一看就是跟client和VIP代理之间的rtt扩大有关系，不过不是因为扩大后发送窗口不够之类导致的。</p>
<h2 id="长肥网络（高rtt）场景下tcp-metrics记录的ssthresh太小导致传输慢的案例"><a href="#长肥网络（高rtt）场景下tcp-metrics记录的ssthresh太小导致传输慢的案例" class="headerlink" title="长肥网络（高rtt）场景下tcp_metrics记录的ssthresh太小导致传输慢的案例"></a>长肥网络（高rtt）场景下tcp_metrics记录的ssthresh太小导致传输慢的案例</h2><p><a href="https://www.atatech.org/articles/109967" target="_blank" rel="external">https://www.atatech.org/articles/109967</a></p>
<blockquote>
<p>tcp_metrics会记录下之前已关闭tcp 连接的状态，包括发送端拥塞窗口和拥塞控制门限，如果之前网络有一段时间比较差或者丢包比较严重，就会导致tcp 的拥塞控制门限ssthresh降低到一个很低的值，这个值在连接结束后会被tcp_metrics cache 住，在新连接建立时，即使网络状况已经恢复，依然会继承 tcp_metrics 中cache 的一个很低的ssthresh 值，在长肥管道情况下，新连接经历短暂的“慢启动”后，随即进入缓慢的拥塞控制阶段, 导致连接速度很难在短时间内上去。而后面的连接，需要很特殊的场景之下才能将ssthresh 再次推到一个比较高的值缓存下来，因此很有很能在接下来的很长一段时间，连接的速度都会处于一个很低的水平</p>
</blockquote>
<p>因为 tcp_metrics记录的ssthresh非常小，导致后面新的tcp连接传输数据时很快进入拥塞控制阶段，如果传输的文件不大的话就没有机会将ssthresh撑大。除非传输一个特别大的文件，忍受拥塞控制阶段的慢慢增长，最后tcp_metrics记录下撑大后的ssthresh，整个网络才会恢复正常。</p>
<p>所以关闭 tcp_metrics其实是个不错的选择： net.ipv4.tcp_no_metrics_save = 1 </p>
<p>或者清除： sudo ip tcp_metrics flush all</p>
<h3 id="从系统cache中查看-tcp-metrics-item"><a href="#从系统cache中查看-tcp-metrics-item" class="headerlink" title="从系统cache中查看 tcp_metrics item"></a>从系统cache中查看 tcp_metrics item</h3><pre><code>$sudo ip tcp_metrics show | grep  100.118.58.7
100.118.58.7 age 1457674.290sec tw_ts 3195267888/5752641sec ago rtt 1000us rttvar 1000us ssthresh 361 cwnd 40 ----这两个值对传输性能很重要

192.168.1.100 age 1051050.859sec ssthresh 4 cwnd 2 rtt 4805us rttvar 4805us source 192.168.0.174 ---这条记录有问题，缓存的ssthresh 4 cwnd 2都太小，传输速度一定慢 

清除 tcp_metrics, sudo ip tcp_metrics flush all 
关闭 tcp_metrics 功能，net.ipv4.tcp_no_metrics_save = 1
sudo ip tcp_metrics delete 100.118.58.7
</code></pre><p>每个连接的ssthresh默认是个无穷大的值，但是内核会cache对端ip上次的ssthresh（大部分时候两个ip之间的拥塞窗口大小不会变），这样大概率到达ssthresh之后就基本拥塞了，然后进入cwnd的慢增长阶段。</p>
<h2 id="长肥网络（rt很高、带宽也高）下接收窗口对传输性能的影响"><a href="#长肥网络（rt很高、带宽也高）下接收窗口对传输性能的影响" class="headerlink" title="长肥网络（rt很高、带宽也高）下接收窗口对传输性能的影响"></a>长肥网络（rt很高、带宽也高）下接收窗口对传输性能的影响</h2><p>最后通过一个实际碰到的案例，涉及到了接收窗口、发送Buffer以及高延时情况下的性能问题</p>
<p>案例描述：从中国访问美国的服务器下载图片，只能跑到220K，远远没有达到带宽能力，其中中美之间的网络延时时150ms，这个150ms已经不能再优化了。业务结构是：</p>
<p>client ——150ms—–&gt;&gt;&gt;LVS—1ms–&gt;&gt;&gt;美国的统一接入server—–1ms—–&gt;&gt;&gt;nginx</p>
<p>通过下载一个4M的文件大概需要20秒，分别在client和nginx上抓包来分析这个问题（统一接入server没权限上去）</p>
<h3 id="Nginx上抓包"><a href="#Nginx上抓包" class="headerlink" title="Nginx上抓包"></a>Nginx上抓包</h3><p><img src="/images/oss/259767fb17f7dbffe7f77ab059c47dbd.png" alt="image.png"></p>
<p>从这里可以看到Nginx大概在60ms内就将4M的数据都发完了</p>
<h3 id="client上抓包"><a href="#client上抓包" class="headerlink" title="client上抓包"></a>client上抓包</h3><p><img src="/images/oss/466fba92829f6a922ccd2d57a7e3fdac.png" alt="image.png"></p>
<p>从这个图上可以清楚看到大概每传输大概30K数据就有一个150ms的等待平台，这个150ms基本是client到美国的rt。</p>
<p>从我们前面的阐述可以清楚了解到因为rt比较高，统一接入server每发送30K数据后要等150ms才能收到client的ack，然后继续发送，猜是因为上面设置的发送buffer大概是30K。</p>
<p>检查统一接入server的配置，可以看到接入server的配置里面果然有个32K buffer设置</p>
<h3 id="将buffer改大"><a href="#将buffer改大" class="headerlink" title="将buffer改大"></a>将buffer改大</h3><p>速度可以到420K，但是还没有跑满带宽：</p>
<p><img src="/images/oss/93e254c5154ce2e065bec9fb34f3db2b.png" alt="image.png"></p>
<p><img src="/images/oss/0a8c68a58da6f169573b57cde0ffba93.png" alt="image.png"></p>
<p>接着看一下client上的抓包</p>
<p><img src="/images/oss/822737a4ed6ffe6b920d4b225a1be5bf.png" alt="image.png"></p>
<p>可以清楚看到 client的接收窗口是64K， 64K*1000/150=426K 这个64K很明显是16位的最大值，应该是TCP握手有一方不支持window scaling factor</p>
<p>那么继续分析一下握手包，syn：</p>
<p><img src="/images/oss/004886698ddbaa1cbc8342a9cd667c76.png" alt="image.png"></p>
<p>说明client是支持的，再看 syn+ack：</p>
<p><img src="/images/oss/70155e021390cb1ee07091c306c375f4.png" alt="image.png"></p>
<p>可以看到服务端不支持，那就最大只能用到64K。需要修改服务端代理程序，这主要是LVS或者代理的锅。</p>
<p>如果内网之间rt很小这个锅不会爆发，一旦网络慢一点就把问题恶化了</p>
<p>比如这是这个应用的开发人员的反馈：</p>
<p><img src="/images/oss/a08a204ec7ad4bba7867dacea1668322.png" alt="image.png"></p>
<p>长肥网络就像是很长很宽的高速公路，上面可以同时跑很多车，而如果发车能力不够，就容易跑不满高速公路。<br>在rt很短的时候可以理解为高速公路很短，所以即使发车慢也还好，因为车很快就到了，到了后就又能发新车了。rt很长的话就要求更大的仓库了。</p>
<p>整个这个问题，我最初拿到的问题描述结构是这样的（不要笑用户连自己的业务结构都描述不清）：</p>
<p>client ——150ms—–&gt;&gt;&gt;nginx</p>
<p>实际开发人员也不能完全描述清楚结构，从抓包中慢慢分析反推他们的结构，到最后问题的解决。</p>
<p>这个案例综合了发送窗口（32K）、接收窗口（64K，因为握手LVS不支持window scale）、rt很大将问题暴露出来（跨国网络，rt没法优化）。</p>
<p>nginx buffer 分析参考案例：<a href="https://club.perfma.com/article/433792?from=timeline" target="_blank" rel="external">https://club.perfma.com/article/433792?from=timeline</a></p>
<h2 id="应用层发包逻辑影响了BDP不能跑满"><a href="#应用层发包逻辑影响了BDP不能跑满" class="headerlink" title="应用层发包逻辑影响了BDP不能跑满"></a>应用层发包逻辑影响了BDP不能跑满</h2><p><a href="https://zhuanlan.zhihu.com/p/413732839" target="_blank" rel="external">一行代码解决scp在Internet传输慢的问题（RT高的网络环境）</a></p>
<blockquote>
<p>遇到一个迟来的case，用scp在长链路上传输文件竟然慢到无法忍受！100～200毫秒往返时延的链路，wget下载文件吞吐可达40MBps，scp却只有9MBps。</p>
<p>这次不是因为buffer导致BDP跑不满，而是也scp业务层有自己流控的逻辑导致发包慢了</p>
<p><strong>SSH允许在一个TCP连接上复用多个channel，需要对每一个channel做流控以保证公平，所以每个channel必须自己做而不是使用TCP的流控，OpenSSH的实现有问题。</strong></p>
</blockquote>
<h2 id="delay-ack拉高实际rt的案例"><a href="#delay-ack拉高实际rt的案例" class="headerlink" title="delay ack拉高实际rt的案例"></a>delay ack拉高实际rt的案例</h2><p><strong>这个案例跟速度没有关系，只是解析监控图表上的rt为什么不符合逻辑地偏高了。</strong></p>
<p>如下业务监控图：实际处理时间（逻辑服务时间1ms，rtt2.4ms，加起来3.5ms），但是系统监控到的rt（蓝线）是6ms，如果一个请求分很多响应包串行发给client，这个6ms是正常的（1+2.4*N），但实际上如果send buffer足够的话，按我们前面的理解多个响应包会并发发出去，所以如果整个rt是3.5ms才是正常的。</p>
<p><img src="/images/oss/d56f87a19a10b0ac9a3b7009641247a0.png" alt="image.png"></p>
<p>抓包来分析原因：</p>
<p><img src="/images/oss/d5e2e358dd1a24e104f54815c84875c9.png" alt="image.png"></p>
<p>实际看到大量的response都是3.5ms左右，符合我们的预期，但是有少量rt被delay ack严重影响了</p>
<p>从下图也可以看到有很多rtt超过3ms的，这些超长时间的rtt会最终影响到整个服务rt</p>
<p><img src="/images/oss/48eae3dcd7c78a68b0afd5c66f783f23.png" alt="image.png"></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="http://www.allanjude.com/bsd/AsiaBSDCon2017_-_SSH_Performance.pdf" target="_blank" rel="external">SSH Performance</a></p>
<p><a href="https://stackoverflow.com/questions/8849240/why-when-i-transfer-a-file-through-sftp-it-takes-longer-than-ftp" target="_blank" rel="external">Why when I transfer a file through SFTP, it takes longer than FTP?</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/01/03/mac路由和DSN相关知识/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/01/03/mac路由和DSN相关知识/" itemprop="url">mac 路由和DSN相关知识</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-01-03T17:30:03+08:00">
                2021-01-03
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/其它/" itemprop="url" rel="index">
                    <span itemprop="name">其它</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="mac-路由和DSN相关知识"><a href="#mac-路由和DSN相关知识" class="headerlink" title="mac 路由和DSN相关知识"></a>mac 路由和DSN相关知识</h1><p>Mac 下上网,尤其是在双网卡一起使用的时候, 一个网卡连内网，一个网卡连外网，经常会碰到ip不通(路由问题,比较好解决)或者dns解析不了问题. 或者是在通过VPN连公司网络会插入一些内网route,导致部分网络访问不了.</p>
<p>即使对Linux下的DNS解析无比熟悉了，但是在Mac下还是花了一些时间来折腾，配置不好路由和DNS是不配使用Mac的，所以记录下。</p>
<h2 id="route"><a href="#route" class="headerlink" title="route"></a>route</h2><p>如果ip不通就看路由表, 根据内外网IP增加/删除相应的路由信息,常用命令如下:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">sudo route -n add 10.176/16 192.168.3.1</div><div class="line">sudo route -n add -net 10.176.0.0/16 192.168.3.1 //添加路由, 访问10.176.0.0/16 走192.168.3.1 </div><div class="line">sudo route -n delete -net 10.176.0.0/16 192.168.3.1</div><div class="line">sudo route -n delete 0.0.0.0 192.168.184.1</div><div class="line">sudo route -n add 0.0.0.0 192.168.184.1  //添加默认路由访问外网 </div><div class="line"></div><div class="line">sudo route -n delete 0.0.0.0 192.168.3.1</div><div class="line">sudo route -n add 10.176/16 192.168.3.1</div><div class="line">sudo route -n delete 0.0.0.0 192.168.184.1 -ifscope en0</div><div class="line">sudo route -n add 0.0.0.0 192.168.184.1 </div><div class="line">sudo networksetup -setdnsservers 'Apple USB Ethernet Adapter' 202.106.196.115 202.106.0.20 114.114.114.114</div><div class="line"></div><div class="line">sudo networksetup -setdnsservers 'USB 10/100/1000 LAN' 223.5.5.5 30.30.30.30 114.114.114.114</div><div class="line"></div><div class="line">ip route get 8.8.8.8</div><div class="line">netstat -rn  //查看路由  </div><div class="line">netstat -nr -f inet  //只看ipv4相关路由</div></pre></td></tr></table></figure>
<p>如果本来IP能通,连上VPN后就通不了,那一定是VPN加入了一些更精细的路由导致原来的路由不通了,那么很简单停掉VPN就能恢复或者增加一条更精确的路有记录进去,或者删掉VPN增加的某条路由.</p>
<h2 id="DNS-解析"><a href="#DNS-解析" class="headerlink" title="DNS 解析"></a>DNS 解析</h2><p>mac下DNS解析问题搞起来比较费劲,相应的资料也不多, 经过上面的操作后如果IP能通,域名解析有问题,一般都是DNS解析出了问题</p>
<p><a href="https://shockerli.net/post/macos-hostname-scutil/" target="_blank" rel="external">mac下 /etc/resolv.conf 不再用来解析域名, 只有nslookup能用到resolv.conf</a></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">cat /etc/resolv.conf                                                </div><div class="line"><span class="meta">#</span><span class="bash"></span></div><div class="line"><span class="meta">#</span><span class="bash"> macOS Notice</span></div><div class="line"><span class="meta">#</span><span class="bash"></span></div><div class="line"><span class="meta">#</span><span class="bash"> This file is not consulted <span class="keyword">for</span> DNS hostname resolution, address</span></div><div class="line"><span class="meta">#</span><span class="bash"> resolution, or the DNS query routing mechanism used by most</span></div><div class="line"><span class="meta">#</span><span class="bash"> processes on this system.</span></div><div class="line"><span class="meta">#</span><span class="bash"></span></div><div class="line"><span class="meta">#</span><span class="bash"> To view the DNS configuration used by this system, use:</span></div><div class="line"><span class="meta">#</span><span class="bash">   scutil --dns</span></div><div class="line"></div><div class="line">scutil --dns //查看DNS 解析器</div><div class="line">scutil --nwi //查看网络</div></pre></td></tr></table></figure>
<p>解析出了问题先检查nameserver</p>
<p>scutil –dns 一般会展示一大堆的resolver, 每个resolver又可以有多个nameserver</p>
<blockquote>
<p>A scoped DNS query can use only specified network interfaces (e.g. Ethernet or WiFi), while non-scoped can use any available interface.</p>
<p>More verbosely, an application that wants to resolve a name, sends a <em>request</em> (either scoped or non-scoped) to a resolver (usually a DNS client application), if the resolver does not have the answer cached, it sends a DNS <em>query</em> to a particular nameserver (and this goes through one interface, so it is always “scoped”).</p>
<p>In your example resolver #1 “for scoped queries” can use only en0 interface (Ethernet).</p>
</blockquote>
<h3 id="修改-nameserver"><a href="#修改-nameserver" class="headerlink" title="修改 nameserver"></a>修改 nameserver</h3><p>默认用第一个resolver, 如果第一个resolver没有nameserver那么域名没法解析, 可以修改dns resolver的nameserver: </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="meta">$</span><span class="bash">networksetup -listallnetworkservices  //列出网卡service, 比如 wifi ,以下是我的 macos 输出</span></div><div class="line">An asterisk (*) denotes that a network service is disabled.</div><div class="line">USB 10/100/1000 LAN</div><div class="line">Apple USB Ethernet Adapter</div><div class="line">Wi-Fi</div><div class="line">Bluetooth PAN</div><div class="line">Thunderbolt Bridge</div><div class="line"><span class="meta">$</span><span class="bash">sudo networksetup -setdnsservers <span class="string">'Wi-Fi'</span> 202.106.196.115 202.106.0.20 114.114.114.114 //修改nameserver</span></div><div class="line"><span class="meta">$</span><span class="bash">networksetup -getdnsservers Wi-Fi //查看对应的nameserver, 跟 scutil --dns 类似</span></div></pre></td></tr></table></figure>
<p>如上, 只要是你的nameserver工作正常那么DNS就肯定回复了</p>
<p>删掉所有DNS nameserver:</p>
<blockquote>
<p>One note to anyone wanting to remove the DNS, just write “empty” (without the quotes) instead of the DNS: <code>sudo networksetup -setdnsservers &lt;networkservice&gt; empty</code></p>
</blockquote>
<h2 id="networksetup用法"><a href="#networksetup用法" class="headerlink" title="networksetup用法"></a><a href="https://www.jianshu.com/p/c84e0f972353" target="_blank" rel="external">networksetup用法</a></h2><h3 id="查看设备和配置"><a href="#查看设备和配置" class="headerlink" title="查看设备和配置"></a>查看设备和配置</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line"><span class="meta">$</span><span class="bash">networksetup -listallnetworkservices</span></div><div class="line">An asterisk (*) denotes that a network service is disabled.</div><div class="line">USB 10/100/1000 LAN</div><div class="line">Apple USB Ethernet Adapter</div><div class="line">Wi-Fi</div><div class="line">Bluetooth PAN</div><div class="line">Thunderbolt Bridge</div><div class="line">Thunderbolt Bridge 2</div><div class="line"><span class="meta"></span></div><div class="line">#<span class="bash">查看网卡配置</span></div><div class="line"><span class="meta">$</span><span class="bash">networksetup -getinfo <span class="string">"USB 10/100/1000 LAN"</span>                                   </span></div><div class="line">DHCP Configuration</div><div class="line">IP address: 30.25.25.195</div><div class="line">Subnet mask: 255.255.255.128</div><div class="line">Router: 30.25.25.254</div><div class="line">Client ID:</div><div class="line">IPv6 IP address: none</div><div class="line">IPv6 Router: none</div><div class="line">Ethernet Address: 44:67:52:02:16:d4</div><div class="line"><span class="meta"></span></div><div class="line">$<span class="bash">networksetup -listallhardwareports</span></div><div class="line">Hardware Port: USB 10/100/1000 LAN</div><div class="line">Device: en7</div><div class="line">Ethernet Address: 44:67:52:02:16:d4</div><div class="line"></div><div class="line">Hardware Port: Wi-Fi</div><div class="line">Device: en0</div><div class="line">Ethernet Address: 88:66:5a:10:e4:2b</div><div class="line"></div><div class="line">Hardware Port: Thunderbolt Bridge</div><div class="line">Device: bridge0</div><div class="line">Ethernet Address: 82:0a:d5:01:b4:00</div><div class="line"></div><div class="line">VLAN Configurations</div><div class="line">===================</div><div class="line"><span class="meta">$</span><span class="bash">networksetup -getinfo <span class="string">"Thunderbolt Bridge"</span></span></div><div class="line">DHCP Configuration</div><div class="line">Client ID:</div><div class="line">IPv6: Automatic</div><div class="line">IPv6 IP address: none</div><div class="line">IPv6 Router: none</div><div class="line"></div><div class="line">//查看wifi和热点</div><div class="line">networksetup -listpreferredwirelessnetworks en0 </div><div class="line">networksetup -getairportnetwork "en0"</div></pre></td></tr></table></figure>
<h3 id="dhcp、route、domain配置"><a href="#dhcp、route、domain配置" class="headerlink" title="dhcp、route、domain配置"></a>dhcp、route、domain配置</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">[-setmanual networkservice ip subnet router]</div><div class="line"></div><div class="line">[-setdhcp networkservice [clientid]]</div><div class="line"></div><div class="line">[-setbootp networkservice]</div><div class="line"></div><div class="line">[-setmanualwithdhcprouter networkservice ip]</div><div class="line"></div><div class="line">[-getadditionalroutes networkservice]</div><div class="line"></div><div class="line">[-setadditionalroutes networkservice [dest1 mask1 gate1] [dest2 mask2 gate2] ..</div><div class="line"></div><div class="line">. [destN maskN gateN]]</div><div class="line"><span class="meta"></span></div><div class="line">#<span class="bash">给网卡配置ip、网关</span></div><div class="line"><span class="meta">$</span><span class="bash"> networksetup -getinfo <span class="string">"Apple USB Ethernet Adapter"</span>                                DHCP Configuration</span></div><div class="line">Client ID:</div><div class="line">IPv6: Automatic</div><div class="line">IPv6 IP address: none</div><div class="line">IPv6 Router: none</div><div class="line">Ethernet Address: (null)</div><div class="line"><span class="meta">$</span><span class="bash">networksetup -setmanual <span class="string">"Apple USB Ethernet Adapter"</span> 192.168.100.100 255.255.255.0 192.168.100.1</span></div><div class="line"><span class="meta">$</span><span class="bash">networksetup -getinfo <span class="string">"Apple USB Ethernet Adapter"</span></span></div><div class="line">Manual Configuration</div><div class="line">IP address: 192.168.100.100</div><div class="line">Subnet mask: 255.255.255.0</div><div class="line">Router: 192.168.100.1</div><div class="line">IPv6: Automatic</div><div class="line">IPv6 IP address: none</div><div class="line">IPv6 Router: none</div><div class="line">Ethernet Address: (null)</div></pre></td></tr></table></figure>
<h3 id="代理配置"><a href="#代理配置" class="headerlink" title="代理配置"></a>代理配置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">//ftp</div><div class="line">[-getftpproxy networkservice]</div><div class="line"></div><div class="line">[-setftpproxy networkservice domain portnumber authenticated username password]</div><div class="line"></div><div class="line">[-setftpproxystate networkservice on | off]</div></pre></td></tr></table></figure>
<p>网页</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[-getwebproxy networkservice]</div><div class="line">[-setwebproxy networkservice domain portnumber authenticated username password]</div><div class="line">[-setwebproxystate networkservice on | off]</div><div class="line"></div><div class="line">$networksetup -setwebproxy &quot;Built-in Ethernet&quot; proxy.company.com 80</div><div class="line">$networksetup -setwebproxy &quot;Built-In Ethernet&quot; proxy.company.com 80 On authusername authpassword</div></pre></td></tr></table></figure>
<p>Socks5 代理</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="meta">$</span><span class="bash">networksetup -setsocksfirewallproxy <span class="string">"USB 10/100/1000 LAN"</span> 127.0.0.1 13659</span></div><div class="line"><span class="meta">$</span><span class="bash">networksetup -getsocksfirewallproxy <span class="string">"USB 10/100/1000 LAN"</span></span></div><div class="line">Enabled: Yes</div><div class="line">Server: 127.0.0.1</div><div class="line">Port: 13659</div><div class="line">Authenticated Proxy Enabled: 0</div></pre></td></tr></table></figure>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>mac同时连wifi(外网或者vpn)和有线(内网), 如果内网干扰了访问外部ip, 就检查路由表,调整顺序. 如果内网干扰了dns,可以通过scutil –dns查看dns顺序到系统配置里去掉不必要的resolver</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://gowa.club/macOS/macOS%E7%9A%84networksetup%E5%91%BD%E4%BB%A4%E6%9D%A5%E7%AE%A1%E7%90%86%E7%BD%91%E7%BB%9C.html" target="_blank" rel="external">macOS的networksetup命令来管理网络</a></p>
<p><a href="https://www.diamondtin.com/2009/reloading-pac-script-in-mac/" target="_blank" rel="external">在Mac下使用脚本重载proxy自动配置脚本（pac）</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/01/01/网络相关知识/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/01/01/网络相关知识/" itemprop="url">网络硬件相关知识</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-01-01T17:30:03+08:00">
                2021-01-01
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/network/" itemprop="url" rel="index">
                    <span itemprop="name">network</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="网络硬件相关知识"><a href="#网络硬件相关知识" class="headerlink" title="网络硬件相关知识"></a>网络硬件相关知识</h1><p>程序员很难有机会接触到底层的一些东西,尤其是偏硬件部分,所以记录下</p>
<h2 id="光纤和普通网线的性能差异"><a href="#光纤和普通网线的性能差异" class="headerlink" title="光纤和普通网线的性能差异"></a>光纤和普通网线的性能差异</h2><p>以下都是在4.19内核的UOS，光纤交换机为锐捷，服务器是华为鲲鹏920的环境测试所得数据：</p>
<p><img src="/images/oss/553e1c5fff2dd04a668434f0da4f9d90.png" alt="image.png"></p>
<p>光纤稳定性好很多，平均rt是网线的三分之一，最大值则是网线的十分之一. 上述场景下光纤的带宽大约是网线的1.5倍. 实际光纤理论带宽一般都是万M, 网线是千M.</p>
<p>光纤接口：</p>
<p><img src="/images/oss/b67715de1b8e143f6fc17ba574bcf0c4.png" alt="image.png" style="zoom:60%;"></p>
<h3 id="单模光纤和多模光纤"><a href="#单模光纤和多模光纤" class="headerlink" title="单模光纤和多模光纤"></a>单模光纤和多模光纤</h3><p>下图绿色是多模光纤(Multi Mode Fiber),黄色是单模光纤(Single Mode Fiber), 因为光纤最好能和光模块匹配, 我们测试用的光模块都是多模的, 单模光纤线便宜,但是对应的光模块贵多了。</p>
<p>多模光模块工作波长为850nm，单模光模块工作波长为1310nm或1550nm, 从成本上来看，单模光模块所使用的设备多出多模光模块两倍，总体成本远高于多模光模块，但单模光模块的传输距离也要长于多模光模块，单模光模块最远传输距离为100km，多模光模块最远传输距离为2km。因单模光纤的传输原理为使光纤直射到中心，所以主要用作远距离数据传输，而多模光纤则为多通路传播模式，所以主要用于短距离数据传输。单模光模块适用于对距离和传输速率要求较高的大型网络中，多模光模块主要用于短途网路。</p>
<p><img src="/images/951413iMgBlog/image-20210831211315077.png" alt="image-20210831211315077"></p>
<p>ping结果比较:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div></pre></td><td class="code"><pre><div class="line">[aliyun@uos15 11:00 /home/aliyun]  以下88都是光口、89都是电口。</div><div class="line"><span class="meta">$</span><span class="bash">ping -c 10 10.88.88.16 //光纤</span></div><div class="line">PING 10.88.88.16 (10.88.88.16) 56(84) bytes of data.</div><div class="line">64 bytes from 10.88.88.16: icmp_seq=1 ttl=64 time=0.058 ms</div><div class="line">64 bytes from 10.88.88.16: icmp_seq=2 ttl=64 time=0.049 ms</div><div class="line">64 bytes from 10.88.88.16: icmp_seq=3 ttl=64 time=0.053 ms</div><div class="line">64 bytes from 10.88.88.16: icmp_seq=4 ttl=64 time=0.040 ms</div><div class="line">64 bytes from 10.88.88.16: icmp_seq=5 ttl=64 time=0.053 ms</div><div class="line">64 bytes from 10.88.88.16: icmp_seq=6 ttl=64 time=0.043 ms</div><div class="line">64 bytes from 10.88.88.16: icmp_seq=7 ttl=64 time=0.038 ms</div><div class="line">64 bytes from 10.88.88.16: icmp_seq=8 ttl=64 time=0.050 ms</div><div class="line">64 bytes from 10.88.88.16: icmp_seq=9 ttl=64 time=0.043 ms</div><div class="line">64 bytes from 10.88.88.16: icmp_seq=10 ttl=64 time=0.064 ms</div><div class="line"></div><div class="line">--- 10.88.88.16 ping statistics ---</div><div class="line">10 packets transmitted, 10 received, 0% packet loss, time 159ms</div><div class="line">rtt min/avg/max/mdev = 0.038/0.049/0.064/0.008 ms</div><div class="line"></div><div class="line">[aliyun@uos15 11:01 /home/aliyun]</div><div class="line"><span class="meta">$</span><span class="bash">ping -c 10 10.88.89.16 //电口</span></div><div class="line">PING 10.88.89.16 (10.88.89.16) 56(84) bytes of data.</div><div class="line">64 bytes from 10.88.89.16: icmp_seq=1 ttl=64 time=0.087 ms</div><div class="line">64 bytes from 10.88.89.16: icmp_seq=2 ttl=64 time=0.053 ms</div><div class="line">64 bytes from 10.88.89.16: icmp_seq=3 ttl=64 time=0.095 ms</div><div class="line">64 bytes from 10.88.89.16: icmp_seq=4 ttl=64 time=0.391 ms</div><div class="line">64 bytes from 10.88.89.16: icmp_seq=5 ttl=64 time=0.051 ms</div><div class="line">64 bytes from 10.88.89.16: icmp_seq=6 ttl=64 time=0.343 ms</div><div class="line">64 bytes from 10.88.89.16: icmp_seq=7 ttl=64 time=0.045 ms</div><div class="line">64 bytes from 10.88.89.16: icmp_seq=8 ttl=64 time=0.341 ms</div><div class="line">64 bytes from 10.88.89.16: icmp_seq=9 ttl=64 time=0.054 ms</div><div class="line">64 bytes from 10.88.89.16: icmp_seq=10 ttl=64 time=0.066 ms</div><div class="line"></div><div class="line">--- 10.88.89.16 ping statistics ---</div><div class="line">10 packets transmitted, 10 received, 0% packet loss, time 149ms</div><div class="line">rtt min/avg/max/mdev = 0.045/0.152/0.391/0.136 ms</div><div class="line"></div><div class="line">[aliyun@uos15 11:02 /u01]</div><div class="line"><span class="meta">$</span><span class="bash">scp uos.tar aliyun@10.88.89.16:/tmp/</span></div><div class="line">uos.tar                                  100% 3743MB 111.8MB/s   00:33    </div><div class="line"></div><div class="line">[aliyun@uos15 11:03 /u01]</div><div class="line"><span class="meta">$</span><span class="bash">scp uos.tar aliyun@10.88.88.16:/tmp/</span></div><div class="line">uos.tar                                   100% 3743MB 178.7MB/s   00:20    </div><div class="line"></div><div class="line">[aliyun@uos15 11:07 /u01]</div><div class="line"><span class="meta">$</span><span class="bash">sudo ping -f 10.88.89.16</span></div><div class="line">PING 10.88.89.16 (10.88.89.16) 56(84) bytes of data.</div><div class="line">--- 10.88.89.16 ping statistics ---</div><div class="line">284504 packets transmitted, 284504 received, 0% packet loss, time 702ms</div><div class="line">rtt min/avg/max/mdev = 0.019/0.040/1.014/0.013 ms, ipg/ewma 0.048/0.042 ms</div><div class="line"></div><div class="line">[aliyun@uos15 11:07 /u01]</div><div class="line"><span class="meta">$</span><span class="bash">sudo ping -f 10.88.88.16</span></div><div class="line">PING 10.88.88.16 (10.88.88.16) 56(84) bytes of data.</div><div class="line">--- 10.88.88.16 ping statistics ---</div><div class="line">299748 packets transmitted, 299748 received, 0% packet loss, time 242ms</div><div class="line">rtt min/avg/max/mdev = 0.012/0.016/0.406/0.006 ms, pipe 2, ipg/ewma 0.034/0.014 ms</div></pre></td></tr></table></figure>
<h2 id="多网卡bonding"><a href="#多网卡bonding" class="headerlink" title="多网卡bonding"></a>多网卡bonding</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash">cat ifcfg-bond0</span></div><div class="line">DEVICE=bond0</div><div class="line">TYPE=Bond</div><div class="line">ONBOOT=yes</div><div class="line">BOOTPROTO=static</div><div class="line">IPADDR=10.176.7.11</div><div class="line">NETMASK=255.255.255.0</div><div class="line"><span class="meta"></span></div><div class="line">#<span class="bash">cat /etc/sysconfig/network-scripts/ifcfg-eth0</span></div><div class="line">DEVICE=eth0</div><div class="line">TYPE=Ethernet</div><div class="line">ONBOOT=yes</div><div class="line">BOOTPROTO=none</div><div class="line">MASTER=bond0</div><div class="line">SLAVE=yes</div><div class="line"><span class="meta"></span></div><div class="line">#<span class="bash">cat /etc/sysconfig/network-scripts/ifcfg-eth1</span></div><div class="line">DEVICE=eth1</div><div class="line">TYPE=Ethernet</div><div class="line">ONBOOT=yes</div><div class="line">BOOTPROTO=none</div><div class="line">MASTER=bond0</div><div class="line">SLAVE=yes</div><div class="line"><span class="meta"></span></div><div class="line">#<span class="bash">cat /proc/net/bonding/bond0</span></div><div class="line"></div><div class="line">----加载内核bonding模块, mode=0 是RR负载均衡模式</div><div class="line"><span class="meta">#</span><span class="bash">cat /etc/modprobe.d/bonding.conf</span></div><div class="line"><span class="meta">#</span><span class="bash"> modprobe bonding</span></div><div class="line">alias bond0 bonding</div><div class="line">options bond0 mode=0 miimon=100  //这一行也可以放到bond0配置文件中,比如:BONDING_OPTS="miimon=100 mode=4 xmit_hash_policy=layer3+4" 用iperf 多连接测试bonding后的带宽发现，发送端能用上两张网卡，但是接收队列只能使用一张物理网卡</div></pre></td></tr></table></figure>
<p>网卡绑定mode共有七种(0~6) bond0、bond1、bond2、bond3、bond4、bond5、bond6</p>
<p>常用的有三种</p>
<ul>
<li><p>mode=0：平衡负载模式 <strong>(balance-rr)</strong>，有自动备援，两块物理网卡和bond网卡使用同一个mac地址，但需要”Switch”支援及设定。</p>
</li>
<li><p>mode=1：自动备援模式 <strong>(balance-backup)</strong>，其中一条线若断线，其他线路将会自动备援。</p>
</li>
<li><p>mode=6：平衡负载模式<strong>(balance-alb)</strong>，有自动备援，不必”Switch”支援及设定，两块网卡是使用不同的MAC地址</p>
</li>
<li><strong>Mode 4 (802.3ad)</strong>: This mode creates aggregation groups that share the same speed and duplex settings, and it requires a switch that supports an IEEE 802.3ad dynamic link. Mode 4 uses all interfaces in the active aggregation group. For example, you can aggregate three 1 GB per second (GBPS) ports into a 3 GBPS trunk port. This is equivalent to having one interface with 3 GBPS speed. It provides fault tolerance and load balancing.</li>
</ul>
<p>需要说明的是如果想做成mode 0的负载均衡,仅仅设置这里options bond0 miimon=100 mode=0是不够的,与网卡相连的交换机必须做特殊配置（这两个端口应该采取聚合方式），因为做bonding的这两块网卡是使用同一个MAC地址.从原理分析一下（bond运行在mode 0下）：</p>
<p>mode 0下bond所绑定的网卡的IP都被修改成相同的mac地址，如果这些网卡都被接在同一个交换机，那么交换机的arp表里这个mac地址对应的端口就有多 个，那么交换机接受到发往这个mac地址的包应该往哪个端口转发呢？正常情况下mac地址是全球唯一的，一个mac地址对应多个端口肯定使交换机迷惑了。所以 mode0下的bond如果连接到交换机，交换机这几个端口应该采取聚合方式（cisco称为 ethernetchannel，foundry称为portgroup），因为交换机做了聚合后，聚合下的几个端口也被捆绑成一个mac地址.我们的解决办法是，两个网卡接入不同的交换机即可。</p>
<p>mode6模式下无需配置交换机，因为做bonding的这两块网卡是使用不同的MAC地址。</p>
<p>mod=5，即：(balance-tlb) Adaptive transmit load balancing（适配器传输负载均衡）</p>
<p>特点：不需要任何特别的switch(交换机)支持的通道bonding。在每个slave上根据当前的负载（根据速度计算）分配外出流量。如果正在接受数据的slave出故障了，另一个slave接管失败的slave的MAC地址。</p>
<p>该模式的必要条件：ethtool支持获取每个slave的速率.</p>
<p>案例，两块万兆bonding后带宽翻倍</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div></pre></td><td class="code"><pre><div class="line">#ethtool bond0</div><div class="line">Settings for bond0:</div><div class="line">	Supported ports: [ ]</div><div class="line">	Supported link modes:   Not reported</div><div class="line">	Supported pause frame use: No</div><div class="line">	Supports auto-negotiation: No</div><div class="line">	Advertised link modes:  Not reported</div><div class="line">	Advertised pause frame use: No</div><div class="line">	Advertised auto-negotiation: No</div><div class="line">	Speed: 20000Mb/s</div><div class="line">	Duplex: Full</div><div class="line">	Port: Other</div><div class="line">	PHYAD: 0</div><div class="line">	Transceiver: internal</div><div class="line">	Auto-negotiation: off</div><div class="line">	Link detected: yes</div><div class="line"></div><div class="line">[root@phy 16:55 /root]</div><div class="line">#cat /etc/sysconfig/network-scripts/ifcfg-bond0</div><div class="line">DEVICE=bond0</div><div class="line">BOOTPROTO=static</div><div class="line">TYPE=&quot;ethernet&quot;</div><div class="line">IPADDR=100.1.1.2</div><div class="line">NETMASK=255.255.255.192</div><div class="line">ONBOOT=yes</div><div class="line">USERCTL=no</div><div class="line">PEERDNS=no</div><div class="line">BONDING_OPTS=&quot;miimon=100 mode=4 xmit_hash_policy=layer3+4&quot;</div><div class="line"></div><div class="line">#cat /etc/modprobe.d/bonding.conf</div><div class="line">alias netdev-bond0 bonding</div><div class="line"></div><div class="line">#lsmod |grep bond</div><div class="line">bonding               137339  0</div><div class="line"></div><div class="line">#cat ifcfg-bond0</div><div class="line">DEVICE=bond0</div><div class="line">BOOTPROTO=static</div><div class="line">TYPE=&quot;ethernet&quot;</div><div class="line">IPADDR=100.81.131.221</div><div class="line">NETMASK=255.255.255.192</div><div class="line">ONBOOT=yes</div><div class="line">USERCTL=no</div><div class="line">PEERDNS=no</div><div class="line">BONDING_OPTS=&quot;miimon=100 mode=4 xmit_hash_policy=layer3+4&quot;</div><div class="line"></div><div class="line">#cat ifcfg-eth1</div><div class="line">DEVICE=eth1</div><div class="line">TYPE=&quot;Ethernet&quot;</div><div class="line">HWADDR=7C:D3:0A:E0:F7:81</div><div class="line">BOOTPROTO=none</div><div class="line">ONBOOT=yes</div><div class="line">MASTER=bond0</div><div class="line">SLAVE=yes</div><div class="line">PEERDNS=no</div><div class="line">RX_MAX=`ethtool -g &quot;$DEVICE&quot; | grep &apos;Pre-set&apos; -A1 | awk &apos;/RX/&#123;print $2&#125;&apos;`</div><div class="line">RX_CURRENT=`ethtool -g &quot;$DEVICE&quot; | grep &quot;Current&quot; -A1 | awk &apos;/RX/&#123;print $2&#125;&apos;`</div><div class="line">[[ &quot;$RX_CURRENT&quot; -lt &quot;$RX_MAX&quot; ]] &amp;&amp; ethtool -G &quot;$DEVICE&quot; rx &quot;$RX_MAX&quot;</div></pre></td></tr></table></figure>
<h2 id="网络中断和绑核"><a href="#网络中断和绑核" class="headerlink" title="网络中断和绑核"></a>网络中断和绑核</h2><p>网络包的描述符的内存（RingBuffer）跟着设备走（设备在哪个Die/Node上，就近分配内存）， 数据缓冲区（Data Buffer–存放网络包）内存跟着队列(中断)走， 如果队列绑定到DIE0， 而设备在die1上，这样在做DMA通信时， 会产生跨die的交织访问。</p>
<p>不管设备插在哪一个die上， 只要描述符申请的内存和数据缓冲区的内存都在同一个die上（需要修改驱动源代码–非常规），避免跨die内存交织， 性能能保持一致。</p>
<p><strong>irqbalance服务不会将中断进行跨node迁移，只会在同一numa node中进行优化。</strong></p>
<h3 id="ethtool"><a href="#ethtool" class="headerlink" title="ethtool"></a>ethtool</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash">ethtool -i p1p1   //查询网卡bus-info</span></div><div class="line">driver: mlx5_core</div><div class="line">version: 5.0-0</div><div class="line">firmware-version: 14.27.1016 (MT_2420110004)</div><div class="line">expansion-rom-version:</div><div class="line">bus-info: 0000:21:00.0</div><div class="line">supports-statistics: yes</div><div class="line">supports-test: yes</div><div class="line">supports-eeprom-access: no</div><div class="line">supports-register-dump: no</div><div class="line">supports-priv-flags: yes</div><div class="line"></div><div class="line">//根据bus-info找到中断id</div><div class="line"><span class="meta">#</span><span class="bash">cat /proc/interrupts | grep 0000:21:00.0 | awk -F: <span class="string">'&#123;print $1&#125;'</span> | wc -l</span></div><div class="line"></div><div class="line">//修改网卡队列数</div><div class="line">sudo ethtool -L eth0  combined 2 （不能超过网卡最大队列数）</div><div class="line"></div><div class="line">然后检查是否生效了(不需要重启应用和机器，实时生效)：</div><div class="line">sudo ethtool -l eth0</div></pre></td></tr></table></figure>
<p>根据网卡bus-info可以找到对应的irq id</p>
<p>手工绑核脚本:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></div><div class="line"><span class="meta">#</span><span class="bash">irq_list=(`cat /proc/interrupts | grep enp131s0 | awk -F: <span class="string">'&#123;print $1&#125;'</span>`)</span></div><div class="line">intf=$1</div><div class="line">irq_list=(cat /proc/interrupts | grep `ethtool -i $intf |grep bus-info | awk  '&#123; print $2 &#125;'` | awk -F: '&#123;print $1&#125;')</div><div class="line">cpunum=48  # 修改为所在node的第一个Core</div><div class="line">for irq in $&#123;irq_list[@]&#125;</div><div class="line">do</div><div class="line">echo $cpunum &gt; /proc/irq/$irq/smp_affinity_list</div><div class="line">echo `cat /proc/irq/$irq/smp_affinity_list`</div><div class="line">(( cpunum+=1 ))</div><div class="line">done</div></pre></td></tr></table></figure>
<p>检查绑定结果: sh irqCheck.sh enp131s0</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash"> 网卡名</span></div><div class="line">intf=$1</div><div class="line">irqID=`ethtool -i $intf |grep bus-info | awk  '&#123; print $2 &#125;'`</div><div class="line">log=irqSet-`date "+%Y%m%d-%H%M%S"`.log</div><div class="line"><span class="meta">#</span><span class="bash"> 可用的CPU数</span></div><div class="line">cpuNum=$(cat /proc/cpuinfo |grep processor -c)</div><div class="line"><span class="meta">#</span><span class="bash"> RX TX中断列表</span></div><div class="line">irqListRx=$(cat /proc/interrupts | grep $&#123;irqID&#125; | awk -F':' '&#123;print $1&#125;')</div><div class="line">irqListTx=$(cat /proc/interrupts | grep $&#123;irqID&#125; | awk -F':' '&#123;print $1&#125;')</div><div class="line"><span class="meta">#</span><span class="bash"> 绑定接收中断rx irq</span></div><div class="line">for irqRX in $&#123;irqListRx[@]&#125;</div><div class="line">do</div><div class="line">cat /proc/irq/$&#123;irqRX&#125;/smp_affinity_list</div><div class="line">done</div><div class="line"><span class="meta">#</span><span class="bash"> 绑定发送中断tx irq</span></div><div class="line">for irqTX in $&#123;irqListTx[@]&#125;</div><div class="line">do</div><div class="line">cat /proc/irq/$&#123;irqTX&#125;/smp_affinity_list</div><div class="line">done</div></pre></td></tr></table></figure>
<h3 id="irqbalance"><a href="#irqbalance" class="headerlink" title="irqbalance"></a><a href="https://access.redhat.com/documentation/zh-cn/red_hat_enterprise_linux/7/html/performance_tuning_guide/appe-red_hat_enterprise_linux-performance_tuning_guide-tool_reference" target="_blank" rel="external">irqbalance</a></h3><p><strong>irqbalance</strong> 是一个命令行工具，在处理器中分配硬件中断以提高系统性能。默认设置下在后台程序运行，但只可通过 <code>--oneshot</code> 选项运行一次。</p>
<p>以下参数可用于提高性能。</p>
<ul>
<li><p>–powerthresh</p>
<p>CPU 进入节能模式之前，设定可空闲的 CPU 数量。如果有大于阀值数量的 CPU 是大于一个标准的偏差，该差值低于平均软中断工作负载，以及没有 CPU 是大于一个标准偏差，且该偏差高出平均，并有多于一个的 irq 分配给它们，一个 CPU 将处于节能模式。在节能模式中，CPU 不是 irqbalance 的一部分，所以它在有必要时才会被唤醒。</p>
</li>
<li><p>–hintpolicy</p>
<p>决定如何解决 irq 内核关联提示。有效值为 <code>exact</code>（总是应用 irq 关联提示）、<code>subset</code> （irq 是平衡的，但分配的对象是关联提示的子集）、或者 <code>ignore</code>（irq 完全被忽略）。</p>
</li>
<li><p>–policyscript</p>
<p>通过设备路径、当作参数的irq号码以及 <strong>irqbalance</strong> 预期的零退出代码，定义脚本位置以执行每个中断请求。定义的脚本能指定零或多键值对来指导管理传递的 irq 中 <strong>irqbalance</strong>。下列是为效键值对：ban有效值为 <code>true</code>（从平衡中排除传递的 irq）或 <code>false</code>（该 irq 表现平衡）。balance_level允许用户重写传递的 irq 平衡度。默认设置下，平衡度基于拥有 irq 设备的 PCI 设备种类。有效值为 <code>none</code>、<code>package</code>、<code>cache</code>、或 <code>core</code>。numa_node允许用户重写视作为本地传送 irq 的 NUMA 节点。如果本地节点的信息没有限定于 ACPI ，则设备被视作与所有节点距离相等。有效值为识别特定 NUMA 节点的整数（从0开始）和 <code>-1</code>，规定 irq 应被视作与所有节点距离相等。</p>
</li>
<li><p>–banirq</p>
<p>将带有指定中断请求号码的中断添加至禁止中断的列表。</p>
</li>
</ul>
<p>也可以使用 <em><code>IRQBALANCE_BANNED_CPUS</code></em> 环境变量来指定被 <strong>irqbalance</strong> 忽略的 CPU 掩码。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">//默认irqbalance绑定一个numa, -1指定多个numa</div><div class="line">echo -1 &gt;/sys/bus/pci/devices/`ethtool -i p1p1 |grep bus-info | awk  '&#123; print $2 &#125;'`/numa_node ; </div><div class="line">// 目录 /sys/class/net/p1p1/ link到了 /sys/bus/pci/devices/`ethtool -i p1p1 |grep bus-info | awk  '&#123; print $2 &#125;'` </div><div class="line"></div><div class="line">执行 irqbalance --debug 进行调试</div></pre></td></tr></table></figure>
<h4 id="irqbalance指定core"><a href="#irqbalance指定core" class="headerlink" title="irqbalance指定core"></a><a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux_for_real_time/7/html/tuning_guide/interrupt_and_process_binding" target="_blank" rel="external">irqbalance指定core</a></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">cat /etc/sysconfig/irqbalance</div><div class="line"># IRQBALANCE_BANNED_CPUS</div><div class="line"># 64 bit bitmask which allows you to indicate which cpu&apos;s should</div><div class="line"># be skipped when reblancing irqs. Cpu numbers which have their</div><div class="line"># corresponding bits set to one in this mask will not have any</div><div class="line"># irq&apos;s assigned to them on rebalance</div><div class="line">#绑定软中断到8-15core, 每位表示4core</div><div class="line">#IRQBALANCE_BANNED_CPUS=ffffffff,ffff00ff</div><div class="line">#绑定软中断到8-15core和第65core</div><div class="line">IRQBALANCE_BANNED_CPUS=ffffffff,fffffdff,ffffffff,ffff00ff</div></pre></td></tr></table></figure>
<h4 id="irqbalance的流程"><a href="#irqbalance的流程" class="headerlink" title="irqbalance的流程"></a><a href="https://blog.csdn.net/whrszzc/article/details/50533866" target="_blank" rel="external">irqbalance的流程</a></h4><p>初始化的过程只是建立链表的过程，暂不描述，只考虑正常运行状态时的流程<br>-处理间隔是10s<br>-清除所有中断的负载值<br>-/proc/interrupts读取中断，并记录中断数<br>-/proc/stat读取每个cpu的负载，并依次计算每个层次每个节点的负载以及每个中断的负载<br>-通过平衡算法找出需要重新分配的中断<br>-把需要重新分配的中断加入到新的节点中<br>-配置smp_affinity使处理生效</p>
<h3 id="网卡软中断以及内存远近的测试结论"><a href="#网卡软中断以及内存远近的测试结论" class="headerlink" title="网卡软中断以及内存远近的测试结论"></a>网卡软中断以及内存远近的测试结论</h3><p>一般网卡中断会占用一些CPU，如果把网卡中断挪到其它node的core上，在鲲鹏920上测试（网卡插在node0上），业务跑在node3，网卡中断分别在node0和node3，QPS分别是：179000 VS 175000</p>
<p>如果将业务跑在node0上，网卡中断分别在node0和node1上得到的QPS分别是：204000 VS 212000 </p>
<p>以上测试的时候业务进程分配的内存全限制在node0上</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">#/root/numa-maps-summary.pl &lt;/proc/123853/numa_maps</div><div class="line">N0        :      5085548 ( 19.40 GB)</div><div class="line">N1        :         4479 (  0.02 GB)</div><div class="line">N2        :            1 (  0.00 GB)</div><div class="line">active    :            0 (  0.00 GB)</div><div class="line">anon      :      5085455 ( 19.40 GB)</div><div class="line">dirty     :      5085455 ( 19.40 GB)</div><div class="line">kernelpagesize_kB:         2176 (  0.01 GB)</div><div class="line">mapmax    :          348 (  0.00 GB)</div><div class="line">mapped    :         4626 (  0.02 GB)</div></pre></td></tr></table></figure>
<p>从以上测试数据可以看到在这个内存分布场景下，如果就近访问内存性能有20%以上的提升</p>
<h3 id="阿里云绑核脚本"><a href="#阿里云绑核脚本" class="headerlink" title="阿里云绑核脚本"></a>阿里云绑核脚本</h3><p>通常情况下，Linux的网卡中断是由一个CPU核心来处理的，当承担高流量的场景下，会出现一些诡异的情况（网卡尚未达到瓶颈，但是却出现丢包的情况）</p>
<p>这种时候，我们最好看下网卡中断是不是缺少调优。</p>
<p>优化3要点：网卡多队列+irq affinity亲缘性设置+关闭irqbalance (systemctl stop irqbalance)</p>
<p>目前阿里云官方提供的centos和ubuntu镜像里面，已经自带了优化脚本，内容如下:</p>
<p><strong>centos7的脚本路径在 /usr/sbin/ecs_mq_rps_rfs 具体内容如下：</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></div><div class="line"><span class="meta">#</span><span class="bash"> This is the default setting of networking multiqueue and irq affinity</span></div><div class="line"><span class="meta">#</span><span class="bash"> 1. <span class="built_in">enable</span> multiqueue <span class="keyword">if</span> available</span></div><div class="line"><span class="meta">#</span><span class="bash"> 2. irq affinity optimization</span></div><div class="line"><span class="meta">#</span><span class="bash"> 3. stop irqbalance service</span></div><div class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">set</span> and check multiqueue</span></div><div class="line"></div><div class="line">function set_check_multiqueue()</div><div class="line">&#123;</div><div class="line">    eth=$1</div><div class="line">    log_file=$2</div><div class="line">    queue_num=$(ethtool -l $eth | grep -ia5 'pre-set' | grep -i combined | awk &#123;'print $2'&#125;)</div><div class="line">    if [ $queue_num -gt 1 ]; then</div><div class="line">        # set multiqueue</div><div class="line">        ethtool -L $eth combined $queue_num</div><div class="line">        # check multiqueue setting</div><div class="line">        cur_q_num=$(ethtool -l $eth | grep -iA5 current | grep -i combined | awk &#123;'print $2'&#125;)</div><div class="line">        if [ "X$queue_num" != "X$cur_q_num" ]; then</div><div class="line">            echo "Failed to set $eth queue size to $queue_num" &gt;&gt; $log_file</div><div class="line">            echo "after setting, pre-set queue num: $queue_num , current: $cur_q_num" &gt;&gt; $log_file</div><div class="line">            return 1</div><div class="line">        else</div><div class="line">            echo "OK. set $eth queue size to $queue_num" &gt;&gt; $log_file</div><div class="line">        fi</div><div class="line">    else</div><div class="line">        echo "only support $queue_num queue; no need to enable multiqueue on $eth" &gt;&gt; $log_file</div><div class="line">    fi</div><div class="line">&#125;</div><div class="line"><span class="meta"></span></div><div class="line">#<span class="bash"><span class="built_in">set</span> irq affinity</span></div><div class="line">function set_irq_smpaffinity()</div><div class="line">&#123;</div><div class="line">    log_file=$1</div><div class="line">    node_dir=/sys/devices/system/node</div><div class="line">    for i in $(ls -d $node_dir/node*); do</div><div class="line">        i=$&#123;i/*node/&#125;</div><div class="line">    done</div><div class="line">    </div><div class="line">    echo "max node :$i" &gt;&gt; $log_file</div><div class="line">    node_cpumax=$(cat /sys/devices/system/node/node$&#123;i&#125;/cpulist |awk -F- '&#123;print $NF&#125;')</div><div class="line">    irqs=($(cat /proc/interrupts |grep virtio |grep put | awk -F: '&#123;print $1&#125;'))</div><div class="line">    core=0</div><div class="line">    for irq in $&#123;irqs[@]&#125;;do</div><div class="line">        VEC=$core</div><div class="line">        if [ $VEC -ge 32 ];then</div><div class="line">            let "IDX = $VEC / 32"</div><div class="line">            MASK_FILL=""</div><div class="line">            MASK_ZERO="00000000"</div><div class="line">            for ((i=1; i&lt;=$IDX;i++))</div><div class="line">                do</div><div class="line">                    MASK_FILL="$&#123;MASK_FILL&#125;,$&#123;MASK_ZERO&#125;"</div><div class="line">                done</div><div class="line">            let "VEC -= 32 * $IDX"</div><div class="line">            MASK_TMP=$((1&lt;&lt;$VEC))</div><div class="line">            MASK=$(printf "%X%s" $MASK_TMP $MASK_FILL)</div><div class="line">        else</div><div class="line">            MASK_TMP=$((1&lt;&lt;$VEC))</div><div class="line">            MASK=$(printf "%X" $MASK_TMP)</div><div class="line">        fi</div><div class="line">        echo $MASK &gt; /proc/irq/$irq/smp_affinity</div><div class="line">        echo "mask:$MASK, irq:$irq" &gt;&gt; $log_file</div><div class="line">        core=$(((core+1)%(node_cpumax+1)))</div><div class="line">    done</div><div class="line">&#125;</div><div class="line"><span class="meta"></span></div><div class="line">#<span class="bash"> stop irqbalance service</span></div><div class="line">function stop_irqblance()</div><div class="line">&#123;</div><div class="line">    log_file=$1</div><div class="line">    ret=0</div><div class="line">    if [ "X" != "X$(ps -ef | grep irqbalance | grep -v grep)" ]; then</div><div class="line">        if which systemctl;then</div><div class="line">            systemctl stop irqbalance</div><div class="line">        else</div><div class="line">            service irqbalance stop</div><div class="line">        fi</div><div class="line">        if [ $? -ne 0 ]; then</div><div class="line">            echo "Failed to stop irqbalance" &gt;&gt; $log_file</div><div class="line">            ret=1</div><div class="line">        fi</div><div class="line">    else</div><div class="line">       echo "OK. irqbalance stoped." &gt;&gt; $log_file</div><div class="line">    fi</div><div class="line">    return $ret</div><div class="line">&#125;</div><div class="line"><span class="meta">#</span><span class="bash"> main logic</span></div><div class="line">function main()</div><div class="line">&#123;</div><div class="line">    ecs_network_log=/var/log/ecs_network_optimization.log</div><div class="line">    ret_value=0</div><div class="line">    echo "running $0" &gt; $ecs_network_log</div><div class="line">    echo "========  ECS network setting starts $(date +'%Y-%m-%d %H:%M:%S') ========" &gt;&gt; $ecs_network_log</div><div class="line">    # we assume your NIC interface(s) is/are like eth*</div><div class="line">    eth_dirs=$(ls -d /sys/class/net/eth*)</div><div class="line">    if [ "X$eth_dirs" = "X" ]; then</div><div class="line">        echo "ERROR! can not find any ethX in /sys/class/net/ dir." &gt;&gt; $ecs_network_log</div><div class="line">        ret_value=1</div><div class="line">    fi</div><div class="line">    for i in $eth_dirs</div><div class="line">    do</div><div class="line">        cur_eth=$(basename $i)</div><div class="line">        echo "optimize network performance: current device $cur_eth" &gt;&gt; $ecs_network_log</div><div class="line">        # only optimize virtio_net device</div><div class="line">        driver=$(basename $(readlink $i/device/driver))</div><div class="line">        if ! echo $driver | grep -q virtio; then</div><div class="line">            echo "ignore device $cur_eth with driver $driver" &gt;&gt; $ecs_network_log</div><div class="line">            continue</div><div class="line">        fi</div><div class="line">        echo "set and check multiqueue on $cur_eth" &gt;&gt; $ecs_network_log</div><div class="line">        set_check_multiqueue $cur_eth $ecs_network_log</div><div class="line">        if [ $? -ne 0 ]; then</div><div class="line">            echo "Failed to set multiqueue on $cur_eth" &gt;&gt; $ecs_network_log</div><div class="line">            ret_value=1</div><div class="line">        fi</div><div class="line">    done</div><div class="line">    stop_irqblance  $ecs_network_log</div><div class="line">    set_irq_smpaffinity $ecs_network_log</div><div class="line">    echo "========  ECS network setting END $(date +'%Y-%m-%d %H:%M:%S')  ========" &gt;&gt; $ecs_network_log</div><div class="line">    return $ret_value</div><div class="line">&#125;</div><div class="line"><span class="meta"></span></div><div class="line"></div><div class="line">#<span class="bash"> program starts here</span></div><div class="line">main</div><div class="line">exit $?</div></pre></td></tr></table></figure>
<p>查询的rps绑定情况的脚本 get_rps.sh</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></div><div class="line"><span class="meta">#</span><span class="bash"> 获取当前rps情况</span></div><div class="line">for i in $(ls /sys/class/net/eth0/queues/rx-*/rps_cpus); do </div><div class="line">  echo $i</div><div class="line">  cat $i</div><div class="line">done</div></pre></td></tr></table></figure>
<h2 id="查看网卡和numa的关系"><a href="#查看网卡和numa的关系" class="headerlink" title="查看网卡和numa的关系"></a>查看网卡和numa的关系</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">#yum install lshw -y</div><div class="line">#lshw -C network -short</div><div class="line">H/W path               Device          Class      Description</div><div class="line">=============================================================</div><div class="line">/0/100/0/9/0           eth0            network    MT27710 Family [ConnectX-4 Lx]</div><div class="line">/0/100/0/9/0.1         eth1            network    MT27710 Family [ConnectX-4 Lx]</div><div class="line">/1                     e41358fae4ee_h  network    Ethernet interface</div><div class="line">/2                     86b0637ef1e1_h  network    Ethernet interface</div><div class="line">/3                     a6706e785f53_h  network    Ethernet interface</div><div class="line">/4                     d351290e50a0_h  network    Ethernet interface</div><div class="line">/5                     1a9e5df98dd1_h  network    Ethernet interface</div><div class="line">/6                     766ec0dab599_h  network    Ethernet interface</div><div class="line">/7                     bond0.11        network    Ethernet interface</div><div class="line">/8                     ea004888c217_h  network    Ethernet interface</div></pre></td></tr></table></figure>
<p>以及：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">lscpu | grep -i numa</div><div class="line">numactl --hardware</div><div class="line">cat /proc/interrupts | egrep -i &quot;CPU|rx&quot;</div></pre></td></tr></table></figure>
<p><a href="https://ixnfo.com/en/how-to-find-out-on-which-numa-node-network-interfaces.html" target="_blank" rel="external">Check if the network interfaces are tied to Numa</a> (if -1 means not tied, if 0, then to numa0):</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cat /sys/class/net/eth0/device/numa_node</div></pre></td></tr></table></figure>
<p>You can see which NAMA the network card belongs to, for example, using lstopo:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div></pre></td><td class="code"><pre><div class="line">yum install hwloc -y</div><div class="line">lstopo</div><div class="line">lstopo --logical</div><div class="line">lstopo --logical --output-format png &gt; lstopo.png</div><div class="line"></div><div class="line">--</div><div class="line">[root@hygon3 10:58 /root]  //hygon 7280 CPU</div><div class="line">#lstopo --logical</div><div class="line">Machine (503GB total)               //总内存大小</div><div class="line">  NUMANode L#0 (P#0 252GB)          //socket0、numa0 的内存大小</div><div class="line">    Package L#0</div><div class="line">      L3 L#0 (8192KB)               //L3 cache，对应4个物理core，8个HT</div><div class="line">        L2 L#0 (512KB) + L1d L#0 (32KB) + L1i L#0 (64KB) + Core L#0 // L1/L2</div><div class="line">          PU L#0 (P#0)</div><div class="line">          PU L#1 (P#64)</div><div class="line">        L2 L#1 (512KB) + L1d L#1 (32KB) + L1i L#1 (64KB) + Core L#1</div><div class="line">          PU L#2 (P#1)</div><div class="line">          PU L#3 (P#65)</div><div class="line">        L2 L#2 (512KB) + L1d L#2 (32KB) + L1i L#2 (64KB) + Core L#2</div><div class="line">          PU L#4 (P#2)</div><div class="line">          PU L#5 (P#66)</div><div class="line">        L2 L#3 (512KB) + L1d L#3 (32KB) + L1i L#3 (64KB) + Core L#3</div><div class="line">          PU L#6 (P#3)</div><div class="line">          PU L#7 (P#67)</div><div class="line">      L3 L#1 (8192KB)</div><div class="line">      L3 L#2 (8192KB)</div><div class="line">      L3 L#3 (8192KB)</div><div class="line">      L3 L#4 (8192KB)</div><div class="line">      L3 L#5 (8192KB)</div><div class="line">      L3 L#6 (8192KB)</div><div class="line">      L3 L#7 (8192KB)</div><div class="line">    HostBridge L#0</div><div class="line">      PCIBridge</div><div class="line">        PCIBridge</div><div class="line">          PCI 1a03:2000</div><div class="line">            GPU L#0 &quot;controlD64&quot;</div><div class="line">            GPU L#1 &quot;card0&quot;</div><div class="line">      PCIBridge</div><div class="line">        PCI 1d94:7901</div><div class="line">          Block(Disk) L#2 &quot;sdm&quot;   //ssd系统盘，接在Node0上，绑核有优势</div><div class="line">    HostBridge L#4</div><div class="line">      PCIBridge</div><div class="line">        PCI 1000:0097</div><div class="line">      PCIBridge</div><div class="line">        PCI 1c5f:000d</div><div class="line">      PCIBridge</div><div class="line">        PCI 1c5f:000d</div><div class="line">    HostBridge L#8</div><div class="line">      PCIBridge</div><div class="line">        PCI 15b3:1015</div><div class="line">          Net L#3 &quot;p1p1&quot;      //万兆网卡接在Node0上</div><div class="line">        PCI 15b3:1015</div><div class="line">          Net L#4 &quot;p1p2&quot;</div><div class="line">    HostBridge L#10</div><div class="line">      PCIBridge</div><div class="line">        PCI 8086:1521</div><div class="line">          Net L#5 &quot;em1&quot;       //千兆网卡接在Node0上</div><div class="line">        PCI 8086:1521</div><div class="line">          Net L#6 &quot;em2&quot;</div><div class="line">  NUMANode L#1 (P#1 251GB)    //另外一个socket</div><div class="line">    Package L#1</div><div class="line">      L3 L#8 (8192KB)</div><div class="line">        L2 L#32 (512KB) + L1d L#32 (32KB) + L1i L#32 (64KB) + Core L#32</div><div class="line">        </div><div class="line">----------- FT2500 两路共128core</div><div class="line">#lstopo-no-graphics --logical</div><div class="line">Machine (503GB total)</div><div class="line">  Package L#0 + L3 L#0 (64MB)</div><div class="line">    NUMANode L#0 (P#0 31GB)</div><div class="line">      L2 L#0 (2048KB)         //4个物理core共享2M </div><div class="line">        L1d L#0 (32KB) + L1i L#0 (32KB) + Core L#0 + PU L#0 (P#0)</div><div class="line">        L1d L#1 (32KB) + L1i L#1 (32KB) + Core L#1 + PU L#1 (P#1)</div><div class="line">        L1d L#2 (32KB) + L1i L#2 (32KB) + Core L#2 + PU L#2 (P#2)</div><div class="line">        L1d L#3 (32KB) + L1i L#3 (32KB) + Core L#3 + PU L#3 (P#3)</div><div class="line">      L2 L#1 (2048KB)</div><div class="line">        L1d L#4 (32KB) + L1i L#4 (32KB) + Core L#4 + PU L#4 (P#4)</div><div class="line">        L1d L#5 (32KB) + L1i L#5 (32KB) + Core L#5 + PU L#5 (P#5)</div><div class="line">        L1d L#6 (32KB) + L1i L#6 (32KB) + Core L#6 + PU L#6 (P#6)</div><div class="line">        L1d L#7 (32KB) + L1i L#7 (32KB) + Core L#7 + PU L#7 (P#7)</div><div class="line">      HostBridge L#0</div><div class="line">        PCIBridge</div><div class="line">          PCIBridge</div><div class="line">            PCIBridge</div><div class="line">              PCI 1000:00ac</div><div class="line">                Block(Disk) L#0 &quot;sdh&quot;</div><div class="line">                Block(Disk) L#1 &quot;sdf&quot;  // 磁盘挂在Node0上</div><div class="line">            PCIBridge</div><div class="line">              PCI 8086:1521</div><div class="line">                Net L#13 &quot;eth0&quot;</div><div class="line">              PCI 8086:1521</div><div class="line">                Net L#14 &quot;eth1&quot;       //网卡挂在node0上</div><div class="line">        PCIBridge</div><div class="line">          PCIBridge</div><div class="line">            PCI 1a03:2000</div><div class="line">              GPU L#15 &quot;controlD64&quot;</div><div class="line">              GPU L#16 &quot;card0&quot;</div><div class="line">    NUMANode L#1 (P#1 31GB)</div><div class="line">    NUMANode L#2 (P#2 31GB)</div><div class="line">    NUMANode L#3 (P#3 31GB)</div><div class="line">    NUMANode L#4 (P#4 31GB)</div><div class="line">    NUMANode L#5 (P#5 31GB)</div><div class="line">    NUMANode L#6 (P#6 31GB)</div><div class="line">    NUMANode L#7 (P#7 31GB)</div><div class="line">      L2 L#14 (2048KB)</div><div class="line">        L1d L#56 (32KB) + L1i L#56 (32KB) + Core L#56 + PU L#56 (P#56)</div><div class="line">        L1d L#57 (32KB) + L1i L#57 (32KB) + Core L#57 + PU L#57 (P#57)</div><div class="line">        L1d L#58 (32KB) + L1i L#58 (32KB) + Core L#58 + PU L#58 (P#58)</div><div class="line">        L1d L#59 (32KB) + L1i L#59 (32KB) + Core L#59 + PU L#59 (P#59)</div><div class="line">      L2 L#15 (2048KB)</div><div class="line">        L1d L#60 (32KB) + L1i L#60 (32KB) + Core L#60 + PU L#60 (P#60)</div><div class="line">        L1d L#61 (32KB) + L1i L#61 (32KB) + Core L#61 + PU L#61 (P#61)</div><div class="line">        L1d L#62 (32KB) + L1i L#62 (32KB) + Core L#62 + PU L#62 (P#62)</div><div class="line">        L1d L#63 (32KB) + L1i L#63 (32KB) + Core L#63 + PU L#63 (P#63)</div><div class="line">  Package L#1 + L3 L#1 (64MB)   //socket2</div><div class="line">    NUMANode L#8 (P#8 31GB)</div><div class="line">      L2 L#16 (2048KB)</div><div class="line">        L1d L#64 (32KB) + L1i L#64 (32KB) + Core L#64 + PU L#64 (P#64)</div><div class="line">        L1d L#65 (32KB) + L1i L#65 (32KB) + Core L#65 + PU L#65 (P#65)</div><div class="line">        L1d L#66 (32KB) + L1i L#66 (32KB) + Core L#66 + PU L#66 (P#66)</div><div class="line">        L1d L#67 (32KB) + L1i L#67 (32KB) + Core L#67 + PU L#67 (P#67)</div><div class="line">      L2 L#17 (2048KB)</div><div class="line">        L1d L#68 (32KB) + L1i L#68 (32KB) + Core L#68 + PU L#68 (P#68)</div><div class="line">        L1d L#69 (32KB) + L1i L#69 (32KB) + Core L#69 + PU L#69 (P#69)</div><div class="line">        L1d L#70 (32KB) + L1i L#70 (32KB) + Core L#70 + PU L#70 (P#70)</div><div class="line">        L1d L#71 (32KB) + L1i L#71 (32KB) + Core L#71 + PU L#71 (P#71)</div><div class="line">      HostBridge L#7</div><div class="line">        PCIBridge</div><div class="line">          PCIBridge</div><div class="line">            PCIBridge</div><div class="line">              PCI 15b3:1015</div><div class="line">                Net L#17 &quot;eth2&quot;   //node8 上的网卡，eth2、eth3做了bonding</div><div class="line">              PCI 15b3:1015</div><div class="line">                Net L#18 &quot;eth3&quot;</div><div class="line">            PCIBridge</div><div class="line">              PCI 144d:a808</div><div class="line">            PCIBridge</div><div class="line">              PCI 144d:a808</div><div class="line">              </div><div class="line"> ---鲲鹏920 每路48core 2路共4node，网卡插在node0，磁盘插在node2</div><div class="line"> #lstopo-no-graphics</div><div class="line">Machine (755GB total)</div><div class="line">  Package L#0</div><div class="line">    NUMANode L#0 (P#0 188GB)</div><div class="line">      L3 L#0 (24MB)</div><div class="line">        L2 L#0 (512KB) + L1d L#0 (64KB) + L1i L#0 (64KB) + Core L#0 + PU L#0 (P#0)</div><div class="line">        L2 L#1 (512KB) + L1d L#1 (64KB) + L1i L#1 (64KB) + Core L#1 + PU L#1 (P#1)</div><div class="line">        L2 L#22 (512KB) + L1d L#22 (64KB) + L1i L#22 (64KB) + Core L#22 + PU L#22 (P#22)</div><div class="line">        L2 L#23 (512KB) + L1d L#23 (64KB) + L1i L#23 (64KB) + Core L#23 + PU L#23 (P#23)</div><div class="line">      HostBridge L#0</div><div class="line">        PCIBridge</div><div class="line">          PCI 15b3:1017</div><div class="line">            Net L#0 &quot;enp2s0f0&quot;</div><div class="line">          PCI 15b3:1017</div><div class="line">            Net L#1 &quot;eth1&quot;</div><div class="line">        PCIBridge</div><div class="line">          PCI 19e5:1711</div><div class="line">            GPU L#2 &quot;controlD64&quot;</div><div class="line">            GPU L#3 &quot;card0&quot;</div><div class="line">      HostBridge L#3</div><div class="line">        2 x &#123; PCI 19e5:a230 &#125;</div><div class="line">        PCI 19e5:a235</div><div class="line">          Block(Disk) L#4 &quot;sda&quot;</div><div class="line">      HostBridge L#4</div><div class="line">        PCIBridge</div><div class="line">          PCI 19e5:a222</div><div class="line">            Net L#5 &quot;enp125s0f0&quot;</div><div class="line">          PCI 19e5:a221</div><div class="line">            Net L#6 &quot;enp125s0f1&quot;</div><div class="line">          PCI 19e5:a222</div><div class="line">            Net L#7 &quot;enp125s0f2&quot;</div><div class="line">          PCI 19e5:a221</div><div class="line">            Net L#8 &quot;enp125s0f3&quot;</div><div class="line">    NUMANode L#1 (P#1 189GB) + L3 L#1 (24MB)</div><div class="line">      L2 L#24 (512KB) + L1d L#24 (64KB) + L1i L#24 (64KB) + Core L#24 + PU L#24 (P#24)</div><div class="line">  Package L#1</div><div class="line">    NUMANode L#2 (P#2 189GB)</div><div class="line">      L3 L#2 (24MB)</div><div class="line">        L2 L#48 (512KB) + L1d L#48 (64KB) + L1i L#48 (64KB) + Core L#48 + PU L#48 (P#48)</div><div class="line">      HostBridge L#6</div><div class="line">        PCIBridge</div><div class="line">          PCI 19e5:3714</div><div class="line">        PCIBridge</div><div class="line">          PCI 19e5:3714</div><div class="line">        PCIBridge</div><div class="line">          PCI 19e5:3714</div><div class="line">        PCIBridge</div><div class="line">          PCI 19e5:3714</div><div class="line">      HostBridge L#11</div><div class="line">        PCI 19e5:a230</div><div class="line">        PCI 19e5:a235</div><div class="line">        PCI 19e5:a230</div><div class="line">    NUMANode L#3 (P#3 189GB) + L3 L#3 (24MB)</div><div class="line">      L2 L#72 (512KB) + L1d L#72 (64KB) + L1i L#72 (64KB) + Core L#72 + PU L#72 (P#72)</div><div class="line">  Misc(MemoryModule)</div></pre></td></tr></table></figure>
<p>如果cpu core太多, interrupts 没法看的话，通过cut只看其中一部分core</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cat /proc/interrupts | grep -i &apos;eth4\|CPU&apos; | cut -c -8,865-995,1425-</div></pre></td></tr></table></figure>
<h2 id="Default-路由持久化"><a href="#Default-路由持久化" class="headerlink" title="Default 路由持久化"></a>Default 路由持久化</h2><p>通过 ip route 可以添加默认路由，但是reboot就丢失了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">route add default dev bond0</div></pre></td></tr></table></figure>
<p>如果要持久化，在centos下可以创建 /etc/sysconfig/network-scripts/route-bond0 文件，内容如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">default dev bond0    ---默认路由，后面的可以省略</div><div class="line">10.0.0.0/8 via 11.158.239.247 dev bond0</div><div class="line">11.0.0.0/8 via 11.158.239.247 dev bond0</div><div class="line">30.0.0.0/8 via 11.158.239.247 dev bond0</div><div class="line">172.16.0.0/12 via 11.158.239.247 dev bond0</div><div class="line">192.168.0.0/16 via 11.158.239.247 dev bond0</div><div class="line">100.64.0.0/10 via 11.158.239.247 dev bond0</div><div class="line">33.0.0.0/8 via 11.158.239.247 dev bond0</div></pre></td></tr></table></figure>
<p>或者用sed在文件第一行添加</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sed -i &apos;/default /d&apos;  /etc/sysconfig/network-scripts/route-bond0   //先删除默认路由（如果有）</div><div class="line">sed -i &apos;1 i\default dev bond0&apos; /etc/sysconfig/network-scripts/route-bond0   //添加</div></pre></td></tr></table></figure>
<p>Centos 7的话需要在 /etc/sysconfig/network 中添加创建默认路由的命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"># cat /etc/sysconfig/network</div><div class="line"># Created by anaconda</div><div class="line">ip route add default dev eth0</div></pre></td></tr></table></figure>
<h2 id="内核态启动并加载网卡的逻辑"><a href="#内核态启动并加载网卡的逻辑" class="headerlink" title="内核态启动并加载网卡的逻辑"></a>内核态启动并加载网卡的逻辑</h2><ol>
<li><p>运行Linux的机器在BIOS阶段之后，机器的boot loader根据我们预先定义好的配置文件，将intrd和linux kernel加载到内存。这个包含initrd和linux kernel的配置文件通常在/boot分区（从grub.conf中读取参数）</p>
</li>
<li><p>内核启动，运行当前根目录下面的init进程，init进程再运行其他必要的进程，其中跟网卡PCI设备相关的一个进程，就是udevd进程，udevd负责根据内核pci scan的pci设备，从initrd这个临时的根文件系统中加载内核模块，对于网卡来说，就是网卡驱动。(对应systemd-udevd 服务)</p>
</li>
<li><p>udevd，根据内核pci device scan出来的pci device，通过netlink消息机制通知udevd加载相应的内核驱动，其中，网卡驱动就是在这个阶段加载，如果initrd临时文件系统里面有这个网卡的驱动文件。通常upstream到linux内核的驱动，比如ixgbe，或者和内核一起编译的网卡驱动，会默认包含在initrd文件系统中。这些跟内核一起ship的网卡驱动会在这个阶段加载</p>
</li>
<li><p>udevd除了负责网卡驱动加载之外，还要负责为网卡命名。udevd在为网卡命名的时候，会首先check “/etc/udev/rules.d/“下的rule，如果hit到相应的rule，就会通过rule里面指定的binary为网卡命名。如果/etc/udev/rules.d/没有命名成功网卡，那么udevd会使用/usr/lib/udev/rule.d下面的rule，为网卡重命名。其中rule的文件经常以数字开头，数字越小，表示改rule的优先级越高。intrd init不会初始化network服务，所以/etc/sysconfig/network-scripts下面的诸如bond0，route的配置都不会生效。（内核启动先是 intrd init，然后执行一次真正的init）</p>
</li>
<li><p>在完成网卡driver load和name命名之后，initrd里面的init进程，会重启其他用户态进程，如udevd等，并且重新mount真正的根文件系统，启动network service。</p>
</li>
<li><p>重启udevd，会触发一次kernel的rescan device。这样第三方安装的网卡driver，由于其driver模块没有在initrd里面，会在这个阶段由udevd触发加载。同时，也会根据“/etc/udev/rules.d/”和“/usr/lib/udev/rule.d”的rule，重命名网卡设备。–用户态修改网卡名字的机会</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">kernel: ixgbe 0000:3b:00.1 eth1: renamed from enp59s0f1</div><div class="line">kernel: i40e 0000:88:00.0 eth7: renamed from enp136s0</div></pre></td></tr></table></figure>
</li>
<li><p>同时network service 会启动，进而遍历etc/sysconfig/network-scripts下面的脚本，我们配置的bond0， 默认路由，通常会在这个阶段运行，创建</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">kernel: bond0: Enslaving eth0 as a backup interface with a down link</div><div class="line">kernel: ixgbe 0000:3b:00.0 eth0: detected SFP+: 5</div><div class="line">kernel: power_meter ACPI000D:00: Found ACPI power meter.</div><div class="line">kernel: power_meter ACPI000D:00: Ignoring unsafe software power cap!</div><div class="line">kernel: ixgbe 0000:3b:00.1: registered PHC device on eth1</div><div class="line">kernel: ixgbe 0000:3b:00.0 eth0: NIC Link is Up 10 Gbps, Flow Control: RX/TX</div><div class="line">kernel: bond0: Enslaving eth1 as a backup interface with a down link</div><div class="line">kernel: bond0: Warning: No 802.3ad response from the link partner for any adapters in the bond</div><div class="line">kernel: bond0: link status definitely up for interface eth0, 10000 Mbps full duplex</div><div class="line">kernel: bond0: first active interface up!</div></pre></td></tr></table></figure>
</li>
</ol>
<p>由于我们系统的初始化有两个阶段，udevd会运行两次，所以内核态网卡driver的加载，网卡命名也有两次机会。</p>
<p>第一次网卡driver的加载和命名是在initrd运行阶段，这个阶段由于initrd文件系统比较小，只包括和kernel一起ship的内核module，所以这个阶段只能加载initrd里面有的内核模块。网卡的重命名也只能重命名加载了驱动的网卡。</p>
<p>第二个网卡driver的加载和命名，是在真正根文件系统加载后，内核再一次pci scan，这个时候，由于真的根文件系统包含了所有的driver，第一个阶段无法probe的网卡会在这个阶段probe，重命名也会在这个阶段进行。</p>
<blockquote>
<p>内核默认命名规则有一定的局限性，往往不一定准确对应网卡接口的物理顺序，而且每次启动只根据内核发现网卡的顺序进行命名，因此并不固定；所以目前一般情况下会在用户态启用其他的方式去更改网卡名称，原则就是在内核命名ethx后将其在根据用户态的规则rename为其他的名字，这种规则往往是根据网卡的Mac地址以及其他能够唯一代表一块网卡的参数去命名，因此会一一对应；</p>
</blockquote>
<p>内核自带的网卡驱动在initrd中的内核模块中。对于第三方网卡，我们通常通过rpm包的方式安装。这种第三方安装的rpm，通常不会在initrd里面，只存在disk上。这样这种内核模块就只会在第二次udevd启动的时候被加载。</p>
<p>不论第一次重命名还是第二次重命名，其都遵循一样的逻辑，也就是先check /etc/udev/rules.d/的rule，然后check /usr/lib/udev/rule.d中的rule，其中rule的优先级etc下最高，然后是usr下面。并且，rule的文件名中的数字表示该rule在同一文件夹中的优先级，数字越低，优先级越高。</p>
<p>network.service 根据network-script里面的脚本创建bond0，下发路由。这个过程和网卡重命名是同步进行，一般网卡重命名会超级快，单极端情况下重命名可能在network.service后会导致创建bond0失败（依赖网卡名来bonding），这里会依赖network.service retry机制来反复尝试确保network服务能启动成功</p>
<p>要想解决网卡加载慢的问题，可以考虑把安装后的网卡集成到initrd中。Linux系统提供的dracut可以做到这一点，我们只需要在安装完第三方网卡驱动后，执行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">dracut --forace</div><div class="line"></div><div class="line">查看</div><div class="line">udevadm info -q all -a /dev/nvme0</div></pre></td></tr></table></figure>
<p>就可以解决这个问题，该命令会根据最新的内存中的module，重新下刷initrd。</p>
<p>其实在多数第三方网卡的rpm spec或者makefile里面通常也会加入这种强制重刷的逻辑，确保内核驱动在initrd里面，从而加快网卡驱动的加载。</p>
<h3 id="用户态命名网卡流程"><a href="#用户态命名网卡流程" class="headerlink" title="用户态命名网卡流程"></a><a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/networking_guide/sec-understanding_the_device_renaming_procedure" target="_blank" rel="external">用户态命名网卡流程</a></h3><p><a href="https://blog.csdn.net/biaotai/article/details/120710966" target="_blank" rel="external">CentOS 7提供了在网络接口中使用一致且可预期的网络设备命名方法， 目前默认使用的是net.ifnames规则</a>。The device name procedure in detail is as follows:</p>
<ol>
<li>A rule in <code>/usr/lib/udev/rules.d/60-net.rules</code> instructs the <strong>udev</strong> helper utility, <strong>/lib/udev/rename_device</strong>, to look into all <code>/etc/sysconfig/network-scripts/ifcfg-*suffix*</code> files. If it finds an <code>ifcfg</code> file with a <code>HWADDR</code> entry matching the MAC address of an interface it renames the interface to the name given in the <code>ifcfg</code> file by the <code>DEVICE</code> directive.（根据提前定义好的ifcfg-网卡名来命名网卡–依赖mac匹配，如果网卡的ifconfig文件中未加入HWADDR，则rename脚本并不会根据配置文件去重命名网卡）</li>
<li>A rule in <code>/usr/lib/udev/rules.d/71-biosdevname.rules</code> instructs <strong>biosdevname</strong> to rename the interface according to its naming policy, provided that it was not renamed in a previous step, <strong>biosdevname</strong> is installed, and <code>biosdevname=0</code> was not given as a kernel command on the boot command line.</li>
<li>A rule in <code>/lib/udev/rules.d/75-net-description.rules</code> instructs <strong>udev</strong> to fill in the internal <strong>udev</strong> device property values ID_NET_NAME_ONBOARD, ID_NET_NAME_SLOT, ID_NET_NAME_PATH, ID_NET_NAME_MAC by examining the network interface device. Note, that some device properties might be undefined.</li>
<li>A rule in <code>/usr/lib/udev/rules.d/80-net-name-slot.rules</code> instructs <strong>udev</strong> to rename the interface, provided that it was not renamed in step 1 or 2, and the kernel parameter <code>net.ifnames=0</code> was not given, according to the following priority: ID_NET_NAME_ONBOARD, ID_NET_NAME_SLOT, ID_NET_NAME_PATH. It falls through to the next in the list, if one is unset. If none of these are set, then the interface will not be renamed.</li>
</ol>
<p>Steps 3 and 4 are implementing the naming schemes 1, 2, 3, and optionally 4, described in <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/networking_guide/ch-Consistent_Network_Device_Naming#sec-Naming_Schemes_Hierarchy" target="_blank" rel="external">Section 11.1, “Naming Schemes Hierarchy”</a>. Step 2 is explained in more detail in <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/networking_guide/sec-Consistent_Network_Device_Naming_Using_biosdevname" target="_blank" rel="external">Section 11.6, “Consistent Network Device Naming Using biosdevname”</a>.</p>
<p>以上重命名简要概述就是对于CentOS系统，一般有下面几个rule在/usr/lib/udev/rule.d来重命名网卡：</p>
<ol>
<li>/usr/lib/udev/rules.d/60-net.rules 文件中的规则会让 udev 帮助工具/lib/udev/rename_device 查看所有 /etc/sysconfig/network-scripts/ifcfg-* 文件。如果发现包含 HWADDR 条目的 ifcfg 文件与某个接口的 MAC 地址匹配，它会将该接口重命名为ifcfg 文件中由 DEVICE 指令给出的名称。rename条件：如果网卡的ifconfig文件中未加入HWADDR，则rename脚本并不会根据配置文件去重命名网卡；</li>
<li>/usr/lib/udev/rules.d/71-biosdevname.rules 中的规则让 biosdevname 根据其命名策略重命名该接口，即在上一步中没有重命名该接口、安装biosdevname、且在 boot 命令行中将biosdevname=0 作为内核命令给出。（bisodevname规则，从CentOS 7 开始默认不使用，所以该条规则在不配置的情况下失效，直接去执行3；默认在cmdline中bisodevname=0，如果需要启用，则需要设置bisodevname=1）</li>
<li>/lib/udev/rules.d/75-net-description.rules 中的规则让 udev 通过检查网络接口设备，填写内部 udev 设备属性值 ID_NET_NAME_ONBOARD、ID_NET_NAME_SLOT、ID_NET_NAME_PATH、ID_NET_NAME_MAC。注：有些设备属性可能处于未定义状态。 –没有修改网卡名，只是取到了命名需要的一些属性值。查看：udevadm info -p /sys/class/net/enp125s0f0</li>
<li>/usr/lib/udev/rules.d/80-net-name-slot.rules 中的规则让 udev 重命名该接口，优先顺序如下：ID_NET_NAME_ONBOARD、ID_NET_NAME_SLOT、ID_NET_NAME_PATH。并提供如下信息：没有在步骤 1 或 2 中重命名该接口，同时未给出内核参数 net.ifnames=0。如果一个参数未设定，则会按列表的顺序设定下一个。如果没有设定任何参数，则不会重命名该接口 —- 目前主流CentOS流都是这个命名方式</li>
<li>network service起来后会遍历/etc/sysconfig/network-scripts下的脚本，配置bond0、默认路由、其它网卡等</li>
</ol>
<p>其中60 rule会调用rename_device根据ifcfg-xxx脚本来命名，rule 71调用biosdevname来命名网卡。以上规则数字越小优先级越高，高优先级生效后跳过低优先级</p>
<p>总的来说网卡命名规则：grub启动参数 -&gt; /etc/udev/rules.d/的rule -&gt; /usr/lib/udev/rule.d</p>
<h3 id="网卡命名"><a href="#网卡命名" class="headerlink" title="网卡命名"></a>网卡命名</h3><p><a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/networking_guide/sec-consistent_network_device_naming_using_biosdevname" target="_blank" rel="external">默认安装网卡所在位置来命名（enp131s0 等）</a>，按位置命名实例如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">//name example  ---默认方式，按照 /usr/lib/udev/rules.d/80-net-name-slot.rules 来命名</div><div class="line">enp4s10f1                        pci 0000:04:0a.1</div><div class="line">| | |  |                                |  |  | |</div><div class="line">| | |  |                   domain &lt;- 0000  |  | |</div><div class="line">| | |  |                                   |  | |</div><div class="line">en| |  |  --&gt; ethernet                     |  | |</div><div class="line">  | |  |                                   |  | |</div><div class="line">  p4|  |  --&gt; prefix/bus number (4)   &lt;-- 04  | |</div><div class="line">    |  |                                      | |</div><div class="line">    s10|  --&gt; slot/device number (10) &lt;--    10 |</div><div class="line">       |                                        |</div><div class="line">       f1 --&gt; function number (1)     &lt;--       1</div></pre></td></tr></table></figure>
<p>可以<a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/networking_guide/sec-disabling_consistent_network_device_naming" target="_blank" rel="external">关掉这种按位置命名的方式</a>，在grub参数中添加： net.ifnames=0 biosdevname=0，关闭后默认命名方式是eth**，开启biosdevname=1后，默认网卡命名方式是p1p1/p1p2(麒麟默认开启；alios默认关闭，然后以eth来命名)</p>
<blockquote>
<p>You have two options (<a href="https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/Networking_Guide/sec-Disabling_Consistent_Network_Device_Naming.html" target="_blank" rel="external">as described in the new RHEL 7 Networking Guide</a>) to disable the <a href="https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/Networking_Guide/ch-Consistent_Network_Device_Naming.html#sec-Understanding_the_Predictable_Network_Interface_Device_Names" target="_blank" rel="external">new naming scheme</a>:</p>
<ul>
<li>Run once: <code>ln -s /dev/null /etc/udev/rules.d/80-net-name-slot.rules</code></li>
</ul>
<p>or</p>
<ul>
<li>Run once: <code>echo &#39;GRUB_CMDLINE_LINUX=&quot;net.ifnames=0&quot;&#39; &gt;&gt;/etc/default/grub</code></li>
</ul>
<p>Note that the <strong>biosdevname</strong> package is not installed by default, so unless it gets installed, you don’t need to add <code>biosdevname=0</code> as a kernel argument.</p>
</blockquote>
<p>也可以添加命名规则在 /etc/udev/rules.d/ 下(这种优先级挺高），比如</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">cat /etc/udev/rules.d/70-persistent-net.rules</div><div class="line"># PCI device 21:00.0 (ixgbe)</div><div class="line">SUBSYSTEM==&quot;net&quot;, ACTION==&quot;add&quot;, DRIVERS==&quot;?*&quot;, ATTR&#123;address&#125;==&quot;d4:5d:64:bb:06:32&quot;, PROGRAM=&quot;/lib/udev/rename_device&quot;, ATTR&#123;type&#125;==&quot;1&quot;, KERNEL==&quot;eth*&quot;, NAME=&quot;eth0&quot;</div><div class="line"># PCI device 0x8086:0x105e (e1000e)</div><div class="line">SUBSYSTEM==&quot;net&quot;, ACTION==&quot;add&quot;, DRIVERS==&quot;?*&quot;, ATTR&#123;address&#125;==&quot;b8:59:9f:2d:48:2b&quot;, PROGRAM=&quot;/lib/udev/rename_device&quot;, ATTR&#123;type&#125;==&quot;1&quot;, KERNEL==&quot;eth*&quot;, NAME=&quot;eth1&quot;</div></pre></td></tr></table></figure>
<p>但是以上规则在麒麟下没有生效</p>
<p>网卡重命名方式：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">/sbin/ip link set eth1 name eth123</div></pre></td></tr></table></figure>
<h2 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h2><p><a href="https://www.cyberciti.biz/faq/linux-log-suspicious-martian-packets-un-routable-source-addresses/" target="_blank" rel="external">网卡日志打开</a>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">sysctl -w net.ipv4.conf.all.log_martians=1 //所有网卡</div><div class="line">sysctl -w net.ipv4.conf.p1p1.log_martians=1 //特定网卡</div><div class="line"></div><div class="line">/proc/sys/net/ipv4/conf/eth0.9/log_martians</div></pre></td></tr></table></figure>
<p>/var/log/messages中：</p>
<p>messages-20120101:Dec 31 09:25:45 nixcraft-router kernel: martian source 74.xx.47.yy from 10.13.106.25, on dev eth1</p>
<h2 id="修改mac地址"><a href="#修改mac地址" class="headerlink" title="修改mac地址"></a>修改mac地址</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sudo ip link set dev eth1 down</div><div class="line">sudo ip link set dev eth1 address e8:61:1f:33:c5:fd</div><div class="line">sudo ip link set dev eth1 up</div></pre></td></tr></table></figure>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://www.modb.pro/db/29135" target="_blank" rel="external">高斯在鲲鹏下跑TPCC的优化</a></p>
<p><a href="https://www.cyberciti.biz/faq/linux-log-suspicious-martian-packets-un-routable-source-addresses/" target="_blank" rel="external">https://www.cyberciti.biz/faq/linux-log-suspicious-martian-packets-un-routable-source-addresses/</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/01/01/如何用1分钱建站来秒杀搜狐新浪等三大门户网站/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/01/01/如何用1分钱建站来秒杀搜狐新浪等三大门户网站/" itemprop="url">如何用1分钱建站速度秒杀三大门户网站站</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-01-01T12:30:03+08:00">
                2021-01-01
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/技巧/" itemprop="url" rel="index">
                    <span itemprop="name">技巧</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="如何用1分钱建站速度秒杀三大门户网站"><a href="#如何用1分钱建站速度秒杀三大门户网站" class="headerlink" title="如何用1分钱建站速度秒杀三大门户网站"></a>如何用1分钱建站速度秒杀三大门户网站</h1><p>如何快速又便宜地建立一个高质量的网站呢(高质量指的是访问速度快)，还能够双站热备(国内国外热备两份内容)，整个开支大概一分钱吧</p>
<p>核心就是用阿里云的OSS来提供高速的访问。</p>
<h2 id="先看访问速度"><a href="#先看访问速度" class="headerlink" title="先看访问速度"></a>先看访问速度</h2><p>同样是访问下面三个网站首页:</p>
<p>OSS托管，页面大小 96.6MB、242个GET，耗时2.21秒加载，价格不到1分钱</p>
<p>搜狐首页，页面大小16.6MB、555个GET，耗时3.6秒</p>
<p>新浪首页， 页面大小17.8MB、404个GET，耗时9.63秒</p>
<h3 id="OSS托管的网站"><a href="#OSS托管的网站" class="headerlink" title="OSS托管的网站"></a>OSS托管的网站</h3><p>用OSS托管的网站加载速度，96MB页面（很大了）2.21秒加载完毕</p>
<p><img src="/images/951413iMgBlog/image-20210702140950863.png" alt="image-20210702140950863"></p>
<h3 id="访问搜狐首页"><a href="#访问搜狐首页" class="headerlink" title="访问搜狐首页"></a>访问搜狐首页</h3><p><img src="/images/951413iMgBlog/image-20210702141336301.png" alt="image-20210702141336301"></p>
<h3 id="访问新浪首页"><a href="#访问新浪首页" class="headerlink" title="访问新浪首页"></a>访问新浪首页</h3><p><img src="/images/951413iMgBlog/image-20210702142610162.png" alt="image-20210702142610162"></p>
<h2 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h2><p>OSS快的原因是：小网站并发不高，服务器、带宽资源充足，还不用花钱，没有机器、带宽维护成本以及人员成本</p>
<p>有专业的阿里云工程师负责运维，给的是最好的服务器、最大的带宽（你用的少就不用花钱，带宽资源费用超级便宜）</p>
<p>到底有多便宜呢？1.6万次GET请求才1分钱，0.52GB流量才0.25元，计价金额单位震惊我了</p>
<p><img src="/images/951413iMgBlog/image-20210702163910295.png" alt="image-20210702163910295"></p>
<h2 id="OSS托管网站方案"><a href="#OSS托管网站方案" class="headerlink" title="OSS托管网站方案"></a>OSS托管网站方案</h2><p>将所有内容静态化，然后上传到OSS就可以了</p>
<p>发布操作步骤：</p>
<ul>
<li>markdown编辑器中编写要发布的页面</li>
<li>用hexo静态化全站（将markdown转换成html页面）</li>
<li>git commit到github或者ossutil 同步到aliyun oss中</li>
</ul>
<p>比如下面就是我的网站发布脚本：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">#静态化网站，并同步到github，多活</div><div class="line">hexo g -d</div><div class="line"></div><div class="line">#sync all pages to oss</div><div class="line">ossutil --config-file=~/src/script/mac/.ossutilconfig sync ./public/ oss://mysite/ -u --output-dir=/tmp/</div></pre></td></tr></table></figure>
<p>实际我的网站通过github和OSS都能访问到，内容完全一样，github免费，但是多图页面速度太慢, 比如我一个页面几十个图，github加载偶尔失败, 但是我把图片放到了OSS，因为OSS超级快这样github加载也变得超级快了。</p>
<blockquote>
<p>hexo是一个node实现的网站生成工具</p>
</blockquote>
<p><a href="https://help.aliyun.com/document_detail/31872.html" target="_blank" rel="external">oss 托管网站介绍</a></p>
<p>感叹一下，个人建站现在真的是又便宜又方便，只是域名实名制恶心了点，那就干脆不要域名了。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2020/12/25/一个有意思的问题/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/12/25/一个有意思的问题/" itemprop="url">一个有意思的问题</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-12-25T17:30:03+08:00">
                2020-12-25
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Linux/" itemprop="url" rel="index">
                    <span itemprop="name">Linux</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="一个有意思的问题"><a href="#一个有意思的问题" class="headerlink" title="一个有意思的问题"></a>一个有意思的问题</h1><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">$mysql -N -h127.0.0.1 -e &quot;select id from sbtest1 limit 1&quot;</div><div class="line">+--------+</div><div class="line">| 100024 |</div><div class="line">+--------+</div><div class="line"></div><div class="line">$mysql -N -h127.0.0.1 -e &quot;select id from sbtest1 limit 1&quot; | cat</div><div class="line">100024</div><div class="line"></div><div class="line">$mysql -t -N -h127.0.0.1 -e &quot;select id from sbtest1 limit 1&quot; | cat</div><div class="line">+--------+</div><div class="line">| 100024 |</div><div class="line">+--------+</div></pre></td></tr></table></figure>
<p>如上第一和第二个语句，<strong>为什么mysql client的输出重定向后就没有ascii制表符了呢</strong>？ </p>
<p>语句三加上 -t后再经过管道，也有制表符了。</p>
<p><a href="https://stackoverflow.com/questions/15640287/change-output-format-for-mysql-command-line-results-to-csv/17910254" target="_blank" rel="external">stackoverflow上也有很多人有同样的疑问</a>，不过不但没有给出第三行的解法，更没有人讲清楚这个里面的原理。所以接下来我们来分析下这是为什么</p>
<h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>strace看看第一个语句：</p>
<p><img src="/images/oss/086f6cd952d2b91eae7eda6d576765f8.png" alt="image.png"></p>
<p>再对比下第二个语句的strace：</p>
<p><img src="/images/oss/984bcce23ff8766b52fdede8ff3eadec.png" alt="image.png"></p>
<p>从上面两个strace比较来看，似乎mysql client能检测到要输出到命名管道（S_IFIFO ）还是character device（S_IFCHR），如果是命名管道的话就不要输出制表符了，如果是character device那么就输出ascii制表符。</p>
<p><a href="https://linux.die.net/man/2/fstat64" target="_blank" rel="external">fstats里面对不同输出目标的说明</a>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">printf(&quot;File type:                &quot;);</div><div class="line">   switch (sb.st_mode &amp; S_IFMT) &#123;</div><div class="line">    case S_IFBLK:  printf(&quot;block device\n&quot;);            break;</div><div class="line">    case S_IFCHR:  printf(&quot;character device\n&quot;);        break;</div><div class="line">    case S_IFDIR:  printf(&quot;directory\n&quot;);               break;</div><div class="line">    case S_IFIFO:  printf(&quot;FIFO/pipe\n&quot;);               break;</div><div class="line">    case S_IFLNK:  printf(&quot;symlink\n&quot;);                 break;</div><div class="line">    case S_IFREG:  printf(&quot;regular file\n&quot;);            break;</div><div class="line">    case S_IFSOCK: printf(&quot;socket\n&quot;);                  break;</div><div class="line">    default:       printf(&quot;unknown?\n&quot;);                break;</div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<p>第4行和第6行两个类型就是导致mysql client选择了不同的输出内容</p>
<h2 id="误解"><a href="#误解" class="headerlink" title="误解"></a>误解</h2><p>所以这个问题不是： </p>
<blockquote>
<p><strong>为什么mysql client的输出重定向后就没有ascii制表符了呢</strong>？</p>
</blockquote>
<p>而是：</p>
<blockquote>
<p><strong>mysql client 可以检测到不同的输出目标然后输出不同的内容吗？</strong> 管道或者重定向是一个应用能感知的输出目标吗？</p>
</blockquote>
<p>误解：觉得管道写在后面，mysql client不应该知道后面是管道，mysql client输出内容到stdout，然后os将stdout的内容重定向给管道。</p>
<p>实际上mysql是可以检测（detect）输出目标的，如果是管道类的非交互输出那么没必要徒增一些制表符；如果是交互式界面那么就输出一些制表符好看一些。</p>
<p>要是想想在Unix下一切皆文件就更好理解了，输出到管道这个管道也是个文件，所以mysql client是可以感知各种输出文件的属性的。</p>
<p>背后的<a href="https://stackoverflow.com/questions/1312922/detect-if-stdin-is-a-terminal-or-pipe" target="_blank" rel="external">实现</a>大概是这样：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">#include &lt;stdio.h&gt;</div><div class="line">#include &lt;io.h&gt;</div><div class="line">...    </div><div class="line">if (isatty(fileno(stdout)))</div><div class="line">    printf( &quot;stdout is a terminal\n&quot; );      // 输出制表符</div><div class="line">else</div><div class="line">    printf( &quot;stdout is a file or a pipe\n&quot;); // 不输出制表符</div></pre></td></tr></table></figure>
<p><a href="https://linux.die.net/man/3/isatty" target="_blank" rel="external">isatty的解释</a></p>
<p>结论就是 mysql client根据输出目标的不同（stdout、重定向）输出不同的内容，不过这种做法对用户体感上不是太好。</p>
<h2 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h2><p>Linux管道居然不是按顺序，而是并发执行的：<a href="https://unix.stackexchange.com/questions/37508/in-what-order-do-piped-commands-run" target="_blank" rel="external">https://unix.stackexchange.com/questions/37508/in-what-order-do-piped-commands-run</a>  掉坑里了，并发问题就多了，实际测试也发现跑几千次 ps |grep 会出现，ps看不到后面的grep进程</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://www.pyrosoft.co.uk/blog/2014/09/08/how-to-stop-mysql-ascii-tables-column-separators-from-being-lost-when-redirecting-bash-output/" target="_blank" rel="external">https://www.pyrosoft.co.uk/blog/2014/09/08/how-to-stop-mysql-ascii-tables-column-separators-from-being-lost-when-redirecting-bash-output/</a></p>
<p><a href="https://www.oreilly.com/library/view/mysql-cookbook/0596001452/ch01s22.html" target="_blank" rel="external">https://www.oreilly.com/library/view/mysql-cookbook/0596001452/ch01s22.html</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2020/11/30/一台机器上最多能创建多少个TCP连接/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/11/30/一台机器上最多能创建多少个TCP连接/" itemprop="url">到底一台服务器上最多能创建多少个TCP连接</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-11-30T10:30:03+08:00">
                2020-11-30
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/TCP/" itemprop="url" rel="index">
                    <span itemprop="name">TCP</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="到底一台服务器上最多能创建多少个TCP连接"><a href="#到底一台服务器上最多能创建多少个TCP连接" class="headerlink" title="到底一台服务器上最多能创建多少个TCP连接"></a>到底一台服务器上最多能创建多少个TCP连接</h1><blockquote>
<p>经常听到有同学说一台机器最多能创建65535个TCP连接，这其实是错误的理解，为什么会有这个错误的理解呢？</p>
</blockquote>
<h2 id="port-range"><a href="#port-range" class="headerlink" title="port range"></a>port range</h2><p>我们都知道linux下本地随机端口范围由参数控制，也就是listen、connect时候如果没有指定本地端口，那么就从下面的port range中随机取一个可用的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># cat /proc/sys/net/ipv4/ip_local_port_range </div><div class="line">2000	65535</div></pre></td></tr></table></figure>
<p>port range的上限是65535，所以也经常看到这个<strong>误解</strong>：一台机器上最多能创建65535个TCP连接</p>
<h2 id="到底一台机器上最多能创建多少个TCP连接"><a href="#到底一台机器上最多能创建多少个TCP连接" class="headerlink" title="到底一台机器上最多能创建多少个TCP连接"></a>到底一台机器上最多能创建多少个TCP连接</h2><p>先说<strong>结论</strong>：在内存、文件句柄足够的话可以创建的连接是<strong>没有限制</strong>的（每个TCP连接至少要消耗一个文件句柄）。</p>
<p>那么/proc/sys/net/ipv4/ip_local_port_range指定的端口范围到底是什么意思呢？</p>
<p>核心规则：<strong>一个TCP连接只要保证四元组(src-ip src-port dest-ip dest-port)唯一就可以了，而不是要求src port唯一</strong></p>
<p>后面所讲都遵循这个规则，所以在心里反复默念：<strong>四元组唯一</strong> 五个大字，就能分析出来到底能创建多少TCP连接了。</p>
<p>比如如下这个机器上的TCP连接实际状态：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"># netstat -ant |grep 18089</div><div class="line">tcp        0      0 192.168.1.79:18089      192.168.1.79:22         ESTABLISHED</div><div class="line">tcp        0      0 192.168.1.79:18089      192.168.1.79:18080      ESTABLISHED</div><div class="line">tcp        0      0 192.168.0.79:18089      192.168.0.79:22         TIME_WAIT </div><div class="line">tcp        0      0 192.168.1.79:22         192.168.1.79:18089      ESTABLISHED</div><div class="line">tcp        0      0 192.168.1.79:18080      192.168.1.79:18089      ESTABLISHED</div></pre></td></tr></table></figure>
<p>从前三行可以清楚地看到18089被用了三次，第一第二行src-ip、dest-ip也是重复的，但是dest port不一样，第三行的src-port还是18089，但是src-ip变了。他们的四元组均不相同。</p>
<p>所以一台机器能创建的TCP连接是没有限制的，而ip_local_port_range是指没有bind的时候OS随机分配端口的范围，但是分配到的端口要同时满足五元组唯一，这样 ip_local_port_range 限制的是连同一个目标（dest-ip和dest-port一样）的port的数量（请忽略本地多网卡的情况，因为dest-ip为以后route只会选用一个本地ip）。</p>
<p><strong>那么为什么大家有这样的误解呢？</strong>我总结了下，大概是以下两个原因让大家误解了：</p>
<ul>
<li>如果是listen服务，那么肯定端口不能重复使用，这样就跟我们的误解对应上了，一个服务器上最多能监听65535个端口。比如nginx监听了80端口，那么tomcat就没法再监听80端口了，这里的80端口只能监听一次（如果有个连接用了80连别人，这里80还是不能被listen……想想）。</li>
<li>另外如果我们要连的server只有一个，比如：1.1.1.1:80 ，同时本机只有一个ip的话，那么这个时候即使直接调connect 也只能创建出65535个连接，因为四元组中的三个是固定的了。</li>
</ul>
<p>我们在创建连接前，经常会先调bind，bind后可以调listen当做服务端监听，也可以直接调connect当做client来连服务端。</p>
<p>bind(ip,port=0) 的时候是让系统绑定到某个网卡和自动分配的端口，此时系统没有办法确定接下来这个socket是要去connect还是listen. 如果是listen的话，那么肯定是不能出现端口冲突的，如果是connect的话，只要满足4元组唯一即可。在这种情况下，系统只能尽可能满足更强的要求，就是先要求端口不能冲突，即使之后去connect的时候四元组是唯一的。</p>
<p>但如果我只是个client端，只需要连接server建立连接，也就不需要bind，直接调connect就可以了，这个时候只要保证四元组唯一就行。</p>
<p>bind()的时候内核是还不知道四元组的，只知道src_ip、src_port，所以这个时候单网卡下src_port是没法重复的，但是connect()的时候已经知道了四元组的全部信息，所以只要保证四元组唯一就可以了，那么这里的src_port完全是可以重复使用的。</p>
<p><img src="/images/951413iMgBlog/640-20220224103024676.png" alt="Image"></p>
<p><strong>是不是加上了 SO_REUSEADDR、SO_REUSEPORT 就能重用端口了呢？</strong></p>
<h2 id="TCP-SO-REUSEADDR"><a href="#TCP-SO-REUSEADDR" class="headerlink" title="TCP SO_REUSEADDR"></a>TCP SO_REUSEADDR</h2><p>文档描述：</p>
<blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt; SO_REUSEADDR      Indicates that the rules used in validating addresses supplied      in a bind(2) call should allow reuse of local addresses.  For      AF_INET sockets this means that a socket may bind, except when      there is an active listening socket bound to the address.      When the listening socket is bound to INADDR_ANY with a spe‐      cific port then it is not possible to bind to this port for      any local address.  Argument is an integer boolean flag.</div><div class="line">&gt;</div></pre></td></tr></table></figure>
</blockquote>
<p>从这段文档中我们可以知道三个事：</p>
<ol>
<li>使用这个参数后，bind操作是可以重复使用local address的，注意，这里说的是local address，即ip加端口组成的本地地址，也就是说，两个本地地址，如果有任意ip或端口部分不一样，它们本身就是可以共存的，不需要使用这个参数。</li>
<li>当local address被一个处于listen状态的socket使用时，加上该参数也不能重用这个地址。</li>
<li>当处于listen状态的socket监听的本地地址的ip部分是INADDR_ANY，即表示监听本地的所有ip，即使使用这个参数，也不能再bind包含这个端口的任意本地地址，这个和 2 中描述的其实是一样的。</li>
</ol>
<p>SO_REUSEADDR 可以用本地相同的(sip, sport) 去连connect 远程的不同的（dip、dport）//SO_REUSEPORT主要是解决Server端的port重用</p>
<p><a href="https://mp.weixin.qq.com/s/YWzuKBK3TMclejeN2ziAvQ" target="_blank" rel="external">SO_REUSEADDR 还可以重用TIME_WAIT状态的port</a>, 在程序崩溃后之前的TCP连接会进入到TIME_WAIT状态，需要一段时间才能释放，如果立即重启就会抛出Address Already in use的错误导致启动失败。可以通过在调用bind函数之前设置SO_REUSEADDR来解决。</p>
<blockquote>
<p>What exactly does SO_REUSEADDR do?</p>
<p>This socket option tells the kernel that even if this port is busy (in the TIME_WAIT state), go ahead and reuse it anyway. If it is busy, but with another state, you will still get an address already in use error. It is useful if your server has been shut down, and then restarted right away while sockets are still active on its port. You should be aware that if any unexpected data comes in, it may confuse your server, but while this is possible, it is not likely.</p>
<p>It has been pointed out that “A socket is a 5 tuple (proto, local addr, local port, remote addr, remote port). SO_REUSEADDR just says that you can reuse local addresses. The 5 tuple still must be unique!” This is true, and this is why it is very unlikely that unexpected data will ever be seen by your server. The danger is that such a 5 tuple is still floating around on the net, and while it is bouncing around, a new connection from the same client, on the same system, happens to get the same remote port. </p>
</blockquote>
<p>By setting <code>SO_REUSEADDR</code> user informs the kernel of an intention to share the bound port with anyone else, but only if it doesn’t cause a conflict on the protocol layer. There are at least three situations when this flag is useful:</p>
<ol>
<li>Normally after binding to a port and stopping a server it’s neccesary to wait for a socket to time out before another server can bind to the same port. With <code>SO_REUSEADDR</code> set it’s possible to rebind immediately, even if the socket is in a <code>TIME_WAIT</code> state.</li>
<li>When one server binds to <code>INADDR_ANY</code>, say <code>0.0.0.0:1234</code>, it’s impossible to have another server binding to a specific address like <code>192.168.1.21:1234</code>. With <code>SO_REUSEADDR</code> flag this behaviour is allowed.</li>
<li>When using the bind before connect trick only a single connection can use a single outgoing source port. With this flag, it’s possible for many connections to reuse the same source port, given that they connect to different destination addresses.</li>
</ol>
<h2 id="TCP-SO-REUSEPORT"><a href="#TCP-SO-REUSEPORT" class="headerlink" title="TCP SO_REUSEPORT"></a>TCP SO_REUSEPORT</h2><p>SO_REUSEPORT主要用来解决惊群、性能等问题。通过多个进程、线程来监听同一端口，进来的连接通过内核来hash分发做到负载均衡，避免惊群。</p>
<blockquote>
<p>SO_REUSEPORT is also useful for eliminating the try-10-times-to-bind hack in ftpd’s data connection setup routine.  Without SO_REUSEPORT, only one ftpd thread can bind to TCP (lhost, lport, INADDR_ANY, 0) in preparation for connecting back to the client.  Under conditions of heavy load, there are more threads colliding here than the try-10-times hack can accomodate.  With SO_REUSEPORT, things  work nicely and the hack becomes unnecessary.</p>
</blockquote>
<p>SO_REUSEPORT使用场景：linux kernel 3.9 引入了最新的SO_REUSEPORT选项，使得多进程或者多线程创建多个绑定同一个ip:port的监听socket，提高服务器的接收链接的并发能力,程序的扩展性更好；此时需要设置SO_REUSEPORT（<strong>注意所有进程都要设置才生效</strong>）。</p>
<p>setsockopt(listenfd, SOL_SOCKET, SO_REUSEPORT,(const void *)&amp;reuse , sizeof(int));</p>
<p>目的：每一个进程有一个独立的监听socket，并且bind相同的ip:port，独立的listen()和accept()；提高接收连接的能力。（例如nginx多进程同时监听同一个ip:port）</p>
<blockquote>
<p>(a) on Linux SO_REUSEPORT is meant to be used <em>purely</em> for load balancing multiple incoming UDP packets or incoming TCP connection requests across multiple sockets belonging to the same app.  ie. it’s a work around for machines with a lot of cpus, handling heavy load, where a single listening socket becomes a bottleneck because of cross-thread contention on the in-kernel socket lock (and state).</p>
<p>(b) set IP_BIND_ADDRESS_NO_PORT socket option for tcp sockets before binding to a specific source ip<br>with port 0 if you’re going to use the socket for connect() rather then listen() this allows the kernel<br>to delay allocating the source port until connect() time at which point it is much cheaper</p>
</blockquote>
<h2 id="The-Ephemeral-Port-Range"><a href="#The-Ephemeral-Port-Range" class="headerlink" title="The Ephemeral Port Range"></a><a href="http://www.ncftp.com/ncftpd/doc/misc/ephemeral_ports.html" target="_blank" rel="external">The Ephemeral Port Range</a></h2><p>Ephemeral Port Range就是我们前面所说的Port Range（/proc/sys/net/ipv4/ip_local_port_range）</p>
<blockquote>
<p>A TCP/IPv4 connection consists of two endpoints, and each endpoint consists of an IP address and a port number. Therefore, when a client user connects to a server computer, an established connection can be thought of as the 4-tuple of (server IP, server port, client IP, client port).</p>
<p>Usually three of the four are readily known – client machine uses its own IP address and when connecting to a remote service, the server machine’s IP address and service port number are required.</p>
<p>What is not immediately evident is that when a connection is established that the client side of the connection uses a port number. Unless a client program explicitly requests a specific port number, the port number used is an ephemeral port number.</p>
<p>Ephemeral ports are temporary ports assigned by a machine’s IP stack, and are assigned from a designated range of ports for this purpose. When the connection terminates, the ephemeral port is available for reuse, although most IP stacks won’t reuse that port number until the entire pool of ephemeral ports have been used.</p>
<p>So, if the client program reconnects, it will be assigned a different ephemeral port number for its side of the new connection.</p>
</blockquote>
<h2 id="linux-如何选择Ephemeral-Port"><a href="#linux-如何选择Ephemeral-Port" class="headerlink" title="linux 如何选择Ephemeral Port"></a>linux 如何选择Ephemeral Port</h2><p>有资料说是随机从Port Range选择port，有的说是顺序选择，那么实际验证一下。</p>
<p>如下测试代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line">#include &lt;stdio.h&gt;      // printf</div><div class="line">#include &lt;stdlib.h&gt;     // atoi</div><div class="line">#include &lt;unistd.h&gt;     // close</div><div class="line">#include &lt;arpa/inet.h&gt;  // ntohs</div><div class="line">#include &lt;sys/socket.h&gt; // connect, socket</div><div class="line"></div><div class="line">void sample() &#123;</div><div class="line">    // Create socket</div><div class="line">    int sockfd;</div><div class="line">    if (sockfd = socket(AF_INET, SOCK_STREAM, 0), -1 == sockfd) &#123;</div><div class="line">        perror(&quot;socket&quot;);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    // Connect to remote. This does NOT actually send a packet.</div><div class="line">    const struct sockaddr_in raddr = &#123;</div><div class="line">        .sin_family = AF_INET,</div><div class="line">        .sin_port   = htons(8080),     // arbitrary remote port</div><div class="line">        .sin_addr   = htonl(INADDR_ANY)  // arbitrary remote host</div><div class="line">    &#125;;</div><div class="line">    if (-1 == connect(sockfd, (const struct sockaddr *)&amp;raddr, sizeof(raddr))) &#123;</div><div class="line">        perror(&quot;connect&quot;);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    // Display selected ephemeral port</div><div class="line">    const struct sockaddr_in laddr;</div><div class="line">    socklen_t laddr_len = sizeof(laddr);</div><div class="line">    if (-1 == getsockname(sockfd, (struct sockaddr *)&amp;laddr, &amp;laddr_len)) &#123;</div><div class="line">        perror(&quot;getsockname&quot;);</div><div class="line">    &#125;</div><div class="line">    printf(&quot;local port: %i\n&quot;, ntohs(laddr.sin_port));</div><div class="line"></div><div class="line">    // Close socket</div><div class="line">    close(sockfd);</div><div class="line">&#125;</div><div class="line"></div><div class="line">int main() &#123;</div><div class="line">    for (int i = 0; i &lt; 5; i++) &#123;</div><div class="line">        sample();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    return 0;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>bind逻辑测试代码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line">#include &lt;netinet/in.h&gt;</div><div class="line">#include &lt;arpa/inet.h&gt;</div><div class="line">#include &lt;stdio.h&gt;</div><div class="line">#include &lt;stdlib.h&gt;</div><div class="line">#include &lt;unistd.h&gt;</div><div class="line">#include &lt;errno.h&gt;</div><div class="line">#include &lt;string.h&gt;</div><div class="line">#include &lt;sys/types.h&gt;</div><div class="line">#include &lt;time.h&gt;</div><div class="line"></div><div class="line">void test_bind()&#123;</div><div class="line">    int listenfd = 0, connfd = 0;</div><div class="line">    struct sockaddr_in serv_addr;</div><div class="line">    char sendBuff[1025];</div><div class="line">    time_t ticks;</div><div class="line">	  socklen_t len;</div><div class="line"></div><div class="line">    listenfd = socket(AF_INET, SOCK_STREAM, 0);</div><div class="line">    memset(&amp;serv_addr, &apos;0&apos;, sizeof(serv_addr));</div><div class="line">    memset(sendBuff, &apos;0&apos;, sizeof(sendBuff));</div><div class="line"></div><div class="line">    serv_addr.sin_family = AF_INET;</div><div class="line">    serv_addr.sin_addr.s_addr = htonl(INADDR_ANY);</div><div class="line">    serv_addr.sin_port = htons(0);</div><div class="line"></div><div class="line">    bind(listenfd, (struct sockaddr*)&amp;serv_addr, sizeof(serv_addr));</div><div class="line"></div><div class="line">  	len = sizeof(serv_addr);</div><div class="line">	  if (getsockname(listenfd, (struct sockaddr *)&amp;serv_addr, &amp;len) == -1) &#123;</div><div class="line">		      perror(&quot;getsockname&quot;);</div><div class="line">			    return;</div><div class="line">	  &#125;</div><div class="line">	  printf(&quot;port number %d\n&quot;, ntohs(serv_addr.sin_port)); //只是挑选到了port，在系统层面保留，tcp连接还没有，netstat是看不到的</div><div class="line">&#125;</div><div class="line"></div><div class="line">int main(int argc, char *argv[])</div><div class="line">&#123;</div><div class="line">	    for (int i = 0; i &lt; 5; i++) &#123;</div><div class="line">			         test_bind();</div><div class="line">					     &#125;</div><div class="line">		    return 0;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="3-10-0-327-ali2017-alios7-x86-64"><a href="#3-10-0-327-ali2017-alios7-x86-64" class="headerlink" title="3.10.0-327.ali2017.alios7.x86_64"></a>3.10.0-327.ali2017.alios7.x86_64</h3><p>编译后，执行(3.10.0-327.ali2017.alios7.x86_64)：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line">#date; ./client &amp;&amp; echo &quot;+++++++&quot; ; ./client &amp;&amp; sleep 0.1 ; echo &quot;-------&quot; &amp;&amp; ./client &amp;&amp; sleep 10; date; ./client &amp;&amp; echo &quot;+++++++&quot; ; ./client &amp;&amp; sleep 0.1 &amp;&amp; echo &quot;******&quot;; ./client;</div><div class="line">Fri Nov 27 10:52:52 CST 2020</div><div class="line">local port: 17448</div><div class="line">local port: 17449</div><div class="line">local port: 17451</div><div class="line">local port: 17452</div><div class="line">local port: 17453</div><div class="line">+++++++</div><div class="line">local port: 17455</div><div class="line">local port: 17456</div><div class="line">local port: 17457</div><div class="line">local port: 17458</div><div class="line">local port: 17460</div><div class="line">-------</div><div class="line">local port: 17475</div><div class="line">local port: 17476</div><div class="line">local port: 17477</div><div class="line">local port: 17478</div><div class="line">local port: 17479</div><div class="line">Fri Nov 27 10:53:02 CST 2020</div><div class="line">local port: 17997</div><div class="line">local port: 17998</div><div class="line">local port: 17999</div><div class="line">local port: 18000</div><div class="line">local port: 18001</div><div class="line">+++++++</div><div class="line">local port: 18002</div><div class="line">local port: 18003</div><div class="line">local port: 18004</div><div class="line">local port: 18005</div><div class="line">local port: 18006</div><div class="line">******</div><div class="line">local port: 18010</div><div class="line">local port: 18011</div><div class="line">local port: 18012</div><div class="line">local port: 18013</div><div class="line">local port: 18014</div></pre></td></tr></table></figure>
<p>从测试看起来linux下端口选择跟时间有关系，起始端口肯定是顺序增加，起始端口应该是在Ephemeral Port范围内并且和时间戳绑定的某个值（也是递增的），即使没有使用任何端口，起始端口也会随时间增加而增加。</p>
<h3 id="4-19-91-19-1-al7-x86-64"><a href="#4-19-91-19-1-al7-x86-64" class="headerlink" title="4.19.91-19.1.al7.x86_64"></a>4.19.91-19.1.al7.x86_64</h3><p>换个内核版本编译后，执行(4.19.91-19.1.al7.x86_64)：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line">$date; ./client &amp;&amp; echo &quot;+++++++&quot; ; ./client &amp;&amp; sleep 0.1 ; echo &quot;-------&quot; &amp;&amp; ./client &amp;&amp; sleep 10; date; ./client &amp;&amp; echo &quot;+++++++&quot; ; ./client &amp;&amp; sleep 0.1 &amp;&amp; echo &quot;******&quot;; ./client;</div><div class="line">Fri Nov 27 14:10:47 CST 2020</div><div class="line">local port: 7890</div><div class="line">local port: 7892</div><div class="line">local port: 7894</div><div class="line">local port: 7896</div><div class="line">local port: 7898</div><div class="line">+++++++</div><div class="line">local port: 7900</div><div class="line">local port: 7902</div><div class="line">local port: 7904</div><div class="line">local port: 7906</div><div class="line">local port: 7908</div><div class="line">-------</div><div class="line">local port: 7910</div><div class="line">local port: 7912</div><div class="line">local port: 7914</div><div class="line">local port: 7916</div><div class="line">local port: 7918</div><div class="line">Fri Nov 27 14:10:57 CST 2020</div><div class="line">local port: 7966</div><div class="line">local port: 7968</div><div class="line">local port: 7970</div><div class="line">local port: 7972</div><div class="line">local port: 7974</div><div class="line">+++++++</div><div class="line">local port: 7976</div><div class="line">local port: 7978</div><div class="line">local port: 7980</div><div class="line">local port: 7982</div><div class="line">local port: 7984</div><div class="line">******</div><div class="line">local port: 7988</div><div class="line">local port: 7990</div><div class="line">local port: 7992</div><div class="line">local port: 7994</div><div class="line">local port: 7996</div></pre></td></tr></table></figure>
<p>以上测试时的参数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$cat /proc/sys/net/ipv4/ip_local_port_range</div><div class="line">1024    65535</div></pre></td></tr></table></figure>
<p>将1024改成1025后，分配出来的都是奇数端口了：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">$cat /proc/sys/net/ipv4/ip_local_port_range</div><div class="line">1025    1034</div><div class="line"></div><div class="line">$./client</div><div class="line">local port: 1033</div><div class="line">local port: 1025</div><div class="line">local port: 1027</div><div class="line">local port: 1029</div><div class="line">local port: 1031</div><div class="line">local port: 1033</div><div class="line">local port: 1025</div><div class="line">local port: 1027</div><div class="line">local port: 1029</div><div class="line">local port: 1031</div><div class="line">local port: 1033</div><div class="line">local port: 1025</div><div class="line">local port: 1027</div><div class="line">local port: 1029</div><div class="line">local port: 1031</div></pre></td></tr></table></figure>
<p>之所以都是偶数端口，是因为port_range 从偶数开始, 每次从++变到+2的<a href="https://github.com/plantegg/linux/commit/1580ab63fc9a03593072cc5656167a75c4f1d173" target="_blank" rel="external">原因</a>，connect挑选随机端口时都是在起始端口的基础上+2，而bind挑选随机端口的起始端口是系统port_range起始端口+1（这样和connect错开），然后每次仍然尝试+2，这样connect和bind基本一个用偶数另外一个就用奇数，一旦不够了再尝试使用另外一组</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">$cat /proc/sys/net/ipv4/ip_local_port_range</div><div class="line">1024    1047</div><div class="line"></div><div class="line">$./bind &amp;  ---bind程序随机挑选5个端口</div><div class="line">port number 1039</div><div class="line">port number 1043</div><div class="line">port number 1045</div><div class="line">port number 1041</div><div class="line">port number 1047  --用完所有奇数端口</div><div class="line"></div><div class="line">$./bind &amp;    --继续挑选偶数端口</div><div class="line">[8] 4170</div><div class="line">port number 1044</div><div class="line">port number 1042</div><div class="line">port number 1046</div><div class="line">port number 0    --实在没有了</div><div class="line">port number 0</div></pre></td></tr></table></figure>
<p>可见4.19内核下每次port是+2，在3.10内核版本中是+1. 并且都是递增的，同时即使port不使用，也会随着时间的变化这个起始port增大。</p>
<p>Port Range有点像雷达转盘数字，时间就像是雷达上的扫描指针，这个指针不停地旋转，如果这个时候刚好有应用要申请Port，那么就从指针正好指向的Port开始向后搜索可用port</p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><ul>
<li>在内存、文件句柄足够的话一台服务器上可以创建的TCP连接数量是没有限制的</li>
<li>SO_REUSEADDR 主要用于快速重用 TIME_WAIT状态的TCP端口，避免服务重启就会抛出Address Already in use的错误</li>
<li>SO_REUSEPORT主要用来解决惊群、性能等问题</li>
<li>local port的选择是递增搜索的，搜索起始port随时间增加也变大</li>
</ul>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://segmentfault.com/a/1190000002396411" target="_blank" rel="external">https://segmentfault.com/a/1190000002396411</a></p>
<p><a href="https://blog.csdn.net/a364572/article/details/40628171" target="_blank" rel="external">linux中TCP的socket、bind、listen、connect和accept的实现</a></p>
<p><a href="https://ops.tips/blog/how-linux-tcp-introspection/" target="_blank" rel="external">How Linux allows TCP introspection The inner workings of bind and listen on Linux.</a></p>
<p><a href="https://idea.popcount.org/2014-04-03-bind-before-connect/" target="_blank" rel="external">https://idea.popcount.org/2014-04-03-bind-before-connect/</a></p>
<p><a href="https://mp.weixin.qq.com/s/C-Eeoeh9GHxugF4J30fz1A" target="_blank" rel="external">TCP连接中客户端的端口号是如何确定的？</a></p>
<p><a href="https://github.com/plantegg/linux/commit/9b3312bf18f6873e67f1f51dab3364c95c9dc54c" target="_blank" rel="external">对应4.19内核代码解析</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2020/11/23/一次春节大促性能压测不达标的瓶颈推演/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/11/23/一次春节大促性能压测不达标的瓶颈推演/" itemprop="url">一次春节大促性能压测不达标的瓶颈推演</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-11-23T11:30:03+08:00">
                2020-11-23
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/performance/" itemprop="url" rel="index">
                    <span itemprop="name">performance</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="一次春节大促性能压测不达标的瓶颈推演"><a href="#一次春节大促性能压测不达标的瓶颈推演" class="headerlink" title="一次春节大促性能压测不达标的瓶颈推演"></a>一次春节大促性能压测不达标的瓶颈推演</h1><p>本文示范了教科书式的在分布式应用场景下如何通过一个节点的状态来推演分析瓶颈出在上下游的哪个环节上。</p>
<h2 id="场景描述"><a href="#场景描述" class="headerlink" title="场景描述"></a>场景描述</h2><p>某客户通过PTS（一个打压力工具）来压选号业务(HTTP服务在9108端口上），一个HTTP请求对应一次select seq-id 和 一次insert</p>
<p>PTS端看到RT900ms+，QPS大概5万（期望20万）， 数据库代理服务 rt 5ms，QPS 10万+</p>
<h3 id="链路："><a href="#链路：" class="headerlink" title="链路："></a>链路：</h3><p>pts发起压力 -&gt; 5个eip -&gt; slb -&gt; app(300个容器运行tomcat监听9108端口上） -&gt; slb -&gt; 数据库代理服务集群 -&gt; RDS集群</p>
<p>性能不达标，怀疑数据库代理服务或者RDS性能不行，作为数据库需要自证清白，所以从RDS和数据库代理服务开始分析问题在哪里。</p>
<p>略过一系列在数据库代理服务、RDS上分析数据和监控图表都证明数据库代理服务和RDS没问题的过程。</p>
<p>在明确给出证据数据库代理服务和RDS都没问题后还是要解决问题，所以只能进一步帮助前面的app来分析为什么性能不达标。</p>
<h2 id="在其中一个app应用上抓包（00-18秒到1-04秒），到数据库代理服务的一个连接分析："><a href="#在其中一个app应用上抓包（00-18秒到1-04秒），到数据库代理服务的一个连接分析：" class="headerlink" title="在其中一个app应用上抓包（00:18秒到1:04秒），到数据库代理服务的一个连接分析："></a>在其中一个app应用上抓包（00:18秒到1:04秒），到数据库代理服务的一个连接分析：</h2><p><img src="/images/oss/80374e55936bc36bbd243f79fcdb5f8d.png" alt="image.png"></p>
<p>数据库代理服务每个HTTP请求的响应时间都控制在15ms(一个前端HTTP请求对应一个select seq-id，一个 select readonly, 一个insert， 这个响应时间符合预期）。一个连接每秒才收到20 tps（因为压力不够，压力加大的话这个单连接tps还可以增加）， 20*3000 = 6万 ， 跟压测看到基本一致</p>
<p>300个容器，每个容器 10个连接到数据库代理服务</p>
<p>如果300个容器上的并发压力不够的话就没法将3000个连接跑满，所以看到的QPS是5万。</p>
<p><strong>从300个容器可以计算得到这个集群能支持的tps： 300*10（10个连接）* 1000/15(每秒钟每个连接能处理的请求数）=20万个tps （关键分析能力）</strong></p>
<p>也就是说通过单QPS 15ms，我们计算可得整个后端的吞吐能力在20万QPS。所以目前问题不在后端，而是压力没有打到后端就出现瓶颈了。</p>
<h2 id="9108的HTTP服务端口上的抓包分析"><a href="#9108的HTTP服务端口上的抓包分析" class="headerlink" title="9108的HTTP服务端口上的抓包分析"></a>9108的HTTP服务端口上的抓包分析</h2><p><img src="/images/oss/e239a12a1c3612263736256c8efc06e4.png" alt="image.png"></p>
<p>9108服务的每个HTTP response差不多都是15ms（<strong>这个响应时间基本符合预期</strong>），一个HTTP连接上在45秒的抓包时间范围只收到23个HTTP Request。</p>
<p>统计9108端口在45秒总共收到的HTTP请求数量是6745（如下图），也就是每个app每秒钟收到的请求是150个，300<em>150=4.5万（理论值，300个app可能压力分布不一样？），<em>*从这里看app收到的压力还不够</em></em>，所以压力还没有打到应用容器中的app，还在更前面</p>
<p><img src="/images/oss/6a289d1bba1e875d215032b6fdc7b084.png" alt="image.png"></p>
<p>后来从容器app监控也确认了这个响应时间和抓包看到的一致，所以从抓包分析http响应时间也基本得到15ms的rt关键结论</p>
<h2 id="从应用容器上的netstat统计来看，也是压力端回复太慢"><a href="#从应用容器上的netstat统计来看，也是压力端回复太慢" class="headerlink" title="从应用容器上的netstat统计来看，也是压力端回复太慢"></a>从应用容器上的netstat统计来看，也是压力端回复太慢</h2><p><img src="/images/oss/938ce314d19b47cba99e2a09c753f606.png" alt="image.png"></p>
<p>send-q表示回复从9108发走了，没收到对方的ack</p>
<h2 id="ARMS监控分析9108端口上的RT"><a href="#ARMS监控分析9108端口上的RT" class="headerlink" title="ARMS监控分析9108端口上的RT"></a>ARMS监控分析9108端口上的RT</h2><p>后来PTS的同学说ARMS可以捞到监控数据，如下是对rt时间降序排</p>
<p><img src="/images/oss/a479bad250c03aee41d58850afab9c14.png" alt="image.png"></p>
<p>中的rt平均时间，可以看到http的rt确实14.4ms，表现非常平稳，从这个监控也发现实际app是330个而不是用户自己描述的300个，这也就是为什么实际是tps是5万，但是按300个去算的话tps是4.5万（不要纠结客户为什么告诉你是300个容器而不是330个，有时候他们也搞不清楚，业务封装得太好了）</p>
<p><img src="/images/oss/2f3b76be63d331510eb6f2cecd91747f.png" alt="image.png"></p>
<p>5分钟时间，QPS是5万+，HTTP的平均rt是15ms， HTTP的最大rt才79ms，和前面抓包分析一致。</p>
<h2 id="从后端分析的总结"><a href="#从后端分析的总结" class="headerlink" title="从后端分析的总结"></a>从后端分析的总结</h2><p><strong>从9108端口响应时间15ms来看是符合预期的，为什么PTS看到的RT是900ms+，所以压力还没有打到APP上（也就是9108端口）</strong></p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>最后发现是 eip 带宽不足，只有200M，调整到1G后 tps 也翻了5倍到了25万。</p>
<p>pts -&gt; 5个eip(总带宽200M) -&gt; slb -&gt; app(330个HTTP容器） -&gt; slb -&gt; 数据库代理服务 -&gt; RDS</p>
<p>这个案例有意思的地方是可以通过抓包就能分析出集群能扛的QPS20万（实际只有5万），那么可以把这个分析原则在每个角色上挨个分析一下，来看瓶颈出在了哪个环节。</p>
<p>应用端看到的rt是900ms，从后段开始往前面应用端来撸，看看每个环节的rt数据。</p>
<h2 id="教训"><a href="#教训" class="headerlink" title="教训"></a>教训</h2><ul>
<li>搞清楚 请求 从发起端到DB的链路路径，比如 pts -&gt; 5个eip(总带宽200M) -&gt; slb -&gt;  app(330个HTTP容器） -&gt; slb -&gt; 数据库代理服务 -&gt; RDS </li>
<li>压不上去得从发压力端开始往后端撸，撸每个产品的rt，每个产品给出自己的rt来自证清白</li>
<li>应用有arms的话学会看arms对平均rt和QPS的统计，不要纠结个别请求的rt抖动，看平均rt</li>
<li>通过抓包完全可以分析出来系统能扛多少并发，以及可能的瓶颈位置</li>
</ul>
<p>一包在手 万事无忧</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2020/11/18/TCP连接为啥互串了/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/11/18/TCP连接为啥互串了/" itemprop="url">活久见，TCP连接互串了</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-11-18T17:30:03+08:00">
                2020-11-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/TCP/" itemprop="url" rel="index">
                    <span itemprop="name">TCP</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="活久见，TCP连接互串了"><a href="#活久见，TCP连接互串了" class="headerlink" title="活久见，TCP连接互串了"></a>活久见，TCP连接互串了</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>应用每过一段时间总是会抛出几个连接异常的错误，需要查明原因。</p>
<p>排查后发现是TCP连接互串了，这个案例实在是很珍惜，所以记录一下。</p>
<h2 id="抓包"><a href="#抓包" class="headerlink" title="抓包"></a>抓包</h2><p>业务结构： 应用-&gt;MySQL(10.112.61.163)</p>
<p>在 应用 机器上抓包这个异常连接如下（3269为MySQL服务端口）：</p>
<p><img src="/images/oss/dd657fee9d961a786c05e8d3cccbc297.png" alt="image.png"></p>
<p>粗一看没啥奇怪的，就是应用发查询给3269，但是一直没收到3269的ack，所以一直重传。这里唯一的解释就是网络不通。最后MySQL的3269还回复了一个rst，这个rst的id是42889，引起了我的好奇，跟前面的16439不连贯，正常应该是16440才对。（请记住上图中的绿框中的数字）</p>
<p>于是我过滤了一下端口61902上的所有包：</p>
<p><img src="/images/oss/8ca7da8ccec0041dd5d3f66f94d1f574.png" alt="image.png"></p>
<p>可以看到绿框中的查询从61902端口发给3269后，很奇怪居然收到了一个来自别的IP+3306端口的reset，这个包对这个连接来说自然是不认识（这个连接只接受3269的回包），就扔掉了。但是也没收到3269的ack，所以只能不停地重传，然后每次都收到3306的reset，reset包的seq、id都能和上图的绿框对应上。</p>
<p>明明他们应该是两个连接：</p>
<blockquote>
<p> 61902-&gt;10.141.16.0:3306</p>
<p> 61902-&gt;10.112.61.163:3269</p>
</blockquote>
<p>他们虽然用的本地ip端口（61902）是一样的， 但是根据四元组不一样，还是不同的TCP连接，所以应该是不会互相干扰的。但是实际看起来<strong>seq、id都重复了</strong>，不会有这么巧，非常像是TCP互串了。</p>
<h2 id="分析原因"><a href="#分析原因" class="headerlink" title="分析原因"></a>分析原因</h2><p>10.141.16.0 这个ip看起来像是lvs的ip，查了一下系统，果然是lvs，然后这个lvs 后面的rs就是10.112.61.163</p>
<p>那么这个连结构就是10.141.16.0:3306：</p>
<blockquote>
<p>应用 -&gt; lvs(10.141.16.0:3306)-&gt; 10.112.61.163:3269  跟应用直接连MySQL是一回事了</p>
</blockquote>
<p>所以这里的疑问就变成了：<strong>10.141.16.0 这个IP的3306端口为啥能知道 10.112.61.163:3269端口的seq和id，也许是TCP连接串了</strong></p>
<p>接着往下排查</p>
<h3 id="先打个岔，分析下这里的LVS的原理"><a href="#先打个岔，分析下这里的LVS的原理" class="headerlink" title="先打个岔，分析下这里的LVS的原理"></a><a href="/2019/06/20/就是要你懂负载均衡--lvs和转发模式/">先打个岔，分析下这里的LVS的原理</a></h3><p>这里使用的是 full NAT模型(full NetWork Address Translation-全部网络地址转换)</p>
<p>基本流程（类似NAT）：</p>
<ol>
<li>client发出请求（sip 200.200.200.2 dip 200.200.200.1）</li>
<li>请求包到达lvs，lvs修改请求包为<strong>（sip 200.200.200.1， dip rip）</strong> 注意这里sip/dip都被修改了</li>
<li>请求包到达rs， rs回复（sip rip，dip 200.200.200.1）</li>
<li>这个回复包的目的IP是VIP(不像NAT中是 cip)，所以LVS和RS不在一个vlan通过IP路由也能到达lvs</li>
<li>lvs修改sip为vip， dip为cip，修改后的回复包（sip 200.200.200.1，dip 200.200.200.2）发给client</li>
</ol>
<p><img src="/images/oss/94d55b926b5bb1573c4cab8353428712.png" alt="image.png"></p>
<p><strong>注意上图中绿色的进包和红色的出包他们的地址变化</strong></p>
<p>本来这个模型下都是正常的，但是为了Real Server能拿到client ip，也就是Real Server记录来源ip的时候希望记录的是client ip而不是LVS ip。这个时候LVS会将client ip放在tcp的options里面，然后在RealServer机器的内核里面将options中的client ip取出替换掉 lvs ip。所以Real Server上感知到的对端ip就是client ip。</p>
<p>回包的时候RealServer上的内核模块同样将目标地址从client ip改成lvs ip，同时将client ip放入options中。</p>
<h2 id="回到问题"><a href="#回到问题" class="headerlink" title="回到问题"></a>回到问题</h2><p>看完理论，再来分析这两个连接的行为</p>
<p>fulnat模式下连接经过lvs到达mysql后，mysql上看到的连接信息是，cip+port，也就是在MySQL上的连接</p>
<p><strong>lvs-ip:port -&gt; 10.112.61.163:3269  被修改成了 </strong>client-ip:61902 **-&gt; 10.112.61.163:3269</p>
<p>那么跟不走LVS的连接：</p>
<p><strong>client-ip:61902 -&gt;  10.112.61.163:3269 (直连) 完全重复了。</strong></p>
<p>MySQL端看到的两个连接四元组一模一样了：</p>
<blockquote>
<p>10.112.61.163:3269 -&gt; client-ip:61902 (走LVS，本来应该是lvs ip的，但是被替换成了client ip) </p>
<p>10.112.61.163:3269 -&gt; client-ip:61902 (直连) </p>
</blockquote>
<p>这个时候应用端看到的还是两个连接：</p>
<blockquote>
<p>client-ip:61902 -&gt; 10.141.16.0:3306 （走LVS） </p>
<p>client-ip:61902 -&gt;  10.112.61.163:3269 (直连) </p>
</blockquote>
<p>总结下，也就是这个连接经过LVS转换后在服务端（MYSQL）跟直连MySQL的连接四元组完全重复了，也就是MySQL会认为这两个连接就是同一个连接，所以必然出问题了。</p>
<p>实际两个连接建立的情况：</p>
<blockquote>
<p> 和mysqlserver的61902是04:22建起来的，和lvs的61902端口 是42:10建起来的，和lvs的61902建起来之后马上就出问题了</p>
</blockquote>
<h2 id="问题出现的条件"><a href="#问题出现的条件" class="headerlink" title="问题出现的条件"></a>问题出现的条件</h2><ul>
<li>fulnat模式的LVS，RS上装有slb_toa内核模块（RS上会将LVS ip还原成client ip）</li>
<li>client端正好重用一个相同的本地端口分别和RS以及LVS建立了两个连接</li>
</ul>
<p>这个时候这两个连接在MySQL端就会变成一个，然后两个连接的内容互串，必然导致rst</p>
<p>这个问题还挺有意思的，估计没几个程序员一辈子能碰上一次。推荐另外一个好玩的连接：<a href="/2020/07/01/如何创建一个自己连自己的TCP连接/">如何创建一个自己连自己的TCP连接</a></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="/2019/06/20/就是要你懂负载均衡--lvs和转发模式/">就是要你懂负载均衡–lvs和转发模式</a></p>
<p><a href="https://idea.popcount.org/2014-04-03-bind-before-connect/" target="_blank" rel="external">https://idea.popcount.org/2014-04-03-bind-before-connect/</a></p>
<p><a href="https://github.com/kubernetes/kubernetes/issues/81775" target="_blank" rel="external">no route to host</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/127099484" target="_blank" rel="external">另一种形式的tcp连接互串，新连接重用了time_wait的port，导致命中lvs内核表中的维护的旧连接发给了老的realserver</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2020/11/18/MySQL针对秒杀场景的优化/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/11/18/MySQL针对秒杀场景的优化/" itemprop="url">MySQL针对秒杀场景的优化</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-11-18T07:30:03+08:00">
                2020-11-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MySQL/" itemprop="url" rel="index">
                    <span itemprop="name">MySQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="MySQL针对秒杀场景的优化"><a href="#MySQL针对秒杀场景的优化" class="headerlink" title="MySQL针对秒杀场景的优化"></a>MySQL针对秒杀场景的优化</h1><p>对于秒杀热点场景，MySQL官方版本扣减只能做到 500 TPS每秒，扛不住大促的流量，需要优化</p>
<h2 id="针对秒杀场景的优化"><a href="#针对秒杀场景的优化" class="headerlink" title="针对秒杀场景的优化"></a>针对秒杀场景的优化</h2><p>对于秒杀热点场景，MySQL官方版本500 TPS每秒，在对MySQL优化前只能用redis来扛，redis没有事务能力，比如一个item下有多个sku就搞不定了。同时在前端搞限流、答题等让秒杀流量控制在可以承受的范围内。</p>
<p>拍减模式在整个交易过程中只有一次扣减交互，所以是不需要付款减库存那样的判重逻辑，就是说，拍减的减库存sql只有一条update语句就搞定了。而付减有两条，一条insert判重+一条update减库存（双十一拍减接口在高峰的rt约为8ms，而付减接口在高峰的rt约为15ms）；</p>
<p>其次，当大量请求（线程）落到mysql的同一条记录上进行减库存时，线程之间会存在竞争关系，因为要争夺InnoDB的行锁，当一个线程获得了行锁，其他并发线程就只能等待（InnoDB内部还有死锁检测等机制会严重影响性能），当并发度越高时，等待的线程就越多，此时tps会急剧下降，rt会飙升，性能就不能满足要求了。那如何减少锁竞争？答案是：排队！库存中心从几个层面做了排队策略。首先，在应用端进行排队，因为很多商品都是有sku的，当sku库存变化时item的库存也要做相应变化，所以需要根据itemId来进行排队，相同itemId的减库存操作会进入串行化排队处理逻辑，不过应用端的排队只能做到单机内存排队，当应用服务器数量过多时，落到db的并发请求仍然很多，所以最好的办法是在db端也加上排队策略，今年库存中心db部署了两个的排队patch，一个叫“并发控制”，是做在InnoDB层的，另一个叫“queue on pk”，是做在mysql的server层的，两个patch各有优缺点，前者不需要应用修改代码，db自动判断，后者需要应用程序写特殊的sql hint，前者控制的全局的sql，后者是根据hint来控制指定sql，两个patch的本质和应用端的排队逻辑是一致的，具体实现不同。双十一库存中心使用的是“并发控制”的patch。</p>
<blockquote>
<p>2013年的单减库存TPS最高记录是1381次每秒。</p>
</blockquote>
<p>对于秒杀热点场景，官方版本500tps每秒，问题在于同时涌入的请求太多，每次取锁都要检查其它等锁的线程（防止死锁），这个线程队列太长的话导致这个检查时间太长； 继续在前面增加能够进入到后面的并发数的控制，通过增加线程池、控制并发能到1400（no deadlock list check）；</p>
<blockquote>
<p><strong>热点更新下的死锁检测(</strong>no deadlock list check<strong>)</strong></p>
<p>由于热点更新是分布式的客户端并发的向单点的数据库进行了并行更新一条记录，到数据库最后是把并行的线程转行成串行的操作。但在串行操作的时候，由于对同一记录的锁申请列表过大，死锁检测的机制在检测锁队列的时候，反而拖慢了每一个更新。</p>
</blockquote>
<h3 id="缩短锁时间"><a href="#缩短锁时间" class="headerlink" title="缩短锁时间"></a>缩短锁时间</h3><p>接下来的问题在于一个事务中有多条语句（最少也有一个update+一个commit），这样update(减库存，开始锁表），走网络，查询结果（走网络），commit，两次跨网络调用导致update锁行比较久，于是可以新造一个语法 select update一次搞定，继续优化 select update commit_on_success_or_fail_rollback，将所有操作一次网络操作全部搞定，能到4000；</p>
<p>比如库存扣减的业务逻辑可以简化为下面这个事务:</p>
<p>（1）begin;</p>
<p>（2）insert 交易流水表; – 交易流水对账</p>
<p>（3）update 库存明细表 where id in (sku_id，item_id);</p>
<p>（4）select 库存明细表;</p>
<p>（5）commit</p>
<p><img src="/images/951413iMgBlog/TB1yvFqOpXXX.png" alt="Snip20161116_88.png"></p>
<p>SQL case：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">4059550 Query   <span class="keyword">SET</span> autocommit=<span class="number">0</span></div><div class="line"><span class="number">4059550</span> <span class="keyword">Query</span>   <span class="keyword">update</span> ROLLBACK_ON_FAIL TARGET_AFFECT_ROW <span class="number">1</span> trade <span class="keyword">set</span> <span class="keyword">version</span> = <span class="keyword">version</span>+<span class="number">3</span> ,gmt_modified = <span class="keyword">now</span>()    ,           optype = <span class="number">2</span>          ,      feature = <span class="string">';abc;'</span>  <span class="keyword">where</span> sub_biz_order_id = <span class="string">'15'</span> <span class="keyword">and</span> biz_order_type = <span class="number">1</span> <span class="keyword">and</span> <span class="keyword">id</span> = <span class="number">5</span> <span class="keyword">and</span> ti_id = <span class="number">1</span> <span class="keyword">and</span>      optype = <span class="number">3</span>          <span class="keyword">and</span>      root_id = <span class="number">11</span></div><div class="line"><span class="number">4059550</span> <span class="keyword">Query</span>   <span class="keyword">select</span>      <span class="keyword">id</span>,*     <span class="keyword">from</span>   <span class="keyword">update</span> COMMIT_ON_SUCCESS ROLLBACK_ON_FAIL TARGET_AFFECT_ROW <span class="number">1</span> invetory   <span class="keyword">set</span>                                           withholding_quantity = withholding_quantity + <span class="number">-1</span>,  flag=flag &amp;~ (<span class="number">1</span>&lt;&lt;<span class="number">10</span>) &amp;~ (<span class="number">1</span>&lt;&lt;<span class="number">11</span>) , <span class="keyword">version</span>=<span class="keyword">version</span>+<span class="number">3</span>,gmt_modified = <span class="keyword">now</span>()         <span class="keyword">WHERE</span>  root_id = <span class="number">11</span> <span class="keyword">and</span> <span class="keyword">status</span> = <span class="number">1</span> <span class="keyword">and</span> <span class="keyword">id</span> <span class="keyword">in</span>    (     <span class="number">1</span>    )  <span class="keyword">and</span> (withholding_quantity + <span class="number">-1</span>) &gt;= <span class="number">0</span></div><div class="line"><span class="number">4059550</span> <span class="keyword">Query</span>   <span class="keyword">commit</span></div></pre></td></tr></table></figure>
<h3 id="批量提交"><a href="#批量提交" class="headerlink" title="批量提交"></a>批量提交</h3><p>其主要的核心思想是：针对应用层SQL做轻量化改造，带上”热点行SQL”的hint，当这种SQL进入内核后，在内存中维护一个hash表，将主键或唯一键相同的请求(一般也就是同一商品id)hash到同一个地方做请求的合并，经过一段时间后(默认100us)统一提交，从而实现了将串行处理变成了批处理，让每个热点行更新请求并不需要都去扫描和更新btree。</p>
<ol>
<li>热点的自动识别:前面已经讲过了，库存的扣减SQL都会有commit on success标记。mysql内部分为普通通道和热点扣减通道。普通通道里是正常的事务。热点通道里收集带有commit on success标记的事务。在一定的时间区间段内(0.1ms)，将收集到的热点按照主键或者唯一键进行hash; hash到同一个桶中为相同的sku; 分批组提交这0.1ms收集到的热点商品。</li>
<li>轮询处理: 第一批进行提交时，第二批进行收集； 当第一批完成了提交开始收集时，第二批就可以进行提交了。不断轮询，提高效率</li>
</ol>
<p>通过内存合并库存减操作，干到100000（每个减库存操作生成一条独立的update binlog，不影响其他业务2016年双11），实际这里还可以调整批提交时间间隔来进一步提升扣减QPS</p>
<p><img src="/images/951413iMgBlog/TB1I_BvOpXXXXasXVXXXXXXXXXX.png" alt="Snip20161116_87.png"></p>
<p>超卖：付款减库存会超卖，拍减库存要防止恶意拍不付款。拍减的话可以通过增加SQL新语法来进一步优化DB响应(select update)</p>
<p>innodb_buffer_pool_instance: 将buffer pool 分成几个（hash），避免高并发修改的时候一个大锁mutex导致性能不高</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2020/11/17/MySQL线程池导致的延时卡顿排查/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/11/17/MySQL线程池导致的延时卡顿排查/" itemprop="url">MySQL线程池导致的延时卡顿排查</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-11-17T07:30:03+08:00">
                2020-11-17
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MySQL/" itemprop="url" rel="index">
                    <span itemprop="name">MySQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="MySQL-线程池导致的延时卡顿排查"><a href="#MySQL-线程池导致的延时卡顿排查" class="headerlink" title="MySQL 线程池导致的延时卡顿排查"></a>MySQL 线程池导致的延时卡顿排查</h1><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>简单小表的主键点查SQL，单条执行很快，但是放在业务端，有时快有时慢，取了一条慢sql，在MySQL侧查看，执行时间很短。</p>
<p>通过Tomcat业务端监控有显示慢SQL，取slow.log里显示有12秒执行时间的SQL，但是这次12秒的执行在MySQL上记录下来的执行时间都不到1ms。</p>
<p>所在节点的tsar监控没有异常，Tomcat manager监控上没有fgc，Tomcat实例规格 16C32g<em>8, MySQL  32c128g  </em>32 。</p>
<p>5-28号现象复现，从监控图上CPU、内存、网络都没发现异常，MySQL侧查到的SQL依然执行很快，Tomcat侧记录12S执行时间，当时Tomcat节点的网络流量、CPU压力都很小。</p>
<p>所以客户怀疑Tomcat有问题或者Tomcat上的代码写得有问题导致了这个问题，需要排查和解决掉。</p>
<p>接下来我们会先分析这个问题出现的原因，然后会分析这类问题的共性同时拓展到其它场景下的类似问题。</p>
<h2 id="Tomcat上抓包分析"><a href="#Tomcat上抓包分析" class="headerlink" title="Tomcat上抓包分析"></a>Tomcat上抓包分析</h2><h3 id="慢的连接"><a href="#慢的连接" class="headerlink" title="慢的连接"></a>慢的连接</h3><p>经过抓包分析发现在慢的连接上，所有操作都很慢，包括set 命令，慢的时间主要分布在3秒以上，1-3秒的慢查询比较少，这明显不太符合分布规律。并且目前看慢查询基本都发生在MySQL的0库的部分连接上（后端有一堆MySQL组成的集群），下面抓包的4637端口是MySQL的服务端口：</p>
<p><img src="/images/oss/b8ed95b7081ee80eb23465ee0e9acc74.png" alt="image.png"></p>
<p>以上两个连接都很慢，对应的慢查询在MySQL里面记录很快。</p>
<p>慢的SQL的response按时间排序基本都在3秒以上：</p>
<p><img src="/images/oss/36a2a60f64011bc73fee06c291bcd79f.png" alt="image.png" style="zoom:67%;"></p>
<p>或者只看response time 排序，中间几个1秒多的都是 Insert语句。也就是1秒到3秒之间的没有，主要是3秒以上的查询</p>
<p><img src="/images/oss/07146ff29534a1070adbdb8cedd280c9.png" alt="image.png" style="zoom:67%;"></p>
<h3 id="快的连接"><a href="#快的连接" class="headerlink" title="快的连接"></a>快的连接</h3><p>同样一个查询SQL，发到同一个MySQL上(4637端口)，下面的连接上的所有操作都很快，下面是两个快的连接上的执行截图</p>
<p><img src="/images/oss/d129dfe1a50b182f4d100ac7147f9099.png" alt="image.png"></p>
<p>别的MySQL上都比较快，比如5556分片上的所有response RT排序，只有偶尔极个别的慢SQL</p>
<p><img src="/images/oss/01531d138b9bc8dafda76b7c8bbb5bc9.png" alt="image.png"></p>
<h2 id="MySQL相关参数"><a href="#MySQL相关参数" class="headerlink" title="MySQL相关参数"></a>MySQL相关参数</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line">mysql&gt; show variables like &apos;%thread%&apos;;</div><div class="line">+--------------------------------------------+-----------------+</div><div class="line">| Variable_name                              | Value           |</div><div class="line">+--------------------------------------------+-----------------+</div><div class="line">| innodb_purge_threads                       | 1               |</div><div class="line">| innodb_MySQL_thread_extra_concurrency        | 0               |</div><div class="line">| innodb_read_io_threads                     | 16              |</div><div class="line">| innodb_thread_concurrency                  | 0               |</div><div class="line">| innodb_thread_sleep_delay                  | 10000           |</div><div class="line">| innodb_write_io_threads                    | 16              |</div><div class="line">| max_delayed_threads                        | 20              |</div><div class="line">| max_insert_delayed_threads                 | 20              |</div><div class="line">| myisam_repair_threads                      | 1               |</div><div class="line">| performance_schema_max_thread_classes      | 50              |</div><div class="line">| performance_schema_max_thread_instances    | -1              |</div><div class="line">| pseudo_thread_id                           | 12882624        |</div><div class="line">| MySQL_is_dump_thread                         | OFF             |</div><div class="line">| MySQL_threads_running_ctl_mode               | SELECTS         |</div><div class="line">| MySQL_threads_running_high_watermark         | 50000           |</div><div class="line">| rocksdb_enable_thread_tracking             | OFF             |</div><div class="line">| rocksdb_enable_write_thread_adaptive_yield | OFF             |</div><div class="line">| rocksdb_signal_drop_index_thread           | OFF             |</div><div class="line">| thread_cache_size                          | 100             |</div><div class="line">| thread_concurrency                         | 10              |</div><div class="line">| thread_handling                            | pool-of-threads |</div><div class="line">| thread_pool_high_prio_mode                 | transactions    |</div><div class="line">| thread_pool_high_prio_tickets              | 4294967295      |</div><div class="line">| thread_pool_idle_timeout                   | 60              |</div><div class="line">| thread_pool_max_threads                    | 100000          |</div><div class="line">| thread_pool_oversubscribe                  | 10              |</div><div class="line">| thread_pool_size                           | 96              |</div><div class="line">| thread_pool_stall_limit                    | 30              |</div><div class="line">| thread_stack                               | 262144          |</div><div class="line">| threadpool_workaround_epoll_bug            | OFF             |</div><div class="line">| tokudb_cachetable_pool_threads             | 0               |</div><div class="line">| tokudb_checkpoint_pool_threads             | 0               |</div><div class="line">| tokudb_client_pool_threads                 | 0               |</div><div class="line">+--------------------------------------------+-----------------+</div><div class="line">33 rows in set (0.00 sec)</div></pre></td></tr></table></figure>
<h2 id="综上结论"><a href="#综上结论" class="headerlink" title="综上结论"></a>综上结论</h2><p>问题原因跟MySQL线程池比较相关，慢的连接总是慢，快的连接总是快。需要到MySQL Server下排查线程池相关参数。</p>
<p>同一个慢的连接上的回包，所有 ack 就很快（OS直接回，不需要进到MySQL），但是set就很慢，基本理解只要进到MySQL的就慢了，所以排除了网络原因（流量本身也很小，也没看到乱序、丢包之类的）</p>
<h2 id="问题解决"><a href="#问题解决" class="headerlink" title="问题解决"></a>问题解决</h2><p>18点的时候将4637端口上的MySQL thread_pool_oversubscribe 从10调整到20后，基本没有慢查询了：</p>
<p><img src="/images/oss/92069e7521368e4d2519b3b861cc7faa.png" alt="image.png" style="zoom:50%;"></p>
<p>当时从MySQL的观察来看，并发压力很小，很难抓到running thread比较高的情况（update: 可能是任务积压在队列中，只是96个thread pool中的一个thread全部running，导致整体running不高）</p>
<p>MySQL记录的执行时间是指SQL语句开始解析后统计，中间的等锁、等Worker都不会记录在执行时间中，所以当时对应的SQL在MySQL日志记录中很快。</p>
<p>thread_pool_stall_limit 会控制一个SQL过长时间（默认60ms）占用线程，如果出现stall_limit就放更多的SQL进入到thread pool中直到达到thread_pool_oversubscribe个</p>
<blockquote>
<p>The thread_pool_stall_limit affects executing statements. The value is the amount of time a statement has to finish after starting to execute before it becomes defined as stalled, at which point the thread pool permits the thread group to begin executing another statement. The value is measured in 10 millisecond units, so the default of 6 means 60ms. Short wait values permit threads to start more quickly. Short values are also better for avoiding deadlock situations. Long wait values are useful for workloads that include long-running statements, to avoid starting too many new statements while the current ones execute.</p>
</blockquote>
<h2 id="Thread-Pool原理"><a href="#Thread-Pool原理" class="headerlink" title="Thread Pool原理"></a>Thread Pool原理</h2><p><img src="/images/oss/6fbe1c10f07dd1c26eba0c0e804fa9a8.png" alt="image.png"></p>
<p>MySQL 原有线程调度方式有每个连接一个线程(one-thread-per-connection)和所有连接一个线程（no-threads）。</p>
<p>no-threads一般用于调试，生产环境一般用one-thread-per-connection方式。one-thread-per-connection 适合于低并发长连接的环境，而在高并发或大量短连接环境下，大量创建和销毁线程，以及线程上下文切换，会严重影响性能。另外 one-thread-per-connection 对于大量连接数扩展也会影响性能。</p>
<p>为了解决上述问题，MariaDB、Percona、Aliyun RDS、Oracle MySQL 都推出了线程池方案，它们的实现方式大体相似，这里以 Percona 为例来简略介绍实现原理，同时会介绍我们在其基础上的一些改进。</p>
<p>线程池由一系列 worker 线程组成，这些worker线程被分为<code>thread_pool_size</code>个group。用户的连接按 round-robin 的方式映射到相应的group 中，一个连接可以由一个group中的一个或多个worker线程来处理。</p>
<p>thread_pool_oversubscribe  一个group中活跃线程和等待中的线程超过<code>thread_pool_oversubscribe</code>时，不会创建新的线程。 此参数可以控制系统的并发数，同时可以防止调度上的死锁，考虑如下情况，A、B、C三个事务，A、B 需等待C提交。A、B先得到调度，同时活跃线程数达到了<code>thread_pool_max_threads</code>上限，随后C继续执行提交，此时已经没有线程来处理C提交，从而导致A、B一直等待。<code>thread_pool_oversubscribe</code>控制group中活跃线程和等待中的线程总数，从而防止了上述情况。</p>
<p><strong>MySQL Thread Pool之所以分成多个小的Thread Group Pool而不是一个大的Pool，是为了分解锁（每个group中都有队列，队列需要加锁。类似ConcurrentHashMap提高并发的原理），提高并发效率。</strong></p>
<p>group中又有多个队列，用来区分优先级的，事务中的语句会放到高优先队列（非事务语句和autocommit 都会在低优先队列）；等待太久的SQL也会挪到高优先队列，防止饿死。</p>
<p>比如启用Thread Pool后，如果出现多个慢查询，容易导致拨测类请求超时，进而出现Server异常的判断（类似Nginx 边缘触发问题）；或者某个group满后导致慢查询和拨测失败之类的问题</p>
<h3 id="thread-pool-size过小的案例"><a href="#thread-pool-size过小的案例" class="headerlink" title="thread_pool_size过小的案例"></a>thread_pool_size过小的案例</h3><p>应用出现大量1秒超时报错：</p>
<p><img src="/images/951413iMgBlog/52dbeb1c1058e6dbff0a790b4b4ba477.png" alt="image.png"></p>
<p><img src="/images/951413iMgBlog/image-20211104130625676.png" alt="image-20211104130625676"></p>
<p>分析代码，这个Druid报错堆栈是数据库连接池在创建到MySQL的连接后或者从连接池取一个连接给业务使用前会发送一个ping来验证下连接是否有效，有效后才给应用使用。说明TCP连接创建成功，但是MySQL 超过一秒钟都没有响应这个 ping，说明 MySQL处理指令缓慢。</p>
<p>继续分析MySQL的参数：</p>
<p><img src="/images/oss/8987545cc311fdd3ae232aee8c3f855a.png" alt="image.png"></p>
<p>可以看到thread_pool_size是1，太小了，将所有MySQL线程都放到一个buffer里面来抢锁，锁冲突的概率太高。调整到16后可以明显看到MySQL的RT从原来的12ms下降到了3ms不到，整个QPS大概有8%左右的提升。这是因为pool size为1的话所有sql都在一个队列里面，多个worker thread加锁等待比较严重，导致rt延迟增加。</p>
<p><img src="/images/oss/114b5b71468b33128e76129bbc7fb8f4.png" alt="image.png"></p>
<p>这个问题发现是因为压力一上来的时候要创建大量新的连接，这些连结创建后会去验证连接的有效性，也就是Druid给MySQL发一个ping指令，一般都很快，同时Druid对这个valid操作设置了1秒的超时时间，从实际看到大量超时异常堆栈，从而发现MySQL内部响应有问题。</p>
<h3 id="MySQL-ping和MySQL协议相关知识"><a href="#MySQL-ping和MySQL协议相关知识" class="headerlink" title="MySQL ping和MySQL协议相关知识"></a>MySQL ping和MySQL协议相关知识</h3><blockquote>
<p><a href="https://dev.mysql.com/doc/connector-j/8.0/en/connector-j-usagenotes-j2ee-concepts-connection-pooling.html#idm47306928802368" target="_blank" rel="external">Ping</a> use the JDBC method <a href="http://docs.oracle.com/javase/7/docs/api/java/sql/Connection.html#isValid(int" target="_blank" rel="external">Connection.isValid(int timeoutInSecs)</a>). Digging into the MySQL Connector/J source, the actual implementation uses com.mysql.jdbc.ConnectionImpl.pingInternal() to send a simple ping packet to the DB and returns true as long as a valid response is returned.</p>
</blockquote>
<p>MySQL ping protocol是发送了一个 <code>0e</code> 的byte标识给Server，整个包加上2byte的Packet Length（内容为：1），2byte的Packet Number（内容为：0），总长度为5 byte。Druid、DRDS默认都会testOnBorrow，所以每个连接使用前都会先做ping。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">public class MySQLPingPacket implements CommandPacket &#123;</div><div class="line">    private final WriteBuffer buffer = new WriteBuffer();</div><div class="line">    public MySQLPingPacket() &#123;</div><div class="line">        buffer.writeByte((byte) 0x0e);</div><div class="line">    &#125;</div><div class="line">    public int send(final OutputStream os) throws IOException &#123;</div><div class="line">        os.write(buffer.getLengthWithPacketSeq((byte) 0)); // Packet Number</div><div class="line">        os.write(buffer.getBuffer(),0,buffer.getLength()); // Packet Length 固定为1</div><div class="line">        os.flush();</div><div class="line">        return 0;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><img src="/images/oss/7cf291546a167b0ca6a017e98db5a821.png" alt="image.png"></p>
<p>也就是一个TCP包中的Payload为 MySQL协议中的内容长度 + 4（Packet Length+Packet Number）。</p>
<h2 id="线程池卡死案例：show-stats导致集群3406监控卡死"><a href="#线程池卡死案例：show-stats导致集群3406监控卡死" class="headerlink" title="线程池卡死案例：show stats导致集群3406监控卡死"></a>线程池卡死案例：show stats导致集群3406监控卡死</h2><h3 id="现象"><a href="#现象" class="headerlink" title="现象"></a>现象</h3><p>应用用于获取监控信息的端口 3406卡死，监控脚本无法连接上3406，监控没有数据（需要从3406采集）、DDL操作、show processlist、show stats操作卡死（需要跟整个集群的3406端口同步）。</p>
<p>通过jstack看到drds-server进程的manager线程池都是这样: </p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line">"ManagerExecutor-1-thread-1" #47 daemon prio=5 os_prio=0 tid=0x00007fe924004000 nid=0x15c runnable [0x00007fe9034f4000]</div><div class="line">   java.lang.Thread.State: RUNNABLE</div><div class="line">    at java.net.SocketInputStream.socketRead0(Native Method)</div><div class="line">    at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)</div><div class="line">    at java.net.SocketInputStream.read(SocketInputStream.java:171)</div><div class="line">    at java.net.SocketInputStream.read(SocketInputStream.java:141)</div><div class="line">    at com.mysql.jdbc.util.ReadAheadInputStream.fill(ReadAheadInputStream.java:101)</div><div class="line">    at com.mysql.jdbc.util.ReadAheadInputStream.readFromUnderlyingStreamIfNecessary(ReadAheadInputStream.java:144)</div><div class="line">    at com.mysql.jdbc.util.ReadAheadInputStream.read(ReadAheadInputStream.java:174)</div><div class="line">    - locked &lt;0x0000000722538b60&gt; (a com.mysql.jdbc.util.ReadAheadInputStream)</div><div class="line">    at com.mysql.jdbc.MysqlIO.readFully(MysqlIO.java:3005)</div><div class="line">    at com.mysql.jdbc.MysqlIO.reuseAndReadPacket(MysqlIO.java:3466)</div><div class="line">    at com.mysql.jdbc.MysqlIO.reuseAndReadPacket(MysqlIO.java:3456)</div><div class="line">    at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3897)</div><div class="line">    at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2524)</div><div class="line">    at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2677)</div><div class="line">    at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2545)</div><div class="line">    - locked &lt;0x00000007432e19c8&gt; (a com.mysql.jdbc.JDBC4Connection)</div><div class="line">    at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2503)</div><div class="line">    at com.mysql.jdbc.StatementImpl.executeQuery(StatementImpl.java:1369)</div><div class="line">    - locked &lt;0x00000007432e19c8&gt; (a com.mysql.jdbc.JDBC4Connection)</div><div class="line">    at com.alibaba.druid.pool.ValidConnectionCheckerAdapter.isValidConnection(ValidConnectionCheckerAdapter.java:44)</div><div class="line">    at com.alibaba.druid.pool.DruidAbstractDataSource.testConnectionInternal(DruidAbstractDataSource.java:1298)</div><div class="line">    at com.alibaba.druid.pool.DruidDataSource.getConnectionDirect(DruidDataSource.java:1057)</div><div class="line">    at com.alibaba.druid.pool.DruidDataSource.getConnection(DruidDataSource.java:997)</div><div class="line">    at com.alibaba.druid.pool.DruidDataSource.getConnection(DruidDataSource.java:987)</div><div class="line">    at com.alibaba.druid.pool.DruidDataSource.getConnection(DruidDataSource.java:103)</div><div class="line">    at com.taobao.tddl.atom.AbstractTAtomDataSource.getConnection(AbstractTAtomDataSource.java:32)</div><div class="line">    at com.alibaba.cobar.ClusterSyncManager$1.run(ClusterSyncManager.java:60)</div><div class="line">    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)</div><div class="line">    at java.util.concurrent.FutureTask.run(FutureTask.java:266)</div><div class="line">    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)</div><div class="line">    at java.util.concurrent.FutureTask.run(FutureTask.java:266)</div><div class="line">    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1152)</div><div class="line">    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:627)</div><div class="line">    at java.lang.Thread.run(Thread.java:882)</div></pre></td></tr></table></figure>
<h3 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h3><ol>
<li>用户监控采集数据通过访问3306端口上的show stats，这个show stats命令要访问集群下所有节点的3406端口来执行show stats，3406端口上是一个大小为8个的Manager 线程池在执行这些show stats命令，导致占满了manager线程池的8个线程，每个3306的show stats线程都在wait 所有节点3406上的子任务的返回</li>
<li>每个子任务的线程，都在等待向集群所有节点3406端口的manager建立连接，建连接后会先执行testValidatation操作验证连接的有效性，这个验证操作会执行SQL Query：select 1，这个query请求又要申请一个manager线程才能执行成功</li>
<li>默认isValidConnection操作没有超时时间，如果Manager线程池已满后需要等待至socketTimeout后才会返回，导致这里出现卡死，还不如快速返回错误，可以增加超时来改进</li>
</ol>
<p>从线程栈来说，就是出现了活锁</p>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><ul>
<li>增加manager线程池大小</li>
<li>代码逻辑上优化3406 jdbc连接池参数，修改jdbc默认的socketTimeout超时时间以及替换默认checker（一般增加一个1秒超时的checker）</li>
</ul>
<p>对于checker，参考druid的实现，com/alibaba/druid/pool/vendor/MySqlValidConnectionChecker.java：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//druid的MySqlValidConnectionChecker设定了valid超时时间为1秒</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isValidConnection</span><span class="params">(Connection conn, String validateQuery, <span class="keyword">int</span> validationQueryTimeout)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">        <span class="keyword">if</span> (conn.isClosed()) &#123;</div><div class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="keyword">if</span> (usePingMethod) &#123;</div><div class="line">            <span class="keyword">if</span> (conn <span class="keyword">instanceof</span> DruidPooledConnection) &#123;</div><div class="line">                conn = ((DruidPooledConnection) conn).getConnection();</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            <span class="keyword">if</span> (conn <span class="keyword">instanceof</span> ConnectionProxy) &#123;</div><div class="line">                conn = ((ConnectionProxy) conn).getRawObject();</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            <span class="keyword">if</span> (clazz.isAssignableFrom(conn.getClass())) &#123;</div><div class="line">                <span class="keyword">if</span> (validationQueryTimeout &lt;= <span class="number">0</span>) &#123;</div><div class="line">                    validationQueryTimeout = DEFAULT_VALIDATION_QUERY_TIMEOUT;<span class="comment">// 默认值1ms</span></div><div class="line">                &#125;</div><div class="line"></div><div class="line">                <span class="keyword">try</span> &#123;</div><div class="line">                    ping.invoke(conn, <span class="keyword">true</span>, validationQueryTimeout * <span class="number">1000</span>); <span class="comment">//1秒</span></div><div class="line">                &#125; <span class="keyword">catch</span> (InvocationTargetException e) &#123;</div><div class="line">                    Throwable cause = e.getCause();</div><div class="line">                    <span class="keyword">if</span> (cause <span class="keyword">instanceof</span> SQLException) &#123;</div><div class="line">                        <span class="keyword">throw</span> (SQLException) cause;</div><div class="line">                    &#125;</div><div class="line">                    <span class="keyword">throw</span> e;</div><div class="line">                &#125;</div><div class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        String query = validateQuery;</div><div class="line">        <span class="keyword">if</span> (validateQuery == <span class="keyword">null</span> || validateQuery.isEmpty()) &#123;</div><div class="line">            query = DEFAULT_VALIDATION_QUERY;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        Statement stmt = <span class="keyword">null</span>;</div><div class="line">        ResultSet rs = <span class="keyword">null</span>;</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            stmt = conn.createStatement();</div><div class="line">            <span class="keyword">if</span> (validationQueryTimeout &gt; <span class="number">0</span>) &#123;</div><div class="line">                stmt.setQueryTimeout(validationQueryTimeout);</div><div class="line">            &#125;</div><div class="line">            rs = stmt.executeQuery(query);</div><div class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</div><div class="line">        &#125; <span class="keyword">finally</span> &#123;</div><div class="line">            JdbcUtils.close(rs);</div><div class="line">            JdbcUtils.close(stmt);</div><div class="line">        &#125;</div><div class="line"></div><div class="line">    &#125;</div><div class="line"></div><div class="line"><span class="comment">//使用如上validation</span></div><div class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">static</span> String DEFAULT_DRUID_MYSQL_VALID_CONNECTION_CHECKERCLASS =</div><div class="line">        <span class="string">"com.alibaba.druid.pool.vendor.MySqlValidConnectionChecker"</span>;</div><div class="line"></div><div class="line"> String validConnnectionCheckerClassName =</div><div class="line">                    TAtomConstants.DEFAULT_DRUID_MYSQL_VALID_CONNECTION_CHECKERCLASS;</div><div class="line">                <span class="keyword">try</span> &#123;</div><div class="line">                    Class.forName(validConnnectionCheckerClassName);</div><div class="line">                    localDruidDataSource.setValidConnectionCheckerClassName(validConnnectionCheckerClassName);</div></pre></td></tr></table></figure>
<p>这种线程池打满特别容易在分布式环境下出现，除了以上案例比如还有:</p>
<blockquote>
<p>drds-server线程池，接收一个逻辑SQL，如果需要查询1024分片的sort merge join，相当于派生了一批子任务，每个子任务占用一个线程，父任务等待子任务执行后返回数据。如果这样的逻辑SQL同时来一批并发，就会出现父任务都在等子任务，子任务又因为父任务占用了线程，导致子任务也在等着从线程池中取线程，这样父子任务就进入了死锁</p>
<p>比如并行执行的SQL MPP线程池也有这个问题，多个查询节点收到SQL，拆分出子任务做并行，互相等待资源</p>
</blockquote>
<h2 id="DRDS对分布式任务打挂线程池的优化"><a href="#DRDS对分布式任务打挂线程池的优化" class="headerlink" title="DRDS对分布式任务打挂线程池的优化"></a>DRDS对分布式任务打挂线程池的优化</h2><p>对如下这种案例：</p>
<blockquote>
<p>drds-server线程池，接收一个逻辑SQL，如果需要查询1024分片的sort merge join，相当于派生了1024个子任务，每个子任务占用一个线程，父任务等待子任务执行后返回数据。如果这样的逻辑SQL同时来一批并发，就会出现父任务都在等子任务，子任务又因为父任务占用了线程，导致子任务也在等着从线程池中取线程，这样父子任务就进入了死锁</p>
</blockquote>
<p>首先DRDS对执行SQL 的线程池分成了多个bucket，每个SQL只跑在一个bucket里面的线程上，同时通过滑动窗口向线程池提交任务数，来控制并发量，进而避免线程池的死锁、活锁问题。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> ServerThreadPool <span class="title">create</span><span class="params">(String name, <span class="keyword">int</span> poolSize, <span class="keyword">int</span> deadLockCheckPeriod, <span class="keyword">int</span> bucketSize)</span> </span>&#123;</div><div class="line">    <span class="keyword">return</span> <span class="keyword">new</span> ServerThreadPool(name, poolSize, deadLockCheckPeriod, bucketSize); <span class="comment">//bucketSize可以设置</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="title">ServerThreadPool</span><span class="params">(String poolName, <span class="keyword">int</span> poolSize, <span class="keyword">int</span> deadLockCheckPeriod, <span class="keyword">int</span> bucketSize)</span> </span>&#123;</div><div class="line">    <span class="keyword">this</span>.poolName = poolName;</div><div class="line">    <span class="keyword">this</span>.deadLockCheckPeriod = deadLockCheckPeriod;</div><div class="line"></div><div class="line">    <span class="keyword">this</span>.numBuckets = bucketSize;</div><div class="line">    <span class="keyword">this</span>.executorBuckets = <span class="keyword">new</span> ThreadPoolExecutor[bucketSize];</div><div class="line">    <span class="keyword">int</span> bucketPoolSize = poolSize / bucketSize; <span class="comment">//将整个pool分成多个bucket</span></div><div class="line">    <span class="keyword">this</span>.poolSize = bucketPoolSize;</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> bucketIndex = <span class="number">0</span>; bucketIndex &lt; bucketSize; bucketIndex++) &#123;</div><div class="line">        ThreadPoolExecutor executor = <span class="keyword">new</span> ThreadPoolExecutor(bucketPoolSize,</div><div class="line">            bucketPoolSize,</div><div class="line">            <span class="number">0L</span>,</div><div class="line">            TimeUnit.MILLISECONDS,</div><div class="line">            <span class="keyword">new</span> LinkedBlockingQueue&lt;Runnable&gt;(),</div><div class="line">            <span class="keyword">new</span> NamedThreadFactory(poolName + <span class="string">"-bucket-"</span> + bucketIndex, <span class="keyword">true</span>));</div><div class="line"></div><div class="line">        executorBuckets[bucketIndex] = executor;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">this</span>.lastCompletedTaskCountBuckets = <span class="keyword">new</span> <span class="keyword">long</span>[bucketSize];</div><div class="line">    <span class="comment">// for check thread</span></div><div class="line">    <span class="keyword">if</span> (deadLockCheckPeriod &gt; <span class="number">0</span>) &#123;</div><div class="line">        <span class="keyword">this</span>.timer = <span class="keyword">new</span> Timer(SERVER_THREAD_POOL_TIME_CHECK, <span class="keyword">true</span>);</div><div class="line">        buildCheckTask();</div><div class="line">        <span class="keyword">this</span>.timer.scheduleAtFixedRate(checkTask, deadLockCheckPeriod, deadLockCheckPeriod);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>通过bucketSize将一个大的线程池分成多个小的线程池，每个SQL 控制跑在一个小的线程池中，这里和MySQL的thread_pool是同样的设计思路，当然MySQL 的thread_pool主要是为了改进大锁的问题。</p>
<p>另外DRDS上线程池拆分后性能也有提升：</p>
<p><img src="/images/951413iMgBlog/image-20211104163732499.png" alt="image-20211104163732499"></p>
<p>测试结果说明：(以全局线程池为基准，分别关注：关日志、分桶线程池、协程)</p>
<blockquote>
<ol>
<li>关日志，整体性能提升在20%左右 (8core最好成绩在6.4w qps)</li>
<li>协程，整体性能15%左右</li>
<li>关日志+协程，整体提升在35%左右 (8core最好成绩在7w qps)</li>
<li>分桶，整体性能提升在18%左右 </li>
<li>分桶+关日志，整体提升在39%左右 (8core最好成绩在7.4w qps)</li>
<li>分桶+协程，整体提升在36%左右</li>
<li>分桶+关日志+协程，整体提升在60%左右 (8core最好成绩在8.3w qps)</li>
</ol>
</blockquote>
<h3 id="线程池拆成多个bucket优化分析"><a href="#线程池拆成多个bucket优化分析" class="headerlink" title="线程池拆成多个bucket优化分析"></a>线程池拆成多个bucket优化分析</h3><p>拆分前锁主要是：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div></pre></td><td class="code"><pre><div class="line">Started [lock] profiling</div><div class="line">--- Execution profile ---</div><div class="line">Total samples:         <span class="number">496</span></div><div class="line"></div><div class="line">Frame buffer usage:    <span class="number">0.0052</span>%</div><div class="line"></div><div class="line">--- <span class="number">352227700</span> ns (<span class="number">53.09</span>%), <span class="number">248</span> samples</div><div class="line">  [ <span class="number">0</span>] java.util.Properties</div><div class="line">  [ <span class="number">1</span>] java.util.Hashtable.get</div><div class="line">  [ <span class="number">2</span>] java.util.Properties.getProperty</div><div class="line">  [ <span class="number">3</span>] com.taobao.tddl.common.properties.SystemPropertiesHelper.getPropertyValue</div><div class="line">  [ <span class="number">4</span>] com.taobao.tddl.executor.MatrixExecutor.configMppExecutionContext</div><div class="line">  [ <span class="number">5</span>] com.taobao.tddl.executor.MatrixExecutor.optimize</div><div class="line">  [ <span class="number">6</span>] com.taobao.tddl.matrix.jdbc.TConnection.optimizeThenExecute</div><div class="line">  [ <span class="number">7</span>] com.taobao.tddl.matrix.jdbc.TConnection.executeSQL</div><div class="line">  [ <span class="number">8</span>] com.taobao.tddl.matrix.jdbc.TPreparedStatement.executeSQL</div><div class="line">  [ <span class="number">9</span>] com.taobao.tddl.matrix.jdbc.TStatement.executeInternal</div><div class="line">  [<span class="number">10</span>] com.taobao.tddl.matrix.jdbc.TPreparedStatement.execute</div><div class="line">  [<span class="number">11</span>] com.alibaba.cobar.server.ServerConnection.innerExecute</div><div class="line">  [<span class="number">12</span>] com.alibaba.cobar.server.ServerConnection.innerExecute</div><div class="line">  [<span class="number">13</span>] com.alibaba.cobar.server.ServerConnection$<span class="number">1</span>.run</div><div class="line">  [<span class="number">14</span>] com.taobao.tddl.common.utils.thread.FlowControlThreadPool$RunnableAdapter.run</div><div class="line">  [<span class="number">15</span>] java.util.concurrent.Executors$RunnableAdapter.call</div><div class="line">  [<span class="number">16</span>] java.util.concurrent.FutureTask.run</div><div class="line">  [<span class="number">17</span>] java.util.concurrent.ThreadPoolExecutor.runWorker</div><div class="line">  [<span class="number">18</span>] java.util.concurrent.ThreadPoolExecutor$Worker.run</div><div class="line">  [<span class="number">19</span>] java.lang.Thread.run</div><div class="line"></div><div class="line">--- <span class="number">307781689</span> ns (<span class="number">46.39</span>%), <span class="number">243</span> samples</div><div class="line">  [ <span class="number">0</span>] java.util.Properties</div><div class="line">  [ <span class="number">1</span>] java.util.Hashtable.get</div><div class="line">  [ <span class="number">2</span>] java.util.Properties.getProperty</div><div class="line">  [ <span class="number">3</span>] com.taobao.tddl.common.properties.SystemPropertiesHelper.getPropertyValue</div><div class="line">  [ <span class="number">4</span>] com.taobao.tddl.config.ConfigDataMode.isDrdsMasterMode</div><div class="line">  [ <span class="number">5</span>] com.taobao.tddl.matrix.jdbc.TConnection.updatePlanManagementInfo</div><div class="line">  [ <span class="number">6</span>] com.alibaba.cobar.server.ServerConnection.innerExecute</div><div class="line">  [ <span class="number">7</span>] com.alibaba.cobar.server.ServerConnection.innerExecute</div><div class="line">  [ <span class="number">8</span>] com.alibaba.cobar.server.ServerConnection$<span class="number">1</span>.run</div><div class="line">  [ <span class="number">9</span>] com.taobao.tddl.common.utils.thread.FlowControlThreadPool$RunnableAdapter.run</div><div class="line">  [<span class="number">10</span>] java.util.concurrent.Executors$RunnableAdapter.call</div><div class="line">  [<span class="number">11</span>] java.util.concurrent.FutureTask.run</div><div class="line">  [<span class="number">12</span>] java.util.concurrent.ThreadPoolExecutor.runWorker</div><div class="line">  [<span class="number">13</span>] java.util.concurrent.ThreadPoolExecutor$Worker.run</div><div class="line">  [<span class="number">14</span>] java.lang.Thread.run</div><div class="line"></div><div class="line">--- <span class="number">3451038</span> ns (<span class="number">0.52</span>%), <span class="number">4</span> samples</div><div class="line">  [ <span class="number">0</span>] java.lang.Object</div><div class="line">  [ <span class="number">1</span>] sun.nio.ch.SocketChannelImpl.ensureReadOpen</div><div class="line">  [ <span class="number">2</span>] sun.nio.ch.SocketChannelImpl.read</div><div class="line">  [ <span class="number">3</span>] com.alibaba.cobar.net.AbstractConnection.read</div><div class="line">  [ <span class="number">4</span>] com.alibaba.cobar.net.NIOReactor$R.read</div><div class="line">  [ <span class="number">5</span>] com.alibaba.cobar.net.NIOReactor$R.run</div><div class="line">  [ <span class="number">6</span>] java.lang.Thread.run</div><div class="line"></div><div class="line">--- <span class="number">4143</span> ns (<span class="number">0.00</span>%), <span class="number">1</span> sample</div><div class="line">  [ <span class="number">0</span>] com.taobao.tddl.common.IdGenerator</div><div class="line">  [ <span class="number">1</span>] com.taobao.tddl.common.IdGenerator.nextId</div><div class="line">  [ <span class="number">2</span>] com.alibaba.cobar.server.ServerConnection.genTraceId</div><div class="line">  [ <span class="number">3</span>] com.alibaba.cobar.server.ServerQueryHandler.query</div><div class="line">  [ <span class="number">4</span>] com.alibaba.cobar.net.FrontendConnection.query</div><div class="line">  [ <span class="number">5</span>] com.alibaba.cobar.net.handler.FrontendCommandHandler.handle</div><div class="line">  [ <span class="number">6</span>] com.alibaba.cobar.net.FrontendConnection$<span class="number">1</span>.run</div><div class="line">  [ <span class="number">7</span>] java.util.concurrent.ThreadPoolExecutor.runWorker</div><div class="line">  [ <span class="number">8</span>] java.util.concurrent.ThreadPoolExecutor$Worker.run</div><div class="line">  [ <span class="number">9</span>] java.lang.Thread.run</div><div class="line"></div><div class="line">          ns  percent  samples  top</div><div class="line">  ----------  -------  -------  ---</div><div class="line">   <span class="number">660009389</span>   <span class="number">99.48</span>%      <span class="number">491</span>  java.util.Properties</div><div class="line">     <span class="number">3451038</span>    <span class="number">0.52</span>%        <span class="number">4</span>  java.lang.Object</div><div class="line">        <span class="number">4143</span>    <span class="number">0.00</span>%        <span class="number">1</span>  com.taobao.tddl.common.IdGenerator</div></pre></td></tr></table></figure>
<p>com.taobao.tddl.matrix.jdbc.TConnection.optimizeThenExecute调用对应代码逻辑：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> (InsertSplitter.needSplit(sql, policy, extraCmd)) &#123;</div><div class="line">             executionContext.setDoingBatchInsertBySpliter(<span class="keyword">true</span>);</div><div class="line">             InsertSplitter insertSplitter = <span class="keyword">new</span> InsertSplitter(executor);</div><div class="line">                        <span class="comment">// In batch insert, update transaction policy in writing</span></div><div class="line">                        <span class="comment">// broadcast table is also needed.</span></div><div class="line">     resultCursor = insertSplitter.execute(sql,executionContext,policy,</div><div class="line">         (String insertSql) -&gt; optimizeThenExecute(insertSql, executionContext,trxPolicyModified));</div><div class="line">                    &#125; <span class="keyword">else</span> &#123;</div><div class="line">       resultCursor = optimizeThenExecute(sql, executionContext,trxPolicyModified);</div><div class="line">                    &#125;</div><div class="line">                    </div><div class="line"> 最终会访问到：</div><div class="line"> <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">configMppExecutionContext</span><span class="params">(ExecutionContext executionContext)</span> </span>&#123;</div><div class="line"></div><div class="line">        String instRole = (String) SystemPropertiesHelper.getPropertyValue(SystemPropertiesHelper.INST_ROLE);</div><div class="line">        SqlType sqlType = executionContext.getSqlType();</div><div class="line">        </div><div class="line"> 相当于执行每个SQL都要加锁访问HashMap(SystemPropertiesHelper.getPropertyValue)，这里排队比较厉害</div></pre></td></tr></table></figure>
<p>实际以上测试结果显示bucket对性能有提升这么大是不对的，刚好这个版本把对HashMap的访问去掉了，这才是提升的主要原因，当然如果线程池入队出队有等锁的话改成多个肯定是有帮助的，但是从等锁观察是没有这个问题的。</p>
<p>在这个代码基础上将bucket改成1，在4core机器下经过反复对比测试性能基本没有明显的差异，可能core越多这个问题会更明显些。总结</p>
<p>回到最开始部分查询卡顿这个问题，本质在于 MySQL线程池开启后，因为会将多个连接分配在一个池子中共享这个池子中的几个线程。导致一个池子中的线程特别慢的时候会影响这个池子中所有的查询都会卡顿。即使别的池子很空闲也不会将任务调度过去。</p>
<p>MySQL线程池设计成多个池子（Group）的原因是为了将任务队列拆成多个，这样每个池子中的线程只是内部竞争锁，跟其他池子不冲突，类似ConcurrentHashmap的实现，当然这个设计带来的问题就是多个池子中的任务不能均衡了。</p>
<p>同时从案例我们也可以清楚地看到这个池子太小会造成锁冲突严重的卡顿，池子太大（每个池子中的线程数量就少）容易造成等线程的卡顿。</p>
<p><strong>类似地这个问题也会出现在Nginx的多worker中，一旦一个连接分发到了某个worker，就会一直在这个worker上处理，如果这个worker上的某个连接有一些慢操作，会导致这个worker上的其它连接的所有操作都受到影响，特别是会影响一些探活任务的误判。</strong>Nginx的worker这么设计也是为了将单worker绑定到固定的cpu，然后避免多核之间的上下文切换。</p>
<p>如果池子卡顿后，调用方有快速fail，比如druid的MySqlValidConnectionChecker，那么调用方从堆栈很快能发现这个问题，如果没有异常一直死等的话对问题的排查不是很友好。</p>
<p>另外可以看到分布式环境下死锁、活锁还是很容易产生的，想要一次性提前设计好比较难，需要不断踩坑爬坑。</p>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://www.atatech.org/articles/36343" target="_blank" rel="external">记一次诡异的数据库故障的排查过程</a></p>
<p><a href="http://mysql.taobao.org/monthly/2016/02/09/" target="_blank" rel="external">http://mysql.taobao.org/monthly/2016/02/09/</a></p>
<p><a href="https://dbaplus.cn/news-11-1989-1.html" target="_blank" rel="external">https://dbaplus.cn/news-11-1989-1.html</a></p>
<p><a href="https://kb.aliyun-inc.com/repo/921/article?id=G71264" target="_blank" rel="external">慢查询触发kill后导致集群卡死</a></p>
<p><a href="https://kb.aliyun-inc.com/repo/921/article?id=G56753" target="_blank" rel="external">青海湖、天津医保 RDS线程池过小导致DRDS查询卡顿问题排查 </a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2020/11/15/Linux内存--pagecache/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/11/15/Linux内存--pagecache/" itemprop="url">Linux内存--PageCache</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-11-15T16:30:03+08:00">
                2020-11-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Memory/" itemprop="url" rel="index">
                    <span itemprop="name">Memory</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Linux内存–PageCache"><a href="#Linux内存–PageCache" class="headerlink" title="Linux内存–PageCache"></a>Linux内存–PageCache</h1><p>本系列有如下几篇</p>
<p><a href="/2020/01/15/Linux 内存问题汇总/">Linux 内存问题汇总</a></p>
<p><a href="/2020/11/15/Linux内存--pagecache/">Linux内存–PageCache</a></p>
<p><a href="/2020/11/15/Linux内存--管理和碎片/">Linux内存–管理和碎片</a></p>
<p><a href="/2020/11/15/Linux内存--HugePage/">Linux内存–HugePage</a></p>
<p><a href="/2020/11/15/Linux内存--零拷贝/">Linux内存–零拷贝</a></p>
<h2 id="read-write"><a href="#read-write" class="headerlink" title="read/write"></a>read/write</h2><p><code>read(2)/write(2)</code> 是 Linux 系统中最基本的 I/O 读写系统调用，我们开发操作 I/O 的程序时必定会接触到它们，而在这两个系统调用和真实的磁盘读写之间存在一层称为 <code>Kernel buffer cache</code> 的缓冲区缓存。在 Linux 中 I/O 缓存其实可以细分为两个：<code>Page Cache</code> 和 <code>Buffer Cache</code>，这两个其实是一体两面，共同组成了 Linux 的内核缓冲区（Kernel Buffer Cache），Page Cache 是在应用程序读写文件的过程中产生的：</p>
<ul>
<li><strong>读磁盘</strong>：内核会先检查 <code>Page Cache</code> 里是不是已经缓存了这个数据，若是，直接从这个内存缓冲区里读取返回，若否，则穿透到磁盘去读取，然后再缓存在 <code>Page Cache</code> 里，以备下次缓存命中；</li>
<li><strong>写磁盘</strong>：内核直接把数据写入 <code>Page Cache</code>，并把对应的页标记为 dirty，添加到 dirty list 里，然后就直接返回，内核会定期把 dirty list 的页缓存 flush 到磁盘，保证页缓存和磁盘的最终一致性。</li>
</ul>
<p>在 Linux 还不支持虚拟内存技术之前，还没有页的概念，因此 <code>Buffer Cache</code> 是基于操作系统读写磁盘的最小单位 – 块（block）来进行的，所有的磁盘块操作都是通过 <code>Buffer Cache</code> 来加速，<strong>Linux 引入虚拟内存的机制来管理内存后，页成为虚拟内存管理的最小单位</strong>，因此也引入了 <code>Page Cache</code> 来缓存 Linux 文件内容，主要用来作为文件系统上的文件数据的缓存，提升读写性能，常见的是针对文件的 <code>read()/write()</code> 操作，另外也包括了通过 <code>mmap()</code> 映射之后的块设备，也就是说，事实上 Page Cache 负责了大部分的块设备文件的缓存工作。而 <code>Buffer Cache</code> 用来在系统对块设备进行读写的时候，对块进行数据缓存的系统来使用。</p>
<p>在 Linux 2.4 版本之后，kernel 就将两者进行了统一，<code>Buffer Cache</code> 不再以独立的形式存在，而是以融合的方式存在于 <code>Page Cache</code> 中</p>
<p><img src="/images/oss/cd1b3a9bebaf1e7219904fd537191cde.png" alt=""></p>
<p>融合之后就可以统一操作 <code>Page Cache</code> 和 <code>Buffer Cache</code>：处理文件 I/O 缓存交给 <code>Page Cache</code>，而当底层 RAW device 刷新数据时以 <code>Buffer Cache</code> 的块单位来实际处理。</p>
<h2 id="pagecache-的产生和释放"><a href="#pagecache-的产生和释放" class="headerlink" title="pagecache 的产生和释放"></a>pagecache 的产生和释放</h2><ul>
<li>标准 I/O 是写的 (write(2)) 用户缓冲区 (Userpace Page 对应的内存)，<strong>然后再将用户缓冲区里的数据拷贝到内核缓冲区 (Pagecache Page 对应的内存)</strong>；如果是读的 (read(2)) 话则是先从内核缓冲区拷贝到用户缓冲区，再从用户缓冲区读数据，也就是 buffer 和文件内容不存在任何映射关系。</li>
<li>对于存储映射 I/O（Memory-Mapped I/O） 而言，则是直接将 Pagecache Page 给映射到用户地址空间，用户直接读写 Pagecache Page 中内容，效率相对标准IO更高一些</li>
</ul>
<p><img src="/images/oss/51bf36aa14dc01e7ad309c1bb9d252e9.png" alt="image.png" style="zoom: 20%;"></p>
<p>当 <strong>将用户缓冲区里的数据拷贝到内核缓冲区 (Pagecache Page 对应的内存)</strong> 最容易发生缺页中断，OS需要先分配Page（应用感知到的就是卡顿了）</p>
<p><img src="/images/oss/d62ea00662f8342b7df3aab6b28e4cbb.png" alt="img.png" style="zoom: 25%;">  </p>
<ul>
<li>Page Cache 是在应用程序读写文件的过程中产生的，所以在读写文件之前你需要留意是否还有足够的内存来分配 Page Cache；</li>
<li>Page Cache 中的脏页很容易引起问题，你要重点注意这一块；</li>
<li>在系统可用内存不足的时候就会回收 Page Cache 来释放出来内存，可以通过 sar 或者 /proc/vmstat 来观察这个行为从而更好的判断问题是否跟回收有关</li>
</ul>
<p>缺页后kswapd在短时间内回收不了足够多的 free 内存，或kswapd 还没有触发执行，操作系统就会进行内存页直接回收。这个过程中，应用会进行自旋等待直到回收的完成，从而产生巨大的延迟。</p>
<p><img src="/images/oss/0a5cdeb75b7dee2068254cd4b7fe254d.png" style="zoom:50%;"></p>
<p>如果page被swapped，那么恢复进内存的过程也对延迟有影响，当匿名内存页被回收后，如果下次再访问就会产生IO的延迟。</p>
<p><img src="/images/oss/740b95056dace8ae6fb3b8f58d91572e.png" style="zoom:50%;"></p>
<h3 id="min-和-low的区别"><a href="#min-和-low的区别" class="headerlink" title="min 和 low的区别"></a>min 和 low的区别</h3><ol>
<li>min下的内存是保留给内核使用的；当到达min，会触发内存的direct reclaim （vm.min_free_kbytes）</li>
<li>low水位比min高一些，当内存可用量小于low的时候，会触发 kswapd回收内存，当kswapd慢慢的将内存 回收到high水位，就开始继续睡眠 </li>
</ol>
<h3 id="内存回收方式"><a href="#内存回收方式" class="headerlink" title="内存回收方式"></a>内存回收方式</h3><p>内存回收方式有两种，主要对应low ，min</p>
<ol>
<li>kswapd reclaim : 达到low水位线时执行 – 异步（实际还有，只是比较危险了，后台kswapd会回收，不会卡顿应用）</li>
<li>direct reclaim : 达到min水位线时执行 – 同步</li>
</ol>
<p>为了减少缺页中断，首先就要保证我们有足够的内存可以使用。由于Linux会尽可能多的使用free的内存，运行很久的应用free的内存是很少的。下面的图中，紫色表示已经使用的内存，白色表示尚未分配的内存。当我们的内存使用达到水位的low值的时候，kswapd就会开始回收工作，而一旦内存分配超过了min，就会进行内存的直接回收。</p>
<p><img src="/images/oss/5933cc4c28f86aa08410a8af4ff4410d.png" style="zoom:50%;"></p>
<p>针对这种情况，需要采用预留内存的手段，系统参数vm.extra_free_kbytes就是用来做这个事情的。这个参数设置了系统预留给应用的内存，可以避免紧急需要内存时发生内存回收不及时导致的高延迟。从下面图中可以看到，通过vm.extra_free_kbytes的设置，预留内存可以让内存的申请处在一个安全的水位。<strong>需要注意的是，因为内核的优化，在3.10以上的内核版本这个参数已经被取消。</strong></p>
<p><img src="/images/oss/f55022d4eb181b92ba5d2e142ec940c8.png" style="zoom: 50%;"></p>
<p>三个watermark的计算方法：</p>
<p>watermark[min] = vm.min_free_kbytes换算为page单位即可，假设为vm.min_free_kbytes。</p>
<p>watermark[low] = watermark[min] * 5 / 4</p>
<p>watermark[high] = watermark[min] * 3 / 2</p>
<p>比如默认 vm.min_free_kbytes = 65536是64K，很容易导致应用的毛刺，可以适当改大</p>
<p>或者禁止： vm.swappiness  来避免swapped来减少延迟</p>
<h3 id="direct-IO"><a href="#direct-IO" class="headerlink" title="direct IO"></a>direct IO</h3><p>绕过page cache，直接读写硬盘</p>
<h2 id="cache回收"><a href="#cache回收" class="headerlink" title="cache回收"></a>cache回收</h2><p>系统内存大体可分为三块，应用程序使用内存、系统Cache 使用内存（包括page cache、buffer，内核slab 等）和Free 内存。</p>
<ul>
<li>应用程序使用内存：应用使用都是虚拟内存，应用申请内存时只是分配了地址空间，并未真正分配出物理内存，等到应用真正访问内存时会触发内核的缺页中断，这时候才真正的分配出物理内存，映射到用户的地址空间，因此应用使用内存是不需要连续的，内核有机制将非连续的物理映射到连续的进程地址空间中（mmu），缺页中断申请的物理内存，内核优先给低阶碎内存。</li>
<li><p>系统Cache 使用内存：使用的也是虚拟内存，申请机制与应用程序相同。</p>
</li>
<li><p>Free 内存，未被使用的物理内存，这部分内存以4k 页的形式被管理在内核伙伴算法结构中，相邻的2^n 个物理页会被伙伴算法组织到一起，形成一块连续物理内存，所谓的阶内存就是这里的n (0&lt;= n &lt;=10)，高阶内存指的就是一块连续的物理内存，在OSS 的场景中，如果3阶内存个数比较小的情况下，如果系统有吞吐burst 就会触发Drop cache 情况。</p>
</li>
</ul>
<blockquote>
<p>echo 1/2/3 &gt;/proc/sys/vm/drop_caches</p>
</blockquote>
<p>查看回收后：</p>
<pre><code>cat /proc/meminfo
</code></pre><p><img src="/images/oss/7cedcb6daa53cbcfc9c68568086500b7.png" alt="image.png" style="zoom:20%;"></p>
<p>当我们执行 echo 2 来 drop slab 的时候，它也会把 Page Cache(inode可能会有对应的pagecache，inode释放后对应的pagecache也释放了)给 drop 掉</p>
<p>在系统内存紧张的时候，运维人员或者开发人员会想要通过 drop_caches 的方式来释放一些内存，但是由于他们清楚 Page Cache 被释放掉会影响业务性能，所以就期望只去 drop slab 而不去 drop pagecache。于是很多人这个时候就运行 echo 2 &gt; /proc/sys/vm/drop_caches，但是结果却出乎了他们的意料：Page Cache 也被释放掉了，业务性能产生了明显的下降。</p>
<p>查看 drop_caches 是否执行过释放：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">$ grep drop /proc/vmstat</div><div class="line">drop_pagecache 1</div><div class="line">drop_slab 0</div><div class="line"></div><div class="line">$ grep inodesteal /proc/vmstat </div><div class="line">pginodesteal 114341</div><div class="line">kswapd_inodesteal 1291853</div></pre></td></tr></table></figure>
<p>在内存紧张的时候会触发内存回收，内存回收会尝试去回收 reclaimable（可以被回收的）内存，这部分内存既包含 Page Cache 又包含 reclaimable kernel memory(比如 slab)。inode被回收后可以通过  grep inodesteal /proc/vmstat 观察到</p>
<blockquote>
<p>kswapd_inodesteal 是指在 kswapd 回收的过程中，因为回收 inode 而释放的 pagecache page 个数；</p>
<p>pginodesteal 是指 kswapd 之外其他线程在回收过程中，因为回收 inode 而释放的 pagecache page 个数;</p>
</blockquote>
<h2 id="Page回收–缺页中断"><a href="#Page回收–缺页中断" class="headerlink" title="Page回收–缺页中断"></a>Page回收–缺页中断</h2><p><img src="/images/oss/3fdffacd66c0981956b15be348fff46a.png" alt="image.png" style="zoom:20%;"></p>
<p>从图里你可以看到，在开始内存回收后，首先进行后台异步回收（上图中蓝色标记的地方），这不会引起进程的延迟；如果后台异步回收跟不上进程内存申请的速度，就会开始同步阻塞回收，导致延迟（上图中红色和粉色标记的地方，这就是引起 load 高的地址 – Sys CPU 使用率飙升/Sys load 飙升）。</p>
<p>那么，针对直接内存回收引起 load 飙高或者业务 RT 抖动的问题，一个解决方案就是及早地触发后台回收来避免应用程序进行直接内存回收，那具体要怎么做呢？</p>
<p><img src="/images/oss/4b341ba757d27e3a81145a55f54363e1.png" alt="image.png" style="zoom:25%;"></p>
<p>它的意思是：当内存水位低于 watermark low 时，就会唤醒 kswapd 进行后台回收，然后 kswapd 会一直回收到 watermark high。</p>
<p>那么，我们可以增大 min_free_kbytes 这个配置选项来及早地触发后台回收，该选项最终控制的是内存回收水位，不过，内存回收水位是内核里面非常细节性的知识点，我们可以先不去讨论。</p>
<p>对于大于等于 128G 的系统而言，将 min_free_kbytes 设置为 4G 比较合理，这是我们在处理很多这种问题时总结出来的一个经验值，既不造成较多的内存浪费，又能避免掉绝大多数的直接内存回收。</p>
<p>该值的设置和总的物理内存并没有一个严格对应的关系，我们在前面也说过，如果配置不当会引起一些副作用，所以在调整该值之前，我的建议是：你可以渐进式地增大该值，比如先调整为 1G，观察 sar -B 中 pgscand 是否还有不为 0 的情况；如果存在不为 0 的情况，继续增加到 2G，再次观察是否还有不为 0 的情况来决定是否增大，以此类推。</p>
<blockquote>
<p>sar -B :  Report paging statistics.</p>
<p>pgscand/s  Number of pages scanned directly per second.</p>
</blockquote>
<h3 id="系统中脏页过多引起-load-飙高"><a href="#系统中脏页过多引起-load-飙高" class="headerlink" title="系统中脏页过多引起 load 飙高"></a>系统中脏页过多引起 load 飙高</h3><p>直接回收过程中，如果存在较多脏页就可能涉及在回收过程中进行回写，这可能会造成非常大的延迟，而且因为这个过程本身是阻塞式的，所以又可能进一步导致系统中处于 D 状态的进程数增多，最终的表现就是系统的 load 值很高。</p>
<p><img src="/images/oss/f16438b744a248d7671d5ac7317b0a98.png" alt="image.png" style="zoom: 25%;"></p>
<p>可以通过 sar -r 来观察系统中的脏页个数：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">$ sar -r 1</div><div class="line">07:30:01 PM kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty</div><div class="line">09:20:01 PM   5681588   2137312     27.34         0   1807432    193016      2.47    534416   1310876         4</div><div class="line">09:30:01 PM   5677564   2141336     27.39         0   1807500    204084      2.61    539192   1310884        20</div><div class="line">09:40:01 PM   5679516   2139384     27.36         0   1807508    196696      2.52    536528   1310888        20</div><div class="line">09:50:01 PM   5679548   2139352     27.36         0   1807516    196624      2.51    536152   1310892        24</div></pre></td></tr></table></figure>
<p>kbdirty 就是系统中的脏页大小，它同样也是对 /proc/vmstat 中 nr_dirty 的解析。你可以通过调小如下设置来将系统脏页个数控制在一个合理范围:</p>
<blockquote>
<p>vm.dirty_background_bytes = 0</p>
<p>vm.dirty_background_ratio = 10</p>
<p>vm.dirty_bytes = 0</p>
<p>vm.dirty_expire_centisecs = 3000</p>
<p>vm.dirty_ratio = 20</p>
</blockquote>
<p>至于这些值调整大多少比较合适，也是因系统和业务的不同而异，我的建议也是一边调整一边观察，将这些值调整到业务可以容忍的程度就可以了，即在调整后需要观察业务的服务质量 (SLA)，要确保 SLA 在可接受范围内。调整的效果可以通过 /proc/vmstat 来查看：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">#grep &quot;nr_dirty_&quot; /proc/vmstat</div><div class="line">nr_dirty_threshold 3071708</div><div class="line">nr_dirty_background_threshold 1023902</div></pre></td></tr></table></figure>
<p>在4.20的内核并且sar 的版本为12.3.3可以看到PSI（Pressure-Stall Information）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">some avg10=45.49 avg60=10.23 avg300=5.41 total=76464318</div><div class="line">full avg10=40.87 avg60=9.05 avg300=4.29 total=58141082</div></pre></td></tr></table></figure>
<p>重点关注 avg10 这一列，它表示最近 10s 内存的平均压力情况，如果它很大（比如大于 40）那 load 飙高大概率是由于内存压力，尤其是 Page Cache 的压力引起的。</p>
<p><img src="/images/oss/cf58f10a523e1e4f0db443be3f54fc04.png" alt="image.png" style="zoom: 25%;"></p>
<h2 id="通过tracepoint分析内存卡顿问题"><a href="#通过tracepoint分析内存卡顿问题" class="headerlink" title="通过tracepoint分析内存卡顿问题"></a>通过tracepoint分析内存卡顿问题</h2><p><img src="/images/oss/d5446b656e8d91a9fb72200a7b97e723.png" alt="image.png" style="zoom:25%;"></p>
<p>我们继续以内存规整 (memory compaction) 为例，来看下如何利用 tracepoint 来对它进行观察：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">#首先来使能compcation相关的一些tracepoing</div><div class="line">$ echo 1 &gt;</div><div class="line">/sys/kernel/debug/tracing/events/compaction/mm_compaction_begin/enable</div><div class="line">$ echo 1 &gt;</div><div class="line">/sys/kernel/debug/tracing/events/compaction/mm_compaction_end/enable </div><div class="line"></div><div class="line">#然后来读取信息，当compaction事件触发后就会有信息输出</div><div class="line">$ cat /sys/kernel/debug/tracing/trace_pipe</div><div class="line">           &lt;...&gt;-49355 [037] .... 1578020.975159: mm_compaction_begin: </div><div class="line">zone_start=0x2080000 migrate_pfn=0x2080000 free_pfn=0x3fe5800 </div><div class="line">zone_end=0x4080000, mode=async</div><div class="line">           &lt;...&gt;-49355 [037] .N.. 1578020.992136: mm_compaction_end: </div><div class="line">zone_start=0x2080000 migrate_pfn=0x208f420 free_pfn=0x3f4b720 </div><div class="line">zone_end=0x4080000, mode=async status=contended</div></pre></td></tr></table></figure>
<p>从这个例子中的信息里，我们可以看到是 49355 这个进程触发了 compaction，begin 和 end 这两个 tracepoint 触发的时间戳相减，就可以得到 compaction 给业务带来的延迟，我们可以计算出这一次的延迟为 17ms。</p>
<p>或者用 <a href="https://lore.kernel.org/linux-mm/20191001144524.GB3321@techsingularity.net/T/" target="_blank" rel="external">perf script</a> 脚本来分析, <a href="https://github.com/iovisor/bcc/blob/master/tools/drsnoop.py" target="_blank" rel="external">基于 bcc(eBPF) 写的direct reclaim snoop</a>来观察进程因为 direct reclaim 而导致的延迟。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://www.atatech.org/articles/66885" target="_blank" rel="external">https://www.atatech.org/articles/66885</a></p>
<p><a href="https://cloud.tencent.com/developer/article/1087455" target="_blank" rel="external">https://cloud.tencent.com/developer/article/1087455</a></p>
<p><a href="https://www.cnblogs.com/xiaolincoding/p/13719610.html" target="_blank" rel="external">https://www.cnblogs.com/xiaolincoding/p/13719610.html</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2020/11/15/Linux内存--HugePage/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/11/15/Linux内存--HugePage/" itemprop="url">Linux内存--HugePage</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-11-15T16:30:03+08:00">
                2020-11-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Memory/" itemprop="url" rel="index">
                    <span itemprop="name">Memory</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Linux内存–HugePage"><a href="#Linux内存–HugePage" class="headerlink" title="Linux内存–HugePage"></a>Linux内存–HugePage</h1><p>本系列有如下几篇</p>
<p><a href="/2020/01/15/Linux 内存问题汇总/">Linux 内存问题汇总</a></p>
<p><a href="/2020/11/15/Linux内存--pagecache/">Linux内存–PageCache</a></p>
<p><a href="/2020/11/15/Linux内存--管理和碎片/">Linux内存–管理和碎片</a></p>
<p><a href="/2020/11/15/Linux内存--HugePage/">Linux内存–HugePage</a></p>
<p><a href="/2020/11/15/Linux内存--零拷贝/">Linux内存–零拷贝</a></p>
<h2 id="proc-buddyinfo"><a href="#proc-buddyinfo" class="headerlink" title="/proc/buddyinfo"></a>/proc/buddyinfo</h2><p>/proc/buddyinfo记录了内存的详细碎片情况。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">#cat /proc/buddyinfo </div><div class="line">Node 0, zone      DMA      1      1      1      0      2      1      1      0      1      1      3 </div><div class="line">Node 0, zone    DMA32      2      5      3      6      2      0      4      4      2      2    404 </div><div class="line">Node 0, zone   Normal 243430 643847 357451  32531   9508   6159   3917   2960  17172   2633  22854</div></pre></td></tr></table></figure>
<p>Normal行的第二列表示：  643847*2^1*Page_Size(4K) ;  第三列表示：  357451*2^2*Page_Size(4K)  ，高阶内存指的是2^3及更大的内存块。</p>
<p>应用申请大块连续内存（高阶内存，一般之4阶及以上, 也就是64K以上–2^4*4K）时，容易导致卡顿。这是因为大块连续内存确实系统需要触发回收或者碎片整理，需要一定的时间。</p>
<h2 id="slabtop和-proc-slabinfo"><a href="#slabtop和-proc-slabinfo" class="headerlink" title="slabtop和/proc/slabinfo"></a>slabtop和/proc/slabinfo</h2><p>slabtop和/proc/slabinfo 查看cached使用情况 主要是：pagecache（页面缓存）， dentries（目录缓存）， inodes</p>
<h2 id="关于hugetlb"><a href="#关于hugetlb" class="headerlink" title="关于hugetlb"></a>关于hugetlb</h2><p>This is an entry in the TLB that points to a HugePage (a large/big page larger than regular 4K and predefined in size). HugePages are implemented via hugetlb entries, i.e. we can say that a HugePage is handled by a “hugetlb page entry”. The ‘hugetlb” term is also (and mostly) used synonymously with a HugePage.</p>
<p> hugetlb 是TLB中指向HugePage的一个entry(通常大于4k或预定义页面大小)。 HugePage 通过hugetlb entries来实现，也可以理解为HugePage 是hugetlb page entry的一个句柄。</p>
<p><strong>Linux下的大页分为两种类型：标准大页（Huge Pages）和透明大页（Transparent Huge Pages）</strong></p>
<p>标准大页管理是预分配的方式，而透明大页管理则是动态分配的方式</p>
<p>目前透明大页与传统HugePages联用会出现一些问题，导致性能问题和系统重启。Oracle 建议禁用透明大页（Transparent Huge Pages）</p>
<p>hugetlbfs比THP要好，开thp的机器碎片化严重（不开THP会有更严重的碎片化问题），最后和没开THP一样 <a href="https://www.atatech.org/articles/152660" target="_blank" rel="external">https://www.atatech.org/articles/152660</a></p>
<p>Linux 中的 HugePages 都被锁定在内存中，所以哪怕是在系统内存不足时，它们也不会被 Swap 到磁盘上，这也就能从根源上杜绝了重要内存被频繁换入和换出的可能。</p>
<blockquote>
<p><strong>Transparent Hugepages</strong> are similar to standard <strong>HugePages</strong>. However, while standard <strong>HugePages</strong> allocate memory at startup, <strong>Transparent Hugepages</strong> memory uses the khugepaged thread in the kernel to allocate memory dynamically during runtime, using swappable <strong>HugePages</strong>.</p>
</blockquote>
<p>HugePage要求OS启动的时候提前分配出来，管理难度比较大，所以Enterprise Linux 6增加了一层抽象层来动态创建管理HugePage，这就是THP，而这个THP对应用透明，由khugepaged thread在后台动态将小页组成大页给应用使用，这里会遇上碎片问题导致需要compact才能得到大页，应用感知到的就是SYS CPU飙高，应用卡顿了。</p>
<p>虽然 HugePages 的开启大都需要开发或者运维工程师的额外配置，但是在应用程序中启用 HugePages 却可以在以下几个方面降低内存页面的管理开销：</p>
<ul>
<li>更大的内存页能够减少内存中的页表层级，这不仅可以降低页表的内存占用，也能降低从虚拟内存到物理内存转换的性能损耗；</li>
<li>更大的内存页意味着更高的缓存命中率，CPU 有更高的几率可以直接在 TLB（Translation lookaside buffer）中获取对应的物理地址；</li>
<li>更大的内存页可以减少获取大内存的次数，使用 HugePages 每次可以获取 2MB 的内存，是 4KB 的默认页效率的 512 倍；</li>
</ul>
<h2 id="HugePage"><a href="#HugePage" class="headerlink" title="HugePage"></a>HugePage</h2><p><strong>为什么需要Huge Page</strong> 了解CPU Cache大致架构的话，一定听过TLB Cache。<code>Linux</code>系统中，对程序可见的，可使用的内存地址是<code>Virtual Address</code>。每个程序的内存地址都是从0开始的。而实际的数据访问是要通过<code>Physical Address</code>进行的。因此，每次内存操作，CPU都需要从<code>page table</code>中把<code>Virtual Address</code>翻译成对应的<code>Physical Address</code>，那么对于大量内存密集型程序来说<code>page table</code>的查找就会成为程序的瓶颈。</p>
<p>所以现代CPU中就出现了TLB(Translation Lookaside Buffer) Cache用于缓存少量热点内存地址的mapping关系。然而由于制造成本和工艺的限制，响应时间需要控制在CPU Cycle级别的Cache容量只能存储几十个对象。那么TLB Cache在应对大量热点数据<code>Virual Address</code>转换的时候就显得捉襟见肘了。我们来算下按照标准的Linux页大小(page size) 4K，一个能缓存64元素的TLB Cache只能涵盖<code>4K*64 = 256K</code>的热点数据的内存地址，显然离理想非常遥远的。于是Huge Page就产生了。</p>
<p>Huge pages require contiguous areas of memory, so allocating them at boot is the most reliable method since memory has not yet become fragmented. To do so, add the following parameters to the kernel boot command line:</p>
<p><strong>Huge pages kernel options</strong></p>
<ul>
<li><p>hugepages</p>
<p>Defines the number of persistent huge pages configured in the kernel at boot time. The default value is <code>0</code>. It is only possible to allocate (or deallocate) huge pages if there are sufficient physically contiguous free pages in the system. Pages reserved by this parameter cannot be used for other purposes.</p>
<p>Default size huge pages can be dynamically allocated or deallocated by changing the value of the <code>/proc/sys/vm/nr_hugepages</code> file.</p>
<p>In a NUMA system, huge pages assigned with this parameter are divided equally between nodes. You can assign huge pages to specific nodes at runtime by changing the value of the node’s <code>/sys/devices/system/node/node_id/hugepages/hugepages-1048576kB/nr_hugepages</code> file.</p>
<p>For more information, read the relevant kernel documentation, which is installed in <code>/usr/share/doc/kernel-doc-kernel_version/Documentation/vm/hugetlbpage.txt</code> by default. This documentation is available only if the <em>kernel-doc</em> package is installed.</p>
</li>
<li><p>hugepagesz</p>
<p>Defines the size of persistent huge pages configured in the kernel at boot time. Valid values are 2 MB and 1 GB. The default value is 2 MB.</p>
</li>
<li><p>default_hugepagesz</p>
<p>Defines the default size of persistent huge pages configured in the kernel at boot time. Valid values are 2 MB and 1 GB. The default value is 2 MB.</p>
</li>
</ul>
<h3 id="HugePage-带来的问题"><a href="#HugePage-带来的问题" class="headerlink" title="HugePage 带来的问题"></a><a href="http://cenalulu.github.io/linux/huge-page-on-numa/" target="_blank" rel="external">HugePage 带来的问题</a></h3><h4 id="CPU对同一个Page抢占增多"><a href="#CPU对同一个Page抢占增多" class="headerlink" title="CPU对同一个Page抢占增多"></a>CPU对同一个Page抢占增多</h4><p>对于写操作密集型的应用，Huge Page会大大增加Cache写冲突的发生概率。由于CPU独立Cache部分的写一致性用的是<code>MESI协议</code>，写冲突就意味：</p>
<ul>
<li>通过CPU间的总线进行通讯，造成总线繁忙</li>
<li>同时也降低了CPU执行效率。</li>
<li>CPU本地Cache频繁失效</li>
</ul>
<p>类比到数据库就相当于，原来一把用来保护10行数据的锁，现在用来锁1000行数据了。必然这把锁在线程之间的争抢概率要大大增加。</p>
<h4 id="连续数据需要跨CPU读取"><a href="#连续数据需要跨CPU读取" class="headerlink" title="连续数据需要跨CPU读取"></a>连续数据需要跨CPU读取</h4><p>Page太大，更容易造成Page跨Numa/CPU 分布。</p>
<p>从下图我们可以看到，原本在4K小页上可以连续分配，并因为较高命中率而在同一个CPU上实现locality的数据。到了Huge Page的情况下，就有一部分数据为了填充统一程序中上次内存分配留下的空间，而被迫分布在了两个页上。而在所在Huge Page中占比较小的那部分数据，由于在计算CPU亲和力的时候权重小，自然就被附着到了其他CPU上。那么就会造成：本该以热点形式存在于CPU2 L1或者L2 Cache上的数据，不得不通过CPU inter-connect去remote CPU获取数据。 假设我们连续申明两个数组，<code>Array A</code>和<code>Array B</code>大小都是1536K。内存分配时由于第一个Page的2M没有用满，因此<code>Array B</code>就被拆成了两份，分割在了两个Page里。而由于内存的亲和配置，一个分配在Zone 0，而另一个在Zone 1。那么当某个线程需要访问Array B时就不得不通过代价较大的Inter-Connect去获取另外一部分数据。</p>
<p><img src="/images/951413iMgBlog/false_sharing.png" alt="img"></p>
<h3 id="Java进程开启HugePage"><a href="#Java进程开启HugePage" class="headerlink" title="Java进程开启HugePage"></a>Java进程开启HugePage</h3><p>从perf数据来看压满后tlab miss比较高，得想办法降低这个值</p>
<h4 id="修改JVM启动参数"><a href="#修改JVM启动参数" class="headerlink" title="修改JVM启动参数"></a>修改JVM启动参数</h4><p>JVM启动参数增加如下三个(-XX:LargePageSizeInBytes=2m, 这个一定要，有些资料没提这个，在我的JDK8.0环境必须要)：</p>
<blockquote>
<p>-XX:+UseLargePages -XX:LargePageSizeInBytes=2m -XX:+UseHugeTLBFS</p>
</blockquote>
<h4 id="修改机器系统配置"><a href="#修改机器系统配置" class="headerlink" title="修改机器系统配置"></a>修改机器系统配置</h4><p>设置HugePage的大小</p>
<blockquote>
<p>cat /proc/sys/vm/nr_hugepages</p>
</blockquote>
<p>nr_hugepages设置多大参考如下计算方法：</p>
<blockquote>
<p>If you are using the option <code>-XX:+UseSHM</code> or <code>-XX:+UseHugeTLBFS</code>, then specify the number of large pages. In the following example, 3 GB of a 4 GB system are reserved for large pages (assuming a large page size of 2048kB, then 3 GB = 3 <em> 1024 MB = 3072 MB = 3072 </em> 1024 kB = 3145728 kB and 3145728 kB / 2048 kB = 1536):</p>
<p>echo 1536 &gt; /proc/sys/vm/nr_hugepages </p>
</blockquote>
<p>透明大页是没有办法减少系统tlab，tlab是对应于进程的，系统分给进程的透明大页还是由物理上的4K page组成。</p>
<p>对于c++来说，他malloc经常会散落得全地址都是，因为会触发各种mmap，冷热区域。所以THP和hugepage都可能导致大量内存被浪费了，进而导致内存紧张，性能下滑。jvm的连续内存布局，加上gc会使得内存密度很紧凑。THP的问题是，他是逻辑页，不是物理页，tlb依旧要N份，所以他的收益来自page fault减少，是一次性的收益。</p>
<p>hugepage的在减少page_fault上和thp效果一样第二个作用是，他只需要一份TLB了，hugepage是真正的大页内存，thp是逻辑上的，物理上还是需要很多小的page。</p>
<p><strong>如果TLB miss，则可能需要额外三次内存读取操作才能将线性地址翻译为物理地址。</strong></p>
<h2 id="THP"><a href="#THP" class="headerlink" title="THP"></a>THP</h2><p>Linux kernel在2.6.38内核增加了Transparent Huge Pages (THP)特性 ，支持大内存页(2MB)分配，默认开启。当开启时可以降低fork子进程的速度，但fork之后，每个内存页从原来4KB变为2MB，会大幅增加重写期间父进程内存消耗。同时<strong>每次写命令引起的复制内存页单位放大了512倍</strong>，会拖慢写操作的执行时间，导致大量写操作慢查询。例如简单的incr命令也会出现在慢查询中。因此Redis日志中建议将此特性进行禁用。  </p>
<p>THP 的目的是用一个页表项来映射更大的内存（大页），这样可以减少 Page Fault，因为需要的页数少了。当然，这也会提升 TLB（Translation Lookaside Buffer，由存储器管理单元用于改进虚拟地址到物理地址的转译速度） 命中率，因为需要的页表项也少了。如果进程要访问的数据都在这个大页中，那么这个大页就会很热，会被缓存在 Cache 中。而大页对应的页表项也会出现在 TLB 中，从上一讲的存储层次我们可以知道，这有助于性能提升。但是反过来，假设应用程序的数据局部性比较差，它在短时间内要访问的数据很随机地位于不同的大页上，那么大页的优势就会消失。</p>
<p>THP 对redis、mongodb 这种cache类推荐关闭，对drds这种java应用最好打开</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">#cat /sys/kernel/mm/transparent_hugepage/enabled</div><div class="line">[always] madvise never</div><div class="line"></div><div class="line">grep &quot;Huge&quot; /proc/meminfo</div><div class="line">AnonHugePages:   1286144 kB</div><div class="line">ShmemHugePages:        0 kB</div><div class="line">HugePages_Total:       0</div><div class="line">HugePages_Free:        0</div><div class="line">HugePages_Rsvd:        0</div><div class="line">HugePages_Surp:        0</div><div class="line">Hugepagesize:       2048 kB</div><div class="line">Hugetlb:               0 kB</div><div class="line"></div><div class="line">$grep -e AnonHugePages  /proc/*/smaps | awk  &apos;&#123; if($2&gt;4) print $0&#125; &apos; |  awk -F &quot;/&quot;  &apos;&#123;print $0; system(&quot;ps -fp &quot; $3)&#125; &apos;</div><div class="line"></div><div class="line">$grep -e AnonHugePages  /proc/*/smaps | awk  &apos;&#123; if($2&gt;4) print $0&#125; &apos; |  awk -F &quot;/&quot;  &apos;&#123;print $0; system(&quot;ps -fp &quot; $3)&#125; &apos;</div><div class="line"></div><div class="line">//查看pagesize（默认4K） </div><div class="line">$getconf PAGESIZE</div></pre></td></tr></table></figure>
<p>在透明大页功能打开时，造成系统性能下降的主要原因可能是 <code>khugepaged</code> 守护进程。该进程会在（它认为）系统空闲时启动，扫描系统中剩余的空闲内存，并将普通 4k 页转换为大页。该操作会在内存路径中加锁，而该守护进程可能会在错误的时间启动扫描和转换大页的操作，从而影响应用性能。</p>
<p>此外，当缺页异常(page faults)增多时，透明大页会和普通 4k 页一样，产生同步内存压缩(direct compaction)操作，以节省内存。该操作是一个同步的内存整理操作，如果应用程序会短时间分配大量内存，内存压缩操作很可能会被触发，从而会对系统性能造成风险。<a href="https://yq.aliyun.com/articles/712830" target="_blank" rel="external">https://yq.aliyun.com/articles/712830</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">#查看系统级别的 THP 使用情况，执行下列命令：</div><div class="line">cat /proc/meminfo  | grep AnonHugePages</div><div class="line">#类似地，查看进程级别的 THP 使用情况，执行下列命令：</div><div class="line">cat /proc/1730/smaps | grep AnonHugePages |grep -v &quot;0 kB&quot;</div><div class="line">#是否开启了hugepage</div><div class="line">$cat /sys/kernel/mm/transparent_hugepage/enabled</div><div class="line">always [madvise] never</div></pre></td></tr></table></figure>
<p><code>/proc/sys/vm/nr_hugepages</code> 中存储的数据就是大页面的数量，虽然在默认情况下它的值都是 0，不过我们可以通过更改该文件的内容申请或者释放操作系统中的大页：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">$ echo 1 &gt; /proc/sys/vm/nr_hugepages</div><div class="line">$ cat /proc/meminfo | grep HugePages_</div><div class="line">HugePages_Total:       1</div><div class="line">HugePages_Free:        1</div></pre></td></tr></table></figure>
<h2 id="MySQL-场景下代码大页对性能的影响"><a href="#MySQL-场景下代码大页对性能的影响" class="headerlink" title="MySQL 场景下代码大页对性能的影响"></a><a href="https://ata.alibaba-inc.com/articles/217859" target="_blank" rel="external">MySQL 场景下代码大页对性能的影响</a></h2><p>不只是数据可以用HugePage，代码段也可以开启HugePage, 无论在x86还是arm（arm下提升更明显）下，都可以得到大页优于透明大页，透明大页优于正常的4K page</p>
<blockquote>
<p>收益：代码大页 &gt; anon THP &gt; 4k</p>
</blockquote>
<p>arm下，对32core机器用32并发的sysbench来对比，代码大页带来的性能提升大概有11%，iTLB miss下降了10倍左右。</p>
<p>x86下，性能提升只有大概3-5%之间，iTLB miss下降了1.5-3倍左右。</p>
<h2 id="TLAB-miss高的案例"><a href="#TLAB-miss高的案例" class="headerlink" title="TLAB miss高的案例"></a><a href="https://ata.alibaba-inc.com/articles/152660" target="_blank" rel="external">TLAB miss高的案例</a></h2><p>程序运行久了之后会变慢大概10%</p>
<p>刚开始运行的时候perf各项数据:</p>
<p><img src="/images/951413iMgBlog/7a26deaf96bdcc07db4db34ae1178641.png" alt="img"></p>
<p>长时间运行后：</p>
<p><img src="/images/951413iMgBlog/3385ae6ffbd5b48b80efa759f42b8174.png" alt="img"></p>
<p>内存的利用以页为单位，当时分析认为，在此4k连续的基础上，页的碎片不应该对64 byte align的cache有什么影响。当时guest和host都没有开THP。</p>
<p>既然无法理解这个结果，那就只有按部就班的查看内核执行路径上各个函数的差别了，祭出ftrace:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">echo kerel_func_name1 &gt; /sys/kernel/debug/tracing/set_ftrace_filter</div><div class="line"></div><div class="line">echo kerel_func_name2 &gt; /sys/kernel/debug/tracing/set_ftrace_filter</div><div class="line"></div><div class="line">echo kerel_func_name3 &gt; /sys/kernel/debug/tracing/set_ftrace_filter</div><div class="line">echo 1 &gt; /sys/kernel/debug/tracing/function_profile_enabled</div></pre></td></tr></table></figure>
<p>在CPU#20上执行代码:</p>
<p>taskset -c 20 ./b</p>
<p>代码执行完后:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">echo 0 &gt; /sys/kernel/debug/tracing/function_profile_enabled</div><div class="line">cat /sys/kernel/debug/tracing/trace_stat/function20</div></pre></td></tr></table></figure>
<p>这个时候就会打印出在各个函数上花费的时间，比如:</p>
<p><img src="/images/951413iMgBlog/329769dd1da2ed324ac11b8b922382cd.png" alt="img"></p>
<p>经过调试后，逐步定位到主要时间差距在  __mem_cgroup_commit_charge() (58%).</p>
<p>在阅读代码的过程中，注意到当前内核使能了CONFIG_SPARSEMEM_VMEMMAP=y</p>
<p>原因就是机器运行久了之后内存碎片化严重，导致TLAB Miss严重。</p>
<p>解决：开启THP后，性能稳定</p>
<h2 id="碎片化"><a href="#碎片化" class="headerlink" title="碎片化"></a>碎片化</h2><p>内存碎片严重的话会导致系统hang很久(回收、压缩内存）</p>
<p>尽量让系统的free多一点(比例高一点）可以调整 vm.min_free_kbytes(128G 以内 2G，256G以内 4G/8G), 线上机器直接修改vm.min_free_kbytes<strong>会触发回收，导致系统hang住</strong> <a href="https://www.atatech.org/articles/163233" target="_blank" rel="external">https://www.atatech.org/articles/163233</a> <a href="https://www.atatech.org/articles/97130" target="_blank" rel="external">https://www.atatech.org/articles/97130</a></p>
<p>compact: 在进行 compcation 时，线程会从前往后扫描已使用的 movable page，然后从后往前扫描 free page，扫描结束后会把这些 movable page 给迁移到 free page 里，最终规整出一个 2M 的连续物理内存，这样 THP 就可以成功申请内存了。</p>
<p><img src="/images/951413iMgBlog/image-20210628144121108.png" alt="image-20210628144121108"></p>
<p>一次THP compact堆栈：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">java          R  running task        0 144305 144271 0x00000080</div><div class="line"> ffff88096393d788 0000000000000086 ffff88096393d7b8 ffffffff81060b13</div><div class="line"> ffff88096393d738 ffffea003968ce50 000000000000000e ffff880caa713040</div><div class="line"> ffff8801688b0638 ffff88096393dfd8 000000000000fbc8 ffff8801688b0640</div><div class="line"></div><div class="line">Call Trace:</div><div class="line"> [&lt;ffffffff81060b13&gt;] ? perf_event_task_sched_out+0x33/0x70</div><div class="line"> [&lt;ffffffff8100bb8e&gt;] ? apic_timer_interrupt+0xe/0x20</div><div class="line"> [&lt;ffffffff810686da&gt;] __cond_resched+0x2a/0x40</div><div class="line"> [&lt;ffffffff81528300&gt;] _cond_resched+0x30/0x40</div><div class="line"> [&lt;ffffffff81169505&gt;] compact_checklock_irqsave+0x65/0xd0</div><div class="line"> [&lt;ffffffff81169862&gt;] compaction_alloc+0x202/0x460</div><div class="line"> [&lt;ffffffff811748d8&gt;] ? buffer_migrate_page+0xe8/0x130</div><div class="line"> [&lt;ffffffff81174b4a&gt;] migrate_pages+0xaa/0x480</div><div class="line"> [&lt;ffffffff81169660&gt;] ? compaction_alloc+0x0/0x460                 //compact and migrate</div><div class="line"> [&lt;ffffffff8116a1a1&gt;] compact_zone+0x581/0x950</div><div class="line"> [&lt;ffffffff8116a81c&gt;] compact_zone_order+0xac/0x100</div><div class="line"> [&lt;ffffffff8116a951&gt;] try_to_compact_pages+0xe1/0x120</div><div class="line"> [&lt;ffffffff8112f1ba&gt;] __alloc_pages_direct_compact+0xda/0x1b0</div><div class="line"> [&lt;ffffffff8112f80b&gt;] __alloc_pages_nodemask+0x57b/0x8d0</div><div class="line"> [&lt;ffffffff81167b9a&gt;] alloc_pages_vma+0x9a/0x150</div><div class="line"> [&lt;ffffffff8118337d&gt;] do_huge_pmd_anonymous_page+0x14d/0x3b0        //huge page</div><div class="line"> [&lt;ffffffff8152a116&gt;] ? rwsem_down_read_failed+0x26/0x30</div><div class="line"> [&lt;ffffffff8114b350&gt;] handle_mm_fault+0x2f0/0x300</div><div class="line"> [&lt;ffffffff810ae950&gt;] ? wake_futex+0x40/0x60</div><div class="line"> [&lt;ffffffff8104a8d8&gt;] __do_page_fault+0x138/0x480</div><div class="line"> [&lt;ffffffff810097cc&gt;] ? __switch_to+0x1ac/0x320</div><div class="line"> [&lt;ffffffff81527910&gt;] ? thread_return+0x4e/0x76e</div><div class="line"> [&lt;ffffffff8152d45e&gt;] do_page_fault+0x3e/0xa0                       //page fault</div><div class="line"> [&lt;ffffffff8152a815&gt;] page_fault+0x25/0x30</div></pre></td></tr></table></figure>
<h3 id="查看pagetypeinfo"><a href="#查看pagetypeinfo" class="headerlink" title="查看pagetypeinfo"></a>查看pagetypeinfo</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line">#cat /proc/pagetypeinfo</div><div class="line">Page block order: 9</div><div class="line">Pages per block:  512</div><div class="line"></div><div class="line">Free pages count per migrate type at order       0      1      2      3      4      5      6      7      8      9     10</div><div class="line">Node    0, zone      DMA, type    Unmovable      1      1      1      0      2      1      1      0      1      0      0</div><div class="line">Node    0, zone      DMA, type  Reclaimable      0      0      0      0      0      0      0      0      0      0      0</div><div class="line">Node    0, zone      DMA, type      Movable      0      0      0      0      0      0      0      0      0      1      3</div><div class="line">Node    0, zone      DMA, type      Reserve      0      0      0      0      0      0      0      0      0      0      0</div><div class="line">Node    0, zone      DMA, type          CMA      0      0      0      0      0      0      0      0      0      0      0</div><div class="line">Node    0, zone      DMA, type      Isolate      0      0      0      0      0      0      0      0      0      0      0</div><div class="line">Node    0, zone    DMA32, type    Unmovable     89    144     98     42     21     14      5      2      1      0      1</div><div class="line">Node    0, zone    DMA32, type  Reclaimable     28     22      9      8      0      0      0      0      0      1      7</div><div class="line">Node    0, zone    DMA32, type      Movable    402     50     21      8    880    924    321     51      4      1    227</div><div class="line">Node    0, zone    DMA32, type      Reserve      0      0      0      0      0      0      0      0      0      0      1</div><div class="line">Node    0, zone    DMA32, type          CMA      0      0      0      0      0      0      0      0      0      0      0</div><div class="line">Node    0, zone    DMA32, type      Isolate      0      0      0      0      0      0      0      0      0      0      0</div><div class="line">Node    0, zone   Normal, type    Unmovable  13709  15231   6637   2646    816    181     46      4      4      1      0</div><div class="line">Node    0, zone   Normal, type  Reclaimable      1      5      6   3293   1295    128     29      7      5      0      0</div><div class="line">Node    0, zone   Normal, type      Movable   6396 1383350 1301956 1007627 670102 366248 160232  54894  13126   1482     37</div><div class="line">Node    0, zone   Normal, type      Reserve      0      0      0      2      1      1      0      0      0      0      0</div><div class="line">Node    0, zone   Normal, type          CMA      0      0      0      0      0      0      0      0      0      0      0</div><div class="line">Node    0, zone   Normal, type      Isolate      0      0      0      0      0      0      0      0      0      0      0</div><div class="line"></div><div class="line">Number of blocks type     Unmovable  Reclaimable      Movable      Reserve          CMA      Isolate</div><div class="line">Node 0, zone      DMA            1            0            7            0            0            0</div><div class="line">Node 0, zone    DMA32           24           38          889            1            0            0</div><div class="line">Node 0, zone   Normal         1568          795       127683            2            0            0</div><div class="line">Page block order: 9</div><div class="line">Pages per block:  512</div><div class="line"></div><div class="line">Free pages count per migrate type at order       0      1      2      3      4      5      6      7      8      9     10</div><div class="line">Node    1, zone   Normal, type    Unmovable   3938   8735   5469   3221   2097    989    202      6      0      0      0</div><div class="line">Node    1, zone   Normal, type  Reclaimable      1      7      7      8      7      2      2      2      1      0      0</div><div class="line">Node    1, zone   Normal, type      Movable  18623 1001037 2084894 1261484 631159 276096  87272  17169   1389    797      0</div><div class="line">Node    1, zone   Normal, type      Reserve      0      0      0      8      0      0      0      0      0      0      0</div><div class="line">Node    1, zone   Normal, type          CMA      0      0      0      0      0      0      0      0      0      0      0</div><div class="line">Node    1, zone   Normal, type      Isolate      0      0      0      0      0      0      0      0      0      0      0</div><div class="line"></div><div class="line">Number of blocks type     Unmovable  Reclaimable      Movable      Reserve          CMA      Isolate</div><div class="line">Node 1, zone   Normal         1530          637       128903            2            0            0</div></pre></td></tr></table></figure>
<p>每个zone都有自己的min low high,如下，但是单位是page, 计算案例：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div></pre></td><td class="code"><pre><div class="line">[root@jiangyi01.sqa.zmf /home/ahao.mah]</div><div class="line">#cat /proc/zoneinfo  |grep &quot;Node&quot;</div><div class="line">Node 0, zone      DMA</div><div class="line">Node 0, zone    DMA32</div><div class="line">Node 0, zone   Normal</div><div class="line">Node 1, zone   Normal</div><div class="line"></div><div class="line">[root@jiangyi01.sqa.zmf /home/ahao.mah]</div><div class="line">#cat /proc/zoneinfo  |grep &quot;Node 0, zone&quot; -A10</div><div class="line">Node 0, zone      DMA</div><div class="line">  pages free     3975</div><div class="line">        min      20</div><div class="line">        low      25</div><div class="line">        high     30</div><div class="line">        scanned  0</div><div class="line">        spanned  4095</div><div class="line">        present  3996</div><div class="line">        managed  3975</div><div class="line">    nr_free_pages 3975</div><div class="line">    nr_alloc_batch 5</div><div class="line">--</div><div class="line">Node 0, zone    DMA32</div><div class="line">  pages free     382873</div><div class="line">        min      2335</div><div class="line">        low      2918</div><div class="line">        high     3502</div><div class="line">        scanned  0</div><div class="line">        spanned  1044480</div><div class="line">        present  513024</div><div class="line">        managed  450639</div><div class="line">    nr_free_pages 382873</div><div class="line">    nr_alloc_batch 584</div><div class="line">--</div><div class="line">Node 0, zone   Normal</div><div class="line">  pages free     11105097</div><div class="line">        min      61463</div><div class="line">        low      76828</div><div class="line">        high     92194</div><div class="line">        scanned  0</div><div class="line">        spanned  12058624</div><div class="line">        present  12058624</div><div class="line">        managed  11859912</div><div class="line">    nr_free_pages 11105097</div><div class="line">    nr_alloc_batch 12344</div><div class="line">    </div><div class="line">    low = 5/4 * min</div><div class="line">high = 3/2 * min</div><div class="line"></div><div class="line">[root@jiangyi01.sqa.zmf /home/ahao.mah]</div><div class="line">#T=min;sum=0;for i in `cat /proc/zoneinfo  |grep $T | awk &apos;&#123;print $NF&#125;&apos;`;do sum=`echo &quot;$sum+$i&quot; |bc`;done;sum=`echo &quot;$sum*4/1024&quot; |bc`;echo &quot;sum=$&#123;sum&#125; MB&quot;</div><div class="line">sum=499 MB</div><div class="line"></div><div class="line">[root@jiangyi01.sqa.zmf /home/ahao.mah]</div><div class="line">#T=low;sum=0;for i in `cat /proc/zoneinfo  |grep $T | awk &apos;&#123;print $NF&#125;&apos;`;do sum=`echo &quot;$sum+$i&quot; |bc`;done;sum=`echo &quot;$sum*4/1024&quot; |bc`;echo &quot;sum=$&#123;sum&#125; MB&quot;</div><div class="line">sum=624 MB</div><div class="line"></div><div class="line">[root@jiangyi01.sqa.zmf /home/ahao.mah]</div><div class="line">#T=high;sum=0;for i in `cat /proc/zoneinfo  |grep $T | awk &apos;&#123;print $NF&#125;&apos;`;do sum=`echo &quot;$sum+$i&quot; |bc`;done;sum=`echo &quot;$sum*4/1024&quot; |bc`;echo &quot;sum=$&#123;sum&#125; MB&quot;</div><div class="line">sum=802 MB</div></pre></td></tr></table></figure>
<h2 id="内存碎片化导致rt升高的诊断"><a href="#内存碎片化导致rt升高的诊断" class="headerlink" title="内存碎片化导致rt升高的诊断"></a>内存碎片化导致rt升高的诊断</h2><p>判定方法如下：</p>
<ol>
<li>运行 sar -B 观察 pgscand/s，其含义为每秒发生的直接内存回收次数，当在一段时间内持续大于 0 时，则应继续执行后续步骤进行排查；</li>
<li>运行 <code>cat /sys/kernel/debug/extfrag/extfrag_index</code> 观察内存碎片指数，重点关注 order &gt;= 3 的碎片指数，当接近 1.000 时，表示碎片化严重，当接近 0 时表示内存不足；</li>
<li>运行 <code>cat /proc/buddyinfo, cat /proc/pagetypeinfo</code> 查看内存碎片情况， 指标含义参考 （<a href="https://man7.org/linux/man-pages/man5/proc.5.html），同样关注" target="_blank" rel="external">https://man7.org/linux/man-pages/man5/proc.5.html），同样关注</a> order &gt;= 3 的剩余页面数量，pagetypeinfo 相比 buddyinfo 展示的信息更详细一些，根据迁移类型 （伙伴系统通过迁移类型实现反碎片化）进行分组，需要注意的是，当迁移类型为 Unmovable 的页面都聚集在 order &lt; 3 时，说明内核 slab 碎片化严重，我们需要结合其他工具来排查具体原因，在本文就不做过多介绍了；</li>
<li>对于 CentOS 7.6 等支持 BPF 的 kernel 也可以运行我们研发的 <a href="https://github.com/iovisor/bcc/blob/master/tools/drsnoop_example.txt" target="_blank" rel="external">drsnoop</a>，<a href="https://github.com/iovisor/bcc/blob/master/tools/compactsnoop_example.txt" target="_blank" rel="external">compactsnoop</a> 工具对延迟进行定量分析，使用方法和解读方式请参考对应文档；</li>
<li>(Opt) 使用 ftrace 抓取 mm_page_alloc_extfrag 事件，观察因内存碎片从备用迁移类型“盗取”页面的信息。</li>
</ol>
<p>​    </p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://www.atatech.org/articles/66885" target="_blank" rel="external">https://www.atatech.org/articles/66885</a></p>
<p><a href="https://cloud.tencent.com/developer/article/1087455" target="_blank" rel="external">https://cloud.tencent.com/developer/article/1087455</a></p>
<p><a href="https://www.cnblogs.com/xiaolincoding/p/13719610.html" target="_blank" rel="external">https://www.cnblogs.com/xiaolincoding/p/13719610.html</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2020/11/15/Linux内存--零拷贝/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/11/15/Linux内存--零拷贝/" itemprop="url">Linux内存--零拷贝</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-11-15T16:30:03+08:00">
                2020-11-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Memory/" itemprop="url" rel="index">
                    <span itemprop="name">Memory</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Linux内存–零拷贝"><a href="#Linux内存–零拷贝" class="headerlink" title="Linux内存–零拷贝"></a>Linux内存–零拷贝</h1><p>本系列有如下几篇</p>
<p><a href="/2020/01/15/Linux 内存问题汇总/">Linux 内存问题汇总</a></p>
<p><a href="/2020/11/15/Linux内存--pagecache/">Linux内存–PageCache</a></p>
<p><a href="/2020/11/15/Linux内存--管理和碎片/">Linux内存–管理和碎片</a></p>
<p><a href="/2020/11/15/Linux内存--HugePage/">Linux内存–HugePage</a></p>
<p><a href="/2020/11/15/Linux内存--零拷贝/">Linux内存–零拷贝</a></p>
<h2 id="零拷贝"><a href="#零拷贝" class="headerlink" title="零拷贝"></a>零拷贝</h2><blockquote>
<p>“<strong>Zero-copy</strong>“ describes computer operations in which the <a href="https://en.wikipedia.org/wiki/Central_processing_unit" target="_blank" rel="external">CPU</a> does not perform the task of copying data from one <a href="https://en.wikipedia.org/wiki/RAM" target="_blank" rel="external">memory</a> area to another. This is frequently used to save CPU cycles and memory bandwidth when transmitting a file over a network.</p>
</blockquote>
<p>零拷贝技术是指计算机执行操作时，<a href="https://zh.wikipedia.org/wiki/中央处理器" target="_blank" rel="external">CPU</a>不需要先将数据从某处<a href="https://zh.wikipedia.org/wiki/随机存取存储器" target="_blank" rel="external">内存</a>复制到另一个特定区域。这种技术通常用于通过网络传输文件时节省 CPU 和<a href="https://zh.wikipedia.org/wiki/内存带宽" target="_blank" rel="external">内存带宽</a>。</p>
<p>零拷贝可以做到用户空间和内核空间共用同一块内存（Java中的DirectBuffer），这样少做一次拷贝。普通Buffer是在JVM堆上分配的内存，而DirectBuffer是堆外分配的（内核和JVM可以同时读写），这样不需要再多一次内核到用户Buffer的拷贝 </p>
<p><img src="/images/951413iMgBlog/83e2dfbd25d703c58877b2faf71c4944.jpg" alt=""></p>
<p>比如通过网络下载文件，普通拷贝的流程会复制4次并有4次上下文切换，上下文切换是因为读写慢导致了IO的阻塞，进而线程被内核挂起，所以发生了上下文切换。在极端情况下如果read/write没有导致阻塞是不会发生上下文切换的：</p>
<p><img src="/images/951413iMgBlog/NoOptimization.jpg" alt="NoOptimization"></p>
<p>改成零拷贝后，也就是将read和write合并成一次，直接在内核中完成磁盘到网卡的数据复制</p>
<p><img src="/images/951413iMgBlog/ccdc10037d35349293cba8a63ad72af5.png" alt="image.png"></p>
<p>零拷贝就是操作系统提供的新函数(sendfile)，同时接收文件描述符和 TCP socket 作为输入参数，这样执行时就可以完全在内核态完成内存拷贝，既减少了内存拷贝次数，也降低了上下文切换次数。</p>
<p>而且，零拷贝取消了用户缓冲区后，不只降低了用户内存的消耗，还通过最大化利用 socket 缓冲区中的内存，间接地再一次减少了系统调用的次数，从而带来了大幅减少上下文切换次数的机会！</p>
<p>应用读取磁盘写入网络的时候还得考虑缓存的大小，一般会设置的比较小，这样一个大文件导致多次小批量的读取，每次读取伴随着多次上下文切换。</p>
<p>零拷贝使我们不必关心 socket 缓冲区的大小（socket缓冲区大小本身默认就是动态调整、或者应用代码指定大小）。比如，调用零拷贝发送方法时，尽可以把发送字节数设为文件的所有未发送字节数，例如 320MB，也许此时 socket 缓冲区大小为 1.4MB，那么一次性就会发送 1.4MB 到客户端，而不是只有 32KB。这意味着对于 1.4MB 的 1 次零拷贝，仅带来 2 次上下文切换，而不使用零拷贝且用户缓冲区为 32KB 时，经历了 176 次（4 * 1.4MB/32KB）上下文切换。</p>
<h2 id="read-write-和零拷贝优化"><a href="#read-write-和零拷贝优化" class="headerlink" title="read+write 和零拷贝优化"></a>read+write 和零拷贝优化</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">read(file, tmp_buf, len);</div><div class="line">write(socket, tmp_buf, len);</div></pre></td></tr></table></figure>
<p><img src="/images/951413iMgBlog/image-20201104175056589.png" alt="image-20201104175056589"></p>
<h3 id="通过mmap替换read优化一下"><a href="#通过mmap替换read优化一下" class="headerlink" title="通过mmap替换read优化一下"></a>通过mmap替换read优化一下</h3><p>用 <code>mmap()</code> 替换原先的 <code>read()</code>，<code>mmap()</code> 也即是内存映射（memory map）：把用户进程空间的一段内存缓冲区（user buffer）映射到文件所在的内核缓冲区（kernel buffer）上。</p>
<p><img src="/images/951413iMgBlog/516c11b9b9d3f6092f00645c1742c111.png" alt="image.png"></p>
<p>通过使用 <code>mmap()</code> 来代替 <code>read()</code>， 可以减少一次数据拷贝的过程。</p>
<p>但这还不是最理想的零拷贝，因为首先仍然需要通过 CPU 把内核缓冲区的数据拷贝到 socket 缓冲区里，而且仍然需要 4 次上下文切换，因为系统调用还是 2 次；另外内存映射技术是一个开销很大的虚拟存储操作：这种操作需要修改页表以及用内核缓冲区里的文件数据汰换掉当前 TLB 里的缓存以维持虚拟内存映射的一致性。</p>
<h3 id="sendfile"><a href="#sendfile" class="headerlink" title="sendfile"></a>sendfile</h3><p>在 Linux 内核版本 2.1 中，提供了一个专门发送文件的系统调用函数 <code>sendfile()</code>，函数形式如下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/socket.h&gt;</span></span></div><div class="line"><span class="keyword">ssize_t</span> sendfile(<span class="keyword">int</span> out_fd, <span class="keyword">int</span> in_fd, <span class="keyword">off_t</span> *offset, <span class="keyword">size_t</span> count);</div></pre></td></tr></table></figure>
<p>它的前两个参数分别是目的端和源端的文件描述符，后面两个参数是源端的偏移量和复制数据的长度，返回值是实际复制数据的长度。</p>
<p>首先，它可以替代前面的 <code>read()</code> 和 <code>write()</code> 这两个系统调用，这样就可以减少一次系统调用，也就减少了 2 次上下文切换的开销。</p>
<p>其次，该系统调用，可以直接把内核缓冲区里的数据拷贝到 socket 缓冲区里，不再拷贝到用户态，这样就只有 2 次上下文切换，和 3 次数据拷贝。如下图：</p>
<p><img src="/images/951413iMgBlog/bd72f4a031bcd88db0ca233e59234832.png" alt="image.png"></p>
<p>当然这里还是有一次CPU来拷贝内存的过程，仍然有文件截断的问题。<code>sendfile()</code> 依然是一个适用性很窄的技术，最适合的场景基本也就是一个静态文件服务器了。</p>
<p>然而 <code>sendfile()</code> 本身是有很大问题的，从不同的角度来看的话主要是：</p>
<ol>
<li>首先一个是这个接口并没有进行标准化，导致 <code>sendfile()</code> 在 Linux 上的接口实现和其他类 Unix 系统的实现并不相同；</li>
<li>其次由于网络传输的异步性，很难在接收端实现和 <code>sendfile()</code> 对接的技术，因此接收端一直没有实现对应的这种技术；</li>
<li>最后从性能方面考量，因为 <code>sendfile()</code> 在把磁盘文件从内核缓冲区（page cache）传输到到套接字缓冲区的过程中依然需要 CPU 参与，这就很难避免 CPU 的高速缓存被传输的数据所污染。</li>
</ol>
<h3 id="SG-DMA（The-Scatter-Gather-Direct-Memory-Access）技术"><a href="#SG-DMA（The-Scatter-Gather-Direct-Memory-Access）技术" class="headerlink" title="SG-DMA（The Scatter-Gather Direct Memory Access）技术"></a>SG-DMA（<em>The Scatter-Gather Direct Memory Access</em>）技术</h3><p>上一小节介绍的 <code>sendfile()</code> 技术已经把一次数据读写过程中的 CPU 拷贝的降低至只有 1 次了，但是人永远是贪心和不知足的，现在如果想要把这仅有的一次 CPU 拷贝也去除掉，有没有办法呢？</p>
<p>当然有！通过引入一个新硬件上的支持，我们可以把这个仅剩的一次 CPU 拷贝也给抹掉：Linux 在内核 2.4 版本里引入了 DMA 的 scatter/gather – 分散/收集功能，并修改了 <code>sendfile()</code> 的代码使之和 DMA 适配。scatter 使得 DMA 拷贝可以不再需要把数据存储在一片连续的内存空间上，而是允许离散存储，gather 则能够让 DMA 控制器根据少量的元信息：一个包含了内存地址和数据大小的缓冲区描述符，收集存储在各处的数据，最终还原成一个完整的网络包，直接拷贝到网卡而非套接字缓冲区，避免了最后一次的 CPU 拷贝：</p>
<p><img src="/images/951413iMgBlog/2361e8c6dcfd20a67f404b684196c160.png" alt="image.png"></p>
<p>如果网卡支持 SG-DMA（<em>The Scatter-Gather Direct Memory Access</em>）技术（和普通的 DMA 有所不同），我们可以进一步减少通过 CPU 把内核缓冲区里的数据拷贝到 socket 缓冲区的过程。</p>
<p>这就是所谓的<strong>零拷贝（Zero-copy）技术，因为我们没有在内存层面去拷贝数据，也就是说全程没有通过 CPU 来搬运数据，所有的数据都是通过 DMA 来进行传输的。</strong> 数据传输过程就再也没有 CPU 的参与了，也因此 CPU 的高速缓存再不会被污染了，也不再需要 CPU 来计算数据校验和了，CPU 可以去执行其他的业务计算任务，同时和 DMA 的 I/O 任务并行，此举能极大地提升系统性能。</p>
<p>零拷贝技术的文件传输方式相比传统文件传输的方式，减少了 2 次上下文切换和数据拷贝次数，<strong>只需要 2 次上下文切换和数据拷贝次数，就可以完成文件的传输，而且 2 次的数据拷贝过程，都不需要通过 CPU，2 次都是由 DMA 来搬运。</strong></p>
<p>所以，总体来看，<strong>零拷贝技术可以把文件传输的性能提高至少一倍以上</strong>。</p>
<h3 id="splice"><a href="#splice" class="headerlink" title="splice()"></a>splice()</h3><p><code>sendfile()</code> + DMA Scatter/Gather 的零拷贝方案虽然高效，但是也有两个缺点：</p>
<ol>
<li>这种方案需要引入新的硬件支持；</li>
<li>虽然 <code>sendfile()</code> 的输出文件描述符在 Linux kernel 2.6.33 版本之后已经可以支持任意类型的文件描述符，但是输入文件描述符依然只能指向文件。</li>
</ol>
<p>这两个缺点限制了 <code>sendfile()</code> + DMA Scatter/Gather 方案的适用场景。为此，Linux 在 2.6.17 版本引入了一个新的系统调用 <code>splice()</code>，它在功能上和 <code>sendfile()</code> 非常相似，但是能够实现在任意类型的两个文件描述符时之间传输数据；而在底层实现上，<code>splice()</code>又比 <code>sendfile()</code> 少了一次 CPU 拷贝，也就是等同于 <code>sendfile()</code> + DMA Scatter/Gather，完全去除了数据传输过程中的 CPU 拷贝。</p>
<p><code>splice()</code> 所谓的写入数据到管道其实并没有真正地拷贝数据，而是玩了个 tricky 的操作：只进行内存地址指针的拷贝而不真正去拷贝数据。所以，数据 <code>splice()</code> 在内核中并没有进行真正的数据拷贝，因此 <code>splice()</code> 系统调用也是零拷贝。</p>
<p>还有一点需要注意，前面说过管道的容量是 16 个内存页，也就是 16 * 4KB = 64 KB，也就是说一次往管道里写数据的时候最好不要超过 64 KB，否则的话会 <code>splice()</code> 会阻塞住，除非在创建管道的时候使用的是 <code>pipe2()</code> 并通过传入 <code>O_NONBLOCK</code> 属性将管道设置为非阻塞。</p>
<h3 id="send-with-MSG-ZEROCOPY"><a href="#send-with-MSG-ZEROCOPY" class="headerlink" title="send() with MSG_ZEROCOPY"></a>send() with MSG_ZEROCOPY</h3><p>Linux 内核在 2017 年的 v4.14 版本接受了来自 Google 工程师 Willem de Bruijn 在 TCP 网络报文的通用发送接口 <code>send()</code> 中实现的 zero-copy 功能 (MSG_ZEROCOPY) 的 patch，通过这个新功能，用户进程就能够把用户缓冲区的数据通过零拷贝的方式经过内核空间发送到网络套接字中去，这个新技术和前文介绍的几种零拷贝方式相比更加先进，因为前面几种零拷贝技术都是要求用户进程不能处理加工数据而是直接转发到目标文件描述符中去的。Willem de Bruijn 在他的论文里给出的压测数据是：采用 netperf 大包发送测试，性能提升 39%，而线上环境的数据发送性能则提升了 5%~8%，官方文档陈述说这个特性通常只在发送 10KB 左右大包的场景下才会有显著的性能提升。一开始这个特性只支持 TCP，到内核 v5.0 版本之后才支持 UDP。</p>
<p>这个技术是基于 redhat 红帽在 2010 年给 Linux 内核提交的 virtio-net zero-copy 技术之上实现的，至于底层原理，简单来说就是通过 <code>send()</code> 把数据在用户缓冲区中的分段指针发送到 socket 中去，利用 page pinning 页锁定机制锁住用户缓冲区的内存页，然后利用 DMA 直接在用户缓冲区通过内存地址指针进行数据读取，实现零拷贝</p>
<p>目前来说，这种技术的主要缺陷有：</p>
<ol>
<li>只适用于大文件 (10KB 左右) 的场景，小文件场景因为 page pinning 页锁定和等待缓冲区释放的通知消息这些机制，甚至可能比直接 CPU 拷贝更耗时；</li>
<li>因为可能异步发送数据，需要额外调用 <code>poll()</code> 和 <code>recvmsg()</code> 系统调用等待 buffer 被释放的通知消息，增加代码复杂度，以及会导致多次用户态和内核态的上下文切换；</li>
<li>MSG_ZEROCOPY 目前只支持发送端，接收端暂不支持。</li>
</ol>
<h3 id="零拷贝应用"><a href="#零拷贝应用" class="headerlink" title="零拷贝应用"></a>零拷贝应用</h3><p>kafka就利用了「零拷贝」技术，从而大幅提升了 I/O 的吞吐率，这也是 Kafka 在处理海量数据为什么这么快的原因之一(利用磁盘顺序写；PageCache)。</p>
<p>非零拷贝代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">File.read(fileDesc, buf, len);</div><div class="line">Socket.send(socket, buf, len);</div></pre></td></tr></table></figure>
<p>Traditional data copying approach：</p>
<p><img src="/images/951413iMgBlog/figure1.gif" alt="Traditional data copying approach"></p>
<p>Traditional context switches：</p>
<p><img src="/images/951413iMgBlog/figure2.gif" alt="Traditional context switches"></p>
<p>如果你追溯 Kafka 文件传输的代码，你会发现，最终它调用了 Java NIO 库里的 <code>transferTo</code> 方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@Overridepublic</span> </div><div class="line"><span class="function"><span class="keyword">long</span> <span class="title">transferFrom</span><span class="params">(FileChannel fileChannel, <span class="keyword">long</span> position, <span class="keyword">long</span> count)</span> <span class="keyword">throws</span> IOException </span>&#123; </div><div class="line">    <span class="keyword">return</span> fileChannel.transferTo(position, count, socketChannel);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Data copy with transferTo()</p>
<p><img src="/images/951413iMgBlog/figure3.gif" alt="Data copy with transferTo()"></p>
<p>Context switching with transferTo()：</p>
<p><img src="/images/951413iMgBlog/figure4.gif" alt="Context switching when using transferTo()"></p>
<p>Data copies when transferTo() and gather operations are used</p>
<p><img src="/images/951413iMgBlog/figure5.gif" alt="Data copies when transferTo() and gather operations are used"></p>
<p>如果 Linux 系统支持 <code>sendfile()</code> 系统调用，那么 <code>transferTo()</code> 实际上最后就会使用到 <code>sendfile()</code> 系统调用函数。</p>
<p>Nginx 也支持零拷贝技术，一般默认是开启零拷贝技术，这样有利于提高文件传输的效率，是否开启零拷贝技术的配置如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">http &#123;</div><div class="line">...</div><div class="line">    sendfile on</div><div class="line">...</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>sendfile 配置的具体意思:</p>
<ul>
<li>设置为 on 表示，使用零拷贝技术来传输文件：sendfile ，这样只需要 2 次上下文切换，和 2 次数据拷贝。</li>
<li>设置为 off 表示，使用传统的文件传输技术：read + write，这时就需要 4 次上下文切换，和 4 次数据拷贝。</li>
</ul>
<p>如果是大文件很容易消耗非常多的PageCache，不推荐使用PageCache（或者说零拷贝），建议使用异步IO+直接IO。</p>
<p>在 nginx 中，我们可以用如下配置，来根据文件的大小来使用不同的方式：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">location /video/ &#123; </div><div class="line">    sendfile on; </div><div class="line">    aio on; </div><div class="line">    directio 1024m; </div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>当文件大小大于 <code>directio</code> 值后，使用「异步 I/O + 直接 I/O」，否则使用「零拷贝技术」。</p>
<h4 id="零拷贝性能"><a href="#零拷贝性能" class="headerlink" title="零拷贝性能"></a>零拷贝性能</h4><p>如果用零拷贝和不用零拷贝来做一个文件服务器，来对比下他们的性能</p>
<p><a href="https://developer.ibm.com/articles/j-zerocopy/" target="_blank" rel="external">Performance comparison: Traditional approach vs. zero copy</a></p>
<table>
<thead>
<tr>
<th style="text-align:left">File size</th>
<th style="text-align:left">Normal file transfer (ms)</th>
<th style="text-align:left">transferTo (ms)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">7MB</td>
<td style="text-align:left">156</td>
<td style="text-align:left">45</td>
</tr>
<tr>
<td style="text-align:left">21MB</td>
<td style="text-align:left">337</td>
<td style="text-align:left">128</td>
</tr>
<tr>
<td style="text-align:left">63MB</td>
<td style="text-align:left">843</td>
<td style="text-align:left">387</td>
</tr>
<tr>
<td style="text-align:left">98MB</td>
<td style="text-align:left">1320</td>
<td style="text-align:left">617</td>
</tr>
<tr>
<td style="text-align:left">200MB</td>
<td style="text-align:left">2124</td>
<td style="text-align:left">1150</td>
</tr>
<tr>
<td style="text-align:left">350MB</td>
<td style="text-align:left">3631</td>
<td style="text-align:left">1762</td>
</tr>
<tr>
<td style="text-align:left">700MB</td>
<td style="text-align:left">13498</td>
<td style="text-align:left">4422</td>
</tr>
<tr>
<td style="text-align:left">1GB</td>
<td style="text-align:left">18399</td>
<td style="text-align:left">8537</td>
</tr>
</tbody>
</table>
<h2 id="DMA"><a href="#DMA" class="headerlink" title="DMA"></a>DMA</h2><p>什么是 DMA 技术？简单理解就是，<strong>在进行 I/O 设备和内存的数据传输的时候，数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情，这样 CPU 就可以去处理别的事务</strong></p>
<h2 id="RDMA"><a href="#RDMA" class="headerlink" title="RDMA"></a>RDMA</h2><p>remote DMA</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://www.atatech.org/articles/66885" target="_blank" rel="external">https://www.atatech.org/articles/66885</a></p>
<p><a href="https://cloud.tencent.com/developer/article/1087455" target="_blank" rel="external">https://cloud.tencent.com/developer/article/1087455</a></p>
<p><a href="https://www.cnblogs.com/xiaolincoding/p/13719610.html" target="_blank" rel="external">https://www.cnblogs.com/xiaolincoding/p/13719610.html</a></p>
<p><a href="https://mp.weixin.qq.com/s/dZNjq05q9jMFYhJrjae_LA" target="_blank" rel="external">https://mp.weixin.qq.com/s/dZNjq05q9jMFYhJrjae_LA</a> 从Linux内存管理到零拷贝</p>
<p><a href="https://developer.ibm.com/articles/j-zerocopy/" target="_blank" rel="external">Efficient data transfer through zero copy</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/272200286" target="_blank" rel="external">CPU：一个故事看懂DMA</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2020/11/15/Linux内存--管理和碎片/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/11/15/Linux内存--管理和碎片/" itemprop="url">Linux内存--管理和碎片</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-11-15T16:30:03+08:00">
                2020-11-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Memory/" itemprop="url" rel="index">
                    <span itemprop="name">Memory</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Linux内存–管理和碎片"><a href="#Linux内存–管理和碎片" class="headerlink" title="Linux内存–管理和碎片"></a>Linux内存–管理和碎片</h1><p>本系列有如下几篇</p>
<p><a href="/2020/01/15/Linux 内存问题汇总/">Linux 内存问题汇总</a></p>
<p><a href="/2020/11/15/Linux内存--pagecache/">Linux内存–PageCache</a></p>
<p><a href="/2020/11/15/Linux内存--管理和碎片/">Linux内存–管理和碎片</a></p>
<p><a href="/2020/11/15/Linux内存--HugePage/">Linux内存–HugePage</a></p>
<p><a href="/2020/11/15/Linux内存--零拷贝/">Linux内存–零拷贝</a></p>
<h2 id="物理结构分析"><a href="#物理结构分析" class="headerlink" title="物理结构分析"></a>物理结构分析</h2><p>内存从物理结构上面分为：<strong>Channel &gt; DIMM（对应物理上售卖的内存条） &gt;Rank &gt; Chip &gt; Bank &gt; Row/Column。</strong></p>
<p>Chip就是DRAM芯片，一个chip里面会有很多bank。每个bank就是数据存储的实体，相当于一个二维矩阵，只要声明了column和row就可以从每个bank中取出8bit的数据。</p>
<p>具体可以看如下图，一个通道Channel可以是一个DIMM也可以是两个DIMM，甚至3个DIMM，图中是2个DIMM。</p>
<p><img src="/images/951413iMgBlog/image-20211222135852796.png" alt="image-20211222135852796"></p>
<h2 id="虚拟内存和物理内存"><a href="#虚拟内存和物理内存" class="headerlink" title="虚拟内存和物理内存"></a>虚拟内存和物理内存</h2><p>进程所操作的内存是一个虚拟内存，由OS来将这块虚拟内存映射到实际的物理内存上，这样做的好处是每个进程可以独占 128T 内存，任意地使用，系统上还运行了哪些进程已经与我们完全没有关系了（不需要考虑和其它进程之间的地址会冲突）。为变量和函数分配地址的活，我们交给链接器去自动安排就可以了。这一切都是因为虚拟内存能够提供内存地址空间的隔离，极大地扩展了可用空间。</p>
<p>操作系统管理着这种映射关系，所以你在写代码的时候，就不用再操心物理内存的使用情况了，你看到的内存就是虚拟内存。无论一个进程占用的内存资源有多大，在任一时刻，它需要的物理内存都是很少的。在这个推论的基础上，CPU 为每个进程只需要保留很少的物理内存就可以保证进程的正常执行了。</p>
<p>当程序中使用 malloc 等分配内存的接口时会将内存从待分配状态变成已分配状态，此时这块分配好的内存还没有真正映射到对应的物理内存上，这块内存就是未映射状态，因为它并没有被映射到相应的物理内存，直到对该块内存进行读写时，操作系统才会真正地为它分配物理内存。然后这个页面才能成为正常页面。</p>
<p>i7 处理器的页表也是存储在内存页里的，每个页表项都是 4 字节。所以，人们就将 1024 个页表项组成一张页表。这样一张页表的大小就刚好是 4K，占据一个内存页，这样就更加方便管理。而且，当前市场上主流的处理器也都选择将页大小定为 4K。</p>
<blockquote>
<p>虚拟地址在计算机体系结构里可以评为特优的一项技术；超线程、流水线、多发射只是优；cache则只是良好（成本高）</p>
</blockquote>
<h3 id="CPU-如何找到真实地址"><a href="#CPU-如何找到真实地址" class="headerlink" title="CPU 如何找到真实地址"></a>CPU 如何找到真实地址</h3><p><img src="/images/951413iMgBlog/image-20211107175201297.png" alt="image-20211107175201297"></p>
<ul>
<li>第一步是确定页目录基址。每个 CPU 都有一个页目录基址寄存器，最高级页表的基地址就存在这个寄存器里。在 X86 上，这个寄存器是 CR3。每一次计算物理地址时，MMU 都会从 CR3 寄存器中取出页目录所在的物理地址。</li>
<li>第二步是定位页目录项（PDE）。一个 32 位的虚拟地址可以拆成 10 位，10 位和 12 位三段，上一步找到的页目录表基址加上高 10 位的值乘以 4，就是页目录项的位置。这是因为，一个页目录项正好是 4 字节，所以 1024 个页目录项共占据 4096 字节，刚好组成一页，而 1024 个页目录项需要 10 位进行编码。这样，我们就可以通过最高 10 位找到该地址所对应的 PDE 了。</li>
<li>第三步是定位页表项（PTE）。页目录项里记录着页表的位置，CPU 通过页目录项找到页表的位置以后，再用中间 10 位计算页表中的偏移，可以找到该虚拟地址所对应的页表项了。页表项也是 4 字节的，所以一页之内刚好也是 1024 项，用 10 位进行编码。所以计算公式与上一步相似，用页表基址加上中间 10 位乘以 4，可以得到页表项的地址。</li>
<li>最后一步是确定真实的物理地址。上一步 CPU 已经找到页表项了，这里存储着物理地址，这才真正找到该虚拟地址所对应的物理页。虚拟地址的低 12 位，刚好可以对一页内的所有字节进行编码，所以我们用低 12 位来代表页内偏移。计算的公式是物理页的地址直接加上低 12 位。</li>
</ul>
<p>前面我们分析的是 32 位操作系统，那对于 64 位机器是不是有点不同呢？在 64 位的机器上，使用了 48 位的虚拟地址，所以它需要使用 4 级页表。它的结构与 32 位的 3 级页表是相似的，<strong>只是多了一级页目录，定位的过程也从 32 位的 4 步变成了 5 步。</strong></p>
<p><img src="/images/951413iMgBlog/image-20211107182305732.png" alt="image-20211107182305732"></p>
<p>8086最开始是按不同的作用将内存分为代码段、数据段等，386开始按页开始管理内存（混合有按段管理）。 现代的操作系统都是采用段式管理来做基本的权限管理，而对于内存的分配、回收、调度都是依赖页式管理。</p>
<h3 id="tlab-miss"><a href="#tlab-miss" class="headerlink" title="tlab miss"></a>tlab miss</h3><p>TLB(Translation Lookaside Buffer) Cache用于缓存少量热点内存地址的mapping关系。TLB和L1一样每个core独享，由于制造成本和工艺的限制，响应时间需要控制在CPU Cycle级别的Cache容量只能存储几十个对象。那么TLB Cache在应对大量热点数据<code>Virual Address</code>转换的时候就显得捉襟见肘了。我们来算下按照标准的Linux页大小(page size) 4K，一个能缓存64元素的TLB Cache只能涵盖<code>4K*64 = 256K</code>的热点数据的内存地址，显然离理想非常遥远的。于是Huge Page就产生了。</p>
<p><a href="https://en.wikipedia.org/wiki/Translation_lookaside_buffer" target="_blank" rel="external">These are typical performance levels of a TLB</a>:</p>
<ul>
<li>Size: 12 bits – 4,096 entries</li>
<li>Hit time: 0.5 – 1 clock cycle</li>
<li>Miss penalty: 10 – 100 clock cycles</li>
<li>Miss rate: 0.01 – 1% (20–40% for sparse/graph applications)</li>
</ul>
<p>TLB也分为iTLB和dTLB, 分别顶在L1i和L1d前面（比L1更小更快，每个core独享tlb）</p>
<p><img src="/images/951413iMgBlog/tlb_lookup.png" alt="img"></p>
<p>以intel x86为例，一个cpu也就32到64个tlb, 超出这个范畴，就得去查页表。 每个型号的cpu都不一样，需要查看<a href="https://en.wikichip.org/wiki/WikiChip" target="_blank" rel="external">spec</a></p>
<p>进程分配到的不是内存的实际物理地址，而是一个经过映射后的虚拟地址，这么做的原因是为了让每个应用可以独享完整的虚拟地址，而不需要每个进程互相考虑使用内存的协调。</p>
<p>但是虚拟地址到物理地址的映射需要巨大的映射空间，如何用更少的内存消耗来管理庞大的内存（如果没有分级，4G内存对应着4MB的索引空间，一级比如使用4K就够了，多个二级使总共用4M，但是这4M大部分时候不用提前分配），Linux通过四级表项来做虚拟地址到物理地址的映射，这样4Kb就能管理256T内存，4级映射是时间换空间的典型案例。不过一般而言一个进程是远远用不了256T内存的，那么这四级映射大部分时候都是没必要的，所以实际用不了那么大的PageTable。</p>
<p><a href="https://mp.weixin.qq.com/s/dZNjq05q9jMFYhJrjae_LA" target="_blank" rel="external">虚拟内存的核心原理</a>是：为每个程序设置一段”连续”的虚拟地址空间，把这个地址空间分割成多个具有连续地址范围的页 (page)，并把这些页和物理内存做映射，在程序运行期间动态映射到物理内存。当程序引用到一段在物理内存的地址空间时，由硬件立刻执行必要的映射；而当程序引用到一段不在物理内存中的地址空间时，由操作系统负责将缺失的部分装入物理内存并重新执行失败的指令：</p>
<p><img src="/images/951413iMgBlog/1610941678194-bb42451f-b59a-475d-9b8d-b1085c18766d.png" alt="img"></p>
<p>在 <strong>内存管理单元（Memory Management Unit，MMU）</strong>进行地址转换时，如果页表项的 “在/不在” 位是 0，则表示该页面并没有映射到真实的物理页框，则会引发一个<strong>缺页中断</strong>，CPU 陷入操作系统内核，接着操作系统就会通过页面置换算法选择一个页面将其换出 (swap)，以便为即将调入的新页面腾出位置，如果要换出的页面的页表项里的修改位已经被设置过，也就是被更新过，则这是一个脏页 (dirty page)，需要写回磁盘更新改页面在磁盘上的副本，如果该页面是”干净”的，也就是没有被修改过，则直接用调入的新页面覆盖掉被换出的旧页面即可。</p>
<p>还需要了解的一个概念是<strong>转换检测缓冲器（Translation Lookaside Buffer，TLB，每个core一个TLB，类似L1 cache）</strong>，也叫快表，是用来加速虚拟地址映射的，因为虚拟内存的分页机制，页表一般是保存内存中的一块固定的存储区，导致进程通过 MMU 访问内存比直接访问内存多了一次内存访问，性能至少下降一半，因此需要引入加速机制，即 TLB 快表，TLB 可以简单地理解成页表的高速缓存，保存了最高频被访问的页表项，由于一般是硬件实现的，因此速度极快，MMU 收到虚拟地址时一般会先通过硬件 TLB 查询对应的页表号，若命中且该页表项的访问操作合法，则直接从 TLB 取出对应的物理页框号返回，若不命中则穿透到内存页表里查询，并且会用这个从内存页表里查询到最新页表项替换到现有 TLB 里的其中一个，以备下次缓存命中。</p>
<p>如果没有TLB那么每一次内存映射都需要查表四次然后才是一次真正的内存访问，代价比较高。</p>
<p>有了TLB之后，CPU访问某个虚拟内存地址的过程如下</p>
<ol>
<li>CPU产生一个虚拟地址</li>
<li>MMU从TLB中获取页表，翻译成物理地址</li>
<li>MMU把物理地址发送给L1/L2/L3/内存</li>
<li>L1/L2/L3/内存将地址对应数据返回给CPU</li>
</ol>
<p>由于第2步是类似于寄存器的访问速度，所以<strong>如果TLB能命中，则虚拟地址到物理地址的时间开销几乎可以忽</strong>略。tlab miss比较高的话开启内存大页对性能是有提升的，但是会有一定的内存浪费。</p>
<h2 id="内存布局"><a href="#内存布局" class="headerlink" title="内存布局"></a>内存布局</h2><ul>
<li>代码段：CPU 运行一个程序，实质就是在顺序执行该程序的机器码。一个程序的机器码会被组织到同一个地方。</li>
<li>数据段：程序在运行过程中必然要操作数据。这其中，对于有初值的变量，它的初始值会存放在程序的二进制文件中，而且，这些数据部分也会被装载到内存中，即程序的数据段。数据段存放的是程序中已经初始化且不为 0 的全局变量和静态变量。</li>
<li>BSS 段: 对于未初始化的全局变量和静态变量，因为编译器知道它们的初始值都是 0，因此便不需要再在程序的二进制映像中存放这么多 0 了，只需要记录他们的大小即可，这便是BSS段 。BSS 段这个缩写名字是 Block Started by Symbol，但很多人可能更喜欢把它记作 Better Save Space 的缩写。</li>
<li>堆是程序员可以自由申请的空间，当我们在写程序时要保存数据，优先会选择堆；</li>
<li>栈是函数执行时的活跃记录，这将是我们下一节课要重点分析的内容。</li>
</ul>
<p>数据段和 BSS 段里存放的数据也只能是部分数据，主要是全局变量和静态变量，但程序在运行过程中，仍然需要记录大量的临时变量，以及运行时生成的变量，这里就需要新的内存区域了，即程序的堆空间跟栈空间。与代码段以及数据段不同的是，堆和栈并不是从磁盘中加载，它们都是由程序在运行的过程中申请，在程序运行结束后释放。</p>
<p>总的来说，一个程序想要运行起来所需要的几块基本内存区域：代码段、数据段、BSS 段、堆空间和栈空间。下面就是内存布局的示意图：</p>
<p><img src="/images/951413iMgBlog/image-20211108115717113.png" alt="image-20211108115717113" style="zoom:35%;"></p>
<p>其它内存形态：</p>
<ul>
<li>存放加载的共享库的内存空间：如果一个进程依赖共享库，那对应的，该共享库的代码段、数据段、BSS 段也需要被加载到这个进程的地址空间中。</li>
<li>共享内存段：我们可以通过系统调用映射一块匿名区域作为共享内存，用来进行进程间通信。</li>
<li>内存映射文件：我们也可以将磁盘的文件映射到内存中，用来进行文件编辑或者是类似共享内存的方式进行进程通信。</li>
</ul>
<p>32位 x86机器下，通过 cat /proc/pid/maps 看到的进程所使用的内存分配空间：</p>
<p><img src="/images/951413iMgBlog/image-20211108120532370.png" alt="image-20211108120532370" style="zoom:33%;"></p>
<p>64位 x86机器下，通过 cat /proc/pid/maps 看到的进程所使用的内存分配空间：</p>
<p><img src="/images/951413iMgBlog/image-20211108120718732.png" alt="image-20211108120718732" style="zoom:40%;"></p>
<p>目前的 64 系统下的寻址空间是 2^48(太多用不完，高16位为Canonical空间），即 256TB。而且根据 canonical address 的划分，地址空间天然地被分割成两个区间，分别是 0x0 - 0x00007fffffffffff 和 0xffff800000000000 - 0xffffffffffffffff。这样就直接将低 128T 的空间划分为用户空间，高 128T 划分为内核空间。</p>
<p>brk:内核维护指向堆的顶部</p>
<p>Java程序对应的maps：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div></pre></td><td class="code"><pre><div class="line">#cat /proc/14011/maps</div><div class="line">00400000-00401000 r-xp 00000000 08:03 3935494                            /opt/taobao/install/ajdk-8.3.6_fp9-b30/bin/java</div><div class="line">00600000-00601000 rw-p 00000000 08:03 3935494                            /opt/taobao/install/ajdk-8.3.6_fp9-b30/bin/java</div><div class="line">ed400000-1001e0000 rw-p 00000000 00:00 0</div><div class="line">1001e0000-140000000 ---p 00000000 00:00 0</div><div class="line">7f86e8000000-7f8a7fc00000 rw-p 00000000 00:00 0</div><div class="line">..</div><div class="line">7f8aaecfa000-7f8aaeff8000 rw-p 00000000 00:00 0</div><div class="line">7f8aaeff8000-7f8aaf000000 r-xp 00000000 08:03 3935973                    /opt/taobao/install/ajdk-8.3.6_fp9-b30/jre/lib/amd64/libmanagement.so</div><div class="line">7f8aaf000000-7f8aaf1ff000 ---p 00008000 08:03 3935973                    /opt/taobao/install/ajdk-8.3.6_fp9-b30/jre/lib/amd64/libmanagement.so</div><div class="line">7f8aaf1ff000-7f8aaf200000 rw-p 00007000 08:03 3935973                    /opt/taobao/install/ajdk-8.3.6_fp9-b30/jre/lib/amd64/libmanagement.so</div><div class="line">..</div><div class="line">7f8ad8cea000-7f8ad8cec000 r--s 00004000 08:05 7078938                    /home/admin/drds-worker/lib/netty-handler-proxy-4.1.17.Final.jar</div><div class="line">7f8ad8cec000-7f8ad8cf5000 r--s 0006f000 08:05 7078952                    /home/admin/drds-worker/lib/log4j-1.2.17.jar</div><div class="line">7f8ad8cf5000-7f8ad8cf7000 r--s 00005000 08:05 7078960                    /home/admin/drds-worker/lib/objenesis-1.0.jar</div><div class="line">7f8ad8cf7000-7f8ad8cff000 r--s 0004b000 08:05 7078929                    /home/admin/drds-worker/lib/spring-aop-3.2.18.RELEASE.jar</div><div class="line">7f8ad8cff000-7f8ad8d00000 ---p 00000000 00:00 0</div><div class="line">7f8ad8d00000-7f8ad9000000 rw-p 00000000 00:00 0</div><div class="line">7f8ad90e3000-7f8ad90ef000 r--s 000b6000 08:05 7079066                    /home/admin/drds-worker/lib/transmittable-thread-local-2.5.1.jar</div><div class="line">7f8ad9dd8000-7f8ad9dfe000 r--s 0026f000 08:05 7078997                    /home/admin/drds-worker/lib/druid-1.1.7-preview_12.jar</div><div class="line">7f8ad9dfe000-7f8ad9dff000 ---p 00000000 00:00 0</div><div class="line">7f8ad9dff000-7f8ad9eff000 rw-p 00000000 00:00 0</div><div class="line">7f8ad9eff000-7f8ad9f00000 ---p 00000000 00:00 0</div><div class="line">7f8ad9f00000-7f8ada200000 rw-p 00000000 00:00 0</div><div class="line">7f8ada200000-7f8ada202000 r--s 00003000 08:05 7078944                    /home/admin/drds-worker/lib/liberate-rest-1.0.2.jar</div><div class="line">7f8ada202000-7f8ada206000 r--s 00036000 08:05 7078912                    /home/admin/drds-worker/lib/jackson-core-lgpl-1.9.6.jar</div><div class="line">7f8ada289000-7f8ada28b000 r--s 00001000 08:05 7078998                    /home/admin/drds-worker/lib/opencensus-contrib-grpc-metrics-0.10.0.jar</div><div class="line">7f8ada2b5000-7f8ada2b9000 r--s 0003a000 08:05 7079099                    /home/admin/drds-worker/lib/tddl-repo-mysql-5.2.7-2-EXTEND-HOTMAPPING-SNAPSHOT.jar</div><div class="line">7f8ada2b9000-7f8ada2c6000 r--s 0007d000 08:05 7078982                    /home/admin/drds-worker/lib/grpc-core-1.9.0.jar</div><div class="line">7f8ada2c6000-7f8ada2d6000 r--s 00149000 08:05 7079000                    /home/admin/drds-worker/lib/protobuf-java-3.5.1.jar</div><div class="line">7f8ada2d6000-7f8ada2db000 r--s 0002b000 08:05 7078927                    /home/admin/drds-worker/lib/tddl-net-5.2.7-2-EXTEND-HOTMAPPING-SNAPSHOT.jar</div><div class="line">7f8ada2db000-7f8ada2e0000 r--s 0002a000 08:05 7078939                    /home/admin/drds-worker/lib/grpc-netty-1.9.0.jar</div><div class="line">7f8ada2e0000-7f8ada2ff000 r--s 00150000 08:05 7078965                    /home/admin/drds-worker/lib/mockito-core-1.9.5.jar</div><div class="line">7f8ada2ff000-7f8ada300000 ---p 00000000 00:00 0</div><div class="line">7f8ada300000-7f8ada600000 rw-p 00000000 00:00 0</div><div class="line">7f8ada600000-7f8ada601000 r--s 00003000 08:05 7079089                    /home/admin/drds-worker/lib/ushura-1.0.jar</div><div class="line">7f8ae9ba2000-7f8ae9baa000 r-xp 00000000 08:03 3935984                    /opt/taobao/install/ajdk-8.3.6_fp9-b30/jre/lib/amd64/libzip.so</div><div class="line">7f8ae9baa000-7f8ae9da9000 ---p 00008000 08:03 3935984                    /opt/taobao/install/ajdk-8.3.6_fp9-b30/jre/lib/amd64/libzip.so</div><div class="line">7f8ae9da9000-7f8ae9daa000 rw-p 00007000 08:03 3935984                    /opt/taobao/install/ajdk-8.3.6_fp9-b30/jre/lib/amd64/libzip.so</div><div class="line">7f8ae9daa000-7f8ae9db6000 r-xp 00000000 08:03 1837851                    /usr/lib64/libnss_files-2.17.so;614d5f07 (deleted)</div><div class="line">7f8ae9db6000-7f8ae9fb5000 ---p 0000c000 08:03 1837851                    /usr/lib64/libnss_files-2.17.so;614d5f07 (deleted)</div><div class="line">7f8ae9fb5000-7f8ae9fb6000 r--p 0000b000 08:03 1837851                    /usr/lib64/libnss_files-2.17.so;614d5f07 (deleted)</div><div class="line">7f8ae9fb6000-7f8ae9fb7000 rw-p 0000c000 08:03 1837851                    /usr/lib64/libnss_files-2.17.so;614d5f07 (deleted)</div><div class="line">7f8ae9fb7000-7f8ae9fbd000 rw-p 00000000 00:00 0</div><div class="line">7f8ae9fbd000-7f8ae9fe7000 r-xp 00000000 08:03 3935961                    /opt/taobao/install/ajdk-8.3.6_fp9-b30/jre/lib/amd64/libjava.so</div><div class="line">7f8aebc03000-7f8aebc05000 r--s 00008000 08:05 7079098                    /home/admin/drds-worker/lib/grpc-stub-1.9.0.jar</div><div class="line">7f8aebc05000-7f8aebc07000 r--s 00020000 08:05 7078930                    /home/admin/drds-worker/lib/tddl-group-5.2.7-2-EXTEND-HOTMAPPING-SNAPSHOT.jar</div><div class="line">7f8aebc07000-7f8aebc1f000 r--s 001af000 08:05 7079085                    /home/admin/drds-worker/lib/aspectjweaver-1.8.5.jar</div><div class="line">7f8aebc1f000-7f8aebc20000 ---p 00000000 00:00 0</div><div class="line">7f8aebc20000-7f8aebd20000 rw-p 00000000 00:00 0</div><div class="line">7f8aebd20000-7f8aebd35000 r-xp 00000000 08:03 1837234                    /usr/lib64/libgcc_s-4.8.5-20150702.so.1</div><div class="line">7f8aebd35000-7f8aebf34000 ---p 00015000 08:03 1837234                    /usr/lib64/libgcc_s-4.8.5-20150702.so.1</div><div class="line">7f8aebf34000-7f8aebf35000 r--p 00014000 08:03 1837234                    /usr/lib64/libgcc_s-4.8.5-20150702.so.1</div><div class="line">7f8aebf35000-7f8aebf36000 rw-p 00015000 08:03 1837234                    /usr/lib64/libgcc_s-4.8.5-20150702.so.1</div><div class="line">7f8aebf36000-7f8aec037000 r-xp 00000000 08:03 1837579                    /usr/lib64/libm-2.17.so;614d5f07 (deleted)</div><div class="line">7f8aec037000-7f8aec236000 ---p 00101000 08:03 1837579                    /usr/lib64/libm-2.17.so;614d5f07 (deleted)</div><div class="line">7f8aeca17000-7f8aeca18000 rw-p 0000d000 08:03 3936057                    /opt/taobao/install/ajdk-8.3.6_fp9-b30/lib/amd64/jli/libjli.so</div><div class="line">7f8aeca18000-7f8aeca2d000 r-xp 00000000 08:03 1836998                    /usr/lib64/libz.so.1.2.7</div><div class="line">7f8aeca2d000-7f8aecc2c000 ---p 00015000 08:03 1836998                    /usr/lib64/libz.so.1.2.7</div><div class="line">7f8aecc2c000-7f8aecc2d000 r--p 00014000 08:03 1836998                    /usr/lib64/libz.so.1.2.7</div><div class="line">7f8aecc2d000-7f8aecc2e000 rw-p 00015000 08:03 1836998                    /usr/lib64/libz.so.1.2.7</div><div class="line">7f8aecc2e000-7f8aecc45000 r-xp 00000000 08:03 1836993                    /usr/lib64/libpthread-2.17.so;614d5f07 (deleted)</div><div class="line">7f8aecc45000-7f8aece44000 ---p 00017000 08:03 1836993                    /usr/lib64/libpthread-2.17.so;614d5f07 (deleted)</div><div class="line">7f8aece44000-7f8aece45000 r--p 00016000 08:03 1836993                    /usr/lib64/libpthread-2.17.so;614d5f07 (deleted)</div><div class="line">7f8aece45000-7f8aece46000 rw-p 00017000 08:03 1836993                    /usr/lib64/libpthread-2.17.so;614d5f07 (deleted)</div><div class="line">7f8aece46000-7f8aece4a000 rw-p 00000000 00:00 0</div><div class="line">7f8aece4a000-7f8aecea1000 r-xp 00000000 08:03 3936059                    /opt/taobao/install/ajdk-8.3.6_fp9-b30/lib/amd64/libjemalloc.so.2</div><div class="line">7f8aecea1000-7f8aed0a0000 ---p 00057000 08:03 3936059                    /opt/taobao/install/ajdk-8.3.6_fp9-b30/lib/amd64/libjemalloc.so.2</div><div class="line">7f8aed0a0000-7f8aed0a3000 rw-p 00056000 08:03 3936059                    /opt/taobao/install/ajdk-8.3.6_fp9-b30/lib/amd64/libjemalloc.so.2</div><div class="line">7f8aed0a3000-7f8aed0b5000 rw-p 00000000 00:00 0</div><div class="line">7f8aed0b5000-7f8aed0d7000 r-xp 00000000 08:03 1837788                    /usr/lib64/ld-2.17.so;614d5f07 (deleted)</div><div class="line">7f8aed0d7000-7f8aed0dc000 r--s 00038000 08:05 7079012                    /home/admin/drds-worker/lib/org.osgi.core-4.2.0.jar</div><div class="line">7f8aed0dc000-7f8aed0e1000 r--s 00038000 08:05 7079018                    /home/admin/drds-worker/lib/commons-beanutils-1.9.3.jar</div><div class="line">7f8aed0e1000-7f8aed0e3000 r--s 00001000 08:05 7079033                    /home/admin/drds-worker/lib/j2objc-annotations-1.1.jar</div><div class="line">7f8aed0e3000-7f8aed0e8000 r--s 00017000 08:05 7079056                    /home/admin/drds-worker/lib/hibernate-jpa-2.1-api-1.0.0.Final.jar</div><div class="line">7f8aed1be000-7f8aed1c6000 rw-s 00000000 08:04 393222                     /tmp/hsperfdata_admin/14011</div><div class="line">7f8aed1c6000-7f8aed1ca000 ---p 00000000 00:00 0</div><div class="line">7f8aed1ca000-7f8aed2cd000 rw-p 00000000 00:00 0</div><div class="line">7f8aed2cd000-7f8aed2ce000 r--s 00005000 08:05 7079029                    /home/admin/drds-worker/lib/jersey-apache-connector-2.26.jar</div><div class="line">7f8aed2ce000-7f8aed2d1000 r--s 0000a000 08:05 7079027                    /home/admin/drds-worker/lib/metrics-jvm-1.7.4.jar</div><div class="line">7f8aed2d1000-7f8aed2d3000 r--s 00006000 08:05 7078961                    /home/admin/drds-worker/lib/tddl-client-5.2.7-2-EXTEND-HOTMAPPING-SNAPSHOT.jar</div><div class="line">7f8aed2d3000-7f8aed2d4000 rw-p 00000000 00:00 0</div><div class="line">7f8aed2d4000-7f8aed2d5000 r--p 00000000 00:00 0</div><div class="line">7f8aed2d5000-7f8aed2d6000 rw-p 00000000 00:00 0</div><div class="line">7f8aed2d6000-7f8aed2d7000 r--p 00021000 08:03 1837788                    /usr/lib64/ld-2.17.so;614d5f07 (deleted)</div><div class="line">7f8aed2d7000-7f8aed2d8000 rw-p 00022000 08:03 1837788                    /usr/lib64/ld-2.17.so;614d5f07 (deleted)</div><div class="line">7f8aed2d8000-7f8aed2d9000 rw-p 00000000 00:00 0</div><div class="line">7fff087e0000-7fff08801000 rw-p 00000000 00:00 0                          [stack]</div><div class="line">7fff089c2000-7fff089c4000 r-xp 00000000 00:00 0                          [vdso]</div><div class="line">ffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0                  [vsyscall]</div></pre></td></tr></table></figure>
<h2 id="内存管理和使用"><a href="#内存管理和使用" class="headerlink" title="内存管理和使用"></a>内存管理和使用</h2><h3 id="malloc"><a href="#malloc" class="headerlink" title="malloc"></a>malloc</h3><p>malloc()分配内存时：</p>
<ul>
<li>如果用户分配的内存小于 128 KB，则通过 brk() 申请内存–在堆顶分配；</li>
<li>如果用户分配的内存大于 128 KB，则通过 mmap()  申请内存–从文件映射区域分配；</li>
</ul>
<p><img src="/images/951413iMgBlog/640-20220323120420806.png" alt="图片"></p>
<p><img src="/images/951413iMgBlog/640-20220323120443853.png" alt="图片"></p>
<p>对于 「malloc 申请的内存，free 释放内存会归还给操作系统吗？」：</p>
<ul>
<li>malloc 通过 <strong>brk()</strong> 方式申请的内存，free 释放内存的时候，<strong>并不会把内存归还给操作系统，而是缓存在 malloc 的内存池中，待下次使用</strong>–小内存分配避免反复调用系统操作导致上下文切换，缺点是没回收容易导致内存碎片进而浪费内存。brk分配出来的内存在maps中显示有heap字样；</li>
<li>malloc 通过 <strong>mmap()</strong> 方式申请的内存，free 释放内存的时候，<strong>会把内存归还给操作系统，内存得到真正的释放</strong>。并且mmap分配的虚拟内存都是缺页状态的。</li>
</ul>
<h3 id="malloc和mmap"><a href="#malloc和mmap" class="headerlink" title="malloc和mmap"></a>malloc和mmap</h3><p>glibc中的malloc/free 负责向内核批发内存（不需要每次分配都真正地去调用内核态来分配），分配好的内存按大小分成不同的桶，每次malloc的时候实际到对应的桶上摘取对应的块(slab)就好，用完free的时候挂回去。</p>
<p><img src="/images/951413iMgBlog/image-20211118121500859.png" alt="image-20211118121500859"></p>
<p>mmap映射内存</p>
<p><img src="/images/951413iMgBlog/image-20211108122432263.png" alt="image-20211108122432263" style="zoom:20%;"></p>
<p>私有匿名映射常用于分配内存，也就是申请堆内存</p>
<p>分桶式内存管理比简单算法无论是在算法效率方面，还是在碎片控制方面都有很大的提升。但它的缺陷也很明显：区域内部的使用率不够高和动态扩展能力不够好。例如，4 字节的区域提前消耗完了，但 8 字节的空闲区域还有很多，此时就会面临两难选择，如果直接分配 8 字节的区域，则区域内部浪费就比较多，如果不分配，则明明还有空闲区域，却无法成功分配。</p>
<p>为了解决以上问题所以搞了buddy</p>
<h3 id="node-gt-zone-gt-buddy-gt-slab"><a href="#node-gt-zone-gt-buddy-gt-slab" class="headerlink" title="node-&gt;zone-&gt;buddy-&gt;slab"></a>node-&gt;zone-&gt;buddy-&gt;slab</h3><p><img src="/images/oss/debfe12e-d1b9-49cd-988d-3f7fcba6ecd2.png" alt="img"></p>
<p>假如需要分配一块 4 字节大小的空间，但是在 4 字节的 free list 上找不到空闲区域，系统就会往上找，假如 8 字节和 16 字节的 free list 中也没有空闲区域，就会一直向上找到 32 字节的 free list。</p>
<p><img src="/images/951413iMgBlog/image-20211118120823595.png" alt="image-20211118120823595"></p>
<p>伙伴系统不会直接把 32 的空闲区域分配出去，因为这样做的话，会带来巨大的浪费。它会先把 32 字节分成两个 16 字节，把后边一个挂入到 16 字节的 free list 中。然后继续拆分前一半。前一半继续拆成两个 8 字节，再把后一半挂入到 8 字节的 free list，最后，把前一半 8 字节拿去分配，当然这里也要继续拆分成两个 4 字节的空闲区域，其中一个用于本次 malloc 分配，另一个则挂入到 4 字节的 free list。分配后的内存的状态如下所示：</p>
<p><img src="/images/951413iMgBlog/image-20211118120851731.png" alt="image-20211118120851731"></p>
<h3 id="查看zone"><a href="#查看zone" class="headerlink" title="查看zone"></a>查看zone</h3><p><a href="https://utcc.utoronto.ca/~cks/space/blog/linux/KernelMemoryZones" target="_blank" rel="external">The zones are</a>:</p>
<ul>
<li><code>DMA</code> is the low 16 MBytes of memory. At this point it exists for historical reasons; once upon what is now a long time ago, there was hardware that could only do DMA into this area of physical memory.</li>
<li><code>DMA32</code> exists only in 64-bit Linux; it is the low 4 GBytes of memory, more or less. It exists because the transition to large memory 64-bit machines has created a class of hardware that can only do DMA to the low 4 GBytes of memory.(This is where people mutter about everything old being new again.)</li>
<li><strong><code>Normal</code></strong> is different on 32-bit and 64-bit machines. On 64-bit machines, it is all RAM from 4GB or so on upwards. On 32-bit machines it is all RAM from 16 MB to 896 MB for complex and somewhat historical reasons. Note that this implies that machines with a 64-bit kernel can have very small amounts of Normal memory unless they have significantly more than 4GB of RAM. For example, a 2 GB machine running a 64-bit kernel will have no Normal memory at all while a 4 GB machine will have only a tiny amount of it.</li>
<li><code>HighMem</code> exists only on 32-bit Linux; it is all RAM above 896 MB, including RAM above 4 GB on sufficiently large machines.</li>
</ul>
<p>每个zone下很多pages(大小为4K)，buddy就是这些Pages的组织管理者</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line"># cat /proc/zoneinfo |grep Node -A10</div><div class="line">Node 0, zone      DMA</div><div class="line">  pages free     3972</div><div class="line">        min      0</div><div class="line">        low      0</div><div class="line">        high     0</div><div class="line">        scanned  0</div><div class="line">        spanned  4095</div><div class="line">        present  3993</div><div class="line">        managed  3972</div><div class="line">    nr_free_pages 3972</div><div class="line">    nr_alloc_batch 0</div><div class="line">--</div><div class="line">Node 0, zone    DMA32</div><div class="line">  pages free     361132</div><div class="line">        min      30</div><div class="line">        low      37</div><div class="line">        high     45</div><div class="line">        scanned  0</div><div class="line">        spanned  1044480</div><div class="line">        present  430773</div><div class="line">        managed  361133</div><div class="line">    nr_free_pages 361132</div><div class="line">    nr_alloc_batch 8</div><div class="line">--</div><div class="line">Node 0, zone   Normal</div><div class="line">  pages free     96017308</div><div class="line">        min      16864</div><div class="line">        low      21080</div><div class="line">        high     25296</div><div class="line">        scanned  0</div><div class="line">        spanned  200736768</div><div class="line">        present  200736768</div><div class="line">        managed  197571780</div><div class="line">    nr_free_pages 96017308</div><div class="line">    nr_alloc_batch 3807</div><div class="line">    </div><div class="line"># free -g</div><div class="line">              total        used        free      shared  buff/cache   available</div><div class="line">Mem:            755         150         367           3         236         589</div><div class="line">Swap:             0           0           0</div></pre></td></tr></table></figure>
<p>每个页面大小是4K，很容易可以计算出每个 zone 的大小。比如对于上面 Node0 的 Normal， 197571780 <em> 4K/(1024</em>1024) = 753 GB。</p>
<p>dmidecode 可以查看到服务器上插着的所有内存条，也可以看到它是和哪个CPU直接连接的。每一个CPU以及和他直连的内存条组成了一个 <strong>node（节点）</strong></p>
<h3 id="proc-buddyinfo"><a href="#proc-buddyinfo" class="headerlink" title="/proc/buddyinfo"></a>/proc/buddyinfo</h3><p>/proc/buddyinfo记录了<strong>可用内存</strong>的情况。</p>
<p>Normal那行之后的第二列表示：  643847*2^1*Page_Size(4K) ;  第三列表示：  357451*2^2*Page_Size(4K)  ，高阶内存指的是2^3及更大的内存块。</p>
<p>应用申请大块连续内存（高阶内存，一般之4阶及以上, 也就是64K以上–2^4*4K）时，容易导致卡顿。这是因为大块连续内存确实系统需要触发回收或者碎片整理，需要一定的时间。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div></pre></td><td class="code"><pre><div class="line">#cat /proc/buddyinfo </div><div class="line">Node 0, zone      DMA      1      1      1      0      2      1      1      0      1      1      3 </div><div class="line">Node 0, zone    DMA32      2      5      3      6      2      0      4      4      2      2    404 </div><div class="line">Node 0, zone   Normal 243430 643847 357451  32531   9508   6159   3917   2960  17172   2633  22854</div><div class="line"></div><div class="line">如果是多node机器：</div><div class="line">#cat /proc/buddyinfo</div><div class="line">Node 0, zone      DMA      4      6      3      2      3      3      1      1      2      3      1</div><div class="line">Node 0, zone    DMA32   1607   1619   1552   1520   1370   1065    827    576    284    105     13</div><div class="line">Node 0, zone   Normal  38337 145731 222145 199776 151452  91969  38086  10037   1762    104      1</div><div class="line">Node 1, zone   Normal  21521 147637 299185 245533 172451  81459  19451   7198    579      3      0</div><div class="line">Node 2, zone   Normal  68427 538670 446906 229138 123555  62539  21161   4407   1122    166    274</div><div class="line">Node 3, zone   Normal  27353  54601 114355 123568 101892  79098  48610  21036   5021    475      6</div><div class="line">Node 4, zone   Normal  45802  42758   8573 184548 148397  70540  20772   4147    381    148    109</div><div class="line">Node 5, zone   Normal  19514  39583 140493 167901 134774  61888  22998   6326    457     32      0</div><div class="line">Node 6, zone   Normal 104493 378362 355158  93138  12928   2248   1019    663    172     40    121</div><div class="line">Node 7, zone   Normal  34185 256886 249560  95547  54526  51022  28180   9757   2038   1351    280</div><div class="line"></div><div class="line">[root@hygon8 15:50 /root]</div><div class="line">#numactl -H</div><div class="line">available: 8 nodes (0-7)</div><div class="line">node 0 cpus: 0 1 2 3 4 5 6 7 64 65 66 67 68 69 70 71</div><div class="line">node 0 size: 64083 MB</div><div class="line">node 0 free: 49838 MB</div><div class="line">node 1 cpus: 8 9 10 11 12 13 14 15 72 73 74 75 76 77 78 79</div><div class="line">node 1 size: 64480 MB</div><div class="line">node 1 free: 43596 MB</div><div class="line">node 2 cpus: 16 17 18 19 20 21 22 23 80 81 82 83 84 85 86 87</div><div class="line">node 2 size: 64507 MB</div><div class="line">node 2 free: 44216 MB</div><div class="line">node 3 cpus: 24 25 26 27 28 29 30 31 88 89 90 91 92 93 94 95</div><div class="line">node 3 size: 64507 MB</div><div class="line">node 3 free: 51095 MB</div><div class="line">node 4 cpus: 32 33 34 35 36 37 38 39 96 97 98 99 100 101 102 103</div><div class="line">node 4 size: 64507 MB</div><div class="line">node 4 free: 32877 MB</div><div class="line">node 5 cpus: 40 41 42 43 44 45 46 47 104 105 106 107 108 109 110 111</div><div class="line">node 5 size: 64507 MB</div><div class="line">node 5 free: 33430 MB</div><div class="line">node 6 cpus: 48 49 50 51 52 53 54 55 112 113 114 115 116 117 118 119</div><div class="line">node 6 size: 64507 MB</div><div class="line">node 6 free: 14233 MB</div><div class="line">node 7 cpus: 56 57 58 59 60 61 62 63 120 121 122 123 124 125 126 127</div><div class="line">node 7 size: 63483 MB</div><div class="line">node 7 free: 36577 MB</div><div class="line">node distances:</div><div class="line">node   0   1   2   3   4   5   6   7</div><div class="line">  0:  10  16  16  16  28  28  22  28</div><div class="line">  1:  16  10  16  16  28  28  28  22</div><div class="line">  2:  16  16  10  16  22  28  28  28</div><div class="line">  3:  16  16  16  10  28  22  28  28</div><div class="line">  4:  28  28  22  28  10  16  16  16</div><div class="line">  5:  28  28  28  22  16  10  16  16</div><div class="line">  6:  22  28  28  28  16  16  10  16</div><div class="line">  7:  28  22  28  28  16  16  16  10</div><div class="line">  </div><div class="line">[root@hygon8 15:51 /root]</div><div class="line">#cat /proc/pagetypeinfo</div><div class="line">Page block order: 9</div><div class="line">Pages per block:  512</div><div class="line"></div><div class="line">Free pages count per migrate type at order       0      1      2      3      4      5      6      7      8      9     10</div><div class="line">Node    0, zone      DMA, type    Unmovable      1      2      1      1      3      2      0      0      1      0      0</div><div class="line">Node    0, zone      DMA, type      Movable      0      0      0      0      0      0      0      0      0      3      1</div><div class="line">Node    0, zone      DMA, type  Reclaimable      3      4      2      1      0      1      1      1      1      0      0</div><div class="line">Node    0, zone      DMA, type   HighAtomic      0      0      0      0      0      0      0      0      0      0      0</div><div class="line">Node    0, zone      DMA, type      Isolate      0      0      0      0      0      0      0      0      0      0      0</div><div class="line">Node    0, zone    DMA32, type    Unmovable    151    164    162    165    140     78     19      8      0      0      0</div><div class="line">Node    0, zone    DMA32, type      Movable   1435   1430   1374   1335   1214    974    798    563    281     98     12</div><div class="line">Node    0, zone    DMA32, type  Reclaimable     21     25     16     20     16     13     10      5      3      7      1</div><div class="line">Node    0, zone    DMA32, type   HighAtomic      0      0      0      0      0      0      0      0      0      0      0</div><div class="line">Node    0, zone    DMA32, type      Isolate      0      0      0      0      0      0      0      0      0      0      0</div><div class="line">Node    0, zone   Normal, type    Unmovable   4849   6607   4133   1629    654    121     15      3      0      0      0</div><div class="line">Node    0, zone   Normal, type      Movable  21088 &gt;100000 &gt;100000 &gt;100000 &gt;100000  90231  37197   9379   1552     83      1</div><div class="line">Node    0, zone   Normal, type  Reclaimable    153    139   3012   3113   2437   1617    874    655    210     21      0</div><div class="line">Node    0, zone   Normal, type   HighAtomic      0      0      0      0      0      0      0      0      0      0      0</div><div class="line">Node    0, zone   Normal, type      Isolate      0      0      0      0      0      0      0      0      0      0      0</div><div class="line"></div><div class="line">Number of blocks type     Unmovable      Movable  Reclaimable   HighAtomic      Isolate</div><div class="line">Node 0, zone      DMA            1            6            1            0            0</div><div class="line">Node 0, zone    DMA32           27          974           15            0            0</div><div class="line">Node 0, zone   Normal          856        30173          709            0            0</div><div class="line">Page block order: 9</div><div class="line">Pages per block:  512</div><div class="line"></div><div class="line">Free pages count per migrate type at order       0      1      2      3      4      5      6      7      8      9     10</div><div class="line">Node    1, zone   Normal, type    Unmovable    842   2898   2495   1316    490    102     23      1      2      0      0</div><div class="line">Node    1, zone   Normal, type      Movable  22484 &gt;100000 &gt;100000 &gt;100000 &gt;100000  80084  18922   6889     48      4      0</div><div class="line">Node    1, zone   Normal, type  Reclaimable      1   2022   3850   3534   2582   1273    506    308    529      0      0</div><div class="line">Node    1, zone   Normal, type   HighAtomic      0      0      0      0      0      0      0      0      0      0      0</div><div class="line">Node    1, zone   Normal, type      Isolate      0      0      0      0      0      0      0      0      0      0      0</div><div class="line"></div><div class="line">Number of blocks type     Unmovable      Movable  Reclaimable   HighAtomic      Isolate</div><div class="line">Node 1, zone   Normal          810        31221          737            0            0</div><div class="line">Page block order: 9</div><div class="line">Pages per block:  512</div><div class="line"></div><div class="line">Free pages count per migrate type at order       0      1      2      3      4      5      6      7      8      9     10</div><div class="line">Node    2, zone   Normal, type    Unmovable   2833   6802   3888   1636    329      3      1      2      0      0      0</div><div class="line">Node    2, zone   Normal, type      Movable  72017 &gt;100000 &gt;100000 &gt;100000 &gt;100000  61710  20764   4242    841     55    239</div><div class="line">Node    2, zone   Normal, type  Reclaimable    114      8   2056   2221   1544    826    396    163    281    111     35</div><div class="line">Node    2, zone   Normal, type   HighAtomic      0      0      0      0      0      0      0      0      0      0      0</div><div class="line">Node    2, zone   Normal, type      Isolate      0      0      0      0      0      0      0      0      0      0      0</div><div class="line"></div><div class="line">Number of blocks type     Unmovable      Movable  Reclaimable   HighAtomic      Isolate</div><div class="line">Node 2, zone   Normal         1066        31063          639            0            0</div><div class="line">Page block order: 9</div><div class="line">Pages per block:  512</div><div class="line"></div><div class="line">Free pages count per migrate type at order       0      1      2      3      4      5      6      7      8      9     10</div><div class="line">Node    3, zone   Normal, type    Unmovable   2508   6171   3802   1502    365     93     30      1      2      0      0</div><div class="line">Node    3, zone   Normal, type      Movable  23396  48450 &gt;100000 &gt;100000  99802  77850  47910  20587   4796    428      5</div><div class="line">Node    3, zone   Normal, type  Reclaimable     10      0    609   2111   1726   1155    670    448    223     46      1</div><div class="line">Node    3, zone   Normal, type   HighAtomic      0      0      0      0      0      0      0      0      0      0      0</div><div class="line">Node    3, zone   Normal, type      Isolate      0      0      0      0      0      0      0      0      0      0      0</div><div class="line"></div><div class="line">Number of blocks type     Unmovable      Movable  Reclaimable   HighAtomic      Isolate</div><div class="line">Node 3, zone   Normal          768        31425          575            0            0</div><div class="line">Page block order: 9</div><div class="line">Pages per block:  512</div><div class="line"></div><div class="line">Free pages count per migrate type at order       0      1      2      3      4      5      6      7      8      9     10</div><div class="line">Node    4, zone   Normal, type    Unmovable   3817   3739   1716    992    261     39      4      1      0      0      1</div><div class="line">Node    4, zone   Normal, type      Movable  27857  39138   6875 &gt;100000 &gt;100000  70501  20752   4115    362     49    104</div><div class="line">Node    4, zone   Normal, type  Reclaimable      1      8      3      5      0      0     16     31     19     97      4</div><div class="line">Node    4, zone   Normal, type   HighAtomic      0      0      0      0      0      0      0      0      0      0      0</div><div class="line">Node    4, zone   Normal, type      Isolate      0      0      0      0      0      0      0      0      0      0      0</div><div class="line"></div><div class="line">Number of blocks type     Unmovable      Movable  Reclaimable   HighAtomic      Isolate</div><div class="line">Node 4, zone   Normal          712        31706          350            0            0</div><div class="line">Page block order: 9</div><div class="line">Pages per block:  512</div><div class="line"></div><div class="line">Free pages count per migrate type at order       0      1      2      3      4      5      6      7      8      9     10</div><div class="line">Node    5, zone   Normal, type    Unmovable   4875   4728   3165   1202    464     67      3      0      0      0      0</div><div class="line">Node    5, zone   Normal, type      Movable  18382  34874 &gt;100000 &gt;100000 &gt;100000  61296  22711   6235    348     32      0</div><div class="line">Node    5, zone   Normal, type  Reclaimable     16      0      1      7      2    525    284     91    109      0      0</div><div class="line">Node    5, zone   Normal, type   HighAtomic      0      0      0      0      0      0      0      0      0      0      0</div><div class="line">Node    5, zone   Normal, type      Isolate      0      0      0      0      0      0      0      0      0      0      0</div><div class="line"></div><div class="line">Number of blocks type     Unmovable      Movable  Reclaimable   HighAtomic      Isolate</div><div class="line">Node 5, zone   Normal          736        31716          316            0            0</div><div class="line">Page block order: 9</div><div class="line">Pages per block:  512</div><div class="line"></div><div class="line">Free pages count per migrate type at order       0      1      2      3      4      5      6      7      8      9     10</div><div class="line">Node    6, zone   Normal, type    Unmovable  10489   6842   2821    434    257     22      1      1      1      3      0</div><div class="line">Node    6, zone   Normal, type      Movable  90841 &gt;100000 &gt;100000  92129  11336   1526    704    552    141     34    118</div><div class="line">Node    6, zone   Normal, type  Reclaimable    434     41      0    576   1338    700    314    110     30      5      3</div><div class="line">Node    6, zone   Normal, type   HighAtomic      0      0      0      0      0      0      0      0      0      0      0</div><div class="line">Node    6, zone   Normal, type      Isolate      0      0      0      0      0      0      0      0      0      0      0</div><div class="line"></div><div class="line">Number of blocks type     Unmovable      Movable  Reclaimable   HighAtomic      Isolate</div><div class="line">Node 6, zone   Normal          807        31686          275            0            0</div><div class="line">Page block order: 9</div><div class="line">Pages per block:  512</div><div class="line"></div><div class="line">Free pages count per migrate type at order       0      1      2      3      4      5      6      7      8      9     10</div><div class="line">Node    7, zone   Normal, type    Unmovable   1516   1894   2285    908    633    121     16      7      4      2      0</div><div class="line">Node    7, zone   Normal, type      Movable  18209 &gt;100000 &gt;100000  93283  52811  50349  27973   9703   2026   1341    248</div><div class="line">Node    7, zone   Normal, type  Reclaimable      0      1      0   1341   1082    552    191     47      8      8     32</div><div class="line">Node    7, zone   Normal, type   HighAtomic      0      0      0      0      0      0      0      0      0      0      0</div><div class="line">Node    7, zone   Normal, type      Isolate      0      0      0      0      0      0      0      0      0      0      0</div><div class="line"></div><div class="line">Number of blocks type     Unmovable      Movable  Reclaimable   HighAtomic      Isolate</div><div class="line">Node 7, zone   Normal         1262        31265          241            0            0</div></pre></td></tr></table></figure>
<h3 id="proc-pagetypeinfo"><a href="#proc-pagetypeinfo" class="headerlink" title="/proc/pagetypeinfo"></a>/proc/pagetypeinfo</h3><p><code>cat /proc/pagetypeinfo</code>, 你可以看到当前系统里伙伴系统里各个尺寸的可用连续内存块数量。unmovable pages是不可以被迁移的，比如slab等kmem都不可以被迁移，因为内核里面对这些内存很多情况下是通过指针来访问的，而不是通过页表，如果迁移的话，就会导致原来的指针访问出错。</p>
<p><img src="/images/oss/2e73247c-8a10-43e6-bb0e-49ecfff14268.png" alt="img"></p>
<p><strong>当迁移类型为 Unmovable 的页面都聚集在 order &lt; 3 时，说明内核 slab 碎片化严重</strong></p>
<p>alloc_pages分配内存的时候就到上面对应大小的free_area的链表上寻找可用连续页面。<code>alloc_pages</code>是怎么工作的呢？我们举个简单的小例子。假如要申请8K-连续两个页框的内存。为了描述方便，我们先暂时忽略UNMOVEABLE、RELCLAIMABLE等不同类型</p>
<p><img src="/images/oss/16ebe996-0e3a-4d67-810f-3121b457271e.png" alt="img"></p>
<p>基于伙伴系统的内存分配中，有可能需要将大块内存拆分成两个小伙伴。在释放中，可能会将两个小伙伴合并再次组成更大块的连续内存。</p>
<blockquote>
<p>伙伴系统中的伙伴指的是两个内存块，大小相同，地址连续，同属于一个大块区域。</p>
</blockquote>
<p>对于应用来说基本分配单位是4K(开启大页后一般是2M)，对于内核来说4K有点浪费。所以内核又专门给自己定制了一个更精细的内存管理系统slab。</p>
<h3 id="slab"><a href="#slab" class="headerlink" title="slab"></a>slab</h3><p>对于内核运行中实际使用的对象来说，多大的对象都有。有的对象有1K多，但有的对象只有几百、甚至几十个字节。如果都直接分配一个 4K的页面 来存储的话也太浪费了，所以伙伴系统并不能直接使用。</p>
<p>在伙伴系统之上，<strong>内核又给自己搞了一个专用的内存分配器， 叫slab</strong>。</p>
<p>这个分配器最大的特点就是，一个slab内只分配特定大小、甚至是特定的对象。这样当一个对象释放内存后，另一个同类对象可以直接使用这块内存。通过这种办法极大地降低了碎片发生的几率。</p>
<h4 id="kmem-cache"><a href="#kmem-cache" class="headerlink" title="kmem cache"></a>kmem cache</h4><p>slabtop和/proc/slabinfo 查看cached使用情况 主要是：pagecache（页面缓存）， dentries（目录缓存）， inodes</p>
<p>通过查看 <code>/proc/slabinfo</code> 我们可以查看到所有的 kmem cache。</p>
<p><img src="/images/oss/5135d81f-6985-4d6a-8896-e451c0ba20f5.png" alt="img"></p>
<p>slabtop 按占用内存从大往小进行排列。用来分析 slab 内存开销。</p>
<p><img src="/images/oss/0d8a26db-3663-40af-b215-f8601ef23676.png" alt="0d8a26db-3663-40af-b215-f8601ef23676.png (1388×1506)"></p>
<p>无论是 <code>/proc/slabinfo</code>，还是 slabtop 命令的输出。里面都包含了每个 cache 中 slab的如下几个关键属性。</p>
<ul>
<li>objsize：每个对象的大小</li>
<li><p>objperslab：一个 slab 里存放的对象的数量</p>
</li>
<li><p>pagesperslab：一个slab 占用的页面的数量，每个页面4K，这样也就能算出每个 slab 占用的内存大小。</p>
</li>
</ul>
<p>比如如下TCP slabinfo中可以看到每个slab占用8(pagesperslab)个Page(8<em>4096=32768)，每个对象的大小是1984(objsize)，每个slab存放了16(objperslab)个对象. 那么1984 </em>16=31744，现在的空间基本用完，剩下接近1K，又放不下一个1984大小的对象，算是额外开销了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">#cat /proc/slabinfo |grep -E &quot;active_objs|TCP&quot;</div><div class="line"># name            &lt;active_objs&gt; &lt;num_objs&gt; &lt;objsize&gt; &lt;objperslab&gt; &lt;pagesperslab&gt; : tunables &lt;limit&gt; &lt;batchcount&gt; &lt;sharedfactor&gt; : slabdata &lt;active_slabs&gt; &lt;num_slabs&gt; &lt;sharedavail&gt;</div><div class="line">tw_sock_TCP         5372   5728    256   32    2 : tunables    0    0    0 : slabdata    179    179      0</div><div class="line">TCP                 6090   6144   1984   16    8 : tunables    0    0    0 : slabdata    384    384      0</div></pre></td></tr></table></figure>
<h2 id="内存分配和延迟"><a href="#内存分配和延迟" class="headerlink" title="内存分配和延迟"></a>内存分配和延迟</h2><p>内存不够、脏页太多、碎片太多，都会导致分配失败，从而触发回收，导致卡顿。</p>
<h3 id="系统中脏页过多引起-load-飙高"><a href="#系统中脏页过多引起-load-飙高" class="headerlink" title="系统中脏页过多引起 load 飙高"></a>系统中脏页过多引起 load 飙高</h3><p>直接回收过程中，如果存在较多脏页就可能涉及在回收过程中进行回写，这可能会造成非常大的延迟，而且因为这个过程本身是阻塞式的，所以又可能进一步导致系统中处于 D 状态的进程数增多，最终的表现就是系统的 load 值很高。</p>
<p><img src="/images/oss/f16438b744a248d7671d5ac7317b0a98.png" alt="image.png" style="zoom: 50%;"></p>
<p>可以通过 sar -r 来观察系统中的脏页个数：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">$ sar -r 1</div><div class="line">07:30:01 PM kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty</div><div class="line">09:20:01 PM   5681588   2137312     27.34         0   1807432    193016      2.47    534416   1310876         4</div><div class="line">09:30:01 PM   5677564   2141336     27.39         0   1807500    204084      2.61    539192   1310884        20</div><div class="line">09:40:01 PM   5679516   2139384     27.36         0   1807508    196696      2.52    536528   1310888        20</div><div class="line">09:50:01 PM   5679548   2139352     27.36         0   1807516    196624      2.51    536152   1310892        24</div></pre></td></tr></table></figure>
<p>kbdirty 就是系统中的脏页大小，它同样也是对 /proc/vmstat 中 nr_dirty 的解析。你可以通过调小如下设置来将系统脏页个数控制在一个合理范围:</p>
<blockquote>
<p>vm.dirty_background_bytes = 0</p>
<p>vm.dirty_background_ratio = 10</p>
<p>vm.dirty_bytes = 0</p>
<p>vm.dirty_expire_centisecs = 3000</p>
<p>vm.dirty_ratio = 20</p>
</blockquote>
<p>至于这些值调整大多少比较合适，也是因系统和业务的不同而异，我的建议也是一边调整一边观察，将这些值调整到业务可以容忍的程度就可以了，即在调整后需要观察业务的服务质量 (SLA)，要确保 SLA 在可接受范围内。调整的效果你可以通过 /proc/vmstat 来查看：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">#grep &quot;nr_dirty_&quot; /proc/vmstat</div><div class="line">nr_dirty_threshold 3071708</div><div class="line">nr_dirty_background_threshold 1023902</div></pre></td></tr></table></figure>
<p>在4.20的内核并且sar 的版本为12.3.3可以看到PSI（Pressure-Stall Information）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">some avg10=45.49 avg60=10.23 avg300=5.41 total=76464318</div><div class="line">full avg10=40.87 avg60=9.05 avg300=4.29 total=58141082</div></pre></td></tr></table></figure>
<p>你需要重点关注 avg10 这一列，它表示最近 10s 内存的平均压力情况，如果它很大（比如大于 40）那 load 飙高大概率是由于内存压力，尤其是 Page Cache 的压力引起的。</p>
<p><img src="/images/oss/cf58f10a523e1e4f0db443be3f54fc04.png" alt="image.png"></p>
<h3 id="容器中的内存回收"><a href="#容器中的内存回收" class="headerlink" title="容器中的内存回收"></a>容器中的内存回收</h3><blockquote>
<p>kswapd线程(每个node一个kswapd进程，负责本node）回收内存时，可以先对脏页进行回写（writeback）再进行回收，而直接内存回收只回收干净页。也叫同步回收.</p>
<p>直接内存回收是在当前进程的上下文中进行的，要等内存回收完成才能继续尝试进行分配，所以是阻塞了当前进程的执行，会导致响应延迟增加</p>
</blockquote>
<p>如果是在容器里，也就是在某个子memory cgroup 中，那么在分配内存后，还有一个记账（charge）的步骤，就是要把这次分配的内存页记在某个memory cgroup的账上，这样才能控制这个容器里的进程所能使用的内存数量。</p>
<p>在开源社区的linux代码中，如果charge 失败，也就是说，当新分配的内存加上原先的usage超过了limit，就会触发内存回收，try_to_free_mem_cgroup_pages，这个也是同步回收，等同于直接内存回收（发生在当前进程的上下文忠），所以会对应用的响应造成影响（表现为卡顿）。</p>
<h2 id="碎片化"><a href="#碎片化" class="headerlink" title="碎片化"></a>碎片化</h2><p>内存碎片严重的话会导致系统hang很久(回收、压缩内存）</p>
<p>尽量让系统的free多一点(比例高一点）可以调整 vm.min_free_kbytes(128G 以内 2G，256G以内 4G/8G), 线上机器直接修改vm.min_free_kbytes<strong>会触发回收，导致系统hang住</strong> <a href="https://www.atatech.org/articles/163233" target="_blank" rel="external">https://www.atatech.org/articles/163233</a> <a href="https://www.atatech.org/articles/97130" target="_blank" rel="external">https://www.atatech.org/articles/97130</a></p>
<p>每个zone都有自己的min low high,如下，但是单位是page, 计算案例：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div></pre></td><td class="code"><pre><div class="line">#cat /proc/zoneinfo  |grep &quot;Node&quot;</div><div class="line">Node 0, zone      DMA</div><div class="line">Node 0, zone    DMA32</div><div class="line">Node 0, zone   Normal</div><div class="line">Node 1, zone   Normal</div><div class="line"></div><div class="line">#cat /proc/zoneinfo  |grep &quot;Node 0, zone&quot; -A10</div><div class="line">Node 0, zone      DMA</div><div class="line">  pages free     3975</div><div class="line">        min      20</div><div class="line">        low      25</div><div class="line">        high     30</div><div class="line">        scanned  0</div><div class="line">        spanned  4095</div><div class="line">        present  3996</div><div class="line">        managed  3975</div><div class="line">    nr_free_pages 3975</div><div class="line">    nr_alloc_batch 5</div><div class="line">--</div><div class="line">Node 0, zone    DMA32</div><div class="line">  pages free     382873</div><div class="line">        min      2335</div><div class="line">        low      2918</div><div class="line">        high     3502</div><div class="line">        scanned  0</div><div class="line">        spanned  1044480</div><div class="line">        present  513024</div><div class="line">        managed  450639</div><div class="line">    nr_free_pages 382873</div><div class="line">    nr_alloc_batch 584</div><div class="line">--</div><div class="line">Node 0, zone   Normal</div><div class="line">  pages free     11105097</div><div class="line">        min      61463</div><div class="line">        low      76828</div><div class="line">        high     92194</div><div class="line">        scanned  0</div><div class="line">        spanned  12058624</div><div class="line">        present  12058624</div><div class="line">        managed  11859912</div><div class="line">    nr_free_pages 11105097</div><div class="line">    nr_alloc_batch 12344</div><div class="line">    </div><div class="line">    low = 5/4 * min</div><div class="line">high = 3/2 * min</div><div class="line"></div><div class="line"></div><div class="line">#T=min;sum=0;for i in `cat /proc/zoneinfo  |grep $T | awk &apos;&#123;print $NF&#125;&apos;`;do sum=`echo &quot;$sum+$i&quot; |bc`;done;sum=`echo &quot;$sum*4/1024&quot; |bc`;echo &quot;sum=$&#123;sum&#125; MB&quot;</div><div class="line">sum=499 MB</div><div class="line"></div><div class="line">#T=low;sum=0;for i in `cat /proc/zoneinfo  |grep $T | awk &apos;&#123;print $NF&#125;&apos;`;do sum=`echo &quot;$sum+$i&quot; |bc`;done;sum=`echo &quot;$sum*4/1024&quot; |bc`;echo &quot;sum=$&#123;sum&#125; MB&quot;</div><div class="line">sum=624 MB</div><div class="line"></div><div class="line">#T=high;sum=0;for i in `cat /proc/zoneinfo  |grep $T | awk &apos;&#123;print $NF&#125;&apos;`;do sum=`echo &quot;$sum+$i&quot; |bc`;done;sum=`echo &quot;$sum*4/1024&quot; |bc`;echo &quot;sum=$&#123;sum&#125; MB&quot;</div><div class="line">sum=802 MB</div></pre></td></tr></table></figure>
<h2 id="内存碎片化导致rt升高的诊断"><a href="#内存碎片化导致rt升高的诊断" class="headerlink" title="内存碎片化导致rt升高的诊断"></a>内存碎片化导致rt升高的诊断</h2><p>判定方法如下：</p>
<ol>
<li>运行 sar -B 观察 pgscand/s，其含义为每秒发生的直接内存回收次数，当在一段时间内持续大于 0 时，则应继续执行后续步骤进行排查；</li>
<li>运行 <code>cat /sys/kernel/debug/extfrag/extfrag_index</code> 观察内存碎片指数，重点关注 order &gt;= 3 的碎片指数，当接近 1.000 时，表示碎片化严重，当接近 0 时表示内存不足；</li>
<li>运行 <code>cat /proc/buddyinfo, cat /proc/pagetypeinfo</code> 查看内存碎片情况， 指标含义<a href="https://man7.org/linux/man-pages/man5/proc.5.html" target="_blank" rel="external">参考</a> ，同样关注 order &gt;= 3 的剩余页面数量，pagetypeinfo 相比 buddyinfo 展示的信息更详细一些，根据迁移类型 （伙伴系统通过迁移类型实现反碎片化）进行分组，需要注意的是，<strong>当迁移类型为 Unmovable 的页面都聚集在 order &lt; 3 时，说明内核 slab 碎片化严重</strong>，我们需要结合其他工具来排查具体原因，在本文就不做过多介绍了；</li>
<li>对于 CentOS 7.6 等支持 BPF 的 kernel 也可以运行我们研发的 <a href="https://github.com/iovisor/bcc/blob/master/tools/drsnoop_example.txt" target="_blank" rel="external">drsnoop</a>，<a href="https://github.com/iovisor/bcc/blob/master/tools/compactsnoop_example.txt" target="_blank" rel="external">compactsnoop</a> 工具对延迟进行定量分析，使用方法和解读方式请参考对应文档；</li>
<li>(Opt) 使用 ftrace 抓取 mm_page_alloc_extfrag 事件，观察因内存碎片从备用迁移类型“盗取”页面的信息。</li>
</ol>
<h2 id="一个阿里云ECS-因为宿主机碎片导致性能衰退的案例"><a href="#一个阿里云ECS-因为宿主机碎片导致性能衰退的案例" class="headerlink" title="一个阿里云ECS 因为宿主机碎片导致性能衰退的案例"></a>一个阿里云ECS 因为宿主机碎片导致性能衰退的案例</h2><p>LVS后面三个RS在同样压力流量下，其中一个节点CPU非常高，通过top看起来是所有操作都很慢，像是CPU被降频了一样，但是直接跑CPU Prime性能又没有问题</p>
<p><img src="/images/oss/8bbb5c886dc06196546daec46712ff71.png" alt="image.png"></p>
<p>原因：ECS所在的宿主机内存碎片比较严重，导致分配到的内存主要是4K Page，在ECS中大页场景下会慢很多</p>
<p>通过 <strong>openssl speed aes-256-ige 能稳定重现</strong> 在大块的加密上慢很多</p>
<p><img src="/images/oss/8e15e91d4dcc61bbd329e7283c7c7500.png" alt="image.png"></p>
<p>小块上性能一致，这也就是为什么算Prime性能没问题。导致慢只涉及到大块内存分配的场景，这里需要映射到宿主机，但是碎片多分配慢导致了问题。</p>
<p>如果reboot ECS的话实际只是就地重启ECS，仍然使用的reboot前分配好的宿主机内存，不会解决问题。重启ECS中的进程也不会解决问题，只有将ECS迁移到别的物理机（也就是通过控制台重启，会重新选择物理机）才有可能解决这个问题。</p>
<p>或者购买新的ECS机型（比如第6代之后ECS）能避免这个问题。</p>
<p>ECS内部没法查看到这个碎片，只能在宿主机上通过命令查看大页情况：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">有问题NC上buddyinfo信息</div><div class="line">$cat /proc/buddyinfo</div><div class="line">Node 0, zone      DMA      1      1      0      0      2      1      1      0      1      1      3</div><div class="line">Node 0, zone    DMA32     23     23     17     15     13      9      8      8      4      3    367</div><div class="line">Node 0, zone   Normal 295291 298652 286048 266597 218191 156837  93156  45930  25856      0      0</div><div class="line"></div><div class="line">最新建的vm，大页不多</div><div class="line">$sudo cat /proc/9550/smaps |grep AnonHuge |awk &apos;&#123;sum+=$2&#125;END&#123;print sum&#125;&apos;</div><div class="line">210944</div><div class="line">------------------------</div><div class="line">第一台正常ECS所在的NC</div><div class="line">$cat /proc/buddyinfo</div><div class="line">Node 0, zone      DMA      1      1      0      0      2      1      1      0      1      1      3</div><div class="line">Node 0, zone    DMA32      7      5      5      9      8      4      6     10      5      5    366</div><div class="line">Node 0, zone   Normal 203242 217888 184465 176280 148612 102122  55787  26642  24824      0      0</div><div class="line"></div><div class="line">早期的vm，大页充足</div><div class="line">$sudo cat /proc/87369/smaps |grep AnonHuge |awk &apos;&#123;sum+=$2&#125;END&#123;print sum&#125;&apos;</div><div class="line">8275968</div><div class="line"></div><div class="line">近期的vm，大页不够</div><div class="line">$sudo cat /proc/22081/smaps |grep AnonHuge |awk &apos;&#123;sum+=$2&#125;END&#123;print sum&#125;&apos;</div><div class="line">251904</div><div class="line"></div><div class="line">$sudo cat /proc/44073/smaps |grep AnonHuge |awk &apos;&#123;sum+=$2&#125;END&#123;print sum&#125;&apos;</div><div class="line">10240</div></pre></td></tr></table></figure>
<h2 id="内存使用分析"><a href="#内存使用分析" class="headerlink" title="内存使用分析"></a>内存使用分析</h2><h3 id="pmap"><a href="#pmap" class="headerlink" title="pmap"></a>pmap</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">pmap -x 24282 | less</div><div class="line">24282:   /usr/sbin/rsyslogd -n</div><div class="line">Address           Kbytes     RSS   Dirty Mode  Mapping</div><div class="line">000055ce1a99f000     596     580       0 r-x-- rsyslogd</div><div class="line">000055ce1ac34000      12      12      12 r---- rsyslogd</div><div class="line">000055ce1ac37000      28      28      28 rw--- rsyslogd</div><div class="line">000055ce1ac3e000       4       4       4 rw---   [ anon ]</div><div class="line">000055ce1c1f1000     364     204     204 rw---   [ anon ]</div><div class="line">00007fff8b5a4000     132      20      20 rw---   [ stack ]</div><div class="line">00007fff8b5e6000      12       0       0 r----   [ anon ]</div><div class="line">00007fff8b5e9000       8       4       0 r-x--   [ anon ]</div><div class="line">---------------- ------- ------- -------</div><div class="line">total kB          620060   17252    3304</div></pre></td></tr></table></figure>
<ul>
<li>Address：占用内存的文件的内存起始地址。</li>
<li>Kbytes：占用内存的字节数。</li>
<li>RSS：实际占用内存大小。</li>
<li>Dirty：脏页大小。</li>
<li>Mapping：占用内存的文件，[anon] 为已分配的内存，[stack] 为程序堆栈</li>
</ul>
<h3 id="proc-pid"><a href="#proc-pid" class="headerlink" title="/proc/pid/"></a>/proc/pid/</h3><p><code>/proc/[pid]/</code> 下面与进程内存相关的文件主要有<code>maps , smaps, status</code>。<br>maps： 文件可以查看某个进程的代码段、栈区、堆区、动态库、内核区对应的虚拟地址<br>smaps: 显示每个分区更详细的内存占用数据，能看到一个动态库被共享了几次<br>status: 包含了所有CPU活跃的信息，该文件中的所有值都是从系统启动开始累计到当前时刻</p>
<h2 id="Java内存使用分析"><a href="#Java内存使用分析" class="headerlink" title="Java内存使用分析"></a><a href="https://docs.oracle.com/javase/8/docs/technotes/guides/troubleshoot/tooldescr007.html" target="_blank" rel="external">Java内存使用分析</a></h2><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div></pre></td><td class="code"><pre><div class="line">创建1000个线程，ss为2M</div><div class="line">java -XX:NativeMemoryTracking=detail -Xms10g -Xmx10g -Xmn5g -XX:ReservedCodeCacheSize=512m -XX:MetaspaceSize=512m -XX:MaxMetaspaceSize=512m -XX:MaxDirectMemorySize=1g -Xss2048K ThreadPoolExample</div><div class="line"></div><div class="line">分析结果：</div><div class="line">#jcmd 81849 VM.native_memory summary</div><div class="line">81849:</div><div class="line"></div><div class="line">Native Memory Tracking:</div><div class="line"></div><div class="line">Total: reserved=14737064KB, committed=13157168KB</div><div class="line">-                 Java Heap (reserved=10485760KB, committed=10485760KB)</div><div class="line">                            (mmap: reserved=10485760KB, committed=10485760KB)</div><div class="line"></div><div class="line">-                     Class (reserved=1102016KB, committed=50112KB)</div><div class="line">                            (classes #416)</div><div class="line">                            (malloc=45248KB #1420)</div><div class="line">                            (mmap: reserved=1056768KB, committed=4864KB)</div><div class="line"></div><div class="line">//committed 已向OS提请分配，实际要到使用时page fault才会实际分配物理内存并在RSS中反应出来</div><div class="line">-                    Thread (reserved=2134883KB, committed=2134883KB)//reserved还没分配,不能访问</div><div class="line">                            (thread #1070) //1000个应用线程，加70个JVM native线程</div><div class="line">                            (stack: reserved=2128820KB, committed=2128820KB) //需要2G多点</div><div class="line">                            (malloc=3500KB #5390)</div><div class="line">                            (arena=2563KB #2138)</div><div class="line"></div><div class="line">-                      Code (reserved=532612KB, committed=4620KB)</div><div class="line">                            (malloc=132KB #528)</div><div class="line">                            (mmap: reserved=532480KB, committed=4488KB)</div><div class="line"></div><div class="line">-                        GC (reserved=430421KB, committed=430421KB)</div><div class="line">                            (malloc=50737KB #235)</div><div class="line">                            (mmap: reserved=379684KB, committed=379684KB)</div><div class="line"></div><div class="line">-                  Compiler (reserved=137KB, committed=137KB)</div><div class="line">                            (malloc=6KB #53)</div><div class="line">                            (arena=131KB #3)</div><div class="line"></div><div class="line">-                  Internal (reserved=48901KB, committed=48901KB)</div><div class="line">                            (malloc=48869KB #14030)</div><div class="line">                            (mmap: reserved=32KB, committed=32KB)</div><div class="line"></div><div class="line">-                    Symbol (reserved=1479KB, committed=1479KB)</div><div class="line">                            (malloc=959KB #110)</div><div class="line">                            (arena=520KB #1)</div><div class="line"></div><div class="line">-    Native Memory Tracking (reserved=608KB, committed=608KB)</div><div class="line">                            (malloc=193KB #2556)</div><div class="line">                            (tracking overhead=415KB)</div><div class="line"></div><div class="line">-               Arena Chunk (reserved=248KB, committed=248KB)</div><div class="line">                            (malloc=248KB)</div></pre></td></tr></table></figure>
<p>We can see two types of memory:</p>
<ul>
<li><strong>Reserved</strong> — the size which is guaranteed to be available by a host’s OS (but still not allocated and cannot be accessed by JVM) — it’s just a promise</li>
<li><strong>Committed</strong> — already taken, accessible, and allocated by JVM</li>
</ul>
<h3 id="page-fault"><a href="#page-fault" class="headerlink" title="page fault"></a>page fault</h3><p>内核给用户态申请的内存，默认都只是一段虚拟地址空间而已，并没有分配真正的物理内存。在第一次读写的时候才触发物理内存的分配，这个过程叫做page fault。那么，为了访问到真正的物理内存，page fault的时候，就需要更新对应的page table了。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://www.atatech.org/articles/66885" target="_blank" rel="external">https://www.atatech.org/articles/66885</a></p>
<p><a href="https://cloud.tencent.com/developer/article/1087455" target="_blank" rel="external">https://cloud.tencent.com/developer/article/1087455</a></p>
<p><a href="https://www.cnblogs.com/xiaolincoding/p/13719610.html" target="_blank" rel="external">https://www.cnblogs.com/xiaolincoding/p/13719610.html</a></p>
<p><a href="https://blog.csdn.net/fanren224/article/details/103991748" target="_blank" rel="external">rsyslog占用内存高</a></p>
<p><a href="https://sunsea.im/rsyslogd-systemd-journald-high-memory-solution.html" target="_blank" rel="external">https://sunsea.im/rsyslogd-systemd-journald-high-memory-solution.html</a></p>
<p><a href="https://wizardforcel.gitbooks.io/vbird-linux-basic-4e/content/160.html" target="_blank" rel="external">鸟哥 journald 介绍</a></p>
<p><a href="https://mp.weixin.qq.com/s/OR2XB4J76haGc1THeq7WQg" target="_blank" rel="external">说出来你可能不信，内核这家伙在内存的使用上给自己开了个小灶！</a></p>
<p><a href="https://zhengheng.me/2018/08/27/socket-use-slab-dentry/" target="_blank" rel="external">socket 与 slab dentry</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="weibo @plantegg" />
          <p class="site-author-name" itemprop="name">weibo @plantegg</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
           
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">137</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">21</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">233</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
</script>

<div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">weibo @plantegg</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>

<span id="busuanzi_container_site_pv">
    本站总访问量<span id="busuanzi_value_site_pv_footer"></span>次
</span>
<span id="busuanzi_container_site_uv">
  本站访客数<span id="busuanzi_value_site_uv_footer"></span>人次
</span>


        
<div class="busuanzi-count">
  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      人
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>


        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
    <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  





  






  





  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  

  

  

  

</body>
</html>
