<!doctype html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />





  <link rel="alternate" href="/atom.xml" title="plantegg" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="java mysql tcp performance network docker Linux">
<meta property="og:type" content="website">
<meta property="og:title" content="plantegg">
<meta property="og:url" content="https://plantegg.github.io/page/4/index.html">
<meta property="og:site_name" content="plantegg">
<meta property="og:description" content="java mysql tcp performance network docker Linux">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="plantegg">
<meta name="twitter:description" content="java mysql tcp performance network docker Linux">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://plantegg.github.io/page/4/"/>





  <title>plantegg - java tcp mysql performance network docker Linux</title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  















  
  
    
  

  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta custom-logo">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">plantegg</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description">java tcp mysql performance network docker Linux</h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-categories"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-sitemap">
          <a href="/sitemap.xml" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-sitemap"></i> <br />
            
            站点地图
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/02/14/TCP疑难问题案例汇总/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/02/14/TCP疑难问题案例汇总/" itemprop="url">TCP疑难问题案例汇总</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-02-14T13:30:03+08:00">
                2021-02-14
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/TCP/" itemprop="url" rel="index">
                    <span itemprop="name">TCP</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="TCP疑难问题案例汇总"><a href="#TCP疑难问题案例汇总" class="headerlink" title="TCP疑难问题案例汇总"></a>TCP疑难问题案例汇总</h1><p>碰到各种奇葩的TCP相关问题，所以汇总记录一下。分析清楚这些问题的所有来龙去脉，就能帮你在TCP知识体系里建立几个坚固的抓手，让TCP知识慢慢在抓手之间生长和互通</p>
<h2 id="服务不响应的现象或者奇怪异常的原因分析"><a href="#服务不响应的现象或者奇怪异常的原因分析" class="headerlink" title="服务不响应的现象或者奇怪异常的原因分析"></a>服务不响应的现象或者奇怪异常的原因分析</h2><p> <a href="/2021/02/10/%E4%B8%80%E4%B8%AA%E9%BB%91%E7%9B%92%E7%A8%8B%E5%BA%8F%E5%A5%87%E6%80%AA%E7%9A%84%E8%A1%8C%E4%B8%BA%E5%88%86%E6%9E%90/">一个黑盒程序奇怪行为的分析</a> listen端口上很快就全连接队列溢出了，导致整个程序不响应了</p>
<p><a href="/2020/11/02/%E4%B8%BE%E4%B8%89%E5%8F%8D%E4%B8%80--%E4%BB%8E%E7%90%86%E8%AE%BA%E7%9F%A5%E8%AF%86%E5%88%B0%E5%AE%9E%E9%99%85%E9%97%AE%E9%A2%98%E7%9A%84%E6%8E%A8%E5%AF%BC/">举三反一–从理论知识到实际问题的推导</a> 服务端出现大量CLOSE_WAIT 个数正好 等于somaxconn（调整somaxconn大小后 CLOSE_WAIT 也会跟着变成一样的值）</p>
<p><a href="/2020/11/18/TCP%E8%BF%9E%E6%8E%A5%E4%B8%BA%E5%95%A5%E4%BA%92%E4%B8%B2%E4%BA%86/">活久见，TCP连接互串了</a>  应用每过一段时间总是会抛出几个连接异常的错误，需要查明原因。排查后发现是TCP连接互串了，这个案例实在是很珍惜，所以记录一下。</p>
<p> <a href="/2020/07/01/如何创建一个自己连自己的TCP连接/">如何创建一个自己连自己的TCP连接</a></p>
<h2 id="传输速度分析"><a href="#传输速度分析" class="headerlink" title="传输速度分析"></a>传输速度分析</h2><p>案例：<a href="/2021/01/15/TCP%E4%BC%A0%E8%BE%93%E9%80%9F%E5%BA%A6%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90/">TCP传输速度案例分析</a>（长肥网络、rt升高、delay ack的影响等）</p>
<p>原理：<a href="/2019/09/28/就是要你懂TCP--性能和发送接收Buffer的关系/">就是要你懂TCP–性能和发送接收Buffer的关系：发送窗口大小(Buffer)、接收窗口大小(Buffer)对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响。BDP、RT、带宽对传输速度又是怎么影响的</a></p>
<p><a href="/2018/06/14/就是要你懂TCP--最经典的TCP性能问题/">就是要你懂TCP–最经典的TCP性能问题 Nagle和Delay ack</a></p>
<p><a href="/2019/06/21/就是要你懂TCP--性能优化大全/">就是要你懂TCP–性能优化大全</a></p>
<h2 id="TCP队列问题以及连接数"><a href="#TCP队列问题以及连接数" class="headerlink" title="TCP队列问题以及连接数"></a>TCP队列问题以及连接数</h2><p> <a href="/2020/11/30/一台机器上最多能创建多少个TCP连接/">到底一台服务器上最多能创建多少个TCP连接</a></p>
<p> <a href="/2019/08/31/就是要你懂TCP队列--通过实战案例来展示问题/">就是要你懂TCP队列–通过实战案例来展示问题</a></p>
<p> <a href="/2017/06/07/就是要你懂TCP--半连接队列和全连接队列/">就是要你懂TCP–半连接队列和全连接队列</a></p>
<p> <a href="/2017/06/02/就是要你懂TCP--连接和握手/">就是要你懂TCP–握手和挥手</a></p>
<h2 id="防火墙和reset定位分析"><a href="#防火墙和reset定位分析" class="headerlink" title="防火墙和reset定位分析"></a>防火墙和reset定位分析</h2><p>对ttl、identification等的运用</p>
<p><a href="/2018/08/26/关于TCP连接的KeepAlive和reset/">关于TCP连接的Keepalive和reset</a></p>
<p><a href="/2019/11/06/谁动了我的TCP连接/">就是要你懂网络–谁动了我的TCP连接</a></p>
<h2 id="TCP相关参数"><a href="#TCP相关参数" class="headerlink" title="TCP相关参数"></a>TCP相关参数</h2><p> <a href="/2020/01/26/TCP相关参数解释/">TCP相关参数解释</a></p>
<p><a href="/2019/05/16/网络通不通是个大问题--半夜鸡叫/">网络通不通是个大问题–半夜鸡叫</a> </p>
<p><a href="/2018/12/26/网络丢包/">网络丢包</a></p>
<h2 id="工具技巧篇"><a href="#工具技巧篇" class="headerlink" title="工具技巧篇"></a>工具技巧篇</h2><p> <a href="/2019/04/21/netstat定位性能案例/">netstat定位性能案例</a></p>
<p> <a href="/2017/08/28/netstat --timer/">netstat timer keepalive explain</a></p>
<p><a href="/2016/10/12/ss用法大全/">就是要你懂网络监控–ss用法大全</a></p>
<p><a href="/2019/06/21/就是要你懂抓包--WireShark之命令行版tshark/">就是要你懂抓包–WireShark之命令行版tshark</a></p>
<p><a href="/2018/01/01/通过tcpdump对Unix Socket 进行抓包解析/">通过tcpdump对Unix Domain Socket 进行抓包解析</a></p>
<p><a href="/2017/12/07/如何追踪网络流量/">如何追踪网络流量</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/02/10/一个黑盒程序奇怪的行为分析/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/02/10/一个黑盒程序奇怪的行为分析/" itemprop="url">一个黑盒程序奇怪行为的分析</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-02-10T10:30:03+08:00">
                2021-02-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/TCP/" itemprop="url" rel="index">
                    <span itemprop="name">TCP</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="一个黑盒程序奇怪行为的分析"><a href="#一个黑盒程序奇怪行为的分析" class="headerlink" title="一个黑盒程序奇怪行为的分析"></a>一个黑盒程序奇怪行为的分析</h1><h2 id="问题描述："><a href="#问题描述：" class="headerlink" title="问题描述："></a>问题描述：</h2><blockquote>
<p>从银行金主baba手里拿到一个区块链程序，监听4000，在我们的环境中4000端口上很快就全连接队列溢出了，导致整个程序不响应了。这个程序是黑盒子，没有源代码，但是在金主baba自己的环境运行正常（一样的OS）</p>
</blockquote>
<p>如下图所示：</p>
<p><img src="/images/oss/623ca2f46084958efa447882cbb58e72.png" alt="image.png"></p>
<p>ss -lnt 看到全连接队列增长到了39，但是netstat -ant找不到这39个连接，本来是想看看队列堆了这么多连接，都是哪些ip连过来的，实际看不到这就奇怪了</p>
<p>同时验证过程发现我们的环境4000端口上开了slb，也就是slb会不停滴探活4000端口，关掉slb探活后一切正常了。</p>
<p>所以总结下来问题就是：</p>
<ol>
<li><p>为什么全连接队列里面的连接netstat看不到这些连接，但是ss能看到总数 </p>
</li>
<li><p>为什么关掉slb就正常了 </p>
</li>
<li><p>为什么应用不accept连接,也不close（应用是个黑盒子） </p>
</li>
</ol>
<h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><h3 id="为什么全连接队列里面的连接netstat-ss都看不到-ss能看到总数"><a href="#为什么全连接队列里面的连接netstat-ss都看不到-ss能看到总数" class="headerlink" title="为什么全连接队列里面的连接netstat/ss都看不到(ss能看到总数)"></a>为什么全连接队列里面的连接netstat/ss都看不到(ss能看到总数)</h3><p>这是因为这些连接都是探活连接，三次握手后很快被slb reset了，在OS层面这个连接已经被释放，所以肯定看不见。反过来想要是netstat能看见这个连接，那么它的状态是什么？ reset吗？tcp连接状态里肯定是没有reset状态的。</p>
<p>ss看到的总数是指只要这个连接没有被accept，那么连接队列里就还有这个连接，通过ss也能看到连接队列数量。</p>
<h4 id="为什么会产生这个错误理解–全连接队列里面的连接netstat一定要能看到？"><a href="#为什么会产生这个错误理解–全连接队列里面的连接netstat一定要能看到？" class="headerlink" title="为什么会产生这个错误理解–全连接队列里面的连接netstat一定要能看到？"></a>为什么会产生这个错误理解–全连接队列里面的连接netstat一定要能看到？</h4><p>那是因为正常情况都是能看到的，从没有考虑过握手后很快reset的情况。也没反问过如果能看到这个连接该是什么状态呢？</p>
<h4 id="这个连接被reset后，kernel会将全连接队列数量减1吗？"><a href="#这个连接被reset后，kernel会将全连接队列数量减1吗？" class="headerlink" title="这个连接被reset后，kernel会将全连接队列数量减1吗？"></a>这个连接被reset后，kernel会将全连接队列数量减1吗？</h4><p>不会，按照我们的理解连接被reset释放后，那么kernel要释放全连接队列里面的这个连接，因为这些动作都是kernel负责，上层没法处理这个reset。实际上内核认为所有 listen 到的连接, 必须要 accept 走, 用户有权利知道存在过这么一个连接。</p>
<p>也就是reset后，连接在内核层面释放了，所以netstat/ss看不到，但是全连接队列里面的应用数不会减1，只有应用accept后队列才会减1，accept这个空连接后读写会报错。基本可以认为全连接队列溢出了，主要是应用accept太慢导致的。</p>
<p>当应用从accept队列读取到已经被reset了的连接的时候应用层会得到一个报错信息。</p>
<h4 id="什么时候连接状态变成-ESTABLISHED"><a href="#什么时候连接状态变成-ESTABLISHED" class="headerlink" title="什么时候连接状态变成 ESTABLISHED"></a>什么时候连接状态变成 ESTABLISHED</h4><p>三次握手成功就变成 ESTABLISHED 了，三次握手成功的第一是收到第三步的ack并且全连接队列没有满，不需要用户态来accept，如果握手第三步的时候OS发现全连接队列满了，这时OS会扔掉这个第三次握手ack，并重传握手第二步的syn+ack, 在OS端这个连接还是 SYN_RECV 状态的，但是client端是 ESTABLISHED状态的了。</p>
<p>下面是在4000（tearbase）端口上<strong>全连接队列没满，但是应用不再accept了</strong>，nc用12346端口去连4000（tearbase）端口的结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"># netstat -at |grep &quot;:12346 &quot;</div><div class="line">tcp   0      0 dcep-blockchain-1:12346 dcep-blockchai:terabase ESTABLISHED //server</div><div class="line">tcp   0      0 dcep-blockchai:terabase dcep-blockchain-1:12346 ESTABLISHED //client</div><div class="line">[root@dcep-blockchain-1 cfl-sm2-sm3]# ss -lt</div><div class="line">State       Recv-Q Send-Q      Local Address:Port         Peer Address:Port   </div><div class="line">LISTEN      73     1024            *:terabase                 *:*</div></pre></td></tr></table></figure>
<p>这是在4000（tearbase）端口上<strong>全连接队列满掉</strong>后，nc用12346端口去连4000（tearbase）端口的结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"># netstat -at |grep &quot;:12346 &quot;  </div><div class="line">tcp   0      0 dcep-blockchai:terabase dcep-blockchain-1:12346 SYN_RECV    //server</div><div class="line">tcp   0      0 dcep-blockchain-1:12346 dcep-blockchai:terabase ESTABLISHED //client</div><div class="line"># ss -lt</div><div class="line">State       Recv-Q Send-Q      Local Address:Port       Peer Address:Port   </div><div class="line">LISTEN      1025   1024             *:terabase              *:*</div></pre></td></tr></table></figure>
<h3 id="为什么关掉slb就正常了"><a href="#为什么关掉slb就正常了" class="headerlink" title="为什么关掉slb就正常了"></a>为什么关掉slb就正常了</h3><p>slb探活逻辑是向监听端口发起三次握手，握手成功后立即发送一个reset断开连接</p>
<p>这是一个完整的探活过程：</p>
<p><img src="/images/oss/b81dcbaea26a5130383d0bc8317fd3c5.png" alt="image.png"></p>
<p>关掉就正常后要结合第三个问题来讲</p>
<h3 id="为什么应用不accept连接-也不close（应用是个黑盒子）"><a href="#为什么应用不accept连接-也不close（应用是个黑盒子）" class="headerlink" title="为什么应用不accept连接,也不close（应用是个黑盒子）"></a>为什么应用不accept连接,也不close（应用是个黑盒子）</h3><p>因为应用是个黑盒子，看不到源代码，只能从行为来分析了</p>
<p>从行为来看，这个应用在三次握手后，会主动给client发送一个12字节的数据，但是这个逻辑写在了accept主逻辑内部，一旦主动给client发12字节数据失败（比如这个连接reset了）那么一直卡在这里导致应用不再accept也不再close。</p>
<p>正确的实现逻辑是，accept在一个单独的线程里，一旦accept到一个新连接，那么就开启一个新的线程来处理这个新连接的读写。accept线程专注accept。</p>
<p>关掉slb后应用有机会发出这12个字节，然后accept就能继续了，否则就卡死了。</p>
<h2 id="一些验证"><a href="#一些验证" class="headerlink" title="一些验证"></a>一些验证</h2><h3 id="nc测试连接4000端口"><a href="#nc测试连接4000端口" class="headerlink" title="nc测试连接4000端口"></a>nc测试连接4000端口</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"># nc -p 12346 dcep-blockchain-1 4000</div><div class="line"> //握手后4000返回的内容</div><div class="line"></div><div class="line">抓包：</div><div class="line">11:03:16.762547 IP dcep-blockchain-1.12346 &gt; dcep-blockchain-1.terabase: Flags [S], seq 397659761, win 43690, options [mss 65495,sackOK,TS val 2329725964 ecr 0,nop,wscale 7], length 0</div><div class="line">04:42:24.466211 IP dcep-blockchain-1.terabase &gt; dcep-blockchain-1.12346: Flags [S.], seq 4239354556, ack 397659762, win 43690, options [mss 65495,sackOK,TS val 2329725964 ecr 2329725964,nop,wscale 7], length 0</div><div class="line">11:03:16.762571 IP dcep-blockchain-1.12346 &gt; dcep-blockchain-1.terabase: Flags [.], ack 1, win 342, options [nop,nop,TS val 2329725964 ecr 2329725964], length 0</div><div class="line"></div><div class="line">----到这三次握手完毕，下面是隔了大概1.5ms，4000发了12字节给nc</div><div class="line">11:03:16.763893 IP dcep-blockchain-1.terabase &gt; dcep-blockchain-1.12346: Flags [P.], seq 1:13, ack 1, win 342, options [nop,nop,TS val 2329725966 ecr 2329725964], length 12</div><div class="line">11:03:16.763904 IP dcep-blockchain-1.12346 &gt; dcep-blockchain-1.terabase: Flags [.], ack 13, win 342, options [nop,nop,TS val 2329725966 ecr 2329725966], length 0</div></pre></td></tr></table></figure>
<p>如果在上面的1.5ms之间nc  reset了这个连接，那么这12字节就发不出来了</p>
<h3 id="握手后Server主动发数据的行为非常像MySQL-Server"><a href="#握手后Server主动发数据的行为非常像MySQL-Server" class="headerlink" title="握手后Server主动发数据的行为非常像MySQL Server"></a>握手后Server主动发数据的行为非常像MySQL Server</h3><p>MySQL Server在收到mysql client连接后会主动发送 Server Greeting、版本号、认证方式等给client</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">#nc -p 12345 127.0.0.1 3306</div><div class="line">J</div><div class="line">5.6.29�CuaV9v0xo�!</div><div class="line">                  qCHRrGRIJqvzmysql_native_password  </div><div class="line">                  </div><div class="line">#tcpdump -i any port 12345 -ennt</div><div class="line">tcpdump: verbose output suppressed, use -v or -vv for full protocol decode</div><div class="line">listening on any, link-type LINUX_SLL (Linux cooked), capture size 262144 bytes</div><div class="line"> In 00:00:00:00:00:00 ethertype IPv4 (0x0800), length 76: 127.0.0.1.12345 &gt; 127.0.0.1.3306: Flags [S], seq 3186409724, win 43690, options [mss 65495,sackOK,TS val 3967896050 ecr 0,nop,wscale 7], length 0</div><div class="line"> In 00:00:00:00:00:00 ethertype IPv4 (0x0800), length 76: 127.0.0.1.3306 &gt; 127.0.0.1.12345: Flags [S.], seq 4188709983, ack 3186409725, win 43690, options [mss 65495,sackOK,TS val 3967896051 ecr 3967896050,nop,wscale 7], length 0</div><div class="line"> In 00:00:00:00:00:00 ethertype IPv4 (0x0800), length 68: 127.0.0.1.12345 &gt; 127.0.0.1.3306: Flags [.], ack 1, win 342, options [nop,nop,TS val 3967896051 ecr 3967896051], length 0 // 握手完毕</div><div class="line"> In 00:00:00:00:00:00 ethertype IPv4 (0x0800), length 146: 127.0.0.1.3306 &gt; 127.0.0.1.12345: Flags [P.], seq 1:79, ack 1, win 342, options [nop,nop,TS val 3967896051 ecr 3967896051], length 78 //Server 发出Greeting</div><div class="line"> In 00:00:00:00:00:00 ethertype IPv4 (0x0800), length 68: 127.0.0.1.12345 &gt; 127.0.0.1.3306: Flags [.], ack 79, win 342, options [nop,nop,TS val 3967896051 ecr 3967896051], length 0</div><div class="line"> In 00:00:00:00:00:00 ethertype IPv4 (0x0800), length 68: 127.0.0.1.3306 &gt; 127.0.0.1.12345: Flags [F.], seq 79, ack 1, win 342, options [nop,nop,TS val 3967913551 ecr 3967896051], length 0</div><div class="line"> In 00:00:00:00:00:00 ethertype IPv4 (0x0800), length 68: 127.0.0.1.12345 &gt; 127.0.0.1.3306: Flags [.], ack 80, win 342, options [nop,nop,TS val 3967913591 ecr 3967913551], length 0</div></pre></td></tr></table></figure>
<p>如下是Server发出的长度为 78 的 Server Greeting信息内容</p>
<p><img src="/images/oss/203c52d94018bbf72dfd4fc64d8a237b.png" alt="image.png"></p>
<p>理论上如果slb探活连接检查MySQL Server的状态的时候也是很快reset了，如果MySQL Server程序写得烂的话也会出现同样的情况。</p>
<p>但是比如我们有实验验证MySQL  Server 是否正常的时候会用 nc 去测试，一般以能看到</p>
<blockquote>
<p>5.6.29�CuaV9v0xo�!<br>                  qCHRrGRIJqvzmysql_native_password </p>
</blockquote>
<p>就认为MySQL Server是正常的。但是真的是这样吗？我们看看 nc 的如下案例</p>
<h4 id="nc-6-4-快速fin"><a href="#nc-6-4-快速fin" class="headerlink" title="nc 6.4 快速fin"></a>nc 6.4 快速fin</h4><blockquote>
<p>#nc –version<br>Ncat: Version 6.40 ( <a href="http://nmap.org/ncat" target="_blank" rel="external">http://nmap.org/ncat</a> )</p>
</blockquote>
<p>用 nc 测试发现有一定的概率没有出现上面的Server Greeting信息，那么这是因为MySQL Server服务不正常了吗？</p>
<p><img src="/images/oss/1607660605575-1305739f-1621-4a01-89ad-0f81eef94922.png?x-oss-process=image%2Fresize%2Cw_1500" alt="image.png"></p>
<blockquote>
<p> nc -i 3 10.97.170.11 3306 -w 4 -p 1234</p>
</blockquote>
<p>-i 3 表示握手成功后 等三秒钟nc退出（发fin）</p>
<p>nc 6.4 握手后立即发fin断开连接，导致可能收不到Greeting，换成7.5或者mysql client就OK了</p>
<p>nc 7.5的抓包，明显可以看到nc在发fin前会先等4秒钟：</p>
<p><img src="/images/oss/1607660937618-d66c4074-9aa2-44cb-8054-f7d3680d1181.png?x-oss-process=image%2Fresize%2Cw_1500" alt="image.png"></p>
<h3 id="tcpping-模拟slb-探活"><a href="#tcpping-模拟slb-探活" class="headerlink" title="tcpping 模拟slb 探活"></a>tcpping 模拟slb 探活</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python tcpping.py -R -i 0.1 -t 1 dcep-blockchain-1 4000</div></pre></td></tr></table></figure>
<p>-i 间隔0.1秒 </p>
<p>-R reset断开连接</p>
<p>-t 超时时间1秒</p>
<p>执行如上代码，跟4000端口握手，然后立即发出reset断开连接（完全模拟slb探活行为），很快重现了问题</p>
<p>增加延时</p>
<p>-D 0.01表示握手成功后10ms后再发出reset（让应用有机会成功发出那12个字节），应用工作正常</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python tcpping.py -R -i 0.1 -t 1 -D 0.01 dcep-blockchain-1 4000</div></pre></td></tr></table></figure>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>最大的错误认知就是 ss 看到的全连接队列数量，netstat也能看到。实际是不一定，而这个快速reset+应用不accept就导致了看不到这个现象</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/01/28/journald和rsyslog/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/01/28/journald和rsyslog/" itemprop="url">journald和rsyslogd</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-01-28T17:30:03+08:00">
                2021-01-28
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Linux/" itemprop="url" rel="index">
                    <span itemprop="name">Linux</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="journald和rsyslogd"><a href="#journald和rsyslogd" class="headerlink" title="journald和rsyslogd"></a>journald和rsyslogd</h1><p>碰到rsyslog-8.24.0-34.1.al7.x86_64 的 rsyslogd 占用内存过高，于是分析了一下原因并学习了一下系统日志、rsyslog、journald之间的关系，流水账记录此文。</p>
<h2 id="rsyslogd-占用内存过高的分析"><a href="#rsyslogd-占用内存过高的分析" class="headerlink" title="rsyslogd 占用内存过高的分析"></a>rsyslogd 占用内存过高的分析</h2><p>rsyslogd使用了大概1.6-2G内存，不正常（正常情况下内存占用30-50M之间）</p>
<p>现象：</p>
<p><img src="/images/oss/12d137f9416d7935dbe6540c626ca8b4.png" alt="image.png"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line">KiB Mem :  7971268 total,   131436 free,  7712020 used,   127812 buff/cache</div><div class="line">KiB Swap:        0 total,        0 free,        0 used.    43484 avail Mem</div><div class="line"></div><div class="line">  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND</div><div class="line">24850 admin     20   0 8743896   5.1g      0 S   2.0 66.9   1413:55 java</div><div class="line"> 1318 root      20   0 2380404   1.6g    536 S   0.0 21.6 199:09.36 rsyslogd</div><div class="line"> </div><div class="line"># systemctl status rsyslog</div><div class="line">● rsyslog.service - System Logging Service</div><div class="line">   Loaded: loaded (/usr/lib/systemd/system/rsyslog.service; enabled; vendor preset: disabled)</div><div class="line">   Active: active (running) since Tue 2020-10-20 16:01:01 CST; 3 months 8 days ago</div><div class="line">     Docs: man:rsyslogd(8)</div><div class="line">           http://www.rsyslog.com/doc/</div><div class="line"> Main PID: 1318 (rsyslogd)</div><div class="line">   CGroup: /system.slice/rsyslog.service</div><div class="line">           └─1318 /usr/sbin/rsyslogd -n</div><div class="line"></div><div class="line">Jan 28 09:10:07 iZwz95gaul6x9167sqdqz4Z rsyslogd[1318]: sd_journal_get_cursor() failed: &apos;Cannot assign requested address&apos;  [v8.24.0-34.1.al7]</div><div class="line">Jan 28 09:10:07 iZwz95gaul6x9167sqdqz4Z rsyslogd[1318]: imjournal: journal reloaded... [v8.24.0-34.1.al7 try http://www.rsyslog.com/e/0 ]</div><div class="line">Jan 28 10:27:48 iZwz95gaul6x9167sqdqz4Z rsyslogd[1318]: sd_journal_get_cursor() failed: &apos;Cannot assign requested address&apos;  [v8.24.0-34.1.al7]</div><div class="line">Jan 28 10:27:49 iZwz95gaul6x9167sqdqz4Z rsyslogd[1318]: imjournal: journal reloaded... [v8.24.0-34.1.al7 try http://www.rsyslog.com/e/0 ]</div><div class="line">Jan 28 11:45:23 iZwz95gaul6x9167sqdqz4Z rsyslogd[1318]: sd_journal_get_cursor() failed: &apos;Cannot assign requested address&apos;  [v8.24.0-34.1.al7]</div><div class="line">Jan 28 11:45:24 iZwz95gaul6x9167sqdqz4Z rsyslogd[1318]: imjournal: journal reloaded... [v8.24.0-34.1.al7 try http://www.rsyslog.com/e/0 ]</div><div class="line">Jan 28 13:03:00 iZwz95gaul6x9167sqdqz4Z rsyslogd[1318]: sd_journal_get_cursor() failed: &apos;Cannot assign requested address&apos;  [v8.24.0-34.1.al7]</div><div class="line">Jan 28 13:03:01 iZwz95gaul6x9167sqdqz4Z rsyslogd[1318]: imjournal: journal reloaded... [v8.24.0-34.1.al7 try http://www.rsyslog.com/e/0 ]</div><div class="line">Jan 28 14:20:42 iZwz95gaul6x9167sqdqz4Z rsyslogd[1318]: sd_journal_get_cursor() failed: &apos;Cannot assign requested address&apos;  [v8.24.0-34.1.al7]</div><div class="line">Jan 28 14:20:42 iZwz95gaul6x9167sqdqz4Z rsyslogd[1318]: imjournal: journal reloaded... [v8.24.0-34.1.al7 try http://www.rsyslog.com/e/0 ] </div><div class="line"></div><div class="line"></div><div class="line"># grep HUPed /var/log/messages</div><div class="line">Jan 24 03:39:15 iZwz95gaul6x9167sqdqz4Z rsyslogd: [origin software=&quot;rsyslogd&quot; swVersion=&quot;8.24.0-34.1.al7&quot; x-pid=&quot;1318&quot; x-info=&quot;http://www.rsyslog.com&quot;] rsyslogd was HUPed</div><div class="line"></div><div class="line"># journalctl --verify</div><div class="line">PASS: /var/log/journal/20190829214900434421844640356160/system@efef6fd56e2e4c9f861d0be25c8c0781-0000000001567546-0005b9e2e02a0a4f.journal</div><div class="line">PASS: /var/log/journal/20190829214900434421844640356160/system@efef6fd56e2e4c9f861d0be25c8c0781-00000000015ae56b-0005b9ea76e922e9.journal</div><div class="line">1be1e0: Data object references invalid entry at 1d03018</div><div class="line">File corruption detected at /var/log/journal/20190829214900434421844640356160/system.journal:1d02d80 (of 33554432 bytes, 90%).</div><div class="line">FAIL: /var/log/journal/20190829214900434421844640356160/system.journal (Bad message)</div></pre></td></tr></table></figure>
<p><code>journalctl --verify</code>命令检查发现系统日志卷文件损坏</p>
<h3 id="问题根因"><a href="#问题根因" class="headerlink" title="问题根因"></a>问题根因</h3><p><a href="https://access.redhat.com/solutions/3705051" target="_blank" rel="external">来自redhat官网的描述</a></p>
<p><img src="/images/oss/e1a1cd75553b5cbe2a64e835ba9f99a7.png" alt="image.png"></p>
<p>以下是现场收集到的日志：</p>
<p><img src="/images/oss/cdfe3fb8d50ee148b816a82a432f1b88.png" alt="image.png"></p>
<p>主要是rsyslogd的sd_journal_get_cursor报错，然后导致内存泄露。</p>
<p>journald 报Bad message, 跟rsyslogd内存泄露完全没关系，实际上升级rsyslogd后也有journald bad message,但是rsyslogd的内存一直稳定在30M以内</p>
<p><a href="https://blog.csdn.net/fanren224/article/details/103991748" target="_blank" rel="external">这个CSDN的文章中有完全一样的症状</a> 但是作者的结论是：这是systemd的bug，在journald需要压缩的时候就会发生这个问题。实际上我用的是 systemd-219-62.6.al7.9.x86_64 比他描述的已经修复的版本还要要新，也还是有这个问题，所以这个结论是不对的</p>
<h3 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h3><p>1、重启rsyslog <code>systemctl restart rsyslog</code> 可以释放内存</p>
<p>2、升级rsyslog到rsyslog-8.24.0-38.1.al7.x86_64或更新的版本才能彻底修复这个问题</p>
<h3 id="一些配置方法"><a href="#一些配置方法" class="headerlink" title="一些配置方法"></a>一些配置方法</h3><p>修改配置/etc/rsyslog.conf，增加如下两行，然后重启<code>systemctl restart rsyslog</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$imjournalRatelimitInterval 0</div><div class="line">$imjournalRatelimitBurst 0</div><div class="line">12</div></pre></td></tr></table></figure>
<p>1、关掉journal压缩配置</p>
<p>vi /etc/systemd/journald.conf，把#Compress=yes改成Compress=no，之后systemctl restart systemd-journald即可</p>
<p>2、限制rsyslogd 内存大小</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">cat /etc/systemd/system/multi-user.target.wants/rsyslog.service</div><div class="line"></div><div class="line">在Service配置中添加MemoryAccounting=yes，MemoryMax=80M，MemoryHigh=8M三项如下所示。</div><div class="line">[Service]</div><div class="line">Type=notify</div><div class="line">EnvironmentFile=-/etc/sysconfig/rsyslog</div><div class="line">ExecStart=/usr/sbin/rsyslogd -n $SYSLOGD_OPTIONS</div><div class="line">Restart=on-failure</div><div class="line">UMask=0066</div><div class="line">StandardOutput=null</div><div class="line">Restart=on-failure</div><div class="line">MemoryAccounting=yes</div><div class="line">MemoryMax=80M</div><div class="line">MemoryHigh=8M</div></pre></td></tr></table></figure>
<h2 id="OOM-kill"><a href="#OOM-kill" class="headerlink" title="OOM kill"></a>OOM kill</h2><p>rsyslogd内存消耗过高后导致了OOM Kill</p>
<p><img src="/images/oss/c7332f5b48506ea1faa015cfc6ae1709.png" alt="image.png"></p>
<p><strong>RSS对应物理内存，单位是4K（page大小）</strong>，红框两个进程用了5G+2G，总内存是8G，所以触发OOM killer了</p>
<p>每次OOM Kill日志前后总带着systemd-journald的重启</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">Jan 28 19:03:04 iZwz95gaul6x9167sqdqz5Z journal: Permanent journal is using 520.0M (max allowed 500.0M, trying to leave 4.0G free of 83.7G available → current limit 520.0M).</div><div class="line">Jan 28 19:03:04 iZwz95gaul6x9167sqdqz5Z journal: Journal started</div><div class="line">Jan 28 19:03:04 iZwz95gaul6x9167sqdqz5Z kernel: AliYunDun invoked oom-killer: gfp_mask=0x6200ca(GFP_HIGHUSER_MOVABLE), nodemask=(null), order=0, oom_score_adj=0</div><div class="line">Jan 28 19:03:04 iZwz95gaul6x9167sqdqz5Z kernel: AliYunDun cpuset=/ mems_allowed=0</div><div class="line">Jan 28 19:03:04 iZwz95gaul6x9167sqdqz5Z kernel: CPU: 3 PID: 13296 Comm: AliYunDun Tainted: G           OE     4.19.57-15.1.al7.x86_64 #1</div><div class="line">Jan 28 19:03:04 iZwz95gaul6x9167sqdqz5Z kernel: Hardware name: Alibaba Cloud Alibaba Cloud ECS, BIOS 8c24b4c 04/01/2014</div><div class="line">Jan 28 19:03:04 iZwz95gaul6x9167sqdqz5Z kernel: Call Trace:</div><div class="line">Jan 28 19:03:04 iZwz95gaul6x9167sqdqz5Z kernel: dump_stack+0x5c/0x7b</div><div class="line">Jan 28 19:03:04 iZwz95gaul6x9167sqdqz5Z kernel: dump_header+0x77/0x29f</div><div class="line">***</div><div class="line">Jan 28 19:03:04 iZwz95gaul6x9167sqdqz5Z kernel: [  18118]     0 18118    28218      255   245760        0             0 sshd</div><div class="line">Jan 28 19:03:04 iZwz95gaul6x9167sqdqz5Z kernel: Out of memory: Kill process 18665 (java) score 617 or sacrifice child</div><div class="line">Jan 28 19:03:04 iZwz95gaul6x9167sqdqz5Z kernel: Killed process 18665 (java) total-vm:8446992kB, anon-rss:4905856kB, file-rss:0kB, shmem-rss:0kB</div><div class="line">Jan 28 19:03:04 iZwz95gaul6x9167sqdqz5Z kernel: oom_reaper: reaped process 18665 (java), now anon-rss:0kB, file-rss:0kB, shmem-rss:0kB</div><div class="line">Jan 28 19:03:04 iZwz95gaul6x9167sqdqz5Z systemd: systemd-journald.service watchdog timeout (limit 3min)!</div><div class="line">Jan 28 19:03:04 iZwz95gaul6x9167sqdqz5Z rsyslogd: sd_journal_get_cursor() failed: &apos;Cannot assign requested address&apos;  [v8.24.0-34.1.al7]</div><div class="line">Jan 28 19:03:04 iZwz95gaul6x9167sqdqz5Z rsyslogd: imjournal: journal reloaded... [v8.24.0-34.1.al7 try http://www.rsyslog.com/e/0 ]</div><div class="line">Jan 28 20:14:38 iZwz95gaul6x9167sqdqz5Z rsyslogd: imjournal: journal reloaded... [v8.24.0-57.1.al7 try http://www.rsyslog.com/e/0 ]</div></pre></td></tr></table></figure>
<p><img src="/images/oss/45008a8323742fb7f145211a6281afbc.png" alt="image.png"></p>
<p>OOM kill前大概率伴随着systemd-journald 重启是因为watch dog timeout(limit 3min)，造成timeout的原因是journald定期要把日志刷到磁盘上，然后要么是内存不够，要么是io负载太重，导致刷磁盘这个过程非常慢，于是就timeout了。</p>
<p>当然systemd-journald 重启也不一定意味着OOM Killer，只是肯定是内存比较紧张了。</p>
<h2 id="What-is-the-difference-between-syslog-rsyslog-and-syslog-ng"><a href="#What-is-the-difference-between-syslog-rsyslog-and-syslog-ng" class="headerlink" title="What is the difference between syslog, rsyslog and syslog-ng? "></a><a href="https://serverfault.com/questions/692309/what-is-the-difference-between-syslog-rsyslog-and-syslog-ng" target="_blank" rel="external">What is the difference between syslog, rsyslog and syslog-ng? </a></h2><p>Basically, they are all the same, in the way they all permit the logging of data from different types of systems in a central repository.</p>
<p>But they are three different project, each project trying to improve the previous one with more reliability and functionalities.</p>
<p>The <code>Syslog</code> project was the very first project. It started in 1980. It is the root project to <code>Syslog</code> protocol. At this time Syslog is a very simple protocol. At the beginning it only supports UDP for transport, so that it does not guarantee the delivery of the messages.</p>
<p>Next came <code>syslog-ng</code> in 1998. It extends basic <code>syslog</code> protocol with new features like:</p>
<ul>
<li>content-based filtering</li>
<li>Logging directly into a database</li>
<li>TCP for transport</li>
<li>TLS encryption</li>
</ul>
<p>Next came <code>Rsyslog</code> in 2004. It extends <code>syslog</code> protocol with new features like:</p>
<ul>
<li>RELP Protocol support</li>
<li>Buffered operation support</li>
</ul>
<h2 id="rsyslog和journald的基础知识"><a href="#rsyslog和journald的基础知识" class="headerlink" title="rsyslog和journald的基础知识"></a>rsyslog和journald的基础知识</h2><p><code>systemd-journald</code>是用来协助<code>rsyslog</code>记录系统启动服务和服务启动失败的情况等等. <code>systemd-journald</code>使用内存保存记录, 系统重启记录会丢失. 所有还要用<code>rsyslog</code>来记录分类信息, 如上面<code>/etc/rsyslog.d/listen.conf</code>中的<code>syslog</code>分类.</p>
<p><code>systemd-journald</code>跟随systemd开机就启动，能及时记录所有日志：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"># systemd-analyze critical-chain systemd-journald.service</div><div class="line">The time after the unit is active or started is printed after the &quot;@&quot; character.</div><div class="line">The time the unit takes to start is printed after the &quot;+&quot; character.</div><div class="line"></div><div class="line">systemd-journald.service +13ms</div><div class="line">└─system.slice</div><div class="line">  └─-.slice</div></pre></td></tr></table></figure>
<p>systemd-journald 由于是使用于内存的登录文件记录方式，因此重新开机过后，开机前的登录文件信息当然就不会被记载了。 为此，我们还是建议启动 rsyslogd 来协助分类记录！也就是说， systemd-journald 用来管理与查询这次开机后的登录信息，而 rsyslogd 可以用来记录以前及现在的所以数据到磁盘文件中，方便未来进行查询喔！</p>
<p><strong>Tips</strong> 虽然 systemd-journald 所记录的数据其实是在内存中，但是系统还是利用文件的型态将它记录到 /run/log/ 下面！ 不过我们从前面几章也知道， /run 在 CentOS 7 其实是内存内的数据，所以重新开机过后，这个 /run/log 下面的数据当然就被刷新，旧的当然就不再存在了！</p>
<blockquote>
<p>其实鸟哥是这样想的，既然我们还有 rsyslog.service 以及 logrotate 的存在，因此这个 systemd-journald.service 产生的登录文件， 个人建议最好还是放置到 /run/log 的内存当中，以加快存取的速度！而既然 rsyslog.service 可以存放我们的登录文件， 似乎也没有必要再保存一份 journal 登录文件到系统当中就是了。单纯的建议！如何处理，依照您的需求即可喔！</p>
</blockquote>
<p><strong><code>system-journal</code>服务监听 <code>/dev/log</code> socket获取日志, 保存在内存中, 并间歇性的写入<code>/var/log/journal</code>目录中.</strong></p>
<p><code>rsyslog</code>服务启动后监听<code>/run/systemd/journal/socket</code> 获取syslog类型日志, 并写入<code>/var/log/messages</code>文件中. </p>
<p>获取日志时需要记录日志条目的<code>position</code>到<code>/var/lib/rsyslog/imjournal.state</code>文件中.</p>
<p>比如haproxy日志配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"># cat /etc/haproxy/haproxy.cfg</div><div class="line">global</div><div class="line"># log发给journald(journald监听 /dev/log)</div><div class="line">        log /dev/log    local1 warning</div></pre></td></tr></table></figure>
<p>以下是drds 的iptables日志配置，将tcp reset包记录下来，默认iptable日志输出到/varlog/messages中（dmesg也能看到），然后可以通过rsyslog.d 配置将这部分日志输出到单独的文件中：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"># 配置iptables 日志，增加 [drds] 标识</div><div class="line"># cat /home/admin/drds-worker/install/drds_filter.conf</div><div class="line"># Generated by iptables-save v1.4.21 on Wed Apr  1 11:39:31 2020</div><div class="line">*filter</div><div class="line">:INPUT ACCEPT [557:88127]</div><div class="line">:FORWARD ACCEPT [0:0]</div><div class="line">:OUTPUT ACCEPT [527:171711]</div><div class="line">-A INPUT -p tcp -m tcp ! --sport 3406  --tcp-flags RST RST -j LOG --log-prefix &quot;[drds] &quot; --log-level 7 --log-tcp-sequence --log-tcp-options --log-ip-options</div><div class="line"># -A INPUT -p tcp -m tcp ! --dport 3406  --tcp-flags RST RST -j LOG --log-prefix &quot;[drds] &quot; --log-level7 --log-tcp-sequence --log-tcp-options --log-ip-options</div><div class="line">-A OUTPUT -p tcp -m tcp ! --sport 3406 --tcp-flags RST RST -j LOG --log-prefix &quot;[drds] &quot; --log-level 7 --log-tcp-sequence --log-tcp-options --log-ip-options</div><div class="line">COMMIT</div><div class="line"># Completed on Wed Apr  1 11:39:31 2020</div><div class="line"></div><div class="line">#通过rsyslogd将日志写出到指定位置(不配置的话默认输出到 dmesg)</div><div class="line"># cat /etc/rsyslog.d/drds_filter_log.conf</div><div class="line">:msg, startswith, &quot;[drds]&quot; -/home/admin/logs/tcp-rt/drds-tcp.log</div></pre></td></tr></table></figure>
<h3 id="journald-log持久化"><a href="#journald-log持久化" class="headerlink" title="journald log持久化"></a>journald log持久化</h3><p>创建 /var/log/journal 文件夹后默认会持久化，设置持久化后 /run/log 里面就没有日志了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line"># cat /etc/systemd/journald.conf</div><div class="line">#  This file is part of systemd.</div><div class="line">#</div><div class="line">#  systemd is free software; you can redistribute it and/or modify it</div><div class="line">#  under the terms of the GNU Lesser General Public License as published by</div><div class="line">#  the Free Software Foundation; either version 2.1 of the License, or</div><div class="line">#  (at your option) any later version.</div><div class="line">#</div><div class="line"># Entries in this file show the compile time defaults.</div><div class="line"># You can change settings by editing this file.</div><div class="line"># Defaults can be restored by simply deleting this file.</div><div class="line">#</div><div class="line"># See journald.conf(5) for details.</div><div class="line"></div><div class="line">[Journal]</div><div class="line">#Storage=auto  //默认如果有 /var/log/journal 目录就会持久化到这里</div><div class="line">Compress=no</div><div class="line">#Seal=yes</div><div class="line">#SplitMode=uid</div><div class="line">#SyncIntervalSec=5m</div><div class="line">#RateLimitInterval=30s</div><div class="line">#RateLimitBurst=1000</div><div class="line">SystemMaxUse=500M   //最多保留500M日志文件，免得撑爆磁盘</div><div class="line">#SystemKeepFree=</div><div class="line">#SystemMaxFileSize=</div><div class="line">#RuntimeMaxUse=</div><div class="line">#RuntimeKeepFree=</div><div class="line">#RuntimeMaxFileSize=</div><div class="line">#MaxRetentionSec=</div><div class="line">#MaxFileSec=1month</div><div class="line">#ForwardToSyslog=yes</div><div class="line">#ForwardToKMsg=no</div><div class="line">#ForwardToConsole=no</div><div class="line">#ForwardToWall=yes</div><div class="line">#TTYPath=/dev/console</div><div class="line">#MaxLevelStore=debug</div><div class="line">#MaxLevelSyslog=debug</div><div class="line">#MaxLevelKMsg=notice</div><div class="line">#MaxLevelConsole=info</div><div class="line">#MaxLevelWall=emerg</div><div class="line">#LineMax=48K</div></pre></td></tr></table></figure>
<p>清理日志保留1M：journalctl –vacuum-size=1M </p>
<p>设置最大保留500M日志： journalctl –vacuum-size=500</p>
<h3 id="rsyslogd"><a href="#rsyslogd" class="headerlink" title="rsyslogd"></a>rsyslogd</h3><p>以下内容来自鸟哥的书：</p>
<p>CentOS 7 除了保有既有的 rsyslog.service 之外，其实最上游还使用了 systemd 自己的登录文件日志管理功能喔！他使用的是 systemd-journald.service 这个服务来支持的。基本上，系统由 systemd 所管理，那所有经由 systemd 启动的服务，如果再启动或结束的过程中发生一些问题或者是正常的讯息， 就会将该讯息由 systemd-journald.service 以二进制的方式记录下来，之后再将这个讯息发送给 rsyslog.service 作进一步的记载。</p>
<p>基本上， rsyslogd 针对各种服务与讯息记录在某些文件的配置文件就是 /etc/rsyslog.conf， 这个文件规定了“（1）什么服务 （2）的什么等级讯息 （3）需要被记录在哪里（设备或文件）” 这三个咚咚，所以设置的语法会是这样：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">$cat /etc/rsyslog.conf</div><div class="line">服务名称[.=!]讯息等级        讯息记录的文件名或设备或主机</div><div class="line"># 下面以 mail 这个服务产生的 info 等级为例：</div><div class="line">mail.info            /var/log/maillog_info</div><div class="line"># 这一行说明：mail 服务产生的大于等于 info 等级的讯息，都记录到</div><div class="line"># /var/log/maillog_info 文件中的意思。</div></pre></td></tr></table></figure>
<p><img src="/images/oss/1cce7612a84cf1a1addceeff6032cb5c.png" alt="syslog 所制订的服务名称与软件调用的方式"></p>
<p> CentOS 7.x 默认的 rsyslogd 本身就已经具有远程日志服务器的功能了， 只是默认并没有启动该功能而已。你可以通过 man rsyslogd 去查询一下相关的选项就能够知道啦！ 既然是远程日志服务器，那么我们的 Linux 主机当然会启动一个端口来监听了，那个默认的端口就是 UDP 或 TCP 的 port 514 </p>
<p><img src="/images/oss/40740cd5cfc8896c07c15b959420646f.png" alt="image.png"></p>
<p>Server配置如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">$ cat /etc/rsyslog.conf</div><div class="line"># 找到下面这几行：</div><div class="line"># Provides UDP syslog reception</div><div class="line">#$ModLoad imudp</div><div class="line">#$UDPServerRun 514</div><div class="line"></div><div class="line"># Provides TCP syslog reception</div><div class="line">#$ModLoad imtcp</div><div class="line">#$InputTCPServerRun 514</div><div class="line"># 上面的是 UDP 端口，下面的是 TCP 端口！如果你的网络状态很稳定，就用 UDP 即可。</div><div class="line"># 不过，如果你想要让数据比较稳定传输，那么建议使用 TCP 啰！所以修改下面两行即可！</div><div class="line">$ModLoad imtcp</div><div class="line">$InputTCPServerRun 514</div><div class="line"></div><div class="line"># 2\. 重新启动与观察 rsyslogd 喔！</div><div class="line">[root@study ~]# systemctl restart rsyslog.service</div><div class="line">[root@study ~]# netstat -ltnp &amp;#124; grep syslog</div><div class="line">Proto Recv-Q Send-Q Local Address  Foreign Address   State    PID/Program name</div><div class="line">tcp        0      0 0.0.0.0:514    0.0.0.0:*         LISTEN   2145/rsyslogd</div><div class="line">tcp6       0      0 :::514         :::*              LISTEN   2145/rsyslogd</div><div class="line"># 嘿嘿！你的登录文件主机已经设置妥当啰！很简单吧！</div></pre></td></tr></table></figure>
<p>client配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ cat /etc/rsyslog.conf</div><div class="line">*.*       @@192.168.1.100</div><div class="line">#*.*       @192.168.1.100  # 若用 UDP 传输，设置要变这样！</div></pre></td></tr></table></figure>
<p>常见的几个系统日志有哪些呢？一般而言，有下面几个：</p>
<ul>
<li>/var/log/boot.log： 开机的时候系统核心会去侦测与启动硬件，接下来开始各种核心支持的功能启动等。这些流程都会记录在 /var/log/boot.log 里面哩！ 不过这个文件只会存在这次开机启动的信息，前次开机的信息并不会被保留下来！</li>
<li>/var/log/cron： 还记得<a href="https://wizardforcel.gitbooks.io/vbird-linux-basic-4e/Text/index.html" target="_blank" rel="external">第十五章例行性工作调度</a>吧？你的 crontab 调度有没有实际被进行？ 进行过程有没有发生错误？你的 /etc/crontab 是否撰写正确？在这个登录文件内查询看看。</li>
<li>/var/log/dmesg： 记录系统在开机的时候核心侦测过程所产生的各项信息。由于 CentOS 默认将开机时核心的硬件侦测过程取消显示， 因此额外将数据记录一份在这个文件中；</li>
<li>/var/log/lastlog： 可以记录系统上面所有的帐号最近一次登陆系统时的相关信息。<a href="https://wizardforcel.gitbooks.io/vbird-linux-basic-4e/Text/index.html#uselinux_find" target="_blank" rel="external">第十三章讲到的 lastlog</a> 指令就是利用这个文件的记录信息来显示的。</li>
<li>/var/log/maillog 或 /var/log/mail/*： 记录邮件的往来信息，其实主要是记录 postfix （SMTP 协定提供者） 与 dovecot （POP3 协定提供者） 所产生的讯息啦。 SMTP 是发信所使用的通讯协定， POP3 则是收信使用的通讯协定。 postfix 与 dovecot 则分别是两套达成通讯协定的软件。</li>
<li>/var/log/messages： 这个文件相当的重要，几乎系统发生的错误讯息 （或者是重要的信息） 都会记录在这个文件中； 如果系统发生莫名的错误时，这个文件是一定要查阅的登录文件之一。</li>
<li>/var/log/secure： 基本上，只要牵涉到“需要输入帐号密码”的软件，那么当登陆时 （不管登陆正确或错误） 都会被记录在此文件中。 包括系统的 login 程序、图形接口登陆所使用的 gdm 程序、 su, sudo 等程序、还有网络连线的 ssh, telnet 等程序， 登陆信息都会被记载在这里；</li>
<li>/var/log/wtmp, /var/log/faillog： 这两个文件可以记录正确登陆系统者的帐号信息 （wtmp） 与错误登陆时所使用的帐号信息 （faillog） ！ 我们在<a href="https://wizardforcel.gitbooks.io/vbird-linux-basic-4e/Text/index.html#last" target="_blank" rel="external">第十章谈到的 last</a> 就是读取 wtmp 来显示的， 这对于追踪一般帐号者的使用行为很有帮助！</li>
<li>/var/log/httpd/<em>, /var/log/samba/</em>： 不同的网络服务会使用它们自己的登录文件来记载它们自己产生的各项讯息！上述的目录内则是个别服务所制订的登录文件。</li>
</ul>
<h2 id="journalctl-常用参数"><a href="#journalctl-常用参数" class="headerlink" title="journalctl 常用参数"></a><a href="https://linuxhint.com/journalctl-tail-and-cheatsheet/" target="_blank" rel="external">journalctl 常用参数</a></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">-n or –lines= Show the most recent **n** number of log lines</div><div class="line"></div><div class="line">-f or –follow Like a tail operation for viewing live updates</div><div class="line"></div><div class="line">-S, –since=, -U, –until= Search based on a date. “2019-07-04 13:19:17”, “00:00:00”, “yesterday”, “today”, “tomorrow”, “now” are valid formats. For complete time and date specification, see systemd.time(7)</div><div class="line"></div><div class="line">-u service unit</div></pre></td></tr></table></figure>
<p>清理journald日志</p>
<blockquote>
<p> journalctl –vacuum-size=1M &amp;&amp; journalctl –vacuum-size=500</p>
</blockquote>
<h2 id="logrotate"><a href="#logrotate" class="headerlink" title="logrotate"></a>logrotate</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">/var/log/cron</div><div class="line">&#123;</div><div class="line">    sharedscripts</div><div class="line">    postrotate</div><div class="line">        /bin/kill -HUP `cat /var/run/syslogd.pid 2&gt; /dev/null` 2&gt; /dev/null || true</div><div class="line">    endscript</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="kill-HUP"><a href="#kill-HUP" class="headerlink" title="kill -HUP"></a><a href="https://unix.stackexchange.com/questions/440004/why-is-kill-hup-used-in-logrotate-in-rhel-is-it-necessary-in-all-cases" target="_blank" rel="external">kill -HUP</a></h3><p>Generally services keep the log files opened while they are running. This mean that they do not care if the log files are renamed/moved or deleted they will continue to write to the open file handled.</p>
<p>When logrotate move the files, the services keep writing to the same file.</p>
<p>Example: syslogd will write to /var/log/cron.log. Then logrotate will rename the file to /var/log/cron.log.1, so syslogd will keep writing to the open file /var/log/cron.log.1.</p>
<p>Sending the HUP signal to syslogd will force him to close existing file handle and open new file handle to the original path /var/log/cron.log which will create a new file.</p>
<p>The use of the HUP signal instead of another one is at the discretion of the program. Some services like php-fpm will listen to the USR1 signal to reopen it’s file handle without terminating itself.</p>
<p>不过还得看应用是否屏蔽了 HUP 信号</p>
<h2 id="systemd"><a href="#systemd" class="headerlink" title="systemd"></a>systemd</h2><p>sudo systemctl list-unit-files –type=service | grep enabled //列出启动项</p>
<p> journalctl -b -1 //复审前一次启动， -2 复审倒数第 2 次启动. 重演你的系统启动的所有消息</p>
<p>sudo systemd-analyze blame   <strong>sudo systemd-analyze critical-chain</strong></p>
<p>systemd-analyze critical-chain –fuzz 1h</p>
<p>sudo systemd-analyze blame networkd</p>
<p>systemd-analyze critical-chain network.target local-fs.target</p>
<p><img src="/images/oss/bb21293e-9b52-40f9-9ab2-7c5aeb7beca1.png" alt="img"></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>一模一样的症状，但是根因找错了：<a href="https://blog.csdn.net/fanren224/article/details/103991748" target="_blank" rel="external">rsyslog占用内存高</a> </p>
<p><a href="https://access.redhat.com/solutions/3705051" target="_blank" rel="external">https://access.redhat.com/solutions/3705051</a></p>
<p><a href="https://sunsea.im/rsyslogd-systemd-journald-high-memory-solution.html" target="_blank" rel="external">https://sunsea.im/rsyslogd-systemd-journald-high-memory-solution.html</a></p>
<p><a href="https://wizardforcel.gitbooks.io/vbird-linux-basic-4e/content/160.html" target="_blank" rel="external">鸟哥 journald 介绍</a></p>
<p><a href="https://linuxhint.com/journalctl-tail-and-cheatsheet/" target="_blank" rel="external">journalctl tail and cheatsheet</a></p>
<p><a href="https://lp007819.wordpress.com/2015/01/17/systemd-journal-介绍/" target="_blank" rel="external">Journal的由来</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/01/15/TCP传输速度案例分析/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/01/15/TCP传输速度案例分析/" itemprop="url">TCP传输速度案例分析</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-01-15T17:30:03+08:00">
                2021-01-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/TCP/" itemprop="url" rel="index">
                    <span itemprop="name">TCP</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="TCP传输速度案例分析"><a href="#TCP传输速度案例分析" class="headerlink" title="TCP传输速度案例分析"></a>TCP传输速度案例分析</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>TCP传输速度受网络带宽和传输窗口的影响（接收、发送、拥塞窗口），带宽我们没办法改变，以下案例主要是讨论rt、窗口如何影响速度。</p>
<p>详细的buffer、rt对TCP传输速度的影响请看这篇：</p>
<p> <a href="/2019/09/28/就是要你懂TCP--性能和发送接收Buffer的关系/">就是要你懂TCP–性能和发送接收Buffer的关系：发送窗口大小(Buffer)、接收窗口大小(Buffer)对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响。BDP、RT、带宽对传输速度又是怎么影响的</a></p>
<p>以及 <a href="/2018/06/14/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E6%9C%80%E7%BB%8F%E5%85%B8%E7%9A%84TCP%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98/">就是要你懂TCP–最经典的TCP性能问题 Nagle和Delay ack</a></p>
<p>上面两篇以及下面几个案例读完，应该所有TCP传输速度问题都能解决了。</p>
<h2 id="前后端rtt差异大-vip下载慢的案例"><a href="#前后端rtt差异大-vip下载慢的案例" class="headerlink" title="前后端rtt差异大+vip下载慢的案例"></a>前后端rtt差异大+vip下载慢的案例</h2><p>来源：<a href="https://mp.weixin.qq.com/s/er8vTKZUcahA6-Pf8DZBng" target="_blank" rel="external">https://mp.weixin.qq.com/s/er8vTKZUcahA6-Pf8DZBng</a> 文章中的trace-cmd工具也不错</p>
<p>如下三个链路，有一个不正常了</p>
<p><img src="/images/oss/2422ae219d3b27cfe8c799642662d5b2.png" alt="image.png"></p>
<p>首先通过 ss -it dst “ip:port” 来分析cwnd、ssthresh、buffer，到底是什么导致了传输慢</p>
<h3 id="原因TCPLossProbe："><a href="#原因TCPLossProbe：" class="headerlink" title="原因TCPLossProbe："></a>原因TCPLossProbe：</h3><p>如果尾包发生了丢包，没有新包可发送触发多余的dup ack来实现快速重传，完全依赖RTO超时来重传，代价太大，那如何能优化解决这种尾丢包的情况。也就是在某些情况下一个可以的重传包就能触发ssthresh减半，从而导致传输速度上不来。</p>
<p>本案例中，因为client到TGW跨了地域，导致rtt增大，但是TGW和STGW之间的rtt很小，导致握手完毕后STGW认为和client的rtt很小，所以很快就触发了丢包重传，实际没有丢包，只是rtt变大了，所以触发了如上的TLP( PTO=max(2rtt, 10ms) ， 因为只有一次重传并收到了 dup，还是不应该触发TLP，但是因为老版本kernel bug导致，4.0的kernel修复了这个问题， 函数 is_tlp_dupack)</p>
<p>握手完毕后第七号包很快重传了</p>
<p><img src="/images/oss/2867daa600363af61f8f971479246858.png" alt="image.png"></p>
<h3 id="观察："><a href="#观察：" class="headerlink" title="观察："></a>观察：</h3><p>netstat -s |grep TCPLossProbes</p>
<h3 id="解决："><a href="#解决：" class="headerlink" title="解决："></a>解决：</h3><p>tcp_early_retrans可用于开启和关闭ER和TLP，默认是3（enable TLP and delayed ER），sysctl -w net.ipv4.tcp_early_retrans=2 关掉TLP</p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>kernel版本小于4.0+TLP开启+VIP代理导致RS认为rtt很小，实际比较大，这两个条件下就会出现如上问题。</p>
<p>这个问题一看就是跟client和VIP代理之间的rtt扩大有关系，不过不是因为扩大后发送窗口不够之类导致的。</p>
<h2 id="长肥网络（高rtt）场景下tcp-metrics记录的ssthresh太小导致传输慢的案例"><a href="#长肥网络（高rtt）场景下tcp-metrics记录的ssthresh太小导致传输慢的案例" class="headerlink" title="长肥网络（高rtt）场景下tcp_metrics记录的ssthresh太小导致传输慢的案例"></a>长肥网络（高rtt）场景下tcp_metrics记录的ssthresh太小导致传输慢的案例</h2><p><a href="https://www.atatech.org/articles/109967" target="_blank" rel="external">https://www.atatech.org/articles/109967</a></p>
<blockquote>
<p>tcp_metrics会记录下之前已关闭tcp 连接的状态，包括发送端拥塞窗口和拥塞控制门限，如果之前网络有一段时间比较差或者丢包比较严重，就会导致tcp 的拥塞控制门限ssthresh降低到一个很低的值，这个值在连接结束后会被tcp_metrics cache 住，在新连接建立时，即使网络状况已经恢复，依然会继承 tcp_metrics 中cache 的一个很低的ssthresh 值，在长肥管道情况下，新连接经历短暂的“慢启动”后，随即进入缓慢的拥塞控制阶段, 导致连接速度很难在短时间内上去。而后面的连接，需要很特殊的场景之下才能将ssthresh 再次推到一个比较高的值缓存下来，因此很有很能在接下来的很长一段时间，连接的速度都会处于一个很低的水平</p>
</blockquote>
<p>因为 tcp_metrics记录的ssthresh非常小，导致后面新的tcp连接传输数据时很快进入拥塞控制阶段，如果传输的文件不大的话就没有机会将ssthresh撑大。除非传输一个特别大的文件，忍受拥塞控制阶段的慢慢增长，最后tcp_metrics记录下撑大后的ssthresh，整个网络才会恢复正常。</p>
<p>所以关闭 tcp_metrics其实是个不错的选择： net.ipv4.tcp_no_metrics_save = 1 </p>
<p>或者清除： sudo ip tcp_metrics flush all</p>
<h3 id="从系统cache中查看-tcp-metrics-item"><a href="#从系统cache中查看-tcp-metrics-item" class="headerlink" title="从系统cache中查看 tcp_metrics item"></a>从系统cache中查看 tcp_metrics item</h3><pre><code>$sudo ip tcp_metrics show | grep  100.118.58.7
100.118.58.7 age 1457674.290sec tw_ts 3195267888/5752641sec ago rtt 1000us rttvar 1000us ssthresh 361 cwnd 40 ----这两个值对传输性能很重要

192.168.1.100 age 1051050.859sec ssthresh 4 cwnd 2 rtt 4805us rttvar 4805us source 192.168.0.174 ---这条记录有问题，缓存的ssthresh 4 cwnd 2都太小，传输速度一定慢 

清除 tcp_metrics, sudo ip tcp_metrics flush all 
关闭 tcp_metrics 功能，net.ipv4.tcp_no_metrics_save = 1
sudo ip tcp_metrics delete 100.118.58.7
</code></pre><p>每个连接的ssthresh默认是个无穷大的值，但是内核会cache对端ip上次的ssthresh（大部分时候两个ip之间的拥塞窗口大小不会变），这样大概率到达ssthresh之后就基本拥塞了，然后进入cwnd的慢增长阶段。</p>
<h2 id="长肥网络（rt很高、带宽也高）下接收窗口对传输性能的影响"><a href="#长肥网络（rt很高、带宽也高）下接收窗口对传输性能的影响" class="headerlink" title="长肥网络（rt很高、带宽也高）下接收窗口对传输性能的影响"></a>长肥网络（rt很高、带宽也高）下接收窗口对传输性能的影响</h2><p>最后通过一个实际碰到的案例，涉及到了接收窗口、发送Buffer以及高延时情况下的性能问题</p>
<p>案例描述：从中国访问美国的服务器下载图片，只能跑到220K，远远没有达到带宽能力，其中中美之间的网络延时时150ms，这个150ms已经不能再优化了。业务结构是：</p>
<p>client ——150ms—–&gt;&gt;&gt;LVS—1ms–&gt;&gt;&gt;美国的统一接入server—–1ms—–&gt;&gt;&gt;nginx</p>
<p>通过下载一个4M的文件大概需要20秒，分别在client和nginx上抓包来分析这个问题（统一接入server没权限上去）</p>
<h3 id="Nginx上抓包"><a href="#Nginx上抓包" class="headerlink" title="Nginx上抓包"></a>Nginx上抓包</h3><p><img src="/images/oss/259767fb17f7dbffe7f77ab059c47dbd.png" alt="image.png"></p>
<p>从这里可以看到Nginx大概在60ms内就将4M的数据都发完了</p>
<h3 id="client上抓包"><a href="#client上抓包" class="headerlink" title="client上抓包"></a>client上抓包</h3><p><img src="/images/oss/466fba92829f6a922ccd2d57a7e3fdac.png" alt="image.png"></p>
<p>从这个图上可以清楚看到大概每传输大概30K数据就有一个150ms的等待平台，这个150ms基本是client到美国的rt。</p>
<p>从我们前面的阐述可以清楚了解到因为rt比较高，统一接入server每发送30K数据后要等150ms才能收到client的ack，然后继续发送，猜是因为上面设置的发送buffer大概是30K。</p>
<p>检查统一接入server的配置，可以看到接入server的配置里面果然有个32K buffer设置</p>
<h3 id="将buffer改大"><a href="#将buffer改大" class="headerlink" title="将buffer改大"></a>将buffer改大</h3><p>速度可以到420K，但是还没有跑满带宽：</p>
<p><img src="/images/oss/93e254c5154ce2e065bec9fb34f3db2b.png" alt="image.png"></p>
<p><img src="/images/oss/0a8c68a58da6f169573b57cde0ffba93.png" alt="image.png"></p>
<p>接着看一下client上的抓包</p>
<p><img src="/images/oss/822737a4ed6ffe6b920d4b225a1be5bf.png" alt="image.png"></p>
<p>可以清楚看到 client的接收窗口是64K， 64K*1000/150=426K 这个64K很明显是16位的最大值，应该是TCP握手有一方不支持window scaling factor</p>
<p>那么继续分析一下握手包，syn：</p>
<p><img src="/images/oss/004886698ddbaa1cbc8342a9cd667c76.png" alt="image.png"></p>
<p>说明client是支持的，再看 syn+ack：</p>
<p><img src="/images/oss/70155e021390cb1ee07091c306c375f4.png" alt="image.png"></p>
<p>可以看到服务端不支持，那就最大只能用到64K。需要修改服务端代理程序，这主要是LVS或者代理的锅。</p>
<p>如果内网之间rt很小这个锅不会爆发，一旦网络慢一点就把问题恶化了</p>
<p>比如这是这个应用的开发人员的反馈：</p>
<p><img src="/images/oss/a08a204ec7ad4bba7867dacea1668322.png" alt="image.png"></p>
<p><a href="https://datatracker.ietf.org/doc/html/rfc1072" target="_blank" rel="external">长肥网络</a>就像是很长很宽的高速公路，上面可以同时跑很多车，而如果发车能力不够，就容易跑不满高速公路。<br>在rt很短的时候可以理解为高速公路很短，所以即使发车慢也还好，因为车很快就到了，到了后就又能发新车了。rt很长的话就要求更大的仓库了。</p>
<p>整个这个问题，我最初拿到的问题描述结构是这样的（不要笑程序员连自己的业务结构都描述不清）：</p>
<p>client ——150ms—–&gt;&gt;&gt;nginx</p>
<p>实际开发人员也不能完全描述清楚结构，从抓包中慢慢分析反推他们的结构，到最后问题的解决。</p>
<p>这个案例综合了发送窗口（32K）、接收窗口（64K，因为握手LVS不支持window scale）、rt很大将问题暴露出来（跨国网络，rt没法优化）。</p>
<p>nginx buffer 分析参考案例：<a href="https://juejin.cn/post/6875223721615818765" target="_blank" rel="external">https://juejin.cn/post/6875223721615818765</a> nginx上下游收发包速率不一致导致nginx buffer打爆, 关闭nginx proxy_buffering 可解 （作者：挖坑的张师傅）</p>
<p><img src="/images/951413iMgBlog/433762.png" alt="image.png"></p>
<h2 id="应用层发包逻辑影响了BDP不能跑满"><a href="#应用层发包逻辑影响了BDP不能跑满" class="headerlink" title="应用层发包逻辑影响了BDP不能跑满"></a>应用层发包逻辑影响了BDP不能跑满</h2><p>来自 dog250: <a href="https://zhuanlan.zhihu.com/p/413732839" target="_blank" rel="external">一行代码解决scp在Internet传输慢的问题（RT高的网络环境）</a> </p>
<blockquote>
<p>用scp在长链路上传输文件竟然慢到无法忍受！100～200毫秒往返时延的链路，wget下载文件吞吐可达40MBps，scp却只有9MBps。</p>
<p>这次不是因为buffer导致BDP跑不满，而是也scp业务层有自己流控的逻辑导致发包慢了</p>
<p><strong>SSH允许在一个TCP连接上复用多个channel，需要对每一个channel做流控以保证公平，所以每个channel必须自己做而不是使用TCP的流控，OpenSSH的实现有问题。</strong></p>
</blockquote>
<h2 id="delay-ack拉高实际rt的案例"><a href="#delay-ack拉高实际rt的案例" class="headerlink" title="delay ack拉高实际rt的案例"></a>delay ack拉高实际rt的案例</h2><p><strong>这个案例跟速度没有关系，只是解析监控图表上的rt为什么不符合逻辑地偏高了。</strong></p>
<p>如下业务监控图：实际处理时间（逻辑服务时间1ms，rtt2.4ms，加起来3.5ms），但是系统监控到的rt（蓝线）是6ms，如果一个请求分很多响应包串行发给client，这个6ms是正常的（1+2.4*N），但实际上如果send buffer足够的话，按我们前面的理解多个响应包会并发发出去，所以如果整个rt是3.5ms才是正常的。</p>
<p><img src="/images/oss/d56f87a19a10b0ac9a3b7009641247a0.png" alt="image.png"></p>
<p>抓包来分析原因：</p>
<p><img src="/images/oss/d5e2e358dd1a24e104f54815c84875c9.png" alt="image.png"></p>
<p>实际看到大量的response都是3.5ms左右，符合我们的预期，但是有少量rt被delay ack严重影响了</p>
<p>从下图也可以看到有很多rtt超过3ms的，这些超长时间的rtt会最终影响到整个服务rt</p>
<p><img src="/images/oss/48eae3dcd7c78a68b0afd5c66f783f23.png" alt="image.png"></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="http://www.allanjude.com/bsd/AsiaBSDCon2017_-_SSH_Performance.pdf" target="_blank" rel="external">SSH Performance</a></p>
<p><a href="https://stackoverflow.com/questions/8849240/why-when-i-transfer-a-file-through-sftp-it-takes-longer-than-ftp" target="_blank" rel="external">Why when I transfer a file through SFTP, it takes longer than FTP?</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/01/03/mac路由和DSN相关知识/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/01/03/mac路由和DSN相关知识/" itemprop="url">mac 路由和DSN相关知识</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-01-03T17:30:03+08:00">
                2021-01-03
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/其它/" itemprop="url" rel="index">
                    <span itemprop="name">其它</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="mac-路由和DSN相关知识"><a href="#mac-路由和DSN相关知识" class="headerlink" title="mac 路由和DSN相关知识"></a>mac 路由和DSN相关知识</h1><p>Mac 下上网,尤其是在双网卡一起使用的时候, 一个网卡连内网，一个网卡连外网，经常会碰到ip不通(路由问题,比较好解决)或者dns解析不了问题. 或者是在通过VPN连公司网络会插入一些内网route,导致部分网络访问不了.</p>
<p>即使对Linux下的DNS解析无比熟悉了，但是在Mac下还是花了一些时间来折腾，配置不好路由和DNS是不配使用Mac的，所以记录下。</p>
<h2 id="route"><a href="#route" class="headerlink" title="route"></a>route</h2><p>如果ip不通就看路由表, 根据内外网IP增加/删除相应的路由信息,常用命令如下:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">sudo route -n add 10.176/16 192.168.3.1</div><div class="line">sudo route -n add -net 10.176.0.0/16 192.168.3.1 //添加路由, 访问10.176.0.0/16 走192.168.3.1 </div><div class="line">sudo route -n delete -net 10.176.0.0/16 192.168.3.1</div><div class="line">sudo route -n delete 0.0.0.0 192.168.184.1</div><div class="line">sudo route -n add 0.0.0.0 192.168.184.1  //添加默认路由访问外网 </div><div class="line"></div><div class="line">sudo route -n delete 0.0.0.0 192.168.3.1</div><div class="line">sudo route -n add 10.176/16 192.168.3.1</div><div class="line">sudo route -n delete 0.0.0.0 192.168.184.1 -ifscope en0</div><div class="line">sudo route -n add 0.0.0.0 192.168.184.1 </div><div class="line">sudo networksetup -setdnsservers 'Apple USB Ethernet Adapter' 202.106.196.115 202.106.0.20 114.114.114.114</div><div class="line"></div><div class="line">sudo networksetup -setdnsservers 'USB 10/100/1000 LAN' 223.5.5.5 30.30.30.30 114.114.114.114</div><div class="line"></div><div class="line">ip route get 8.8.8.8 //linux</div><div class="line">route get 8.8.8.8    //macos</div><div class="line">netstat -rn          //查看路由  </div><div class="line">netstat -nr -f inet  //只看ipv4相关路由</div></pre></td></tr></table></figure>
<p>如果本来IP能通,连上VPN后就通不了,那一定是VPN加入了一些更精细的路由导致原来的路由不通了,那么很简单停掉VPN就能恢复或者增加一条更精确的路有记录进去,或者删掉VPN增加的某条路由.</p>
<h2 id="DNS-解析"><a href="#DNS-解析" class="headerlink" title="DNS 解析"></a>DNS 解析</h2><p>mac下DNS解析问题搞起来比较费劲,相应的资料也不多, 经过上面的操作后如果IP能通,域名解析有问题,一般都是DNS解析出了问题</p>
<p><a href="https://shockerli.net/post/macos-hostname-scutil/" target="_blank" rel="external">mac下 /etc/resolv.conf 不再用来解析域名, 只有nslookup能用到resolv.conf</a></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">cat /etc/resolv.conf                                                </div><div class="line"><span class="meta">#</span><span class="bash"></span></div><div class="line"><span class="meta">#</span><span class="bash"> macOS Notice</span></div><div class="line"><span class="meta">#</span><span class="bash"></span></div><div class="line"><span class="meta">#</span><span class="bash"> This file is not consulted <span class="keyword">for</span> DNS hostname resolution, address</span></div><div class="line"><span class="meta">#</span><span class="bash"> resolution, or the DNS query routing mechanism used by most</span></div><div class="line"><span class="meta">#</span><span class="bash"> processes on this system.</span></div><div class="line"><span class="meta">#</span><span class="bash"></span></div><div class="line"><span class="meta">#</span><span class="bash"> To view the DNS configuration used by this system, use:</span></div><div class="line"><span class="meta">#</span><span class="bash">   scutil --dns</span></div><div class="line"></div><div class="line">scutil --dns //查看DNS 解析器</div><div class="line">scutil --nwi //查看网络</div></pre></td></tr></table></figure>
<p>解析出了问题先检查nameserver</p>
<p>scutil –dns 一般会展示一大堆的resolver, 每个resolver又可以有多个nameserver</p>
<blockquote>
<p>A scoped DNS query can use only specified network interfaces (e.g. Ethernet or WiFi), while non-scoped can use any available interface.</p>
<p>More verbosely, an application that wants to resolve a name, sends a <em>request</em> (either scoped or non-scoped) to a resolver (usually a DNS client application), if the resolver does not have the answer cached, it sends a DNS <em>query</em> to a particular nameserver (and this goes through one interface, so it is always “scoped”).</p>
<p>In your example resolver #1 “for scoped queries” can use only en0 interface (Ethernet).</p>
</blockquote>
<h3 id="修改-nameserver"><a href="#修改-nameserver" class="headerlink" title="修改 nameserver"></a>修改 nameserver</h3><p>默认用第一个resolver, 如果第一个resolver没有nameserver那么域名没法解析, 可以修改dns resolver的nameserver: </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="meta">$</span><span class="bash">networksetup -listallnetworkservices  //列出网卡service, 比如 wifi ,以下是我的 macos 输出</span></div><div class="line">An asterisk (*) denotes that a network service is disabled.</div><div class="line">USB 10/100/1000 LAN</div><div class="line">Apple USB Ethernet Adapter</div><div class="line">Wi-Fi</div><div class="line">Bluetooth PAN</div><div class="line">Thunderbolt Bridge</div><div class="line"><span class="meta">$</span><span class="bash">sudo networksetup -setdnsservers <span class="string">'Wi-Fi'</span> 202.106.196.115 202.106.0.20 114.114.114.114 //修改nameserver</span></div><div class="line"><span class="meta">$</span><span class="bash">networksetup -getdnsservers Wi-Fi //查看对应的nameserver, 跟 scutil --dns 类似</span></div></pre></td></tr></table></figure>
<p>如上, 只要是你的nameserver工作正常那么DNS就肯定回复了</p>
<p>删掉所有DNS nameserver:</p>
<blockquote>
<p>One note to anyone wanting to remove the DNS, just write “empty” (without the quotes) instead of the DNS: <code>sudo networksetup -setdnsservers &lt;networkservice&gt; empty</code></p>
</blockquote>
<h2 id="networksetup用法"><a href="#networksetup用法" class="headerlink" title="networksetup用法"></a><a href="https://www.jianshu.com/p/c84e0f972353" target="_blank" rel="external">networksetup用法</a></h2><h3 id="查看设备和配置"><a href="#查看设备和配置" class="headerlink" title="查看设备和配置"></a>查看设备和配置</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line"><span class="meta">$</span><span class="bash">networksetup -listallnetworkservices</span></div><div class="line">An asterisk (*) denotes that a network service is disabled.</div><div class="line">USB 10/100/1000 LAN</div><div class="line">Apple USB Ethernet Adapter</div><div class="line">Wi-Fi</div><div class="line">Bluetooth PAN</div><div class="line">Thunderbolt Bridge</div><div class="line">Thunderbolt Bridge 2</div><div class="line"><span class="meta"></span></div><div class="line">#<span class="bash">查看网卡配置</span></div><div class="line"><span class="meta">$</span><span class="bash">networksetup -getinfo <span class="string">"USB 10/100/1000 LAN"</span>                                   </span></div><div class="line">DHCP Configuration</div><div class="line">IP address: 30.25.25.195</div><div class="line">Subnet mask: 255.255.255.128</div><div class="line">Router: 30.25.25.254</div><div class="line">Client ID:</div><div class="line">IPv6 IP address: none</div><div class="line">IPv6 Router: none</div><div class="line">Ethernet Address: 44:67:52:02:16:d4</div><div class="line"><span class="meta"></span></div><div class="line">$<span class="bash">networksetup -listallhardwareports</span></div><div class="line">Hardware Port: USB 10/100/1000 LAN</div><div class="line">Device: en7</div><div class="line">Ethernet Address: 44:67:52:02:16:d4</div><div class="line"></div><div class="line">Hardware Port: Wi-Fi</div><div class="line">Device: en0</div><div class="line">Ethernet Address: 88:66:5a:10:e4:2b</div><div class="line"></div><div class="line">Hardware Port: Thunderbolt Bridge</div><div class="line">Device: bridge0</div><div class="line">Ethernet Address: 82:0a:d5:01:b4:00</div><div class="line"></div><div class="line">VLAN Configurations</div><div class="line">===================</div><div class="line"><span class="meta">$</span><span class="bash">networksetup -getinfo <span class="string">"Thunderbolt Bridge"</span></span></div><div class="line">DHCP Configuration</div><div class="line">Client ID:</div><div class="line">IPv6: Automatic</div><div class="line">IPv6 IP address: none</div><div class="line">IPv6 Router: none</div><div class="line"></div><div class="line">//查看wifi和热点</div><div class="line">networksetup -listpreferredwirelessnetworks en0 </div><div class="line">networksetup -getairportnetwork "en0"</div></pre></td></tr></table></figure>
<h3 id="dhcp、route、domain配置"><a href="#dhcp、route、domain配置" class="headerlink" title="dhcp、route、domain配置"></a>dhcp、route、domain配置</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">[-setmanual networkservice ip subnet router]</div><div class="line"></div><div class="line">[-setdhcp networkservice [clientid]]</div><div class="line"></div><div class="line">[-setbootp networkservice]</div><div class="line"></div><div class="line">[-setmanualwithdhcprouter networkservice ip]</div><div class="line"></div><div class="line">[-getadditionalroutes networkservice]</div><div class="line"></div><div class="line">[-setadditionalroutes networkservice [dest1 mask1 gate1] [dest2 mask2 gate2] ..</div><div class="line"></div><div class="line">. [destN maskN gateN]]</div><div class="line"><span class="meta"></span></div><div class="line">#<span class="bash">给网卡配置ip、网关</span></div><div class="line"><span class="meta">$</span><span class="bash"> networksetup -getinfo <span class="string">"Apple USB Ethernet Adapter"</span>                                DHCP Configuration</span></div><div class="line">Client ID:</div><div class="line">IPv6: Automatic</div><div class="line">IPv6 IP address: none</div><div class="line">IPv6 Router: none</div><div class="line">Ethernet Address: (null)</div><div class="line"><span class="meta">$</span><span class="bash">networksetup -setmanual <span class="string">"Apple USB Ethernet Adapter"</span> 192.168.100.100 255.255.255.0 192.168.100.1</span></div><div class="line"><span class="meta">$</span><span class="bash">networksetup -getinfo <span class="string">"Apple USB Ethernet Adapter"</span></span></div><div class="line">Manual Configuration</div><div class="line">IP address: 192.168.100.100</div><div class="line">Subnet mask: 255.255.255.0</div><div class="line">Router: 192.168.100.1</div><div class="line">IPv6: Automatic</div><div class="line">IPv6 IP address: none</div><div class="line">IPv6 Router: none</div><div class="line">Ethernet Address: (null)</div></pre></td></tr></table></figure>
<h3 id="代理配置"><a href="#代理配置" class="headerlink" title="代理配置"></a>代理配置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">//ftp</div><div class="line">[-getftpproxy networkservice]</div><div class="line"></div><div class="line">[-setftpproxy networkservice domain portnumber authenticated username password]</div><div class="line"></div><div class="line">[-setftpproxystate networkservice on | off]</div></pre></td></tr></table></figure>
<p>网页</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[-getwebproxy networkservice]</div><div class="line">[-setwebproxy networkservice domain portnumber authenticated username password]</div><div class="line">[-setwebproxystate networkservice on | off]</div><div class="line"></div><div class="line">$networksetup -setwebproxy &quot;Built-in Ethernet&quot; proxy.company.com 80</div><div class="line">$networksetup -setwebproxy &quot;Built-In Ethernet&quot; proxy.company.com 80 On authusername authpassword</div></pre></td></tr></table></figure>
<p>Socks5 代理</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="meta">$</span><span class="bash">networksetup -setsocksfirewallproxy <span class="string">"USB 10/100/1000 LAN"</span> 127.0.0.1 13659</span></div><div class="line"><span class="meta">$</span><span class="bash">networksetup -getsocksfirewallproxy <span class="string">"USB 10/100/1000 LAN"</span></span></div><div class="line">Enabled: Yes</div><div class="line">Server: 127.0.0.1</div><div class="line">Port: 13659</div><div class="line">Authenticated Proxy Enabled: 0</div></pre></td></tr></table></figure>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>mac同时连wifi(外网或者vpn)和有线(内网), 如果内网干扰了访问外部ip, 就检查路由表,调整顺序. 如果内网干扰了dns,可以通过scutil –dns查看dns顺序到系统配置里去掉不必要的resolver</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://gowa.club/macOS/macOS%E7%9A%84networksetup%E5%91%BD%E4%BB%A4%E6%9D%A5%E7%AE%A1%E7%90%86%E7%BD%91%E7%BB%9C.html" target="_blank" rel="external">macOS的networksetup命令来管理网络</a></p>
<p><a href="https://www.diamondtin.com/2009/reloading-pac-script-in-mac/" target="_blank" rel="external">在Mac下使用脚本重载proxy自动配置脚本（pac）</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/01/01/网络相关知识/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/01/01/网络相关知识/" itemprop="url">网络硬件相关知识</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-01-01T17:30:03+08:00">
                2021-01-01
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/network/" itemprop="url" rel="index">
                    <span itemprop="name">network</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="网络硬件相关知识"><a href="#网络硬件相关知识" class="headerlink" title="网络硬件相关知识"></a>网络硬件相关知识</h1><p>程序员很难有机会接触到底层的一些东西,尤其是偏硬件部分,所以记录下</p>
<h2 id="光纤和普通网线的性能差异"><a href="#光纤和普通网线的性能差异" class="headerlink" title="光纤和普通网线的性能差异"></a>光纤和普通网线的性能差异</h2><p>以下都是在4.19内核的UOS，光纤交换机为锐捷，服务器是华为鲲鹏920的环境测试所得数据：</p>
<p><img src="/images/oss/553e1c5fff2dd04a668434f0da4f9d90.png" alt="image.png"></p>
<p>光纤稳定性好很多，平均rt是网线的三分之一，最大值则是网线的十分之一. 上述场景下光纤的带宽大约是网线的1.5倍. 实际光纤理论带宽一般都是万M, 网线是千M.</p>
<p>光纤接口：</p>
<p><img src="/images/oss/b67715de1b8e143f6fc17ba574bcf0c4.png" alt="image.png" style="zoom:60%;"></p>
<h3 id="单模光纤和多模光纤"><a href="#单模光纤和多模光纤" class="headerlink" title="单模光纤和多模光纤"></a>单模光纤和多模光纤</h3><p>下图绿色是多模光纤(Multi Mode Fiber),黄色是单模光纤(Single Mode Fiber), 因为光纤最好能和光模块匹配, 我们测试用的光模块都是多模的, 单模光纤线便宜,但是对应的光模块贵多了。</p>
<p>多模光模块工作波长为850nm，单模光模块工作波长为1310nm或1550nm, 从成本上来看，单模光模块所使用的设备多出多模光模块两倍，总体成本远高于多模光模块，但单模光模块的传输距离也要长于多模光模块，单模光模块最远传输距离为100km，多模光模块最远传输距离为2km。因单模光纤的传输原理为使光纤直射到中心，所以主要用作远距离数据传输，而多模光纤则为多通路传播模式，所以主要用于短距离数据传输。单模光模块适用于对距离和传输速率要求较高的大型网络中，多模光模块主要用于短途网路。</p>
<p><img src="/images/951413iMgBlog/image-20210831211315077.png" alt="image-20210831211315077"></p>
<p>ping结果比较:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div></pre></td><td class="code"><pre><div class="line">[aliyun@uos15 11:00 /home/aliyun]  以下88都是光口、89都是电口。</div><div class="line"><span class="meta">$</span>ping -c 10 10.88.88.16 //光纤</div><div class="line">PING 10.88.88.16 (10.88.88.16) 56(84) bytes of data.</div><div class="line">64 bytes from 10.88.88.16: icmp_seq=1 ttl=64 time=0.058 ms</div><div class="line">64 bytes from 10.88.88.16: icmp_seq=2 ttl=64 time=0.049 ms</div><div class="line">64 bytes from 10.88.88.16: icmp_seq=3 ttl=64 time=0.053 ms</div><div class="line">64 bytes from 10.88.88.16: icmp_seq=4 ttl=64 time=0.040 ms</div><div class="line">64 bytes from 10.88.88.16: icmp_seq=5 ttl=64 time=0.053 ms</div><div class="line">64 bytes from 10.88.88.16: icmp_seq=6 ttl=64 time=0.043 ms</div><div class="line">64 bytes from 10.88.88.16: icmp_seq=7 ttl=64 time=0.038 ms</div><div class="line">64 bytes from 10.88.88.16: icmp_seq=8 ttl=64 time=0.050 ms</div><div class="line">64 bytes from 10.88.88.16: icmp_seq=9 ttl=64 time=0.043 ms</div><div class="line">64 bytes from 10.88.88.16: icmp_seq=10 ttl=64 time=0.064 ms</div><div class="line"></div><div class="line">--- 10.88.88.16 ping statistics ---</div><div class="line">10 packets transmitted, 10 received, 0% packet loss, time 159ms</div><div class="line">rtt min/avg/max/mdev = 0.038/0.049/0.064/0.008 ms</div><div class="line"></div><div class="line">[aliyun@uos15 11:01 /home/aliyun]</div><div class="line"><span class="meta">$</span>ping -c 10 10.88.89.16 //电口</div><div class="line">PING 10.88.89.16 (10.88.89.16) 56(84) bytes of data.</div><div class="line">64 bytes from 10.88.89.16: icmp_seq=1 ttl=64 time=0.087 ms</div><div class="line">64 bytes from 10.88.89.16: icmp_seq=2 ttl=64 time=0.053 ms</div><div class="line">64 bytes from 10.88.89.16: icmp_seq=3 ttl=64 time=0.095 ms</div><div class="line">64 bytes from 10.88.89.16: icmp_seq=4 ttl=64 time=0.391 ms</div><div class="line">64 bytes from 10.88.89.16: icmp_seq=5 ttl=64 time=0.051 ms</div><div class="line">64 bytes from 10.88.89.16: icmp_seq=6 ttl=64 time=0.343 ms</div><div class="line">64 bytes from 10.88.89.16: icmp_seq=7 ttl=64 time=0.045 ms</div><div class="line">64 bytes from 10.88.89.16: icmp_seq=8 ttl=64 time=0.341 ms</div><div class="line">64 bytes from 10.88.89.16: icmp_seq=9 ttl=64 time=0.054 ms</div><div class="line">64 bytes from 10.88.89.16: icmp_seq=10 ttl=64 time=0.066 ms</div><div class="line"></div><div class="line">--- 10.88.89.16 ping statistics ---</div><div class="line">10 packets transmitted, 10 received, 0% packet loss, time 149ms</div><div class="line">rtt min/avg/max/mdev = 0.045/0.152/0.391/0.136 ms</div><div class="line"></div><div class="line">[aliyun@uos15 11:02 /u01]</div><div class="line"><span class="meta">$</span>scp uos.tar aliyun@10.88.89.16:/tmp/</div><div class="line">uos.tar                                  100% 3743MB 111.8MB/s   00:33    </div><div class="line"></div><div class="line">[aliyun@uos15 11:03 /u01]</div><div class="line"><span class="meta">$</span>scp uos.tar aliyun@10.88.88.16:/tmp/</div><div class="line">uos.tar                                   100% 3743MB 178.7MB/s   00:20    </div><div class="line"></div><div class="line">[aliyun@uos15 11:07 /u01]</div><div class="line"><span class="meta">$</span>sudo ping -f 10.88.89.16</div><div class="line">PING 10.88.89.16 (10.88.89.16) 56(84) bytes of data.</div><div class="line">--- 10.88.89.16 ping statistics ---</div><div class="line">284504 packets transmitted, 284504 received, 0% packet loss, time 702ms</div><div class="line">rtt min/avg/max/mdev = 0.019/0.040/1.014/0.013 ms, ipg/ewma 0.048/0.042 ms</div><div class="line"></div><div class="line">[aliyun@uos15 11:07 /u01]</div><div class="line"><span class="meta">$</span>sudo ping -f 10.88.88.16</div><div class="line">PING 10.88.88.16 (10.88.88.16) 56(84) bytes of data.</div><div class="line">--- 10.88.88.16 ping statistics ---</div><div class="line">299748 packets transmitted, 299748 received, 0% packet loss, time 242ms</div><div class="line">rtt min/avg/max/mdev = 0.012/0.016/0.406/0.006 ms, pipe 2, ipg/ewma 0.034/0.014 ms</div></pre></td></tr></table></figure>
<h2 id="多网卡bonding"><a href="#多网卡bonding" class="headerlink" title="多网卡bonding"></a>多网卡bonding</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span>cat ifcfg-bond0</div><div class="line">DEVICE=bond0</div><div class="line">TYPE=Bond</div><div class="line">ONBOOT=yes</div><div class="line">BOOTPROTO=static</div><div class="line">IPADDR=10.176.7.11</div><div class="line">NETMASK=255.255.255.0</div><div class="line"><span class="meta"></span></div><div class="line">#cat /etc/sysconfig/network-scripts/ifcfg-eth0</div><div class="line">DEVICE=eth0</div><div class="line">TYPE=Ethernet</div><div class="line">ONBOOT=yes</div><div class="line">BOOTPROTO=none</div><div class="line">MASTER=bond0</div><div class="line">SLAVE=yes</div><div class="line"><span class="meta"></span></div><div class="line">#cat /etc/sysconfig/network-scripts/ifcfg-eth1</div><div class="line">DEVICE=eth1</div><div class="line">TYPE=Ethernet</div><div class="line">ONBOOT=yes</div><div class="line">BOOTPROTO=none</div><div class="line">MASTER=bond0</div><div class="line">SLAVE=yes</div><div class="line"><span class="meta"></span></div><div class="line">#cat /proc/net/bonding/bond0</div><div class="line"></div><div class="line">----加载内核bonding模块, mode=0 是RR负载均衡模式</div><div class="line"><span class="meta">#</span>cat /etc/modprobe.d/bonding.conf</div><div class="line"><span class="meta">#</span> modprobe bonding</div><div class="line">alias bond0 bonding</div><div class="line">options bond0 mode=0 miimon=100  //这一行也可以放到bond0配置文件中,比如:BONDING_OPTS="miimon=100 mode=4 xmit_hash_policy=layer3+4" 用iperf 多连接测试bonding后的带宽发现，发送端能用上两张网卡，但是接收队列只能使用一张物理网卡</div></pre></td></tr></table></figure>
<p>网卡绑定mode共有七种(0~6) bond0、bond1、bond2、bond3、bond4、bond5、bond6</p>
<p>常用的有三种</p>
<ul>
<li><p>mode=0：平衡负载模式 <strong>(balance-rr)</strong>，有自动备援，两块物理网卡和bond网卡使用同一个mac地址，但需要”Switch”支援及设定。</p>
</li>
<li><p>mode=1：自动备援模式 <strong>(balance-backup)</strong>，其中一条线若断线，其他线路将会自动备援。</p>
</li>
<li><p>mode=6：平衡负载模式<strong>(balance-alb)</strong>，有自动备援，不必”Switch”支援及设定，两块网卡是使用不同的MAC地址</p>
</li>
<li><strong>Mode 4 (802.3ad)</strong>: This mode creates aggregation groups that share the same speed and duplex settings, and it requires a switch that supports an IEEE 802.3ad dynamic link. Mode 4 uses all interfaces in the active aggregation group. For example, you can aggregate three 1 GB per second (GBPS) ports into a 3 GBPS trunk port. This is equivalent to having one interface with 3 GBPS speed. It provides fault tolerance and load balancing.</li>
</ul>
<p>需要说明的是如果想做成mode 0的负载均衡,仅仅设置这里options bond0 miimon=100 mode=0是不够的,与网卡相连的交换机必须做特殊配置（这两个端口应该采取聚合方式），因为做bonding的这两块网卡是使用同一个MAC地址.从原理分析一下（bond运行在mode 0下）：</p>
<p>mode 0下bond所绑定的网卡的IP都被修改成相同的mac地址，如果这些网卡都被接在同一个交换机，那么交换机的arp表里这个mac地址对应的端口就有多 个，那么交换机接受到发往这个mac地址的包应该往哪个端口转发呢？正常情况下mac地址是全球唯一的，一个mac地址对应多个端口肯定使交换机迷惑了。所以 mode0下的bond如果连接到交换机，交换机这几个端口应该采取聚合方式（cisco称为 ethernetchannel，foundry称为portgroup），因为交换机做了聚合后，聚合下的几个端口也被捆绑成一个mac地址.我们的解决办法是，两个网卡接入不同的交换机即可。</p>
<p>mode6模式下无需配置交换机，因为做bonding的这两块网卡是使用不同的MAC地址。</p>
<p>mod=5，即：(balance-tlb) Adaptive transmit load balancing（适配器传输负载均衡）</p>
<p>特点：不需要任何特别的switch(交换机)支持的通道bonding。在每个slave上根据当前的负载（根据速度计算）分配外出流量。如果正在接受数据的slave出故障了，另一个slave接管失败的slave的MAC地址。</p>
<p>该模式的必要条件：ethtool支持获取每个slave的速率.</p>
<p>案例，两块万兆bonding后带宽翻倍</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div></pre></td><td class="code"><pre><div class="line">#ethtool bond0</div><div class="line">Settings for bond0:</div><div class="line">	Supported ports: [ ]</div><div class="line">	Supported link modes:   Not reported</div><div class="line">	Supported pause frame use: No</div><div class="line">	Supports auto-negotiation: No</div><div class="line">	Advertised link modes:  Not reported</div><div class="line">	Advertised pause frame use: No</div><div class="line">	Advertised auto-negotiation: No</div><div class="line">	Speed: 20000Mb/s</div><div class="line">	Duplex: Full</div><div class="line">	Port: Other</div><div class="line">	PHYAD: 0</div><div class="line">	Transceiver: internal</div><div class="line">	Auto-negotiation: off</div><div class="line">	Link detected: yes</div><div class="line"></div><div class="line">[root@phy 16:55 /root]</div><div class="line">#cat /etc/sysconfig/network-scripts/ifcfg-bond0</div><div class="line">DEVICE=bond0</div><div class="line">BOOTPROTO=static</div><div class="line">TYPE=&quot;ethernet&quot;</div><div class="line">IPADDR=100.1.1.2</div><div class="line">NETMASK=255.255.255.192</div><div class="line">ONBOOT=yes</div><div class="line">USERCTL=no</div><div class="line">PEERDNS=no</div><div class="line">BONDING_OPTS=&quot;miimon=100 mode=4 xmit_hash_policy=layer3+4&quot;</div><div class="line"></div><div class="line">#cat /etc/modprobe.d/bonding.conf</div><div class="line">alias netdev-bond0 bonding</div><div class="line"></div><div class="line">#lsmod |grep bond</div><div class="line">bonding               137339  0</div><div class="line"></div><div class="line">#cat ifcfg-bond0</div><div class="line">DEVICE=bond0</div><div class="line">BOOTPROTO=static</div><div class="line">TYPE=&quot;ethernet&quot;</div><div class="line">IPADDR=100.81.131.221</div><div class="line">NETMASK=255.255.255.192</div><div class="line">ONBOOT=yes</div><div class="line">USERCTL=no</div><div class="line">PEERDNS=no</div><div class="line">BONDING_OPTS=&quot;miimon=100 mode=4 xmit_hash_policy=layer3+4&quot;</div><div class="line"></div><div class="line">#cat ifcfg-eth1</div><div class="line">DEVICE=eth1</div><div class="line">TYPE=&quot;Ethernet&quot;</div><div class="line">HWADDR=7C:D3:0A:E0:F7:81</div><div class="line">BOOTPROTO=none</div><div class="line">ONBOOT=yes</div><div class="line">MASTER=bond0</div><div class="line">SLAVE=yes</div><div class="line">PEERDNS=no</div><div class="line">RX_MAX=`ethtool -g &quot;$DEVICE&quot; | grep &apos;Pre-set&apos; -A1 | awk &apos;/RX/&#123;print $2&#125;&apos;`</div><div class="line">RX_CURRENT=`ethtool -g &quot;$DEVICE&quot; | grep &quot;Current&quot; -A1 | awk &apos;/RX/&#123;print $2&#125;&apos;`</div><div class="line">[[ &quot;$RX_CURRENT&quot; -lt &quot;$RX_MAX&quot; ]] &amp;&amp; ethtool -G &quot;$DEVICE&quot; rx &quot;$RX_MAX&quot;</div></pre></td></tr></table></figure>
<h2 id="网络中断和绑核"><a href="#网络中断和绑核" class="headerlink" title="网络中断和绑核"></a>网络中断和绑核</h2><p>网络包的描述符的内存（RingBuffer）跟着设备走（设备在哪个Die/Node上，就近分配内存）， 数据缓冲区（Data Buffer–存放网络包）内存跟着队列(中断)走， 如果队列绑定到DIE0， 而设备在die1上，这样在做DMA通信时， <a href="https://ata.alibaba-inc.com/articles/230545" target="_blank" rel="external">会产生跨die的交织访问</a>。</p>
<p>不管设备插在哪一个die上， 只要描述符申请的内存和数据缓冲区的内存都在同一个die上（需要修改驱动源代码–非常规），就能避免跨die内存交织， 性能能保持一致。</p>
<p><strong>irqbalance服务不会将中断进行跨node迁移，只会在同一numa node中进行优化。</strong></p>
<h3 id="ethtool"><a href="#ethtool" class="headerlink" title="ethtool"></a>ethtool</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span>ethtool -i p1p1   //查询网卡bus-info</div><div class="line">driver: mlx5_core</div><div class="line">version: 5.0-0</div><div class="line">firmware-version: 14.27.1016 (MT_2420110004)</div><div class="line">expansion-rom-version:</div><div class="line">bus-info: 0000:21:00.0</div><div class="line">supports-statistics: yes</div><div class="line">supports-test: yes</div><div class="line">supports-eeprom-access: no</div><div class="line">supports-register-dump: no</div><div class="line">supports-priv-flags: yes</div><div class="line"></div><div class="line">//根据bus-info找到中断id</div><div class="line"><span class="meta">#</span>cat /proc/interrupts | grep 0000:21:00.0 | awk -F: '&#123;print $1&#125;' | wc -l</div><div class="line"></div><div class="line">//修改网卡队列数</div><div class="line">sudo ethtool -L eth0  combined 2 （不能超过网卡最大队列数）</div><div class="line"></div><div class="line">然后检查是否生效了(不需要重启应用和机器，实时生效)：</div><div class="line">sudo ethtool -l eth0</div></pre></td></tr></table></figure>
<p>根据网卡bus-info可以找到对应的irq id</p>
<p>手工绑核脚本:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span>!/bin/bash</div><div class="line"><span class="meta">#</span>irq_list=(`cat /proc/interrupts | grep enp131s0 | awk -F: '&#123;print $1&#125;'`)</div><div class="line">intf=$1</div><div class="line">irq_list=(cat /proc/interrupts | grep `ethtool -i $intf |grep bus-info | awk  '&#123; print $2 &#125;'` | awk -F: '&#123;print $1&#125;')</div><div class="line">cpunum=48  # 修改为所在node的第一个Core</div><div class="line">for irq in $&#123;irq_list[@]&#125;</div><div class="line">do</div><div class="line">echo $cpunum &gt; /proc/irq/$irq/smp_affinity_list</div><div class="line">echo `cat /proc/irq/$irq/smp_affinity_list`</div><div class="line">(( cpunum+=1 ))</div><div class="line">done</div></pre></td></tr></table></figure>
<p>检查绑定结果: sh irqCheck.sh enp131s0</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span> 网卡名</div><div class="line">intf=$1</div><div class="line">irqID=`ethtool -i $intf |grep bus-info | awk  '&#123; print $2 &#125;'`</div><div class="line">log=irqSet-`date "+%Y%m%d-%H%M%S"`.log</div><div class="line"><span class="meta">#</span> 可用的CPU数</div><div class="line">cpuNum=$(cat /proc/cpuinfo |grep processor -c)</div><div class="line"><span class="meta">#</span> RX TX中断列表</div><div class="line">irqListRx=$(cat /proc/interrupts | grep $&#123;irqID&#125; | awk -F':' '&#123;print $1&#125;')</div><div class="line">irqListTx=$(cat /proc/interrupts | grep $&#123;irqID&#125; | awk -F':' '&#123;print $1&#125;')</div><div class="line"><span class="meta">#</span> 绑定接收中断rx irq</div><div class="line">for irqRX in $&#123;irqListRx[@]&#125;</div><div class="line">do</div><div class="line">cat /proc/irq/$&#123;irqRX&#125;/smp_affinity_list</div><div class="line">done</div><div class="line"><span class="meta">#</span> 绑定发送中断tx irq</div><div class="line">for irqTX in $&#123;irqListTx[@]&#125;</div><div class="line">do</div><div class="line">cat /proc/irq/$&#123;irqTX&#125;/smp_affinity_list</div><div class="line">done</div></pre></td></tr></table></figure>
<h3 id="中断联合（Coalescing）"><a href="#中断联合（Coalescing）" class="headerlink" title="中断联合（Coalescing）"></a>中断联合（Coalescing）</h3><p>中断联合可供我们推迟向内核通告新事件的操作，将多个事件汇总在一个中断中通知内核。该功能的当前设置可通过<code>ethtool -c</code>查看：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">$ ethtool -c eth0</div><div class="line">Coalesce parameters for eth0:</div><div class="line">...</div><div class="line">rx-usecs: 50</div><div class="line">tx-usecs: 50</div></pre></td></tr></table></figure>
<p>此处可以设置固定上限，对每内核每秒处理中断数量的最大值进行硬性限制，或针对特定硬件根据吞吐率<a href="https://community.mellanox.com/docs/DOC-2511" target="_blank" rel="external">自动调整中断速率</a>。</p>
<p>启用联合（使用<code>-C</code>）会增大延迟并可能导致丢包，因此对延迟敏感的工作可能需要避免这样做。另外，彻底禁用该功能可能导致中断受到节流限制，进而影响性能。</p>
<p>多次在nginx场景下测试未发现这个值对TPS有什么明显的改善</p>
<p><a href="https://blog.cloudflare.com/how-to-achieve-low-latency/" target="_blank" rel="external">How to achieve low latency with 10Gbps Ethernet</a> 中有提到 Linux 3.11 added support for the <a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/open-source-kernel-enhancements-paper.pdf" target="_blank" rel="external"><code>SO_BUSY_POLL</code> socket option</a>.  也有类似的作用</p>
<h3 id="irqbalance"><a href="#irqbalance" class="headerlink" title="irqbalance"></a><a href="https://access.redhat.com/documentation/zh-cn/red_hat_enterprise_linux/7/html/performance_tuning_guide/appe-red_hat_enterprise_linux-performance_tuning_guide-tool_reference" target="_blank" rel="external">irqbalance</a></h3><p><strong>irqbalance</strong> 是一个命令行工具，在处理器中分配硬件中断以提高系统性能。默认设置下在后台程序运行，但只可通过 <code>--oneshot</code> 选项运行一次。</p>
<p>以下参数可用于提高性能。</p>
<ul>
<li><p>–powerthresh</p>
<p>CPU 进入节能模式之前，设定可空闲的 CPU 数量。如果有大于阀值数量的 CPU 是大于一个标准的偏差，该差值低于平均软中断工作负载，以及没有 CPU 是大于一个标准偏差，且该偏差高出平均，并有多于一个的 irq 分配给它们，一个 CPU 将处于节能模式。在节能模式中，CPU 不是 irqbalance 的一部分，所以它在有必要时才会被唤醒。</p>
</li>
<li><p>–hintpolicy</p>
<p>决定如何解决 irq 内核关联提示。有效值为 <code>exact</code>（总是应用 irq 关联提示）、<code>subset</code> （irq 是平衡的，但分配的对象是关联提示的子集）、或者 <code>ignore</code>（irq 完全被忽略）。</p>
</li>
<li><p>–policyscript</p>
<p>通过设备路径、当作参数的irq号码以及 <strong>irqbalance</strong> 预期的零退出代码，定义脚本位置以执行每个中断请求。定义的脚本能指定零或多键值对来指导管理传递的 irq 中 <strong>irqbalance</strong>。下列是为效键值对：ban有效值为 <code>true</code>（从平衡中排除传递的 irq）或 <code>false</code>（该 irq 表现平衡）。balance_level允许用户重写传递的 irq 平衡度。默认设置下，平衡度基于拥有 irq 设备的 PCI 设备种类。有效值为 <code>none</code>、<code>package</code>、<code>cache</code>、或 <code>core</code>。numa_node允许用户重写视作为本地传送 irq 的 NUMA 节点。如果本地节点的信息没有限定于 ACPI ，则设备被视作与所有节点距离相等。有效值为识别特定 NUMA 节点的整数（从0开始）和 <code>-1</code>，规定 irq 应被视作与所有节点距离相等。</p>
</li>
<li><p>–banirq</p>
<p>将带有指定中断请求号码的中断添加至禁止中断的列表。</p>
</li>
</ul>
<p>也可以使用 <em><code>IRQBALANCE_BANNED_CPUS</code></em> 环境变量来指定被 <strong>irqbalance</strong> 忽略的 CPU 掩码。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">//默认irqbalance绑定一个numa, -1指定多个numa</div><div class="line">echo -1 &gt;/sys/bus/pci/devices/`ethtool -i p1p1 |grep bus-info | awk  '&#123; print $2 &#125;'`/numa_node ; </div><div class="line">// 目录 /sys/class/net/p1p1/ link到了 /sys/bus/pci/devices/`ethtool -i p1p1 |grep bus-info | awk  '&#123; print $2 &#125;'` </div><div class="line"></div><div class="line">执行 irqbalance --debug 进行调试</div></pre></td></tr></table></figure>
<h4 id="irqbalance指定core"><a href="#irqbalance指定core" class="headerlink" title="irqbalance指定core"></a><a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux_for_real_time/7/html/tuning_guide/interrupt_and_process_binding" target="_blank" rel="external">irqbalance指定core</a></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">cat /etc/sysconfig/irqbalance</div><div class="line"># IRQBALANCE_BANNED_CPUS</div><div class="line"># 64 bit bitmask which allows you to indicate which cpu&apos;s should</div><div class="line"># be skipped when reblancing irqs. Cpu numbers which have their</div><div class="line"># corresponding bits set to one in this mask will not have any</div><div class="line"># irq&apos;s assigned to them on rebalance</div><div class="line">#绑定软中断到8-15core, 每位表示4core</div><div class="line">#IRQBALANCE_BANNED_CPUS=ffffffff,ffff00ff</div><div class="line">#绑定软中断到8-15core和第65core</div><div class="line">IRQBALANCE_BANNED_CPUS=ffffffff,fffffdff,ffffffff,ffff00ff</div><div class="line"></div><div class="line">#96core 鲲鹏920下绑前16core</div><div class="line">IRQBALANCE_BANNED_CPUS=ffffffff,ffffffff,ffff0000</div></pre></td></tr></table></figure>
<h4 id="irqbalance的流程"><a href="#irqbalance的流程" class="headerlink" title="irqbalance的流程"></a><a href="https://blog.csdn.net/whrszzc/article/details/50533866" target="_blank" rel="external">irqbalance的流程</a></h4><p>初始化的过程只是建立链表的过程，暂不描述，只考虑正常运行状态时的流程<br>-处理间隔是10s<br>-清除所有中断的负载值<br>-/proc/interrupts读取中断，并记录中断数<br>-/proc/stat读取每个cpu的负载，并依次计算每个层次每个节点的负载以及每个中断的负载<br>-通过平衡算法找出需要重新分配的中断<br>-把需要重新分配的中断加入到新的节点中<br>-配置smp_affinity使处理生效</p>
<p><strong>irqbalance服务不会将中断进行跨node迁移，只会在同一numa node中进行优化。</strong></p>
<h3 id="网卡软中断以及内存远近的测试结论"><a href="#网卡软中断以及内存远近的测试结论" class="headerlink" title="网卡软中断以及内存远近的测试结论"></a><a href="https://ata.alibaba-inc.com/articles/230545" target="_blank" rel="external">网卡软中断以及内存远近</a>的测试结论</h3><p>一般网卡中断会占用一些CPU，如果把网卡中断挪到其它node的core上，在鲲鹏920上测试（网卡插在node0上），业务跑在node3，网卡中断分别在node0和node3，QPS分别是：179000 VS 175000</p>
<p>如果将业务跑在node0上，网卡中断分别在node0和node1上得到的QPS分别是：204000 VS 212000 </p>
<p>以上测试的时候业务进程分配的内存全限制在node0上</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">#/root/numa-maps-summary.pl &lt;/proc/123853/numa_maps</div><div class="line">N0        :      5085548 ( 19.40 GB)</div><div class="line">N1        :         4479 (  0.02 GB)</div><div class="line">N2        :            1 (  0.00 GB)</div><div class="line">active    :            0 (  0.00 GB)</div><div class="line">anon      :      5085455 ( 19.40 GB)</div><div class="line">dirty     :      5085455 ( 19.40 GB)</div><div class="line">kernelpagesize_kB:         2176 (  0.01 GB)</div><div class="line">mapmax    :          348 (  0.00 GB)</div><div class="line">mapped    :         4626 (  0.02 GB)</div></pre></td></tr></table></figure>
<p>从以上测试数据可以看到在这个内存分布场景下，如果就近访问内存性能有20%以上的提升</p>
<p>一般默认申请的data buffer也都在设备所在的numa节点上<strong>， 如果将队列的中断绑定到其他cpu上， 那么</strong>队列申请的data buffer的节点也会跟着中断迁移。</p>
<h3 id="阿里云绑核脚本"><a href="#阿里云绑核脚本" class="headerlink" title="阿里云绑核脚本"></a>阿里云绑核脚本</h3><p>通常情况下，Linux的网卡中断是由一个CPU核心来处理的，当承担高流量的场景下，会出现一些诡异的情况（网卡尚未达到瓶颈，但是却出现丢包的情况）</p>
<p>这种时候，我们最好看下网卡中断是不是缺少调优。</p>
<p>优化3要点：网卡多队列+irq affinity亲缘性设置+关闭irqbalance (systemctl stop irqbalance)</p>
<p>目前阿里云官方提供的centos和ubuntu镜像里面，已经自带了优化脚本，内容如下:</p>
<p><strong>centos7的脚本路径在 /usr/sbin/ecs_mq_rps_rfs 具体内容如下：</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span>!/bin/bash</div><div class="line"><span class="meta">#</span> This is the default setting of networking multiqueue and irq affinity</div><div class="line"><span class="meta">#</span> 1. enable multiqueue if available</div><div class="line"><span class="meta">#</span> 2. irq affinity optimization</div><div class="line"><span class="meta">#</span> 3. stop irqbalance service</div><div class="line"><span class="meta">#</span> set and check multiqueue</div><div class="line"></div><div class="line">function set_check_multiqueue()</div><div class="line">&#123;</div><div class="line">    eth=$1</div><div class="line">    log_file=$2</div><div class="line">    queue_num=$(ethtool -l $eth | grep -ia5 'pre-set' | grep -i combined | awk &#123;'print $2'&#125;)</div><div class="line">    if [ $queue_num -gt 1 ]; then</div><div class="line">        # set multiqueue</div><div class="line">        ethtool -L $eth combined $queue_num</div><div class="line">        # check multiqueue setting</div><div class="line">        cur_q_num=$(ethtool -l $eth | grep -iA5 current | grep -i combined | awk &#123;'print $2'&#125;)</div><div class="line">        if [ "X$queue_num" != "X$cur_q_num" ]; then</div><div class="line">            echo "Failed to set $eth queue size to $queue_num" &gt;&gt; $log_file</div><div class="line">            echo "after setting, pre-set queue num: $queue_num , current: $cur_q_num" &gt;&gt; $log_file</div><div class="line">            return 1</div><div class="line">        else</div><div class="line">            echo "OK. set $eth queue size to $queue_num" &gt;&gt; $log_file</div><div class="line">        fi</div><div class="line">    else</div><div class="line">        echo "only support $queue_num queue; no need to enable multiqueue on $eth" &gt;&gt; $log_file</div><div class="line">    fi</div><div class="line">&#125;</div><div class="line"><span class="meta"></span></div><div class="line">#set irq affinity</div><div class="line">function set_irq_smpaffinity()</div><div class="line">&#123;</div><div class="line">    log_file=$1</div><div class="line">    node_dir=/sys/devices/system/node</div><div class="line">    for i in $(ls -d $node_dir/node*); do</div><div class="line">        i=$&#123;i/*node/&#125;</div><div class="line">    done</div><div class="line">    </div><div class="line">    echo "max node :$i" &gt;&gt; $log_file</div><div class="line">    node_cpumax=$(cat /sys/devices/system/node/node$&#123;i&#125;/cpulist |awk -F- '&#123;print $NF&#125;')</div><div class="line">    irqs=($(cat /proc/interrupts |grep virtio |grep put | awk -F: '&#123;print $1&#125;'))</div><div class="line">    core=0</div><div class="line">    for irq in $&#123;irqs[@]&#125;;do</div><div class="line">        VEC=$core</div><div class="line">        if [ $VEC -ge 32 ];then</div><div class="line">            let "IDX = $VEC / 32"</div><div class="line">            MASK_FILL=""</div><div class="line">            MASK_ZERO="00000000"</div><div class="line">            for ((i=1; i&lt;=$IDX;i++))</div><div class="line">                do</div><div class="line">                    MASK_FILL="$&#123;MASK_FILL&#125;,$&#123;MASK_ZERO&#125;"</div><div class="line">                done</div><div class="line">            let "VEC -= 32 * $IDX"</div><div class="line">            MASK_TMP=$((1&lt;&lt;$VEC))</div><div class="line">            MASK=$(printf "%X%s" $MASK_TMP $MASK_FILL)</div><div class="line">        else</div><div class="line">            MASK_TMP=$((1&lt;&lt;$VEC))</div><div class="line">            MASK=$(printf "%X" $MASK_TMP)</div><div class="line">        fi</div><div class="line">        echo $MASK &gt; /proc/irq/$irq/smp_affinity</div><div class="line">        echo "mask:$MASK, irq:$irq" &gt;&gt; $log_file</div><div class="line">        core=$(((core+1)%(node_cpumax+1)))</div><div class="line">    done</div><div class="line">&#125;</div><div class="line"><span class="meta"></span></div><div class="line"># stop irqbalance service</div><div class="line">function stop_irqblance()</div><div class="line">&#123;</div><div class="line">    log_file=$1</div><div class="line">    ret=0</div><div class="line">    if [ "X" != "X$(ps -ef | grep irqbalance | grep -v grep)" ]; then</div><div class="line">        if which systemctl;then</div><div class="line">            systemctl stop irqbalance</div><div class="line">        else</div><div class="line">            service irqbalance stop</div><div class="line">        fi</div><div class="line">        if [ $? -ne 0 ]; then</div><div class="line">            echo "Failed to stop irqbalance" &gt;&gt; $log_file</div><div class="line">            ret=1</div><div class="line">        fi</div><div class="line">    else</div><div class="line">       echo "OK. irqbalance stoped." &gt;&gt; $log_file</div><div class="line">    fi</div><div class="line">    return $ret</div><div class="line">&#125;</div><div class="line"><span class="meta">#</span> main logic</div><div class="line">function main()</div><div class="line">&#123;</div><div class="line">    ecs_network_log=/var/log/ecs_network_optimization.log</div><div class="line">    ret_value=0</div><div class="line">    echo "running $0" &gt; $ecs_network_log</div><div class="line">    echo "========  ECS network setting starts $(date +'%Y-%m-%d %H:%M:%S') ========" &gt;&gt; $ecs_network_log</div><div class="line">    # we assume your NIC interface(s) is/are like eth*</div><div class="line">    eth_dirs=$(ls -d /sys/class/net/eth*)</div><div class="line">    if [ "X$eth_dirs" = "X" ]; then</div><div class="line">        echo "ERROR! can not find any ethX in /sys/class/net/ dir." &gt;&gt; $ecs_network_log</div><div class="line">        ret_value=1</div><div class="line">    fi</div><div class="line">    for i in $eth_dirs</div><div class="line">    do</div><div class="line">        cur_eth=$(basename $i)</div><div class="line">        echo "optimize network performance: current device $cur_eth" &gt;&gt; $ecs_network_log</div><div class="line">        # only optimize virtio_net device</div><div class="line">        driver=$(basename $(readlink $i/device/driver))</div><div class="line">        if ! echo $driver | grep -q virtio; then</div><div class="line">            echo "ignore device $cur_eth with driver $driver" &gt;&gt; $ecs_network_log</div><div class="line">            continue</div><div class="line">        fi</div><div class="line">        echo "set and check multiqueue on $cur_eth" &gt;&gt; $ecs_network_log</div><div class="line">        set_check_multiqueue $cur_eth $ecs_network_log</div><div class="line">        if [ $? -ne 0 ]; then</div><div class="line">            echo "Failed to set multiqueue on $cur_eth" &gt;&gt; $ecs_network_log</div><div class="line">            ret_value=1</div><div class="line">        fi</div><div class="line">    done</div><div class="line">    stop_irqblance  $ecs_network_log</div><div class="line">    set_irq_smpaffinity $ecs_network_log</div><div class="line">    echo "========  ECS network setting END $(date +'%Y-%m-%d %H:%M:%S')  ========" &gt;&gt; $ecs_network_log</div><div class="line">    return $ret_value</div><div class="line">&#125;</div><div class="line"><span class="meta"></span></div><div class="line"></div><div class="line"># program starts here</div><div class="line">main</div><div class="line">exit $?</div></pre></td></tr></table></figure>
<p>查询的rps绑定情况的脚本 get_rps.sh</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span>!/bin/bash</div><div class="line"><span class="meta">#</span> 获取当前rps情况</div><div class="line">for i in $(ls /sys/class/net/eth0/queues/rx-*/rps_cpus); do </div><div class="line">  echo $i</div><div class="line">  cat $i</div><div class="line">done</div></pre></td></tr></table></figure>
<h2 id="查看网卡和numa的关系"><a href="#查看网卡和numa的关系" class="headerlink" title="查看网卡和numa的关系"></a>查看网卡和numa的关系</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">#yum install lshw -y</div><div class="line">#lshw -C network -short</div><div class="line">H/W path               Device          Class      Description</div><div class="line">=============================================================</div><div class="line">/0/100/0/9/0           eth0            network    MT27710 Family [ConnectX-4 Lx]</div><div class="line">/0/100/0/9/0.1         eth1            network    MT27710 Family [ConnectX-4 Lx]</div><div class="line">/1                     e41358fae4ee_h  network    Ethernet interface</div><div class="line">/2                     86b0637ef1e1_h  network    Ethernet interface</div><div class="line">/3                     a6706e785f53_h  network    Ethernet interface</div><div class="line">/4                     d351290e50a0_h  network    Ethernet interface</div><div class="line">/5                     1a9e5df98dd1_h  network    Ethernet interface</div><div class="line">/6                     766ec0dab599_h  network    Ethernet interface</div><div class="line">/7                     bond0.11        network    Ethernet interface</div><div class="line">/8                     ea004888c217_h  network    Ethernet interface</div></pre></td></tr></table></figure>
<p>以及：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">lscpu | grep -i numa</div><div class="line">numactl --hardware</div><div class="line">cat /proc/interrupts | egrep -i &quot;CPU|rx&quot;</div></pre></td></tr></table></figure>
<p><a href="https://ixnfo.com/en/how-to-find-out-on-which-numa-node-network-interfaces.html" target="_blank" rel="external">Check if the network interfaces are tied to Numa</a> (if -1 means not tied, if 0, then to numa0):</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cat /sys/class/net/eth0/device/numa_node</div></pre></td></tr></table></figure>
<p>You can see which NAMA the network card belongs to, for example, using lstopo:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div></pre></td><td class="code"><pre><div class="line">yum install hwloc -y</div><div class="line">lstopo</div><div class="line">lstopo --logical</div><div class="line">lstopo --logical --output-format png &gt; lstopo.png</div><div class="line"></div><div class="line">--</div><div class="line">[root@hygon3 10:58 /root]  //hygon 7280 CPU</div><div class="line">#lstopo --logical</div><div class="line">Machine (503GB total)               //总内存大小</div><div class="line">  NUMANode L#0 (P#0 252GB)          //socket0、numa0 的内存大小</div><div class="line">    Package L#0</div><div class="line">      L3 L#0 (8192KB)               //L3 cache，对应4个物理core，8个HT</div><div class="line">        L2 L#0 (512KB) + L1d L#0 (32KB) + L1i L#0 (64KB) + Core L#0 // L1/L2</div><div class="line">          PU L#0 (P#0)</div><div class="line">          PU L#1 (P#64)</div><div class="line">        L2 L#1 (512KB) + L1d L#1 (32KB) + L1i L#1 (64KB) + Core L#1</div><div class="line">          PU L#2 (P#1)</div><div class="line">          PU L#3 (P#65)</div><div class="line">        L2 L#2 (512KB) + L1d L#2 (32KB) + L1i L#2 (64KB) + Core L#2</div><div class="line">          PU L#4 (P#2)</div><div class="line">          PU L#5 (P#66)</div><div class="line">        L2 L#3 (512KB) + L1d L#3 (32KB) + L1i L#3 (64KB) + Core L#3</div><div class="line">          PU L#6 (P#3)</div><div class="line">          PU L#7 (P#67)</div><div class="line">      L3 L#1 (8192KB)</div><div class="line">      L3 L#2 (8192KB)</div><div class="line">      L3 L#3 (8192KB)</div><div class="line">      L3 L#4 (8192KB)</div><div class="line">      L3 L#5 (8192KB)</div><div class="line">      L3 L#6 (8192KB)</div><div class="line">      L3 L#7 (8192KB)</div><div class="line">    HostBridge L#0</div><div class="line">      PCIBridge</div><div class="line">        PCIBridge</div><div class="line">          PCI 1a03:2000</div><div class="line">            GPU L#0 &quot;controlD64&quot;</div><div class="line">            GPU L#1 &quot;card0&quot;</div><div class="line">      PCIBridge</div><div class="line">        PCI 1d94:7901</div><div class="line">          Block(Disk) L#2 &quot;sdm&quot;   //ssd系统盘，接在Node0上，绑核有优势</div><div class="line">    HostBridge L#4</div><div class="line">      PCIBridge</div><div class="line">        PCI 1000:0097</div><div class="line">      PCIBridge</div><div class="line">        PCI 1c5f:000d</div><div class="line">      PCIBridge</div><div class="line">        PCI 1c5f:000d</div><div class="line">    HostBridge L#8</div><div class="line">      PCIBridge</div><div class="line">        PCI 15b3:1015</div><div class="line">          Net L#3 &quot;p1p1&quot;      //万兆网卡接在Node0上</div><div class="line">        PCI 15b3:1015</div><div class="line">          Net L#4 &quot;p1p2&quot;</div><div class="line">    HostBridge L#10</div><div class="line">      PCIBridge</div><div class="line">        PCI 8086:1521</div><div class="line">          Net L#5 &quot;em1&quot;       //千兆网卡接在Node0上</div><div class="line">        PCI 8086:1521</div><div class="line">          Net L#6 &quot;em2&quot;</div><div class="line">  NUMANode L#1 (P#1 251GB)    //另外一个socket</div><div class="line">    Package L#1</div><div class="line">      L3 L#8 (8192KB)</div><div class="line">        L2 L#32 (512KB) + L1d L#32 (32KB) + L1i L#32 (64KB) + Core L#32</div><div class="line">        </div><div class="line">----------- FT2500 两路共128core</div><div class="line">#lstopo-no-graphics --logical</div><div class="line">Machine (503GB total)</div><div class="line">  Package L#0 + L3 L#0 (64MB)</div><div class="line">    NUMANode L#0 (P#0 31GB)</div><div class="line">      L2 L#0 (2048KB)         //4个物理core共享2M </div><div class="line">        L1d L#0 (32KB) + L1i L#0 (32KB) + Core L#0 + PU L#0 (P#0)</div><div class="line">        L1d L#1 (32KB) + L1i L#1 (32KB) + Core L#1 + PU L#1 (P#1)</div><div class="line">        L1d L#2 (32KB) + L1i L#2 (32KB) + Core L#2 + PU L#2 (P#2)</div><div class="line">        L1d L#3 (32KB) + L1i L#3 (32KB) + Core L#3 + PU L#3 (P#3)</div><div class="line">      L2 L#1 (2048KB)</div><div class="line">        L1d L#4 (32KB) + L1i L#4 (32KB) + Core L#4 + PU L#4 (P#4)</div><div class="line">        L1d L#5 (32KB) + L1i L#5 (32KB) + Core L#5 + PU L#5 (P#5)</div><div class="line">        L1d L#6 (32KB) + L1i L#6 (32KB) + Core L#6 + PU L#6 (P#6)</div><div class="line">        L1d L#7 (32KB) + L1i L#7 (32KB) + Core L#7 + PU L#7 (P#7)</div><div class="line">      HostBridge L#0</div><div class="line">        PCIBridge</div><div class="line">          PCIBridge</div><div class="line">            PCIBridge</div><div class="line">              PCI 1000:00ac</div><div class="line">                Block(Disk) L#0 &quot;sdh&quot;</div><div class="line">                Block(Disk) L#1 &quot;sdf&quot;  // 磁盘挂在Node0上</div><div class="line">            PCIBridge</div><div class="line">              PCI 8086:1521</div><div class="line">                Net L#13 &quot;eth0&quot;</div><div class="line">              PCI 8086:1521</div><div class="line">                Net L#14 &quot;eth1&quot;       //网卡挂在node0上</div><div class="line">        PCIBridge</div><div class="line">          PCIBridge</div><div class="line">            PCI 1a03:2000</div><div class="line">              GPU L#15 &quot;controlD64&quot;</div><div class="line">              GPU L#16 &quot;card0&quot;</div><div class="line">    NUMANode L#1 (P#1 31GB)</div><div class="line">    NUMANode L#2 (P#2 31GB)</div><div class="line">    NUMANode L#3 (P#3 31GB)</div><div class="line">    NUMANode L#4 (P#4 31GB)</div><div class="line">    NUMANode L#5 (P#5 31GB)</div><div class="line">    NUMANode L#6 (P#6 31GB)</div><div class="line">    NUMANode L#7 (P#7 31GB)</div><div class="line">      L2 L#14 (2048KB)</div><div class="line">        L1d L#56 (32KB) + L1i L#56 (32KB) + Core L#56 + PU L#56 (P#56)</div><div class="line">        L1d L#57 (32KB) + L1i L#57 (32KB) + Core L#57 + PU L#57 (P#57)</div><div class="line">        L1d L#58 (32KB) + L1i L#58 (32KB) + Core L#58 + PU L#58 (P#58)</div><div class="line">        L1d L#59 (32KB) + L1i L#59 (32KB) + Core L#59 + PU L#59 (P#59)</div><div class="line">      L2 L#15 (2048KB)</div><div class="line">        L1d L#60 (32KB) + L1i L#60 (32KB) + Core L#60 + PU L#60 (P#60)</div><div class="line">        L1d L#61 (32KB) + L1i L#61 (32KB) + Core L#61 + PU L#61 (P#61)</div><div class="line">        L1d L#62 (32KB) + L1i L#62 (32KB) + Core L#62 + PU L#62 (P#62)</div><div class="line">        L1d L#63 (32KB) + L1i L#63 (32KB) + Core L#63 + PU L#63 (P#63)</div><div class="line">  Package L#1 + L3 L#1 (64MB)   //socket2</div><div class="line">    NUMANode L#8 (P#8 31GB)</div><div class="line">      L2 L#16 (2048KB)</div><div class="line">        L1d L#64 (32KB) + L1i L#64 (32KB) + Core L#64 + PU L#64 (P#64)</div><div class="line">        L1d L#65 (32KB) + L1i L#65 (32KB) + Core L#65 + PU L#65 (P#65)</div><div class="line">        L1d L#66 (32KB) + L1i L#66 (32KB) + Core L#66 + PU L#66 (P#66)</div><div class="line">        L1d L#67 (32KB) + L1i L#67 (32KB) + Core L#67 + PU L#67 (P#67)</div><div class="line">      L2 L#17 (2048KB)</div><div class="line">        L1d L#68 (32KB) + L1i L#68 (32KB) + Core L#68 + PU L#68 (P#68)</div><div class="line">        L1d L#69 (32KB) + L1i L#69 (32KB) + Core L#69 + PU L#69 (P#69)</div><div class="line">        L1d L#70 (32KB) + L1i L#70 (32KB) + Core L#70 + PU L#70 (P#70)</div><div class="line">        L1d L#71 (32KB) + L1i L#71 (32KB) + Core L#71 + PU L#71 (P#71)</div><div class="line">      HostBridge L#7</div><div class="line">        PCIBridge</div><div class="line">          PCIBridge</div><div class="line">            PCIBridge</div><div class="line">              PCI 15b3:1015</div><div class="line">                Net L#17 &quot;eth2&quot;   //node8 上的网卡，eth2、eth3做了bonding</div><div class="line">              PCI 15b3:1015</div><div class="line">                Net L#18 &quot;eth3&quot;</div><div class="line">            PCIBridge</div><div class="line">              PCI 144d:a808</div><div class="line">            PCIBridge</div><div class="line">              PCI 144d:a808</div><div class="line">              </div><div class="line"> ---鲲鹏920 每路48core 2路共4node，网卡插在node0，磁盘插在node2</div><div class="line"> #lstopo-no-graphics</div><div class="line">Machine (755GB total)</div><div class="line">  Package L#0</div><div class="line">    NUMANode L#0 (P#0 188GB)</div><div class="line">      L3 L#0 (24MB)</div><div class="line">        L2 L#0 (512KB) + L1d L#0 (64KB) + L1i L#0 (64KB) + Core L#0 + PU L#0 (P#0)</div><div class="line">        L2 L#1 (512KB) + L1d L#1 (64KB) + L1i L#1 (64KB) + Core L#1 + PU L#1 (P#1)</div><div class="line">        L2 L#22 (512KB) + L1d L#22 (64KB) + L1i L#22 (64KB) + Core L#22 + PU L#22 (P#22)</div><div class="line">        L2 L#23 (512KB) + L1d L#23 (64KB) + L1i L#23 (64KB) + Core L#23 + PU L#23 (P#23)</div><div class="line">      HostBridge L#0</div><div class="line">        PCIBridge</div><div class="line">          PCI 15b3:1017</div><div class="line">            Net L#0 &quot;enp2s0f0&quot;</div><div class="line">          PCI 15b3:1017</div><div class="line">            Net L#1 &quot;eth1&quot;</div><div class="line">        PCIBridge</div><div class="line">          PCI 19e5:1711</div><div class="line">            GPU L#2 &quot;controlD64&quot;</div><div class="line">            GPU L#3 &quot;card0&quot;</div><div class="line">      HostBridge L#3</div><div class="line">        2 x &#123; PCI 19e5:a230 &#125;</div><div class="line">        PCI 19e5:a235</div><div class="line">          Block(Disk) L#4 &quot;sda&quot;</div><div class="line">      HostBridge L#4</div><div class="line">        PCIBridge</div><div class="line">          PCI 19e5:a222</div><div class="line">            Net L#5 &quot;enp125s0f0&quot;</div><div class="line">          PCI 19e5:a221</div><div class="line">            Net L#6 &quot;enp125s0f1&quot;</div><div class="line">          PCI 19e5:a222</div><div class="line">            Net L#7 &quot;enp125s0f2&quot;</div><div class="line">          PCI 19e5:a221</div><div class="line">            Net L#8 &quot;enp125s0f3&quot;</div><div class="line">    NUMANode L#1 (P#1 189GB) + L3 L#1 (24MB)</div><div class="line">      L2 L#24 (512KB) + L1d L#24 (64KB) + L1i L#24 (64KB) + Core L#24 + PU L#24 (P#24)</div><div class="line">  Package L#1</div><div class="line">    NUMANode L#2 (P#2 189GB)</div><div class="line">      L3 L#2 (24MB)</div><div class="line">        L2 L#48 (512KB) + L1d L#48 (64KB) + L1i L#48 (64KB) + Core L#48 + PU L#48 (P#48)</div><div class="line">      HostBridge L#6</div><div class="line">        PCIBridge</div><div class="line">          PCI 19e5:3714</div><div class="line">        PCIBridge</div><div class="line">          PCI 19e5:3714</div><div class="line">        PCIBridge</div><div class="line">          PCI 19e5:3714</div><div class="line">        PCIBridge</div><div class="line">          PCI 19e5:3714</div><div class="line">      HostBridge L#11</div><div class="line">        PCI 19e5:a230</div><div class="line">        PCI 19e5:a235</div><div class="line">        PCI 19e5:a230</div><div class="line">    NUMANode L#3 (P#3 189GB) + L3 L#3 (24MB)</div><div class="line">      L2 L#72 (512KB) + L1d L#72 (64KB) + L1i L#72 (64KB) + Core L#72 + PU L#72 (P#72)</div><div class="line">  Misc(MemoryModule)</div></pre></td></tr></table></figure>
<p>如果cpu core太多, interrupts 没法看的话，通过cut只看其中一部分core</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cat /proc/interrupts | grep -i &apos;eth4\|CPU&apos; | cut -c -8,865-995,1425-</div></pre></td></tr></table></figure>
<h2 id="lspci"><a href="#lspci" class="headerlink" title="lspci"></a>lspci</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span>lspci -s 21:00.0 -vvv</div><div class="line">21:00.0 Ethernet controller: Mellanox Technologies MT27710 Family [ConnectX-4 Lx]</div><div class="line">	Subsystem: Mellanox Technologies ConnectX-4 Lx Stand-up dual-port 10GbE MCX4121A-XCAT</div><div class="line">	Control: I/O- Mem+ BusMaster+ SpecCycle- MemWINV- VGASnoop- ParErr+ Stepping- SERR+ FastB2B- DisINTx+</div><div class="line">	Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast &gt;TAbort- &lt;TAbort- &lt;MAbort- &gt;SERR- &lt;PERR- INTx-</div><div class="line">	Latency: 0, Cache Line Size: 64 bytes</div><div class="line">	Interrupt: pin A routed to IRQ 105</div><div class="line">	Region 0: Memory at 3249c000000 (64-bit, prefetchable) [size=32M]</div><div class="line">	Expansion ROM at db300000 [disabled] [size=1M]</div><div class="line">	Capabilities: [60] Express (v2) Endpoint, MSI 00</div><div class="line">		DevCap:	MaxPayload 512 bytes, PhantFunc 0, Latency L0s unlimited, L1 unlimited</div><div class="line">			ExtTag+ AttnBtn- AttnInd- PwrInd- RBE+ FLReset+ SlotPowerLimit 0.000W</div><div class="line">		DevCtl:	CorrErr+ NonFatalErr+ FatalErr+ UnsupReq-</div><div class="line">			RlxdOrd+ ExtTag+ PhantFunc- AuxPwr- NoSnoop+ FLReset-</div><div class="line">			MaxPayload 512 bytes, MaxReadReq 512 bytes</div><div class="line">		DevSta:	CorrErr+ NonFatalErr- FatalErr- UnsupReq+ AuxPwr- TransPend-</div><div class="line">		LnkCap:	Port #0, Speed 8GT/s, Width x8, ASPM not supported</div><div class="line">			ClockPM- Surprise- LLActRep- BwNot- ASPMOptComp+</div><div class="line">		LnkCtl:	ASPM Disabled; RCB 64 bytes Disabled- CommClk+</div><div class="line">			ExtSynch- ClockPM- AutWidDis- BWInt- AutBWInt-</div><div class="line">		LnkSta:	Speed 8GT/s (ok), Width x8 (ok)</div><div class="line">			TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt-</div><div class="line">		DevCap2: Completion Timeout: Range ABC, TimeoutDis+, LTR-, OBFF Not Supported</div><div class="line">			 AtomicOpsCap: 32bit- 64bit- 128bitCAS-</div><div class="line">		DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF Disabled</div><div class="line">			 AtomicOpsCtl: ReqEn-</div><div class="line">		LnkCtl2: Target Link Speed: 8GT/s, EnterCompliance- SpeedDis-</div><div class="line">			 Transmit Margin: Normal Operating Range, EnterModifiedCompliance- ComplianceSOS-</div><div class="line">			 Compliance De-emphasis: -6dB</div><div class="line">		LnkSta2: Current De-emphasis Level: -6dB, EqualizationComplete+, EqualizationPhase1+</div><div class="line">			 EqualizationPhase2+, EqualizationPhase3+, LinkEqualizationRequest-</div><div class="line">	Capabilities: [48] Vital Product Data</div><div class="line">		Product Name: CX4121A - ConnectX-4 LX SFP28</div><div class="line">		Read-only fields:</div><div class="line">			[PN] Part number: MCX4121A-XCAT</div><div class="line">			[EC] Engineering changes: AJ</div><div class="line">			[SN] Serial number: MT2031J09199</div><div class="line">			[V0] Vendor specific: PCIeGen3 x8</div><div class="line">			[RV] Reserved: checksum good, 0 byte(s) reserved</div><div class="line">		End</div><div class="line">	Capabilities: [9c] MSI-X: Enable+ Count=64 Masked-</div><div class="line">		Vector table: BAR=0 offset=00002000</div><div class="line">		PBA: BAR=0 offset=00003000</div><div class="line">	Capabilities: [c0] Vendor Specific Information: Len=18 &lt;?&gt;</div><div class="line">	Capabilities: [40] Power Management version 3</div><div class="line">		Flags: PMEClk- DSI- D1- D2- AuxCurrent=375mA PME(D0-,D1-,D2-,D3hot-,D3cold+)</div><div class="line">		Status: D0 NoSoftRst+ PME-Enable- DSel=0 DScale=0 PME-</div><div class="line">	Capabilities: [100 v1] Advanced Error Reporting</div><div class="line">		UESta:	DLP- SDES- TLP- FCP- CmpltTO- CmpltAbrt- UnxCmplt- RxOF- MalfTLP- ECRC- UnsupReq- ACSViol-</div><div class="line">		UEMsk:	DLP- SDES- TLP- FCP- CmpltTO- CmpltAbrt- UnxCmplt- RxOF- MalfTLP- ECRC- UnsupReq- ACSViol-</div><div class="line">		UESvrt:	DLP+ SDES- TLP- FCP+ CmpltTO- CmpltAbrt- UnxCmplt- RxOF+ MalfTLP+ ECRC+ UnsupReq- ACSViol-</div><div class="line">		CESta:	RxErr- BadTLP- BadDLLP- Rollover- Timeout- AdvNonFatalErr-</div><div class="line">		CEMsk:	RxErr- BadTLP- BadDLLP- Rollover- Timeout- AdvNonFatalErr+</div><div class="line">		AERCap:	First Error Pointer: 04, ECRCGenCap+ ECRCGenEn+ ECRCChkCap+ ECRCChkEn+</div><div class="line">			MultHdrRecCap- MultHdrRecEn- TLPPfxPres- HdrLogCap-</div><div class="line">		HeaderLog: 00000000 00000000 00000000 00000000</div><div class="line">	Capabilities: [150 v1] Alternative Routing-ID Interpretation (ARI)</div><div class="line">		ARICap:	MFVC- ACS-, Next Function: 1</div><div class="line">		ARICtl:	MFVC- ACS-, Function Group: 0</div><div class="line">	Capabilities: [180 v1] Single Root I/O Virtualization (SR-IOV)</div><div class="line">		IOVCap:	Migration-, Interrupt Message Number: 000</div><div class="line">		IOVCtl:	Enable- Migration- Interrupt- MSE- ARIHierarchy+</div><div class="line">		IOVSta:	Migration-</div><div class="line">		Initial VFs: 8, Total VFs: 8, Number of VFs: 0, Function Dependency Link: 00</div><div class="line">		VF offset: 2, stride: 1, Device ID: 1016</div><div class="line">		Supported Page Size: 000007ff, System Page Size: 00000001</div><div class="line">		Region 0: Memory at 000003249e800000 (64-bit, prefetchable)</div><div class="line">		VF Migration: offset: 00000000, BIR: 0</div><div class="line">	Capabilities: [1c0 v1] Secondary PCI Express &lt;?&gt;</div><div class="line">	Capabilities: [230 v1] Access Control Services</div><div class="line">		ACSCap:	SrcValid- TransBlk- ReqRedir- CmpltRedir- UpstreamFwd- EgressCtrl- DirectTrans-</div><div class="line">		ACSCtl:	SrcValid- TransBlk- ReqRedir- CmpltRedir- UpstreamFwd- EgressCtrl- DirectTrans-</div><div class="line">	Kernel driver in use: mlx5_core</div><div class="line">	Kernel modules: mlx5_core</div></pre></td></tr></table></figure>
<p>如果有多个高速设备争夺带宽（例如将高速网络连接到高速存储），那么 PCIe 也可能成为瓶颈，因此可能需要从物理上将 PCIe 设备划分给不同 CPU，以获得最高吞吐率。</p>
<p><img src="/images/951413iMgBlog/d718966f8f1fa1375e4437842fc759c2.png" alt="img"></p>
<p>数据来源：<a href="https://en.wikipedia.org/wiki/PCI_Express#History_and_revisions" target="_blank" rel="external"> https://en.wikipedia.org/wiki/PCI_Express#History_and_revisions</a></p>
<p>Intel 认为，有时候 PCIe 电源管理（ASPM）可能导致延迟提高，因进而导致丢包率增高。因此也可以为内核命令行参数添加<code>pcie_aspm=off</code>将其禁用。</p>
<h2 id="Default-路由持久化"><a href="#Default-路由持久化" class="headerlink" title="Default 路由持久化"></a>Default 路由持久化</h2><p>通过 ip route 可以添加默认路由，但是reboot就丢失了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">route add default dev bond0</div></pre></td></tr></table></figure>
<p>如果要持久化，在centos下可以创建 /etc/sysconfig/network-scripts/route-bond0 文件，内容如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">default dev bond0    ---默认路由，后面的可以省略</div><div class="line">10.0.0.0/8 via 11.158.239.247 dev bond0</div><div class="line">11.0.0.0/8 via 11.158.239.247 dev bond0</div><div class="line">30.0.0.0/8 via 11.158.239.247 dev bond0</div><div class="line">172.16.0.0/12 via 11.158.239.247 dev bond0</div><div class="line">192.168.0.0/16 via 11.158.239.247 dev bond0</div><div class="line">100.64.0.0/10 via 11.158.239.247 dev bond0</div><div class="line">33.0.0.0/8 via 11.158.239.247 dev bond0</div></pre></td></tr></table></figure>
<p>或者用sed在文件第一行添加</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sed -i &apos;/default /d&apos;  /etc/sysconfig/network-scripts/route-bond0   //先删除默认路由（如果有）</div><div class="line">sed -i &apos;1 i\default dev bond0&apos; /etc/sysconfig/network-scripts/route-bond0   //添加</div></pre></td></tr></table></figure>
<p>Centos 7的话需要在 /etc/sysconfig/network 中添加创建默认路由的命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"># cat /etc/sysconfig/network</div><div class="line"># Created by anaconda</div><div class="line">ip route add default dev eth0</div></pre></td></tr></table></figure>
<h2 id="内核态启动并加载网卡的逻辑"><a href="#内核态启动并加载网卡的逻辑" class="headerlink" title="内核态启动并加载网卡的逻辑"></a>内核态启动并加载网卡的逻辑</h2><ol>
<li><p>运行Linux的机器在BIOS阶段之后，机器的boot loader根据我们预先定义好的配置文件，将intrd和linux kernel加载到内存。这个包含initrd和linux kernel的配置文件通常在/boot分区（从grub.conf中读取参数）</p>
</li>
<li><p>内核启动，运行当前根目录下面的init进程，init进程再运行其他必要的进程，其中跟网卡PCI设备相关的一个进程，就是udevd进程，udevd负责根据内核pci scan的pci设备，从initrd这个临时的根文件系统中加载内核模块，对于网卡来说，就是网卡驱动。(对应systemd-udevd 服务)</p>
</li>
<li><p>udevd，根据内核pci device scan出来的pci device，通过netlink消息机制通知udevd加载相应的内核驱动，其中，网卡驱动就是在这个阶段加载，如果initrd临时文件系统里面有这个网卡的驱动文件。通常upstream到linux内核的驱动，比如ixgbe，或者和内核一起编译的网卡驱动，会默认包含在initrd文件系统中。这些跟内核一起ship的网卡驱动会在这个阶段加载</p>
</li>
<li><p>udevd除了负责网卡驱动加载之外，还要负责为网卡命名。udevd在为网卡命名的时候，会首先check “/etc/udev/rules.d/“下的rule，如果hit到相应的rule，就会通过rule里面指定的binary为网卡命名。如果/etc/udev/rules.d/没有命名成功网卡，那么udevd会使用/usr/lib/udev/rule.d下面的rule，为网卡重命名。其中rule的文件经常以数字开头，数字越小，表示改rule的优先级越高。intrd init不会初始化network服务，所以/etc/sysconfig/network-scripts下面的诸如bond0，route的配置都不会生效。（内核启动先是 intrd init，然后执行一次真正的init）</p>
</li>
<li><p>在完成网卡driver load和name命名之后，initrd里面的init进程，会重启其他用户态进程，如udevd等，并且重新mount真正的根文件系统，启动network service。</p>
</li>
<li><p>重启udevd，会触发一次kernel的rescan device。这样第三方安装的网卡driver，由于其driver模块没有在initrd里面，会在这个阶段由udevd触发加载。同时，也会根据“/etc/udev/rules.d/”和“/usr/lib/udev/rule.d”的rule，重命名网卡设备。–用户态修改网卡名字的机会</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">kernel: ixgbe 0000:3b:00.1 eth1: renamed from enp59s0f1</div><div class="line">kernel: i40e 0000:88:00.0 eth7: renamed from enp136s0</div></pre></td></tr></table></figure>
</li>
<li><p>同时network service 会启动，进而遍历etc/sysconfig/network-scripts下面的脚本，我们配置的bond0， 默认路由，通常会在这个阶段运行，创建</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">kernel: bond0: Enslaving eth0 as a backup interface with a down link</div><div class="line">kernel: ixgbe 0000:3b:00.0 eth0: detected SFP+: 5</div><div class="line">kernel: power_meter ACPI000D:00: Found ACPI power meter.</div><div class="line">kernel: power_meter ACPI000D:00: Ignoring unsafe software power cap!</div><div class="line">kernel: ixgbe 0000:3b:00.1: registered PHC device on eth1</div><div class="line">kernel: ixgbe 0000:3b:00.0 eth0: NIC Link is Up 10 Gbps, Flow Control: RX/TX</div><div class="line">kernel: bond0: Enslaving eth1 as a backup interface with a down link</div><div class="line">kernel: bond0: Warning: No 802.3ad response from the link partner for any adapters in the bond</div><div class="line">kernel: bond0: link status definitely up for interface eth0, 10000 Mbps full duplex</div><div class="line">kernel: bond0: first active interface up!</div></pre></td></tr></table></figure>
</li>
</ol>
<p>由于我们系统的初始化有两个阶段，udevd会运行两次，所以内核态网卡driver的加载，网卡命名也有两次机会。</p>
<p>第一次网卡driver的加载和命名是在initrd运行阶段，这个阶段由于initrd文件系统比较小，只包括和kernel一起ship的内核module，所以这个阶段只能加载initrd里面有的内核模块。网卡的重命名也只能重命名加载了驱动的网卡。</p>
<p>第二个网卡driver的加载和命名，是在真正根文件系统加载后，内核再一次pci scan，这个时候，由于真的根文件系统包含了所有的driver，第一个阶段无法probe的网卡会在这个阶段probe，重命名也会在这个阶段进行。</p>
<blockquote>
<p>内核默认命名规则有一定的局限性，往往不一定准确对应网卡接口的物理顺序，而且每次启动只根据内核发现网卡的顺序进行命名，因此并不固定；所以目前一般情况下会在用户态启用其他的方式去更改网卡名称，原则就是在内核命名ethx后将其在根据用户态的规则rename为其他的名字，这种规则往往是根据网卡的Mac地址以及其他能够唯一代表一块网卡的参数去命名，因此会一一对应；</p>
</blockquote>
<p>内核自带的网卡驱动在initrd中的内核模块中。对于第三方网卡，我们通常通过rpm包的方式安装。这种第三方安装的rpm，通常不会在initrd里面，只存在disk上。这样这种内核模块就只会在第二次udevd启动的时候被加载。</p>
<p>不论第一次重命名还是第二次重命名，其都遵循一样的逻辑，也就是先check /etc/udev/rules.d/的rule，然后check /usr/lib/udev/rule.d中的rule，其中rule的优先级etc下最高，然后是usr下面。并且，rule的文件名中的数字表示该rule在同一文件夹中的优先级，数字越低，优先级越高。</p>
<p>network.service 根据network-script里面的脚本创建bond0，下发路由。这个过程和网卡重命名是同步进行，一般网卡重命名会超级快，单极端情况下重命名可能在network.service后会导致创建bond0失败（依赖网卡名来bonding），这里会依赖network.service retry机制来反复尝试确保network服务能启动成功</p>
<p>要想解决网卡加载慢的问题，可以考虑把安装后的网卡集成到initrd中。Linux系统提供的dracut可以做到这一点，我们只需要在安装完第三方网卡驱动后，执行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">dracut --forace</div><div class="line"></div><div class="line">查看</div><div class="line">udevadm info -q all -a /dev/nvme0</div></pre></td></tr></table></figure>
<p>就可以解决这个问题，该命令会根据最新的内存中的module，重新下刷initrd。</p>
<p>其实在多数第三方网卡的rpm spec或者makefile里面通常也会加入这种强制重刷的逻辑，确保内核驱动在initrd里面，从而加快网卡驱动的加载。</p>
<h3 id="用户态命名网卡流程"><a href="#用户态命名网卡流程" class="headerlink" title="用户态命名网卡流程"></a><a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/networking_guide/sec-understanding_the_device_renaming_procedure" target="_blank" rel="external">用户态命名网卡流程</a></h3><p><a href="https://blog.csdn.net/biaotai/article/details/120710966" target="_blank" rel="external">CentOS 7提供了在网络接口中使用一致且可预期的网络设备命名方法， 目前默认使用的是net.ifnames规则</a>。The device name procedure in detail is as follows:</p>
<ol>
<li>A rule in <code>/usr/lib/udev/rules.d/60-net.rules</code> instructs the <strong>udev</strong> helper utility, <strong>/lib/udev/rename_device</strong>, to look into all <code>/etc/sysconfig/network-scripts/ifcfg-*suffix*</code> files. If it finds an <code>ifcfg</code> file with a <code>HWADDR</code> entry matching the MAC address of an interface it renames the interface to the name given in the <code>ifcfg</code> file by the <code>DEVICE</code> directive.（根据提前定义好的ifcfg-网卡名来命名网卡–依赖mac匹配，如果网卡的ifconfig文件中未加入HWADDR，则rename脚本并不会根据配置文件去重命名网卡）</li>
<li>A rule in <code>/usr/lib/udev/rules.d/71-biosdevname.rules</code> instructs <strong>biosdevname</strong> to rename the interface according to its naming policy, provided that it was not renamed in a previous step, <strong>biosdevname</strong> is installed, and <code>biosdevname=0</code> was not given as a kernel command on the boot command line.</li>
<li>A rule in <code>/lib/udev/rules.d/75-net-description.rules</code> instructs <strong>udev</strong> to fill in the internal <strong>udev</strong> device property values ID_NET_NAME_ONBOARD, ID_NET_NAME_SLOT, ID_NET_NAME_PATH, ID_NET_NAME_MAC by examining the network interface device. Note, that some device properties might be undefined.</li>
<li>A rule in <code>/usr/lib/udev/rules.d/80-net-name-slot.rules</code> instructs <strong>udev</strong> to rename the interface, provided that it was not renamed in step 1 or 2, and the kernel parameter <code>net.ifnames=0</code> was not given, according to the following priority: ID_NET_NAME_ONBOARD, ID_NET_NAME_SLOT, ID_NET_NAME_PATH. It falls through to the next in the list, if one is unset. If none of these are set, then the interface will not be renamed.</li>
</ol>
<p>Steps 3 and 4 are implementing the naming schemes 1, 2, 3, and optionally 4, described in <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/networking_guide/ch-Consistent_Network_Device_Naming#sec-Naming_Schemes_Hierarchy" target="_blank" rel="external">Section 11.1, “Naming Schemes Hierarchy”</a>. Step 2 is explained in more detail in <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/networking_guide/sec-Consistent_Network_Device_Naming_Using_biosdevname" target="_blank" rel="external">Section 11.6, “Consistent Network Device Naming Using biosdevname”</a>.</p>
<p>以上重命名简要概述就是对于CentOS系统，一般有下面几个rule在/usr/lib/udev/rule.d来重命名网卡：</p>
<ol>
<li>/usr/lib/udev/rules.d/60-net.rules 文件中的规则会让 udev 帮助工具/lib/udev/rename_device 查看所有 /etc/sysconfig/network-scripts/ifcfg-* 文件。如果发现包含 HWADDR 条目的 ifcfg 文件与某个接口的 MAC 地址匹配，它会将该接口重命名为ifcfg 文件中由 DEVICE 指令给出的名称。rename条件：如果网卡的ifconfig文件中未加入HWADDR，则rename脚本并不会根据配置文件去重命名网卡；</li>
<li>/usr/lib/udev/rules.d/71-biosdevname.rules 中的规则让 biosdevname 根据其命名策略重命名该接口，即在上一步中没有重命名该接口、安装biosdevname、且在 boot 命令行中将biosdevname=0 作为内核命令给出。（bisodevname规则，从CentOS 7 开始默认不使用，所以该条规则在不配置的情况下失效，直接去执行3；默认在cmdline中bisodevname=0，如果需要启用，则需要设置bisodevname=1）</li>
<li>/lib/udev/rules.d/75-net-description.rules 中的规则让 udev 通过检查网络接口设备，填写内部 udev 设备属性值 ID_NET_NAME_ONBOARD、ID_NET_NAME_SLOT、ID_NET_NAME_PATH、ID_NET_NAME_MAC。注：有些设备属性可能处于未定义状态。 –没有修改网卡名，只是取到了命名需要的一些属性值。查看：udevadm info -p /sys/class/net/enp125s0f0</li>
<li>/usr/lib/udev/rules.d/80-net-name-slot.rules 中的规则让 udev 重命名该接口，优先顺序如下：ID_NET_NAME_ONBOARD、ID_NET_NAME_SLOT、ID_NET_NAME_PATH。并提供如下信息：没有在步骤 1 或 2 中重命名该接口，同时未给出内核参数 net.ifnames=0。如果一个参数未设定，则会按列表的顺序设定下一个。如果没有设定任何参数，则不会重命名该接口 —- 目前主流CentOS流都是这个命名方式</li>
<li>network service起来后会遍历/etc/sysconfig/network-scripts下的脚本，配置bond0、默认路由、其它网卡等</li>
</ol>
<p>其中60 rule会调用rename_device根据ifcfg-xxx脚本来命名，rule 71调用biosdevname来命名网卡。以上规则数字越小优先级越高，高优先级生效后跳过低优先级</p>
<p>总的来说网卡命名规则：grub启动参数 -&gt; /etc/udev/rules.d/的rule -&gt; /usr/lib/udev/rule.d</p>
<p><a href="https://opensource.com/article/22/8/network-configuration-files?continueFlag=0e1c90589c7c691ec44a1aaecdcba76e" target="_blank" rel="external">参考</a>：</p>
<p>The following is an excerpt from Chapter 11 of the RHEL 7 “Networking Guide”:</p>
<ul>
<li>Scheme 1: Names incorporating Firmware or BIOS provided index numbers for on-board devices (example: eno1), are applied if that information from the firmware or BIOS is applicable and available, else falling back to scheme 2.</li>
<li>Scheme 2: Names incorporating Firmware or BIOS provided PCI Express hotplug slot index numbers (example: ens1) are applied if that information from the firmware or BIOS is applicable and available, else falling back to scheme 3.</li>
<li>Scheme 3: Names incorporating physical location of the connector of the hardware (example: enp2s0), are applied if applicable, else falling directly back to scheme 5 in all other cases.</li>
<li>Scheme 4: Names incorporating interface’s MAC address (example: enx78e7d1ea46da), is not used by default, but is available if the user chooses.</li>
<li>Scheme 5: The traditional unpredictable kernel naming scheme, is used if all other methods fail (example: eth0).</li>
</ul>
<h3 id="网卡命名"><a href="#网卡命名" class="headerlink" title="网卡命名"></a>网卡命名</h3><p><a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/networking_guide/sec-consistent_network_device_naming_using_biosdevname" target="_blank" rel="external">默认安装网卡所在位置来命名（enp131s0 等）</a>，按位置命名实例如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">//name example  ---默认方式，按照 /usr/lib/udev/rules.d/80-net-name-slot.rules 来命名</div><div class="line">enp4s10f1                        pci 0000:04:0a.1</div><div class="line">| | |  |                                |  |  | |</div><div class="line">| | |  |                   domain &lt;- 0000  |  | |</div><div class="line">| | |  |                                   |  | |</div><div class="line">en| |  |  --&gt; ethernet                     |  | |</div><div class="line">  | |  |                                   |  | |</div><div class="line">  p4|  |  --&gt; prefix/bus number (4)   &lt;-- 04  | |</div><div class="line">    |  |                                      | |</div><div class="line">    s10|  --&gt; slot/device number (10) &lt;--    10 |</div><div class="line">       |                                        |</div><div class="line">       f1 --&gt; function number (1)     &lt;--       1</div></pre></td></tr></table></figure>
<p>可以<a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/networking_guide/sec-disabling_consistent_network_device_naming" target="_blank" rel="external">关掉这种按位置命名的方式</a>，在grub参数中添加： net.ifnames=0 biosdevname=0，关闭后默认命名方式是eth**，开启biosdevname=1后，默认网卡命名方式是p1p1/p1p2(麒麟默认开启；alios默认关闭，然后以eth来命名)</p>
<blockquote>
<p>You have two options (<a href="https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/Networking_Guide/sec-Disabling_Consistent_Network_Device_Naming.html" target="_blank" rel="external">as described in the new RHEL 7 Networking Guide</a>) to disable the <a href="https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/Networking_Guide/ch-Consistent_Network_Device_Naming.html#sec-Understanding_the_Predictable_Network_Interface_Device_Names" target="_blank" rel="external">new naming scheme</a>:</p>
<ul>
<li>Run once: <code>ln -s /dev/null /etc/udev/rules.d/80-net-name-slot.rules</code></li>
</ul>
<p>or</p>
<ul>
<li>Run once: <code>echo &#39;GRUB_CMDLINE_LINUX=&quot;net.ifnames=0&quot;&#39; &gt;&gt;/etc/default/grub</code></li>
</ul>
<p>Note that the <strong>biosdevname</strong> package is not installed by default, so unless it gets installed, you don’t need to add <code>biosdevname=0</code> as a kernel argument.</p>
</blockquote>
<p>也可以添加命名规则在 /etc/udev/rules.d/ 下(这种优先级挺高），比如</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">cat /etc/udev/rules.d/70-persistent-net.rules</div><div class="line"># PCI device 21:00.0 (ixgbe)</div><div class="line">SUBSYSTEM==&quot;net&quot;, ACTION==&quot;add&quot;, DRIVERS==&quot;?*&quot;, ATTR&#123;address&#125;==&quot;d4:5d:64:bb:06:32&quot;, PROGRAM=&quot;/lib/udev/rename_device&quot;, ATTR&#123;type&#125;==&quot;1&quot;, KERNEL==&quot;eth*&quot;, NAME=&quot;eth0&quot;</div><div class="line"># PCI device 0x8086:0x105e (e1000e)</div><div class="line">SUBSYSTEM==&quot;net&quot;, ACTION==&quot;add&quot;, DRIVERS==&quot;?*&quot;, ATTR&#123;address&#125;==&quot;b8:59:9f:2d:48:2b&quot;, PROGRAM=&quot;/lib/udev/rename_device&quot;, ATTR&#123;type&#125;==&quot;1&quot;, KERNEL==&quot;eth*&quot;, NAME=&quot;eth1&quot;</div></pre></td></tr></table></figure>
<p>但是以上规则在麒麟下没有生效</p>
<p>网卡重命名方式：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">/sbin/ip link set eth1 name eth123</div></pre></td></tr></table></figure>
<h2 id="校验"><a href="#校验" class="headerlink" title="校验"></a><a href="https://www.kernel.org/doc/html/latest/networking/checksum-offloads.html" target="_blank" rel="external">校验</a></h2><p>比如如下结构下因为通过xdp redirect来联通veth0、veth1，两边能ping通，但是TCP、UDP 都不通</p>
<p><img src="/images/951413iMgBlog/image-20220614171759153.png" alt="image-20220614171759153"></p>
<p>正常走bridge ping/tcp/udp是不会有问题的, 这也是docker下常见用法</p>
<p><img src="/images/951413iMgBlog/image-20220614173416775.png" alt="image-20220614173416775"></p>
<p>当前主流的网卡（包括虚拟网卡，如veth/tap）都支持一个叫做RX/TX Checksum Offload（RX和TX对应接收和发送两个方向）的特性，用于将传输层协议的校验和计算卸载到网卡硬件中（IP头的检验和会被操作系统用软件方式正确计算）。对于经过启用该功能的网卡的报文，操作系统不会对该报文进行校验和的计算，从而减少对系统CPU资源的占用。</p>
<p><img src="/images/951413iMgBlog/1613803162582-ce09e9cc-36e4-4805-b968-98d8dd601f52-5197629.png" alt="1613803162582-ce09e9cc-36e4-4805-b968-98d8dd601f52"></p>
<p>对于没有挂载XDP程序的且开启Checksum Offload功能的Veth设备，在接收到数据包时，会将<code>ip_summed</code>置为<code>CHECKSUM_UNNECESSARY</code>，因此上层L4协议栈在收到该数据包的时候不会再检查校验和，即使是数据包的校验和不正确也会正常被处理。但是若我们在veth设备上挂载了XDP程序，XDP程序运行时将网卡接收队列中的数据转换为结构<code>struct xdp_buff</code>时会丢失掉<code>ip_summed</code>信息，这就导致数据包被L4协议栈接收后由于校验和错误而被丢弃。</p>
<p>如上图因为veth挂载了XDP程序，导致包没有校验信息而丢掉，如果在同样环境下ping是可以通的，因为ping包提前计算好了正确的校验和</p>
<p><img src="/images/951413iMgBlog/1613982679299-d6832373-6a5f-4b54-9440-fd16606b8341.png" alt="img"></p>
<p>这种丢包可以通过 <code>/proc/net/snmp</code> 看到</p>
<p><img src="/images/951413iMgBlog/1613814089563-fb1de2e7-46d4-4bb7-9162-356e39c19a4c.png" alt="img"></p>
<p>通过命令<code>ethtool -K &lt;nic-name&gt; tx off</code>工具关闭Checksum Offload特性，强行让操作系统用软件方式计算校验和。</p>
<h2 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h2><p><a href="https://www.cyberciti.biz/faq/linux-log-suspicious-martian-packets-un-routable-source-addresses/" target="_blank" rel="external">网卡日志打开</a>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">sysctl -w net.ipv4.conf.all.log_martians=1 //所有网卡</div><div class="line">sysctl -w net.ipv4.conf.p1p1.log_martians=1 //特定网卡</div><div class="line"></div><div class="line">/proc/sys/net/ipv4/conf/eth0.9/log_martians</div></pre></td></tr></table></figure>
<p>/var/log/messages中：</p>
<p>messages-20120101:Dec 31 09:25:45 nixcraft-router kernel: martian source 74.xx.47.yy from 10.13.106.25, on dev eth1</p>
<h2 id="修改mac地址"><a href="#修改mac地址" class="headerlink" title="修改mac地址"></a>修改mac地址</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sudo ip link set dev eth1 down</div><div class="line">sudo ip link set dev eth1 address e8:61:1f:33:c5:fd</div><div class="line">sudo ip link set dev eth1 up</div></pre></td></tr></table></figure>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://www.modb.pro/db/29135" target="_blank" rel="external">高斯在鲲鹏下跑TPCC的优化</a></p>
<p><a href="https://www.cyberciti.biz/faq/linux-log-suspicious-martian-packets-un-routable-source-addresses/" target="_blank" rel="external">https://www.cyberciti.biz/faq/linux-log-suspicious-martian-packets-un-routable-source-addresses/</a></p>
<p><a href="https://www.hikunpeng.com/document/detail/zh/kunpenggrf/tuningtip/kunpengtuning_12_0025.html" target="_blank" rel="external">鲲鹏性能优化十板斧</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2021/01/01/如何用1分钱建站来秒杀搜狐新浪等三大门户网站/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/01/01/如何用1分钱建站来秒杀搜狐新浪等三大门户网站/" itemprop="url">如何用1分钱建站速度秒杀三大门户网站站</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-01-01T12:30:03+08:00">
                2021-01-01
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/技巧/" itemprop="url" rel="index">
                    <span itemprop="name">技巧</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="如何用1分钱建站速度秒杀三大门户网站"><a href="#如何用1分钱建站速度秒杀三大门户网站" class="headerlink" title="如何用1分钱建站速度秒杀三大门户网站"></a>如何用1分钱建站速度秒杀三大门户网站</h1><p>如何快速又便宜地建立一个高质量的网站呢(高质量指的是访问速度快)，还能够双站热备(国内国外热备两份内容)，整个开支大概一分钱吧</p>
<p>核心就是用阿里云的OSS来提供高速的访问。</p>
<h2 id="先看访问速度"><a href="#先看访问速度" class="headerlink" title="先看访问速度"></a>先看访问速度</h2><p>同样是访问下面三个网站首页:</p>
<p>OSS托管，页面大小 96.6MB、242个GET，耗时2.21秒加载，价格不到1分钱</p>
<p>搜狐首页，页面大小16.6MB、555个GET，耗时3.6秒</p>
<p>新浪首页， 页面大小17.8MB、404个GET，耗时9.63秒</p>
<h3 id="OSS托管的网站"><a href="#OSS托管的网站" class="headerlink" title="OSS托管的网站"></a>OSS托管的网站</h3><p>用OSS托管的网站加载速度，96MB页面（很大了）2.21秒加载完毕</p>
<p><img src="/images/951413iMgBlog/image-20210702140950863.png" alt="image-20210702140950863"></p>
<h3 id="访问搜狐首页"><a href="#访问搜狐首页" class="headerlink" title="访问搜狐首页"></a>访问搜狐首页</h3><p><img src="/images/951413iMgBlog/image-20210702141336301.png" alt="image-20210702141336301"></p>
<h3 id="访问新浪首页"><a href="#访问新浪首页" class="headerlink" title="访问新浪首页"></a>访问新浪首页</h3><p><img src="/images/951413iMgBlog/image-20210702142610162.png" alt="image-20210702142610162"></p>
<h2 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h2><p>OSS快的原因是：小网站并发不高，服务器、带宽资源充足，还不用花钱，没有机器、带宽维护成本以及人员成本</p>
<p>有专业的阿里云工程师负责运维，给的是最好的服务器、最大的带宽（你用的少就不用花钱，带宽资源费用超级便宜）</p>
<p>到底有多便宜呢？1.6万次GET请求才1分钱，0.52GB流量才0.25元，计价金额单位震惊我了</p>
<p><img src="/images/951413iMgBlog/image-20210702163910295.png" alt="image-20210702163910295"></p>
<h2 id="OSS托管网站方案"><a href="#OSS托管网站方案" class="headerlink" title="OSS托管网站方案"></a>OSS托管网站方案</h2><p>将所有内容静态化，然后上传到OSS就可以了</p>
<p>发布操作步骤：</p>
<ul>
<li>markdown编辑器中编写要发布的页面</li>
<li>用hexo静态化全站（将markdown转换成html页面）</li>
<li>git commit到github或者ossutil 同步到aliyun oss中</li>
</ul>
<p>比如下面就是我的网站发布脚本：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">#静态化网站，并同步到github，多活</div><div class="line">hexo g -d</div><div class="line"></div><div class="line">#sync all pages to oss</div><div class="line">ossutil --config-file=~/src/script/mac/.ossutilconfig sync ./public/ oss://mysite/ -u --output-dir=/tmp/</div></pre></td></tr></table></figure>
<p>实际我的网站通过github和OSS都能访问到，内容完全一样，github免费，但是多图页面速度太慢, 比如我一个页面几十个图，github加载偶尔失败, 但是我把图片放到了OSS，因为OSS超级快这样github加载也变得超级快了。</p>
<blockquote>
<p>hexo是一个node实现的网站生成工具</p>
</blockquote>
<p><a href="https://help.aliyun.com/document_detail/31872.html" target="_blank" rel="external">oss 托管网站介绍</a></p>
<p>感叹一下，个人建站现在真的是又便宜又方便，只是域名实名制恶心了点，那就干脆不要域名了。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2020/12/25/一个有意思的问题/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/12/25/一个有意思的问题/" itemprop="url">一个有意思的问题</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-12-25T17:30:03+08:00">
                2020-12-25
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Linux/" itemprop="url" rel="index">
                    <span itemprop="name">Linux</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="一个有意思的问题"><a href="#一个有意思的问题" class="headerlink" title="一个有意思的问题"></a>一个有意思的问题</h1><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">$mysql -N -h127.0.0.1 -e &quot;select id from sbtest1 limit 1&quot;</div><div class="line">+--------+</div><div class="line">| 100024 |</div><div class="line">+--------+</div><div class="line"></div><div class="line">$mysql -N -h127.0.0.1 -e &quot;select id from sbtest1 limit 1&quot; | cat</div><div class="line">100024</div><div class="line"></div><div class="line">$mysql -t -N -h127.0.0.1 -e &quot;select id from sbtest1 limit 1&quot; | cat</div><div class="line">+--------+</div><div class="line">| 100024 |</div><div class="line">+--------+</div></pre></td></tr></table></figure>
<p>如上第一和第二个语句，<strong>为什么mysql client的输出重定向后就没有ascii制表符了呢</strong>？ </p>
<p>语句三加上 -t后再经过管道，也有制表符了。</p>
<p><a href="https://stackoverflow.com/questions/15640287/change-output-format-for-mysql-command-line-results-to-csv/17910254" target="_blank" rel="external">stackoverflow上也有很多人有同样的疑问</a>，不过不但没有给出第三行的解法，更没有人讲清楚这个里面的原理。所以接下来我们来分析下这是为什么</p>
<h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>strace看看第一个语句：</p>
<p><img src="/images/oss/086f6cd952d2b91eae7eda6d576765f8.png" alt="image.png"></p>
<p>再对比下第二个语句的strace：</p>
<p><img src="/images/oss/984bcce23ff8766b52fdede8ff3eadec.png" alt="image.png"></p>
<p>从上面两个strace比较来看，似乎mysql client能检测到要输出到命名管道（S_IFIFO ）还是character device（S_IFCHR），如果是命名管道的话就不要输出制表符了，如果是character device那么就输出ascii制表符。</p>
<p><a href="https://linux.die.net/man/2/fstat64" target="_blank" rel="external">fstats里面对不同输出目标的说明</a>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">printf(&quot;File type:                &quot;);</div><div class="line">   switch (sb.st_mode &amp; S_IFMT) &#123;</div><div class="line">    case S_IFBLK:  printf(&quot;block device\n&quot;);            break;</div><div class="line">    case S_IFCHR:  printf(&quot;character device\n&quot;);        break;</div><div class="line">    case S_IFDIR:  printf(&quot;directory\n&quot;);               break;</div><div class="line">    case S_IFIFO:  printf(&quot;FIFO/pipe\n&quot;);               break;</div><div class="line">    case S_IFLNK:  printf(&quot;symlink\n&quot;);                 break;</div><div class="line">    case S_IFREG:  printf(&quot;regular file\n&quot;);            break;</div><div class="line">    case S_IFSOCK: printf(&quot;socket\n&quot;);                  break;</div><div class="line">    default:       printf(&quot;unknown?\n&quot;);                break;</div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<p>第4行和第6行两个类型就是导致mysql client选择了不同的输出内容</p>
<h2 id="误解"><a href="#误解" class="headerlink" title="误解"></a>误解</h2><p>所以这个问题不是： </p>
<blockquote>
<p><strong>为什么mysql client的输出重定向后就没有ascii制表符了呢</strong>？</p>
</blockquote>
<p>而是：</p>
<blockquote>
<p><strong>mysql client 可以检测到不同的输出目标然后输出不同的内容吗？</strong> 管道或者重定向是一个应用能感知的输出目标吗？</p>
</blockquote>
<p>误解：觉得管道写在后面，mysql client不应该知道后面是管道，mysql client输出内容到stdout，然后os将stdout的内容重定向给管道。</p>
<p>实际上mysql是可以检测（detect）输出目标的，如果是管道类的非交互输出那么没必要徒增一些制表符；如果是交互式界面那么就输出一些制表符好看一些。</p>
<p>要是想想在Unix下一切皆文件就更好理解了，输出到管道这个管道也是个文件，所以mysql client是可以感知各种输出文件的属性的。</p>
<p>背后的<a href="https://stackoverflow.com/questions/1312922/detect-if-stdin-is-a-terminal-or-pipe" target="_blank" rel="external">实现</a>大概是这样：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">#include &lt;stdio.h&gt;</div><div class="line">#include &lt;io.h&gt;</div><div class="line">...    </div><div class="line">if (isatty(fileno(stdout)))</div><div class="line">    printf( &quot;stdout is a terminal\n&quot; );      // 输出制表符</div><div class="line">else</div><div class="line">    printf( &quot;stdout is a file or a pipe\n&quot;); // 不输出制表符</div></pre></td></tr></table></figure>
<p><a href="https://linux.die.net/man/3/isatty" target="_blank" rel="external">isatty的解释</a></p>
<p>结论就是 mysql client根据输出目标的不同（stdout、重定向）输出不同的内容，不过这种做法对用户体感上不是太好。</p>
<h2 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h2><p>Linux管道居然不是按顺序，而是并发执行的：<a href="https://unix.stackexchange.com/questions/37508/in-what-order-do-piped-commands-run" target="_blank" rel="external">https://unix.stackexchange.com/questions/37508/in-what-order-do-piped-commands-run</a>  掉坑里了，并发问题就多了，实际测试也发现跑几千次 ps |grep 会出现，ps看不到后面的grep进程</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://www.pyrosoft.co.uk/blog/2014/09/08/how-to-stop-mysql-ascii-tables-column-separators-from-being-lost-when-redirecting-bash-output/" target="_blank" rel="external">https://www.pyrosoft.co.uk/blog/2014/09/08/how-to-stop-mysql-ascii-tables-column-separators-from-being-lost-when-redirecting-bash-output/</a></p>
<p><a href="https://www.oreilly.com/library/view/mysql-cookbook/0596001452/ch01s22.html" target="_blank" rel="external">https://www.oreilly.com/library/view/mysql-cookbook/0596001452/ch01s22.html</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2020/11/30/一台机器上最多能创建多少个TCP连接/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/11/30/一台机器上最多能创建多少个TCP连接/" itemprop="url">到底一台服务器上最多能创建多少个TCP连接</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-11-30T10:30:03+08:00">
                2020-11-30
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/TCP/" itemprop="url" rel="index">
                    <span itemprop="name">TCP</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="到底一台服务器上最多能创建多少个TCP连接"><a href="#到底一台服务器上最多能创建多少个TCP连接" class="headerlink" title="到底一台服务器上最多能创建多少个TCP连接"></a>到底一台服务器上最多能创建多少个TCP连接</h1><blockquote>
<p>经常听到有同学说一台机器最多能创建65535个TCP连接，这其实是错误的理解，为什么会有这个错误的理解呢？</p>
</blockquote>
<h2 id="port-range"><a href="#port-range" class="headerlink" title="port range"></a>port range</h2><p>我们都知道linux下本地随机端口范围由参数控制，也就是listen、connect时候如果没有指定本地端口，那么就从下面的port range中随机取一个可用的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># cat /proc/sys/net/ipv4/ip_local_port_range </div><div class="line">2000	65535</div></pre></td></tr></table></figure>
<p>port range的上限是65535，所以也经常看到这个<strong>误解</strong>：一台机器上最多能创建65535个TCP连接</p>
<h2 id="到底一台机器上最多能创建多少个TCP连接"><a href="#到底一台机器上最多能创建多少个TCP连接" class="headerlink" title="到底一台机器上最多能创建多少个TCP连接"></a>到底一台机器上最多能创建多少个TCP连接</h2><p>先说<strong>结论</strong>：在内存、文件句柄足够的话可以创建的连接是<strong>没有限制</strong>的（每个TCP连接至少要消耗一个文件句柄）。</p>
<p>那么/proc/sys/net/ipv4/ip_local_port_range指定的端口范围到底是什么意思呢？</p>
<p>核心规则：<strong>一个TCP连接只要保证四元组(src-ip src-port dest-ip dest-port)唯一就可以了，而不是要求src port唯一</strong></p>
<p>后面所讲都遵循这个规则，所以在心里反复默念：<strong>四元组唯一</strong> 五个大字，就能分析出来到底能创建多少TCP连接了。</p>
<p>比如如下这个机器上的TCP连接实际状态：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"># netstat -ant |grep 18089</div><div class="line">tcp        0      0 192.168.1.79:18089      192.168.1.79:22         ESTABLISHED</div><div class="line">tcp        0      0 192.168.1.79:18089      192.168.1.79:18080      ESTABLISHED</div><div class="line">tcp        0      0 192.168.0.79:18089      192.168.0.79:22         TIME_WAIT </div><div class="line">tcp        0      0 192.168.1.79:22         192.168.1.79:18089      ESTABLISHED</div><div class="line">tcp        0      0 192.168.1.79:18080      192.168.1.79:18089      ESTABLISHED</div></pre></td></tr></table></figure>
<p>从前三行可以清楚地看到18089被用了三次，第一第二行src-ip、dest-ip也是重复的，但是dest port不一样，第三行的src-port还是18089，但是src-ip变了。他们的四元组均不相同。</p>
<p>所以一台机器能创建的TCP连接是没有限制的，而ip_local_port_range是指没有bind的时候OS随机分配端口的范围，但是分配到的端口要同时满足五元组唯一，这样 ip_local_port_range 限制的是连同一个目标（dest-ip和dest-port一样）的port的数量（请忽略本地多网卡的情况，因为dest-ip为以后route只会选用一个本地ip）。</p>
<p><strong>那么为什么大家有这样的误解呢？</strong>我总结了下，大概是以下两个原因让大家误解了：</p>
<ul>
<li>如果是listen服务，那么肯定端口不能重复使用，这样就跟我们的误解对应上了，一个服务器上最多能监听65535个端口。比如nginx监听了80端口，那么tomcat就没法再监听80端口了，这里的80端口只能监听一次（如果有个连接用了80连别人，这里80还是不能被listen……想想）。</li>
<li>另外如果我们要连的server只有一个，比如：1.1.1.1:80 ，同时本机只有一个ip的话，那么这个时候即使直接调connect 也只能创建出65535个连接，因为四元组中的三个是固定的了。</li>
</ul>
<p>我们在创建连接前，经常会先调bind，bind后可以调listen当做服务端监听，也可以直接调connect当做client来连服务端。</p>
<p>bind(ip,port=0) 的时候是让系统绑定到某个网卡和自动分配的端口，此时系统没有办法确定接下来这个socket是要去connect还是listen. 如果是listen的话，那么肯定是不能出现端口冲突的，如果是connect的话，只要满足4元组唯一即可。在这种情况下，系统只能尽可能满足更强的要求，就是先要求端口不能冲突，即使之后去connect的时候四元组是唯一的。</p>
<p>但如果我只是个client端，只需要连接server建立连接，也就不需要bind，直接调connect就可以了，这个时候只要保证四元组唯一就行。</p>
<p>bind()的时候内核是还不知道四元组的，只知道src_ip、src_port，所以这个时候单网卡下src_port是没法重复的，但是connect()的时候已经知道了四元组的全部信息，所以只要保证四元组唯一就可以了，那么这里的src_port完全是可以重复使用的。</p>
<p><img src="/images/951413iMgBlog/640-20220224103024676.png" alt="Image"></p>
<p><strong>是不是加上了 SO_REUSEADDR、SO_REUSEPORT 就能重用端口了呢？</strong></p>
<h2 id="TCP-SO-REUSEADDR"><a href="#TCP-SO-REUSEADDR" class="headerlink" title="TCP SO_REUSEADDR"></a>TCP SO_REUSEADDR</h2><p>文档描述：</p>
<blockquote>
<p>SO_REUSEADDR      Indicates that the rules used in validating addresses supplied in a bind(2) call should allow reuse of local addresses.  For AF_INET sockets this means that a socket may bind, except when there is an active listening socket bound to the address. When the listening socket is bound to INADDR_ANY with a specific port then it is not possible to bind to this port for any local address.  Argument is an integer boolean flag.</p>
</blockquote>
<p>从这段文档中我们可以知道三个事：</p>
<ol>
<li>使用这个参数后，bind操作是可以重复使用local address的，注意，这里说的是local address，即ip加端口组成的本地地址，也就是两个本地地址，如果有任意ip或端口部分不一样，它们本身就是可以共存的，不需要使用这个参数。</li>
<li>当local address被一个处于listen状态的socket使用时，加上该参数也不能重用这个地址。</li>
<li>当处于listen状态的socket监听的本地地址的ip部分是INADDR_ANY，即表示监听本地的所有ip，即使使用这个参数，也不能再bind包含这个端口的任意本地地址，这个和 2 中描述的其实是一样的。</li>
</ol>
<p>==SO_REUSEADDR 可以用本地相同的(sip, sport) 去连connect 远程的不同的（dip、dport）//SO_REUSEPORT主要是解决Server端的port重用==</p>
<p><a href="https://mp.weixin.qq.com/s/YWzuKBK3TMclejeN2ziAvQ" target="_blank" rel="external">SO_REUSEADDR 还可以重用TIME_WAIT状态的port</a>, 在程序崩溃后之前的TCP连接会进入到TIME_WAIT状态，需要一段时间才能释放，如果立即重启就会抛出<u>Address Already in use</u>的错误导致启动失败。这时候可以通过在调用bind函数之前设置SO_REUSEADDR来解决。</p>
<blockquote>
<p>What exactly does SO_REUSEADDR do?</p>
<p>This socket option tells the kernel that even if this port is busy (in the TIME_WAIT state), go ahead and reuse it anyway. If it is busy, but with another state, you will still get an address already in use error. It is useful if your server has been shut down, and then restarted right away while sockets are still active on its port. You should be aware that if any unexpected data comes in, it may confuse your server, but while this is possible, it is not likely.</p>
<p>It has been pointed out that “A socket is a 5 tuple (proto, local addr, local port, remote addr, remote port). SO_REUSEADDR just says that you can reuse local addresses. The 5 tuple still must be unique!” This is true, and this is why it is very unlikely that unexpected data will ever be seen by your server. The danger is that such a 5 tuple is still floating around on the net, and while it is bouncing around, a new connection from the same client, on the same system, happens to get the same remote port. </p>
</blockquote>
<p>By setting <code>SO_REUSEADDR</code> user informs the kernel of an intention to share the bound port with anyone else, but only if it doesn’t cause a conflict on the protocol layer. There are at least three situations when this flag is useful:</p>
<ol>
<li>Normally after binding to a port and stopping a server it’s neccesary to wait for a socket to time out before another server can bind to the same port. With <code>SO_REUSEADDR</code> set it’s possible to rebind immediately, even if the socket is in a <code>TIME_WAIT</code> state.</li>
<li>When one server binds to <code>INADDR_ANY</code>, say <code>0.0.0.0:1234</code>, it’s impossible to have another server binding to a specific address like <code>192.168.1.21:1234</code>. With <code>SO_REUSEADDR</code> flag this behaviour is allowed.</li>
<li>When using the bind before connect trick only a single connection can use a single outgoing source port. With this flag, it’s possible for many connections to reuse the same source port, given that they connect to different destination addresses.</li>
</ol>
<h2 id="TCP-SO-REUSEPORT"><a href="#TCP-SO-REUSEPORT" class="headerlink" title="TCP SO_REUSEPORT"></a>TCP SO_REUSEPORT</h2><p>SO_REUSEPORT主要用来解决惊群、性能等问题。通过多个进程、线程来监听同一端口，进来的连接通过内核来hash分发做到负载均衡，避免惊群。</p>
<blockquote>
<p>SO_REUSEPORT is also useful for eliminating the try-10-times-to-bind hack in ftpd’s data connection setup routine.  Without SO_REUSEPORT, only one ftpd thread can bind to TCP (lhost, lport, INADDR_ANY, 0) in preparation for connecting back to the client.  Under conditions of heavy load, there are more threads colliding here than the try-10-times hack can accomodate.  With SO_REUSEPORT, things  work nicely and the hack becomes unnecessary.</p>
</blockquote>
<p>SO_REUSEPORT使用场景：linux kernel 3.9 引入了最新的SO_REUSEPORT选项，使得多进程或者多线程创建多个绑定同一个ip:port的监听socket，提高服务器的接收链接的并发能力,程序的扩展性更好；此时需要设置SO_REUSEPORT（<strong>注意所有进程都要设置才生效</strong>）。</p>
<p>setsockopt(listenfd, SOL_SOCKET, SO_REUSEPORT,(const void *)&amp;reuse , sizeof(int));</p>
<p>目的：每一个进程有一个独立的监听socket，并且bind相同的ip:port，独立的listen()和accept()；提高接收连接的能力。（例如nginx多进程同时监听同一个ip:port）</p>
<blockquote>
<p>(a) on Linux SO_REUSEPORT is meant to be used <em>purely</em> for load balancing multiple incoming UDP packets or incoming TCP connection requests across multiple sockets belonging to the same app.  ie. it’s a work around for machines with a lot of cpus, handling heavy load, where a single listening socket becomes a bottleneck because of cross-thread contention on the in-kernel socket lock (and state).</p>
<p>(b) set IP_BIND_ADDRESS_NO_PORT socket option for tcp sockets before binding to a specific source ip<br>with port 0 if you’re going to use the socket for connect() rather then listen() this allows the kernel<br>to delay allocating the source port until connect() time at which point it is much cheaper</p>
</blockquote>
<h2 id="The-Ephemeral-Port-Range"><a href="#The-Ephemeral-Port-Range" class="headerlink" title="The Ephemeral Port Range"></a><a href="http://www.ncftp.com/ncftpd/doc/misc/ephemeral_ports.html" target="_blank" rel="external">The Ephemeral Port Range</a></h2><p>Ephemeral Port Range就是我们前面所说的Port Range（/proc/sys/net/ipv4/ip_local_port_range）</p>
<blockquote>
<p>A TCP/IPv4 connection consists of two endpoints, and each endpoint consists of an IP address and a port number. Therefore, when a client user connects to a server computer, an established connection can be thought of as the 4-tuple of (server IP, server port, client IP, client port).</p>
<p>Usually three of the four are readily known – client machine uses its own IP address and when connecting to a remote service, the server machine’s IP address and service port number are required.</p>
<p>What is not immediately evident is that when a connection is established that the client side of the connection uses a port number. Unless a client program explicitly requests a specific port number, the port number used is an ephemeral port number.</p>
<p>Ephemeral ports are temporary ports assigned by a machine’s IP stack, and are assigned from a designated range of ports for this purpose. When the connection terminates, the ephemeral port is available for reuse, although most IP stacks won’t reuse that port number until the entire pool of ephemeral ports have been used.</p>
<p>So, if the client program reconnects, it will be assigned a different ephemeral port number for its side of the new connection.</p>
</blockquote>
<h2 id="linux-如何选择Ephemeral-Port"><a href="#linux-如何选择Ephemeral-Port" class="headerlink" title="linux 如何选择Ephemeral Port"></a>linux 如何选择Ephemeral Port</h2><p>有资料说是随机从Port Range选择port，有的说是顺序选择，那么实际验证一下。</p>
<p>如下测试代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line">#include &lt;stdio.h&gt;      // printf</div><div class="line">#include &lt;stdlib.h&gt;     // atoi</div><div class="line">#include &lt;unistd.h&gt;     // close</div><div class="line">#include &lt;arpa/inet.h&gt;  // ntohs</div><div class="line">#include &lt;sys/socket.h&gt; // connect, socket</div><div class="line"></div><div class="line">void sample() &#123;</div><div class="line">    // Create socket</div><div class="line">    int sockfd;</div><div class="line">    if (sockfd = socket(AF_INET, SOCK_STREAM, 0), -1 == sockfd) &#123;</div><div class="line">        perror(&quot;socket&quot;);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    // Connect to remote. This does NOT actually send a packet.</div><div class="line">    const struct sockaddr_in raddr = &#123;</div><div class="line">        .sin_family = AF_INET,</div><div class="line">        .sin_port   = htons(8080),     // arbitrary remote port</div><div class="line">        .sin_addr   = htonl(INADDR_ANY)  // arbitrary remote host</div><div class="line">    &#125;;</div><div class="line">    if (-1 == connect(sockfd, (const struct sockaddr *)&amp;raddr, sizeof(raddr))) &#123;</div><div class="line">        perror(&quot;connect&quot;);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    // Display selected ephemeral port</div><div class="line">    const struct sockaddr_in laddr;</div><div class="line">    socklen_t laddr_len = sizeof(laddr);</div><div class="line">    if (-1 == getsockname(sockfd, (struct sockaddr *)&amp;laddr, &amp;laddr_len)) &#123;</div><div class="line">        perror(&quot;getsockname&quot;);</div><div class="line">    &#125;</div><div class="line">    printf(&quot;local port: %i\n&quot;, ntohs(laddr.sin_port));</div><div class="line"></div><div class="line">    // Close socket</div><div class="line">    close(sockfd);</div><div class="line">&#125;</div><div class="line"></div><div class="line">int main() &#123;</div><div class="line">    for (int i = 0; i &lt; 5; i++) &#123;</div><div class="line">        sample();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    return 0;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>bind逻辑测试代码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line">#include &lt;netinet/in.h&gt;</div><div class="line">#include &lt;arpa/inet.h&gt;</div><div class="line">#include &lt;stdio.h&gt;</div><div class="line">#include &lt;stdlib.h&gt;</div><div class="line">#include &lt;unistd.h&gt;</div><div class="line">#include &lt;errno.h&gt;</div><div class="line">#include &lt;string.h&gt;</div><div class="line">#include &lt;sys/types.h&gt;</div><div class="line">#include &lt;time.h&gt;</div><div class="line"></div><div class="line">void test_bind()&#123;</div><div class="line">    int listenfd = 0, connfd = 0;</div><div class="line">    struct sockaddr_in serv_addr;</div><div class="line">    char sendBuff[1025];</div><div class="line">    time_t ticks;</div><div class="line">	  socklen_t len;</div><div class="line"></div><div class="line">    listenfd = socket(AF_INET, SOCK_STREAM, 0);</div><div class="line">    memset(&amp;serv_addr, &apos;0&apos;, sizeof(serv_addr));</div><div class="line">    memset(sendBuff, &apos;0&apos;, sizeof(sendBuff));</div><div class="line"></div><div class="line">    serv_addr.sin_family = AF_INET;</div><div class="line">    serv_addr.sin_addr.s_addr = htonl(INADDR_ANY);</div><div class="line">    serv_addr.sin_port = htons(0);</div><div class="line"></div><div class="line">    bind(listenfd, (struct sockaddr*)&amp;serv_addr, sizeof(serv_addr));</div><div class="line"></div><div class="line">  	len = sizeof(serv_addr);</div><div class="line">	  if (getsockname(listenfd, (struct sockaddr *)&amp;serv_addr, &amp;len) == -1) &#123;</div><div class="line">		      perror(&quot;getsockname&quot;);</div><div class="line">			    return;</div><div class="line">	  &#125;</div><div class="line">	  printf(&quot;port number %d\n&quot;, ntohs(serv_addr.sin_port)); //只是挑选到了port，在系统层面保留，tcp连接还没有，netstat是看不到的</div><div class="line">&#125;</div><div class="line"></div><div class="line">int main(int argc, char *argv[])</div><div class="line">&#123;</div><div class="line">	    for (int i = 0; i &lt; 5; i++) &#123;</div><div class="line">			         test_bind();</div><div class="line">					     &#125;</div><div class="line">		    return 0;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="3-10-0-327-ali2017-alios7-x86-64"><a href="#3-10-0-327-ali2017-alios7-x86-64" class="headerlink" title="3.10.0-327.ali2017.alios7.x86_64"></a>3.10.0-327.ali2017.alios7.x86_64</h3><p>编译后，执行(3.10.0-327.ali2017.alios7.x86_64)：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line">#date; ./client &amp;&amp; echo &quot;+++++++&quot; ; ./client &amp;&amp; sleep 0.1 ; echo &quot;-------&quot; &amp;&amp; ./client &amp;&amp; sleep 10; date; ./client &amp;&amp; echo &quot;+++++++&quot; ; ./client &amp;&amp; sleep 0.1 &amp;&amp; echo &quot;******&quot;; ./client;</div><div class="line">Fri Nov 27 10:52:52 CST 2020</div><div class="line">local port: 17448</div><div class="line">local port: 17449</div><div class="line">local port: 17451</div><div class="line">local port: 17452</div><div class="line">local port: 17453</div><div class="line">+++++++</div><div class="line">local port: 17455</div><div class="line">local port: 17456</div><div class="line">local port: 17457</div><div class="line">local port: 17458</div><div class="line">local port: 17460</div><div class="line">-------</div><div class="line">local port: 17475</div><div class="line">local port: 17476</div><div class="line">local port: 17477</div><div class="line">local port: 17478</div><div class="line">local port: 17479</div><div class="line">Fri Nov 27 10:53:02 CST 2020</div><div class="line">local port: 17997</div><div class="line">local port: 17998</div><div class="line">local port: 17999</div><div class="line">local port: 18000</div><div class="line">local port: 18001</div><div class="line">+++++++</div><div class="line">local port: 18002</div><div class="line">local port: 18003</div><div class="line">local port: 18004</div><div class="line">local port: 18005</div><div class="line">local port: 18006</div><div class="line">******</div><div class="line">local port: 18010</div><div class="line">local port: 18011</div><div class="line">local port: 18012</div><div class="line">local port: 18013</div><div class="line">local port: 18014</div></pre></td></tr></table></figure>
<p>从测试看起来linux下端口选择跟时间有关系，起始端口肯定是顺序增加，起始端口应该是在Ephemeral Port范围内并且和时间戳绑定的某个值（也是递增的），即使没有使用任何端口，起始端口也会随时间增加而增加。</p>
<h3 id="4-19-91-19-1-al7-x86-64"><a href="#4-19-91-19-1-al7-x86-64" class="headerlink" title="4.19.91-19.1.al7.x86_64"></a>4.19.91-19.1.al7.x86_64</h3><p>换个内核版本编译后，执行(4.19.91-19.1.al7.x86_64)：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line">$date; ./client &amp;&amp; echo &quot;+++++++&quot; ; ./client &amp;&amp; sleep 0.1 ; echo &quot;-------&quot; &amp;&amp; ./client &amp;&amp; sleep 10; date; ./client &amp;&amp; echo &quot;+++++++&quot; ; ./client &amp;&amp; sleep 0.1 &amp;&amp; echo &quot;******&quot;; ./client;</div><div class="line">Fri Nov 27 14:10:47 CST 2020</div><div class="line">local port: 7890</div><div class="line">local port: 7892</div><div class="line">local port: 7894</div><div class="line">local port: 7896</div><div class="line">local port: 7898</div><div class="line">+++++++</div><div class="line">local port: 7900</div><div class="line">local port: 7902</div><div class="line">local port: 7904</div><div class="line">local port: 7906</div><div class="line">local port: 7908</div><div class="line">-------</div><div class="line">local port: 7910</div><div class="line">local port: 7912</div><div class="line">local port: 7914</div><div class="line">local port: 7916</div><div class="line">local port: 7918</div><div class="line">Fri Nov 27 14:10:57 CST 2020</div><div class="line">local port: 7966</div><div class="line">local port: 7968</div><div class="line">local port: 7970</div><div class="line">local port: 7972</div><div class="line">local port: 7974</div><div class="line">+++++++</div><div class="line">local port: 7976</div><div class="line">local port: 7978</div><div class="line">local port: 7980</div><div class="line">local port: 7982</div><div class="line">local port: 7984</div><div class="line">******</div><div class="line">local port: 7988</div><div class="line">local port: 7990</div><div class="line">local port: 7992</div><div class="line">local port: 7994</div><div class="line">local port: 7996</div></pre></td></tr></table></figure>
<p>以上测试时的参数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$cat /proc/sys/net/ipv4/ip_local_port_range</div><div class="line">1024    65535</div></pre></td></tr></table></figure>
<p>将1024改成1025后，分配出来的都是奇数端口了：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">$cat /proc/sys/net/ipv4/ip_local_port_range</div><div class="line">1025    1034</div><div class="line"></div><div class="line">$./client</div><div class="line">local port: 1033</div><div class="line">local port: 1025</div><div class="line">local port: 1027</div><div class="line">local port: 1029</div><div class="line">local port: 1031</div><div class="line">local port: 1033</div><div class="line">local port: 1025</div><div class="line">local port: 1027</div><div class="line">local port: 1029</div><div class="line">local port: 1031</div><div class="line">local port: 1033</div><div class="line">local port: 1025</div><div class="line">local port: 1027</div><div class="line">local port: 1029</div><div class="line">local port: 1031</div></pre></td></tr></table></figure>
<p>之所以都是偶数端口，是因为port_range 从偶数开始, 每次从++变到+2的<a href="https://github.com/plantegg/linux/commit/1580ab63fc9a03593072cc5656167a75c4f1d173" target="_blank" rel="external">原因</a>，connect挑选随机端口时都是在起始端口的基础上+2，而bind挑选随机端口的起始端口是系统port_range起始端口+1（这样和connect错开），然后每次仍然尝试+2，这样connect和bind基本一个用偶数另外一个就用奇数，一旦不够了再尝试使用另外一组</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">$cat /proc/sys/net/ipv4/ip_local_port_range</div><div class="line">1024    1047</div><div class="line"></div><div class="line">$./bind &amp;  ---bind程序随机挑选5个端口</div><div class="line">port number 1039</div><div class="line">port number 1043</div><div class="line">port number 1045</div><div class="line">port number 1041</div><div class="line">port number 1047  --用完所有奇数端口</div><div class="line"></div><div class="line">$./bind &amp;    --继续挑选偶数端口</div><div class="line">[8] 4170</div><div class="line">port number 1044</div><div class="line">port number 1042</div><div class="line">port number 1046</div><div class="line">port number 0    --实在没有了</div><div class="line">port number 0</div></pre></td></tr></table></figure>
<p>可见4.19内核下每次port是+2，在3.10内核版本中是+1. 并且都是递增的，同时即使port不使用，也会随着时间的变化这个起始port增大。</p>
<p>Port Range有点像雷达转盘数字，时间就像是雷达上的扫描指针，这个指针不停地旋转，如果这个时候刚好有应用要申请Port，那么就从指针正好指向的Port开始向后搜索可用port</p>
<h2 id="tcp-max-tw-buckets"><a href="#tcp-max-tw-buckets" class="headerlink" title="tcp_max_tw_buckets"></a>tcp_max_tw_buckets</h2><p>tcp_max_tw_buckets: 在 TIME_WAIT 数量等于 tcp_max_tw_buckets 时，新的连接断开不再进入TIME_WAIT阶段，而是直接断开，并打印warnning.</p>
<p>实际测试发现 在 TIME_WAIT 数量等于 tcp_max_tw_buckets 时 新的连接仍然可以不断地创建和断开，这个参数大小不会影响性能，只是影响TIME_WAIT 数量的展示（当然 TIME_WAIT 太多导致local port不够除外）, 这个值设置小一点会避免出现端口不够的情况</p>
<blockquote>
<p>tcp_max_tw_buckets - INTEGER<br>    Maximal number of timewait sockets held by system simultaneously.If this number is exceeded time-wait socket is immediately destroyed and warning is printed. This limit exists only to prevent simple DoS attacks, you <em>must</em> not lower the limit artificially, but rather increase it (probably, after increasing installed memory), if network conditions require more than default value.</p>
</blockquote>
<h2 id="SO-LINGER"><a href="#SO-LINGER" class="headerlink" title="SO_LINGER"></a><a href="https://notes.shichao.io/unp/ch7/" target="_blank" rel="external">SO_LINGER</a></h2><p>SO_LINGER选项<strong>用来设置延迟关闭的时间，等待套接字发送缓冲区中的数据发送完成</strong>。 没有设置该选项时，在调用close() 后，在发送完FIN后会立即进行一些清理工作并返回。 如果设置了SO_LINGER选项，并且等待时间为正值，则在清理之前会等待一段时间。</p>
<p>如果把延时设置为 0  时，Socket就丢弃数据，并向对方发送一个 <code>RST</code> 来终止连接，因为走的是 RST 包，所以就不会有 <code>TIME_WAIT</code> 了。</p>
<blockquote>
<p>This option specifies how the <code>close</code> function operates for a connection-oriented protocol (for TCP, but not for UDP). By default, <code>close</code> returns immediately, but ==if there is any data still remaining in the socket send buffer, the system will try to deliver the data to the peer==.</p>
</blockquote>
<p>SO_LINGER 有三种情况</p>
<ol>
<li>l_onoff 为false（0）， 那么 l_linger 的值没有意义，socket主动调用close时会立即返回，操作系统会将残留在缓冲区中的数据发送到对端，并按照正常流程关闭(交换FIN-ACK），最后连接进入<code>TIME_WAIT</code>状态。<strong>这是默认情况</strong></li>
<li>l_onoff 为true（非0），  l_linger 为0，主动调用close的一方也是立刻返回，但是这时TCP会丢弃发送缓冲中的数据，而且不是按照正常流程关闭连接（不发送FIN包），直接发送<code>RST</code>，连接不会进入 time_wait 状态，对端会收到 <code>java.net.SocketException: Connection reset</code>异常</li>
<li>l_onoff 为true（非0），  l_linger 也为非 0，这表示 <code>SO_LINGER</code>选项生效，并且超时时间大于零，这时调用close的线程被阻塞，TCP会发送缓冲区中的残留数据，这时有两种可能的情况：<ul>
<li>数据发送完毕，收到对方的ACK，然后进行连接的正常关闭（交换FIN-ACK）</li>
<li>超时，未发送完成的数据被丢弃，连接发送<code>RST</code>进行非正常关闭</li>
</ul>
</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">struct linger &#123;</div><div class="line">  int   l_onoff;        /* 0=off, nonzero=on */</div><div class="line">  int   l_linger;       /* linger time, POSIX specifies units as seconds */</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<h3 id="NIO下设置-SO-LINGER-的错误案例"><a href="#NIO下设置-SO-LINGER-的错误案例" class="headerlink" title="NIO下设置 SO_LINGER 的错误案例"></a>NIO下设置 SO_LINGER 的错误案例</h3><p>在使用NIO时，最好不设置<code>SO_LINGER</code>。比如Tomcat服务端接收到请求创建新连接时，做了这样的设置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">SocketChannel.setOption(SocketOption.SO_LINGER, 1000)</div></pre></td></tr></table></figure>
<p><code>SO_LINGER</code>的单位为<code>秒</code>！在网络环境比较好的时候，例如客户端、服务器都部署在同一个机房，close虽然会被阻塞，但时间极短可以忽略。但当网络环境不那么好时，例如存在丢包、较长的网络延迟，buffer中的数据一直无法发送成功，那么问题就出现了：<code>close会被阻塞较长的时间，从而直接或间接引起NIO的IO线程被阻塞</code>，服务器会不响应，不能处理accept、read、write等任何IO事件。也就是应用频繁出现挂起现象。解决方法就是删掉这个设置，close时立即返回，由操作系统接手后面的工作。</p>
<p>这时会看到如下连接状态</p>
<p><img src="/images/951413iMgBlog/image-20220721100246598.png" alt="image-20220721100246598"></p>
<p>以及对应的堆栈</p>
<p><img src="/images/951413iMgBlog/image-20220721100421130.png" alt="image-20220721100421130"></p>
<p>查看其中一个IO线程等待的锁，发现锁是被HTTP线程持有。这个线程正在执行<code>preClose0</code>，就是在这里等待连接的关闭<img src="/images/951413iMgBlog/image-20220721100446521.png" alt="image-20220721100446521"></p>
<p>每次HTTP线程在关闭连接被阻塞时，同时持有了<code>SocketChannelImpl</code>的对象锁，而IO线程在把这个连接移除出它的selector管理队列时，也要获得同一个<code>SocketChannelImpl</code>的对象锁。IO线程就这么一次次的被阻塞，悲剧的无以复加。有些NIO框架会让IO线程去做close，这时候就更加悲剧了。</p>
<p><strong>总之这里的错误原因有两点：1）网络状态不好；2）错误理解了l_linger 的单位，是秒，不是毫秒。 在这两个原因的共同作用下导致了数据迟迟不能发送完毕，l_linger 超时又需要很久，所以服务会出现一直阻塞的状态。</strong></p>
<h2 id="为什么要有-time-wait-状态"><a href="#为什么要有-time-wait-状态" class="headerlink" title="为什么要有 time_wait 状态"></a>为什么要有 time_wait 状态</h2><blockquote>
<p>TIME-WAIT - represents waiting for enough time to pass to be sure the remote TCP received the acknowledgment of its connection termination request.</p>
</blockquote>
<p><img src="/images/951413iMgBlog/image-20220721093116395.png" alt="alt text"></p>
<h2 id="短连接的开销"><a href="#短连接的开销" class="headerlink" title="短连接的开销"></a>短连接的开销</h2><p>用ab通过短连接走 lo 网卡压本机 nginx，CPU0是 ab 进程，CPU3/4 是 Nginx 服务，可以看到 si 非常高，QPS 2.2万</p>
<p><img src="/images/951413iMgBlog/image-20220627154822263.png" alt="image-20220627154822263"></p>
<p>再将 ab 改用长连接来压，可以看到si、sy都有下降，并且 si 下降到短连接的20%，QPS 还能提升到 5.2万</p>
<p><img src="/images/951413iMgBlog/image-20220627154931495.png" alt="image-20220627154931495"></p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><ul>
<li>在内存、文件句柄足够的话一台服务器上可以创建的TCP连接数量是没有限制的</li>
<li>SO_REUSEADDR 主要用于快速重用 TIME_WAIT状态的TCP端口，避免服务重启就会抛出Address Already in use的错误</li>
<li>SO_REUSEPORT主要用来解决惊群、性能等问题</li>
<li>全局范围可以用 net.ipv4.tcp_max_tw_buckets = 50000 来限制总 time_wait 数量，但是会掩盖问题</li>
<li>local port的选择是递增搜索的，搜索起始port随时间增加也变大</li>
</ul>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://segmentfault.com/a/1190000002396411" target="_blank" rel="external">https://segmentfault.com/a/1190000002396411</a></p>
<p><a href="https://blog.csdn.net/a364572/article/details/40628171" target="_blank" rel="external">linux中TCP的socket、bind、listen、connect和accept的实现</a></p>
<p><a href="https://ops.tips/blog/how-linux-tcp-introspection/" target="_blank" rel="external">How Linux allows TCP introspection The inner workings of bind and listen on Linux.</a></p>
<p><a href="https://idea.popcount.org/2014-04-03-bind-before-connect/" target="_blank" rel="external">https://idea.popcount.org/2014-04-03-bind-before-connect/</a></p>
<p><a href="https://mp.weixin.qq.com/s/C-Eeoeh9GHxugF4J30fz1A" target="_blank" rel="external">TCP连接中客户端的端口号是如何确定的？</a></p>
<p><a href="https://github.com/plantegg/linux/commit/9b3312bf18f6873e67f1f51dab3364c95c9dc54c" target="_blank" rel="external">对应4.19内核代码解析</a></p>
<p><a href="https://blog.cloudflare.com/how-to-stop-running-out-of-ephemeral-ports-and-start-to-love-long-lived-connections/" target="_blank" rel="external">How to stop running out of ephemeral ports and start to love long-lived connections</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2020/11/23/一次春节大促性能压测不达标的瓶颈推演/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weibo @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/11/23/一次春节大促性能压测不达标的瓶颈推演/" itemprop="url">一次春节大促性能压测不达标的瓶颈推演</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-11-23T11:30:03+08:00">
                2020-11-23
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/performance/" itemprop="url" rel="index">
                    <span itemprop="name">performance</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="一次春节大促性能压测不达标的瓶颈推演"><a href="#一次春节大促性能压测不达标的瓶颈推演" class="headerlink" title="一次春节大促性能压测不达标的瓶颈推演"></a>一次春节大促性能压测不达标的瓶颈推演</h1><p>本文示范了教科书式的在分布式应用场景下如何通过一个节点的状态来推演分析瓶颈出在上下游的哪个环节上。</p>
<h2 id="场景描述"><a href="#场景描述" class="headerlink" title="场景描述"></a>场景描述</h2><p>某客户通过PTS（一个打压力工具）来压选号业务(HTTP服务在9108端口上），一个HTTP请求对应一次select seq-id 和 一次insert</p>
<p>PTS端看到RT900ms+，QPS大概5万（期望20万）， 数据库代理服务 rt 5ms，QPS 10万+</p>
<h3 id="链路："><a href="#链路：" class="headerlink" title="链路："></a>链路：</h3><p>pts发起压力 -&gt; 5个eip -&gt; slb -&gt; app(300个容器运行tomcat监听9108端口上） -&gt; slb -&gt; 数据库代理服务集群 -&gt; RDS集群</p>
<p>性能不达标，怀疑数据库代理服务或者RDS性能不行，作为数据库需要自证清白，所以从RDS和数据库代理服务开始分析问题在哪里。</p>
<p>略过一系列在数据库代理服务、RDS上分析数据和监控图表都证明数据库代理服务和RDS没问题的过程。</p>
<p>在明确给出证据数据库代理服务和RDS都没问题后还是要解决问题，所以只能进一步帮助前面的app来分析为什么性能不达标。</p>
<h2 id="在其中一个app应用上抓包（00-18秒到1-04秒），到数据库代理服务的一个连接分析："><a href="#在其中一个app应用上抓包（00-18秒到1-04秒），到数据库代理服务的一个连接分析：" class="headerlink" title="在其中一个app应用上抓包（00:18秒到1:04秒），到数据库代理服务的一个连接分析："></a>在其中一个app应用上抓包（00:18秒到1:04秒），到数据库代理服务的一个连接分析：</h2><p><img src="/images/oss/80374e55936bc36bbd243f79fcdb5f8d.png" alt="image.png"></p>
<p>数据库代理服务每个HTTP请求的响应时间都控制在15ms(一个前端HTTP请求对应一个select seq-id，一个 select readonly, 一个insert， 这个响应时间符合预期）。一个连接每秒才收到20 tps（因为压力不够，压力加大的话这个单连接tps还可以增加）， 20*3000 = 6万 ， 跟压测看到基本一致</p>
<p>300个容器，每个容器 10个连接到数据库代理服务</p>
<p>如果300个容器上的并发压力不够的话就没法将3000个连接跑满，所以看到的QPS是5万。</p>
<p><strong>从300个容器可以计算得到这个集群能支持的tps： 300*10（10个连接）* 1000/15(每秒钟每个连接能处理的请求数）=20万个tps （关键分析能力）</strong></p>
<p>也就是说通过单QPS 15ms，我们计算可得整个后端的吞吐能力在20万QPS。所以目前问题不在后端，而是压力没有打到后端就出现瓶颈了。</p>
<h2 id="9108的HTTP服务端口上的抓包分析"><a href="#9108的HTTP服务端口上的抓包分析" class="headerlink" title="9108的HTTP服务端口上的抓包分析"></a>9108的HTTP服务端口上的抓包分析</h2><p><img src="/images/oss/e239a12a1c3612263736256c8efc06e4.png" alt="image.png"></p>
<p>9108服务的每个HTTP response差不多都是15ms（<strong>这个响应时间基本符合预期</strong>），一个HTTP连接上在45秒的抓包时间范围只收到23个HTTP Request。</p>
<p>或者下图：</p>
<p><img src="/images/951413iMgBlog/image-20220627164250973.png" alt="image-20220627164250973" style="zoom:50%;"></p>
<p><img src="/images/951413iMgBlog/image-20220630101036341.png" alt="image-20220630101036341" style="zoom:50%;"></p>
<p>统计9108端口在45秒总共收到的HTTP请求数量是6745（如下图），也就是每个app每秒钟收到的请求是150个，300<em>150=4.5万（理论值，300个app可能压力分布不一样？），<em>*从这里看app收到的压力还不够</em></em>，所以压力还没有打到应用容器中的app，还在更前面</p>
<p><img src="/images/oss/6a289d1bba1e875d215032b6fdc7b084.png" alt="image.png"></p>
<p>后来从容器app监控也确认了这个响应时间和抓包看到的一致，所以从抓包分析http响应时间也基本得到15ms的rt关键结论</p>
<p>从wireshark IO Graphs 也能看到RT 和 QPS</p>
<p><img src="/images/951413iMgBlog/image-20220623003026351.png" alt="image-20220623003026351"></p>
<h2 id="从应用容器上的netstat统计来看，也是压力端回复太慢"><a href="#从应用容器上的netstat统计来看，也是压力端回复太慢" class="headerlink" title="从应用容器上的netstat统计来看，也是压力端回复太慢"></a>从应用容器上的netstat统计来看，也是压力端回复太慢</h2><p><img src="/images/oss/938ce314d19b47cba99e2a09c753f606.png" alt="image.png"></p>
<p>send-q表示回复从9108发走了，没收到对方的ack</p>
<h2 id="ARMS监控分析9108端口上的RT"><a href="#ARMS监控分析9108端口上的RT" class="headerlink" title="ARMS监控分析9108端口上的RT"></a>ARMS监控分析9108端口上的RT</h2><p>后来PTS的同学说ARMS可以捞到监控数据，如下是对rt时间降序排</p>
<p><img src="/images/oss/a479bad250c03aee41d58850afab9c14.png" alt="image.png"></p>
<p>中的rt平均时间，可以看到http的rt确实14.4ms，表现非常平稳，从这个监控也发现实际app是330个而不是用户自己描述的300个，这也就是为什么实际是tps是5万，但是按300个去算的话tps是4.5万（不要纠结客户为什么告诉你是300个容器而不是330个，有时候他们也搞不清楚，业务封装得太好了）</p>
<p><img src="/images/oss/2f3b76be63d331510eb6f2cecd91747f.png" alt="image.png"></p>
<p>5分钟时间，QPS是5万+，HTTP的平均rt是15ms， HTTP的最大rt才79ms，和前面抓包分析一致。</p>
<h2 id="从后端分析的总结"><a href="#从后端分析的总结" class="headerlink" title="从后端分析的总结"></a>从后端分析的总结</h2><p><strong>从9108端口响应时间15ms来看是符合预期的，为什么PTS看到的RT是900ms+，所以压力还没有打到APP上（也就是9108端口）</strong></p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>最后发现是 eip 带宽不足，只有200M，调整到1G后 tps 也翻了5倍到了25万。</p>
<p>pts -&gt; 5个eip(总带宽200M) -&gt; slb -&gt; app(330个HTTP容器） -&gt; slb -&gt; 数据库代理服务 -&gt; RDS</p>
<p>这个案例有意思的地方是可以通过抓包就能分析出集群能扛的QPS20万（实际只有5万），那么可以把这个分析原则在每个角色上挨个分析一下，来看瓶颈出在了哪个环节。</p>
<p>应用端看到的rt是900ms，从后段开始往前面应用端来撸，看看每个环节的rt数据。</p>
<h2 id="教训"><a href="#教训" class="headerlink" title="教训"></a>教训</h2><ul>
<li>搞清楚 请求 从发起端到DB的链路路径，比如 pts -&gt; 5个eip(总带宽200M) -&gt; slb -&gt;  app(330个HTTP容器） -&gt; slb -&gt; 数据库代理服务 -&gt; RDS </li>
<li>压不上去得从发压力端开始往后端撸，撸每个产品的rt，每个产品给出自己的rt来自证清白</li>
<li>应用有arms的话学会看arms对平均rt和QPS的统计，不要纠结个别请求的rt抖动，看平均rt</li>
<li>通过抓包完全可以分析出来系统能扛多少并发，以及可能的瓶颈位置</li>
</ul>
<p>一包在手 万事无忧</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><span class="space">&hellip;</span><a class="page-number" href="/page/15/">15</a><a class="extend next" rel="next" href="/page/5/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="weibo @plantegg" />
          <p class="site-author-name" itemprop="name">weibo @plantegg</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
           
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">145</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">21</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">240</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
</script>

<div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">weibo @plantegg</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>

<span id="busuanzi_container_site_pv">
    本站总访问量<span id="busuanzi_value_site_pv_footer"></span>次
</span>
<span id="busuanzi_container_site_uv">
  本站访客数<span id="busuanzi_value_site_uv_footer"></span>人次
</span>


        
<div class="busuanzi-count">
  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      人
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>


        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
    <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  





  






  





  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  

  

  

  

</body>
</html>
